{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Change it to the project root path \"\"\"\n",
    "PROJECT_PATH = '../'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU_ID = 1\n",
    "dataset_name = 'power'\n",
    "ID = 2\n",
    "\n",
    "ckpts_PATH = PROJECT_PATH + 'train/models/{}/'.format(dataset_name)\n",
    "data_PATH  = PROJECT_PATH + 'data/'\n",
    "\n",
    "\"\"\" network parameters\"\"\"\n",
    "hidden_features = 108\n",
    "num_flow_steps = 6\n",
    "train_batch_size = 512\n",
    "learning_rate = 0.0005\n",
    "monitor_interval = 5000\n",
    "\n",
    "\n",
    "anneal_learning_rate = True\n",
    "base_transform_type = 'rq-coupling'\n",
    "\n",
    "dropout_probability = 0\n",
    "grad_norm_clip_value = 5.\n",
    "linear_transform_type='lu'\n",
    "\n",
    "num_bins = 8\n",
    "num_training_steps = 400000\n",
    "num_transform_blocks = 2\n",
    "seed = 1638128\n",
    "tail_bound = 3\n",
    "use_batch_norm = False\n",
    "\n",
    "val_batch_size = 262144"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import prefetcher as pf\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "# from tensorboardX import SummaryWriter\n",
    "from time import sleep\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from torch.utils import data\n",
    "from tqdm import tqdm\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from nflows import transforms\n",
    "from nflows import distributions\n",
    "from nflows import utils\n",
    "from nflows import flows\n",
    "import nflows.nn as nn_\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"{}\".format(GPU_ID)\n",
    "assert torch.cuda.is_available()\n",
    "device = torch.device('cuda')\n",
    "\n",
    "\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class  PowerDataset(Dataset):\n",
    "    def __init__(self, split='train', frac=None):\n",
    "        path = os.path.join(data_PATH, '{}.npy'.format(dataset_name))\n",
    "        self.data = np.load(path).astype(np.float32)\n",
    "        print('data shape:', self.data.shape)\n",
    "\n",
    "        self.n, self.dim = self.data.shape\n",
    "        if frac is not None:\n",
    "            self.n = int(frac * self.n)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.data[item]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape: (2049280, 6)\n",
      "data shape: (2049280, 6)\n",
      "Load data took [76.92230010032654] s\n",
      "train loader length is [4003]\n",
      "val loader length is [8]\n"
     ]
    }
   ],
   "source": [
    "st_time = time.time()\n",
    "train_dataset = PowerDataset()\n",
    "train_loader = data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size = train_batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False\n",
    ")\n",
    "\n",
    "val_dataset = PowerDataset()\n",
    "val_loader = data.DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=val_batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False\n",
    ")\n",
    "\n",
    "train_loader = list(train_loader)\n",
    "val_loader = list(val_loader)\n",
    "TRAIN_LOADER_LEN = len(train_loader)\n",
    "\n",
    "\n",
    "features = train_dataset.dim\n",
    "\n",
    "print('Load data took [{}] s'.format(time.time() - st_time))\n",
    "print('train loader length is [{}]'.format(TRAIN_LOADER_LEN))\n",
    "print('val loader length is [{}]'.format(len(val_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp is  23-Feb-24||03:13:27\n"
     ]
    }
   ],
   "source": [
    "def get_timestamp():\n",
    "    formatted_time = time.strftime('%d-%b-%y||%H:%M:%S')\n",
    "    return formatted_time\n",
    "timestamp = get_timestamp()\n",
    "print('Timestamp is ', timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_linear_transform():\n",
    "    if linear_transform_type == 'permutation':\n",
    "        return transforms.RandomPermutation(features=features)\n",
    "    elif linear_transform_type == 'lu':\n",
    "        return transforms.CompositeTransform([\n",
    "            transforms.RandomPermutation(features=features),\n",
    "            transforms.LULinear(features, identity_init=True)\n",
    "        ])\n",
    "    elif linear_transform_type == 'svd':\n",
    "        return transforms.CompositeTransform([\n",
    "            transforms.RandomPermutation(features=features),\n",
    "            transforms.SVDLinear(features, num_householder=10, identity_init=True)\n",
    "        ])\n",
    "    else:\n",
    "        raise ValueError\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_base_transform(i):\n",
    "    # tmp_mask = utils.create_alternating_binary_mask(features, even=(i % 2 == 0))\n",
    "    return transforms.coupling.PiecewiseRationalQuadraticCouplingTransform(\n",
    "        mask=utils.create_alternating_binary_mask(features, even=(i % 2 == 0)),\n",
    "        transform_net_create_fn=lambda in_features, out_features: nn_.nets.ResidualNet(\n",
    "            in_features=in_features,\n",
    "            out_features=out_features,\n",
    "            hidden_features=hidden_features,\n",
    "            context_features=None,\n",
    "            num_blocks=num_transform_blocks,\n",
    "            activation=F.relu,\n",
    "            dropout_probability=dropout_probability,\n",
    "            use_batch_norm=use_batch_norm\n",
    "        ),\n",
    "        num_bins=num_bins,\n",
    "        tails='linear',\n",
    "        tail_bound=tail_bound,\n",
    "        apply_unconditional_transform=True\n",
    "    )\n",
    "\n",
    "\n",
    "# torch.masked_select()\n",
    "def create_transform():\n",
    "    transform = transforms.CompositeTransform([\n",
    "        transforms.CompositeTransform([\n",
    "            create_linear_transform(),\n",
    "            create_base_transform(i)\n",
    "        ]) for i in range(num_flow_steps)\n",
    "    ] + [\n",
    "        create_linear_transform()\n",
    "    ])\n",
    "    return transform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "distribution = distributions.StandardNormal((features,))\n",
    "transform = create_transform()\n",
    "flow = flows.Flow(transform, distribution).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 330954 trainable parameters in this model.\n",
      "Parameters total size is 1.2624893188476562 MB\n"
     ]
    }
   ],
   "source": [
    "n_params = utils.get_num_parameters(flow)\n",
    "print('There are {} trainable parameters in this model.'.format(n_params))\n",
    "print('Parameters total size is {} MB'.format(n_params * 4 / 1024 / 1024))\n",
    "\n",
    "optimizer = optim.Adam(flow.parameters(), lr=learning_rate)\n",
    "if anneal_learning_rate:\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, np.ceil(num_training_steps / TRAIN_LOADER_LEN) , 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num training steps is  400300\n",
      "[2024-02-23 03:13:27.311840] 0/400000  0.0% has finished!\n",
      "[2024-02-23 03:20:01.796374] step now is [  4999] running_val_log_density is 0.3077  ## New best! ##\n",
      "[2024-02-23 03:26:32.451462] step now is [  9999] running_val_log_density is 0.3780  ## New best! ##\n",
      "[2024-02-23 03:26:32.461547] 10000/400000  2.5% has finished!\n",
      "[2024-02-23 03:33:03.731881] step now is [ 14999] running_val_log_density is 0.4089  ## New best! ##\n",
      "[2024-02-23 03:39:33.972806] step now is [ 19999] running_val_log_density is 0.4379  ## New best! ##\n",
      "[2024-02-23 03:39:33.983164] save once. Step is 19999 best val score is 0.43793001770973206\n",
      "[2024-02-23 03:39:33.991198] 20000/400000  5.0% has finished!\n",
      "[2024-02-23 03:46:04.419406] step now is [ 24999] running_val_log_density is 0.4561  ## New best! ##\n",
      "[2024-02-23 03:52:35.169580] step now is [ 29999] running_val_log_density is 0.4674  ## New best! ##\n",
      "[2024-02-23 03:52:35.179728] 30000/400000  7.5% has finished!\n",
      "[2024-02-23 03:59:05.711119] step now is [ 34999] running_val_log_density is 0.4862  ## New best! ##\n",
      "[2024-02-23 04:05:36.268597] step now is [ 39999] running_val_log_density is 0.4948  ## New best! ##\n",
      "[2024-02-23 04:05:36.278876] save once. Step is 39999 best val score is 0.4948040246963501\n",
      "[2024-02-23 04:05:36.286797] 40000/400000  10.0% has finished!\n",
      "[2024-02-23 04:12:06.852526] step now is [ 44999] running_val_log_density is 0.4993  ## New best! ##\n",
      "[2024-02-23 04:18:38.558667] step now is [ 49999] running_val_log_density is 0.4991\n",
      "[2024-02-23 04:18:38.558872] 50000/400000  12.5% has finished!\n",
      "[2024-02-23 04:25:08.738233] step now is [ 54999] running_val_log_density is 0.5063  ## New best! ##\n",
      "[2024-02-23 04:31:39.287946] step now is [ 59999] running_val_log_density is 0.5156  ## New best! ##\n",
      "[2024-02-23 04:31:39.298233] save once. Step is 59999 best val score is 0.5156341791152954\n",
      "[2024-02-23 04:31:39.306091] 60000/400000  15.0% has finished!\n",
      "[2024-02-23 04:38:09.688217] step now is [ 64999] running_val_log_density is 0.4899\n",
      "[2024-02-23 04:44:40.513272] step now is [ 69999] running_val_log_density is 0.5241  ## New best! ##\n",
      "[2024-02-23 04:44:40.523119] 70000/400000  17.5% has finished!\n",
      "[2024-02-23 04:51:11.682493] step now is [ 74999] running_val_log_density is 0.5238\n",
      "[2024-02-23 04:57:58.078278] step now is [ 79999] running_val_log_density is 0.5304  ## New best! ##\n",
      "[2024-02-23 04:57:58.089788] save once. Step is 79999 best val score is 0.5304005742073059\n",
      "[2024-02-23 04:57:58.098854] 80000/400000  20.0% has finished!\n",
      "[2024-02-23 05:04:47.479666] step now is [ 84999] running_val_log_density is 0.5281\n",
      "[2024-02-23 05:11:37.075371] step now is [ 89999] running_val_log_density is 0.5270\n",
      "[2024-02-23 05:11:37.075592] 90000/400000  22.5% has finished!\n",
      "[2024-02-23 05:18:27.323310] step now is [ 94999] running_val_log_density is 0.5322  ## New best! ##\n",
      "[2024-02-23 05:25:17.103913] step now is [ 99999] running_val_log_density is 0.5431  ## New best! ##\n",
      "[2024-02-23 05:25:17.115373] save once. Step is 99999 best val score is 0.5430806875228882\n",
      "[2024-02-23 05:25:17.124551] 100000/400000  25.0% has finished!\n",
      "[2024-02-23 05:32:02.930810] step now is [104999] running_val_log_density is 0.5246\n",
      "[2024-02-23 05:38:03.955046] step now is [109999] running_val_log_density is 0.5375\n",
      "[2024-02-23 05:38:03.955259] 110000/400000  27.5% has finished!\n",
      "[2024-02-23 05:44:05.346733] step now is [114999] running_val_log_density is 0.5548  ## New best! ##\n",
      "[2024-02-23 05:50:07.405134] step now is [119999] running_val_log_density is 0.5422\n",
      "[2024-02-23 05:50:07.405675] save once. Step is 119999 best val score is 0.5547518730163574\n",
      "[2024-02-23 05:50:07.414996] 120000/400000  30.0% has finished!\n",
      "[2024-02-23 05:56:09.782491] step now is [124999] running_val_log_density is 0.5547\n",
      "[2024-02-23 06:02:12.987311] step now is [129999] running_val_log_density is 0.5560  ## New best! ##\n",
      "[2024-02-23 06:02:12.997221] 130000/400000  32.5% has finished!\n",
      "[2024-02-23 06:08:15.221638] step now is [134999] running_val_log_density is 0.5597  ## New best! ##\n",
      "[2024-02-23 06:14:16.649996] step now is [139999] running_val_log_density is 0.5646  ## New best! ##\n",
      "[2024-02-23 06:14:16.660126] save once. Step is 139999 best val score is 0.5646388530731201\n",
      "[2024-02-23 06:14:16.668021] 140000/400000  35.0% has finished!\n",
      "[2024-02-23 06:20:47.816654] step now is [144999] running_val_log_density is 0.5572\n",
      "[2024-02-23 06:27:42.136319] step now is [149999] running_val_log_density is 0.5644\n",
      "[2024-02-23 06:27:42.136536] 150000/400000  37.5% has finished!\n",
      "[2024-02-23 06:34:36.761834] step now is [154999] running_val_log_density is 0.5706  ## New best! ##\n",
      "[2024-02-23 06:41:30.466547] step now is [159999] running_val_log_density is 0.5757  ## New best! ##\n",
      "[2024-02-23 06:41:30.476795] save once. Step is 159999 best val score is 0.5757372379302979\n",
      "[2024-02-23 06:41:30.484729] 160000/400000  40.0% has finished!\n",
      "[2024-02-23 06:48:24.924502] step now is [164999] running_val_log_density is 0.5717\n",
      "[2024-02-23 06:55:20.648785] step now is [169999] running_val_log_density is 0.5608\n",
      "[2024-02-23 06:55:20.649026] 170000/400000  42.5% has finished!\n",
      "[2024-02-23 07:02:21.965345] step now is [174999] running_val_log_density is 0.5707\n",
      "[2024-02-23 07:09:16.206763] step now is [179999] running_val_log_density is 0.5643\n",
      "[2024-02-23 07:09:16.207300] save once. Step is 179999 best val score is 0.5757372379302979\n",
      "[2024-02-23 07:09:16.216833] 180000/400000  45.0% has finished!\n",
      "[2024-02-23 07:16:10.858956] step now is [184999] running_val_log_density is 0.5816  ## New best! ##\n",
      "[2024-02-23 07:23:04.381994] step now is [189999] running_val_log_density is 0.5822  ## New best! ##\n",
      "[2024-02-23 07:23:04.391916] 190000/400000  47.5% has finished!\n",
      "[2024-02-23 07:29:58.310149] step now is [194999] running_val_log_density is 0.5937  ## New best! ##\n",
      "[2024-02-23 07:36:52.237718] step now is [199999] running_val_log_density is 0.5813\n",
      "[2024-02-23 07:36:52.238259] save once. Step is 199999 best val score is 0.593707263469696\n",
      "[2024-02-23 07:36:52.247586] 200000/400000  50.0% has finished!\n",
      "[2024-02-23 07:43:45.975356] step now is [204999] running_val_log_density is 0.5883\n",
      "[2024-02-23 07:50:39.977255] step now is [209999] running_val_log_density is 0.5827\n",
      "[2024-02-23 07:50:39.977487] 210000/400000  52.5% has finished!\n",
      "[2024-02-23 07:57:33.840815] step now is [214999] running_val_log_density is 0.5850\n",
      "[2024-02-23 08:04:27.030527] step now is [219999] running_val_log_density is 0.6037  ## New best! ##\n",
      "[2024-02-23 08:04:27.040733] save once. Step is 219999 best val score is 0.6037111878395081\n",
      "[2024-02-23 08:04:27.048676] 220000/400000  55.0% has finished!\n",
      "[2024-02-23 08:11:20.808101] step now is [224999] running_val_log_density is 0.6000\n",
      "[2024-02-23 08:18:14.955496] step now is [229999] running_val_log_density is 0.5867\n",
      "[2024-02-23 08:18:14.955699] 230000/400000  57.5% has finished!\n",
      "[2024-02-23 08:25:08.985890] step now is [234999] running_val_log_density is 0.5933\n",
      "[2024-02-23 08:32:04.453075] step now is [239999] running_val_log_density is 0.5973\n",
      "[2024-02-23 08:32:04.453615] save once. Step is 239999 best val score is 0.6037111878395081\n",
      "[2024-02-23 08:32:04.462956] 240000/400000  60.0% has finished!\n",
      "[2024-02-23 08:39:02.452297] step now is [244999] running_val_log_density is 0.6057  ## New best! ##\n",
      "[2024-02-23 08:45:58.631612] step now is [249999] running_val_log_density is 0.6114  ## New best! ##\n",
      "[2024-02-23 08:45:58.641558] 250000/400000  62.5% has finished!\n",
      "[2024-02-23 08:52:52.842904] step now is [254999] running_val_log_density is 0.6094\n",
      "[2024-02-23 08:59:43.603826] step now is [259999] running_val_log_density is 0.6135  ## New best! ##\n",
      "[2024-02-23 08:59:43.614069] save once. Step is 259999 best val score is 0.6134828925132751\n",
      "[2024-02-23 08:59:43.622005] 260000/400000  65.0% has finished!\n",
      "[2024-02-23 09:06:37.909159] step now is [264999] running_val_log_density is 0.6124\n",
      "[2024-02-23 09:13:15.447012] step now is [269999] running_val_log_density is 0.6159  ## New best! ##\n",
      "[2024-02-23 09:13:15.456915] 270000/400000  67.5% has finished!\n",
      "[2024-02-23 09:19:16.123232] step now is [274999] running_val_log_density is 0.6169  ## New best! ##\n",
      "[2024-02-23 09:25:16.301838] step now is [279999] running_val_log_density is 0.6191  ## New best! ##\n",
      "[2024-02-23 09:25:16.312030] save once. Step is 279999 best val score is 0.6190869808197021\n",
      "[2024-02-23 09:25:16.320090] 280000/400000  70.0% has finished!\n",
      "[2024-02-23 09:31:16.562190] step now is [284999] running_val_log_density is 0.6220  ## New best! ##\n",
      "[2024-02-23 09:37:16.586745] step now is [289999] running_val_log_density is 0.6214\n",
      "[2024-02-23 09:37:16.586952] 290000/400000  72.5% has finished!\n",
      "[2024-02-23 09:43:17.741769] step now is [294999] running_val_log_density is 0.6235  ## New best! ##\n",
      "[2024-02-23 09:49:18.846118] step now is [299999] running_val_log_density is 0.6264  ## New best! ##\n",
      "[2024-02-23 09:49:18.856329] save once. Step is 299999 best val score is 0.6263673305511475\n",
      "[2024-02-23 09:49:18.864214] 300000/400000  75.0% has finished!\n",
      "[2024-02-23 09:55:19.525236] step now is [304999] running_val_log_density is 0.6237\n",
      "[2024-02-23 10:01:19.502991] step now is [309999] running_val_log_density is 0.6273  ## New best! ##\n",
      "[2024-02-23 10:01:19.512938] 310000/400000  77.5% has finished!\n",
      "[2024-02-23 10:07:19.189449] step now is [314999] running_val_log_density is 0.6284  ## New best! ##\n",
      "[2024-02-23 10:13:19.570370] step now is [319999] running_val_log_density is 0.6324  ## New best! ##\n",
      "[2024-02-23 10:13:19.580654] save once. Step is 319999 best val score is 0.6323649883270264\n",
      "[2024-02-23 10:13:19.588633] 320000/400000  80.0% has finished!\n",
      "[2024-02-23 10:19:19.768966] step now is [324999] running_val_log_density is 0.6307\n",
      "[2024-02-23 10:25:20.122182] step now is [329999] running_val_log_density is 0.6331  ## New best! ##\n",
      "[2024-02-23 10:25:20.132191] 330000/400000  82.5% has finished!\n",
      "[2024-02-23 10:31:20.654721] step now is [334999] running_val_log_density is 0.6362  ## New best! ##\n",
      "[2024-02-23 10:37:21.084064] step now is [339999] running_val_log_density is 0.6371  ## New best! ##\n",
      "[2024-02-23 10:37:21.094393] save once. Step is 339999 best val score is 0.6370771527290344\n",
      "[2024-02-23 10:37:21.102321] 340000/400000  85.0% has finished!\n",
      "[2024-02-23 10:43:21.478396] step now is [344999] running_val_log_density is 0.6388  ## New best! ##\n",
      "[2024-02-23 10:49:21.882036] step now is [349999] running_val_log_density is 0.6386\n",
      "[2024-02-23 10:49:21.882238] 350000/400000  87.5% has finished!\n",
      "[2024-02-23 10:55:25.742785] step now is [354999] running_val_log_density is 0.6389  ## New best! ##\n",
      "[2024-02-23 11:01:26.792441] step now is [359999] running_val_log_density is 0.6398  ## New best! ##\n",
      "[2024-02-23 11:01:26.802745] save once. Step is 359999 best val score is 0.6398192644119263\n",
      "[2024-02-23 11:01:26.810729] 360000/400000  90.0% has finished!\n",
      "[2024-02-23 11:07:27.615627] step now is [364999] running_val_log_density is 0.6411  ## New best! ##\n",
      "[2024-02-23 11:13:27.879370] step now is [369999] running_val_log_density is 0.6417  ## New best! ##\n",
      "[2024-02-23 11:13:27.889312] 370000/400000  92.5% has finished!\n",
      "[2024-02-23 11:19:27.879574] step now is [374999] running_val_log_density is 0.6421  ## New best! ##\n",
      "[2024-02-23 11:25:27.892134] step now is [379999] running_val_log_density is 0.6425  ## New best! ##\n",
      "[2024-02-23 11:25:27.902541] save once. Step is 379999 best val score is 0.6424677968025208\n",
      "[2024-02-23 11:25:27.910428] 380000/400000  95.0% has finished!\n",
      "[2024-02-23 11:31:28.506141] step now is [384999] running_val_log_density is 0.6429  ## New best! ##\n",
      "[2024-02-23 11:37:29.246050] step now is [389999] running_val_log_density is 0.6432  ## New best! ##\n",
      "[2024-02-23 11:37:29.255846] 390000/400000  97.5% has finished!\n",
      "[2024-02-23 11:43:29.508192] step now is [394999] running_val_log_density is 0.6433  ## New best! ##\n",
      "[2024-02-23 11:49:31.210026] step now is [399999] running_val_log_density is 0.6433  ## New best! ##\n",
      "[2024-02-23 11:49:31.220232] save once. Step is 399999 best val score is 0.6433086395263672\n",
      "[2024-02-23 11:49:31.228088] 400000/400000  100.0% has finished!\n"
     ]
    }
   ],
   "source": [
    "best_val_score = -1e10\n",
    "prefetcher = pf.data_prefetcher(train_loader)\n",
    "\n",
    "num_training_steps = int(np.ceil(num_training_steps/TRAIN_LOADER_LEN) * TRAIN_LOADER_LEN)\n",
    "\n",
    "print('num training steps is ', num_training_steps)\n",
    "for step in range(num_training_steps):\n",
    "    if step % 10000 == 0:\n",
    "        print('[{}] {}/400000  {}% has finished!'.format(datetime.datetime.now(), step, 100.*step/400000))\n",
    "\n",
    "    flow.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    batch = prefetcher.next()\n",
    "    if batch is None:\n",
    "        prefetcher = pf.data_prefetcher(train_loader)\n",
    "        batch = prefetcher.next()\n",
    "\n",
    "    log_density = flow.log_prob(batch)\n",
    "    loss = - torch.mean(log_density)\n",
    "    loss.backward()\n",
    "    if grad_norm_clip_value is not None:\n",
    "        clip_grad_norm_(flow.parameters(), grad_norm_clip_value)\n",
    "    optimizer.step()\n",
    "\n",
    "    if (step + 1) % monitor_interval == 0:\n",
    "        flow.eval()\n",
    "        val_prefetcher = pf.data_prefetcher(val_loader)\n",
    "        with torch.no_grad():\n",
    "            running_val_log_density = 0\n",
    "            while True:\n",
    "                val_batch = val_prefetcher.next()\n",
    "                if val_batch is None:\n",
    "                    break\n",
    "\n",
    "                log_density_val = flow.log_prob(val_batch.to(device).detach())\n",
    "                mean_log_density_val = torch.mean(log_density_val).detach()\n",
    "                running_val_log_density += mean_log_density_val\n",
    "            running_val_log_density /= len(val_loader)\n",
    "            print('[{}] step now is [{:6d}] running_val_log_density is {:.4f}'.format(datetime.datetime.now(), step, running_val_log_density), end='')\n",
    "\n",
    "        if running_val_log_density > best_val_score:\n",
    "            best_val_score = running_val_log_density\n",
    "            print('  ## New best! ##')\n",
    "            path = os.path.join(ckpts_PATH,\n",
    "                                '{}-id{}-best-val.t'.format(dataset_name, ID))\n",
    "            torch.save(flow.state_dict(), path)\n",
    "        else:\n",
    "            print('')\n",
    "    \n",
    "\n",
    "    if (step + 1) % 20000 == 0 :\n",
    "        flow.eval()\n",
    "        print('[{}] save once. Step is {} best val score is {}'.format(datetime.datetime.now(), step, best_val_score))\n",
    "\n",
    "\n",
    "        path = os.path.join(ckpts_PATH,\n",
    "                            '{}-id{}-step-{}.t'.format(dataset_name, ID, step + 1))\n",
    "        torch.save(flow.state_dict(), path)\n",
    "        \n",
    "    if anneal_learning_rate and (step + 1) % TRAIN_LOADER_LEN == 0:\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LndCar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
