Input arguments = Namespace(data_update='sample', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 14, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.157722234725952
tensor(0.9960)
result is  tensor(380653.5625)
Enter testHyper
ReportEsts: [1.1797622442245483, 1.1147642135620117, 1.3649882078170776, 1.0629606246948242, 1.2397199869155884, 1.1189683675765991, 1.2361799478530884, 1.2764827013015747, 1.0349870920181274, 1.0703946352005005, 1.004325270652771, 1.1898305416107178, 1.0319406986236572, 1.0669642686843872, 1.0965831279754639, 1.3615505695343018, 1.1784003973007202, 1.154394268989563, 1.1518428325653076, 1.0765305757522583, 1.1540491580963135, 1.0584677457809448, 1.1425540447235107, 1.167283535003662, 1.1600098609924316, 1.241410493850708, 1.0686936378479004, 1.323770523071289, 1.137137770652771, 1.1169768571853638, 1.0787513256072998, 1.1776834726333618, 1.1699916124343872, 1.1118791103363037, 1.0847059488296509, 1.1008787155151367, 1.4083343744277954, 1.1647509336471558, 1.0436956882476807, 1.044071912765503, 1.0545330047607422, 1.1445331573486328, 1.1381787061691284, 1.0438722372055054, 1.0769068002700806, 1.0272108316421509, 1.1132383346557617, 1.2202026844024658, 1.2510873079299927, 1.0879864692687988, 1.232620358467102, 1.2711915969848633, 1.0918723344802856, 1.2290242910385132, 1.1831997632980347, 1.0078812837600708, 1.1654205322265625, 1.0981667041778564, 1.1998625993728638, 1.4292452335357666, 1.2972888946533203, 1.1624919176101685, 1.2740073204040527, 1.0217149257659912, 1.3095238208770752, 1.2000000476837158, 1.1977077722549438, 1.1888498067855835, 1.0522451400756836, 1.221052646636963, 1.0048503875732422, 1.017181158065796, 1.217251181602478, 1.1233210563659668, 1.0925410985946655, 1.112847924232483, 1.8352241516113281, 1.021276593208313, 1.0551263093948364, 1.237670660018921, 1.2145025730133057, 1.1639477014541626, 1.0628738403320312, 1.254390835762024, 1.1827336549758911, 1.1010689735412598, 1.0385358333587646, 1.0234371423721313, 1.0085448026657104, 1.026038646697998, 1.0069334506988525, 1.2499380111694336, 1.0072124004364014, 1.3391727209091187, 1.0893855094909668, 1.1521577835083008, 1.2024823427200317, 1.345799446105957, 1.01694917678833, 1.2469806671142578, 1.252293586730957, 1.129509687423706, 1.0000872611999512, 1.002936840057373, 1.078033447265625, 1.001018762588501, 1.1386487483978271, 1.2111692428588867, 1.0394268035888672, 1.01400887966156, 1.214508056640625, 1.0772058963775635, 1.2001551389694214, 1.0639837980270386, 1.118349313735962, 1.065727710723877, 1.0094255208969116, 1.0468206405639648, 1.2063859701156616, 1.1831618547439575, 1.211444616317749, 1.0836207866668701, 1.1714342832565308, 1.198207139968872, 1.24321711063385, 1.1975855827331543, 1.2618755102157593, 1.1383243799209595, 1.318259358406067, 1.1252504587173462, 1.092491626739502, 1.221332311630249, 1.1522685289382935, 1.5, 1.1155896186828613, 1.0194276571273804, 1.0448863506317139, 1.0738211870193481, 1.1230199337005615, 1.2668874263763428, 1.1520732641220093, 1.0307797193527222, 1.0423260927200317, 1.0818978548049927, 1.0158464908599854, 1.1381999254226685, 1.0265778303146362, 1.4037322998046875, 1.0292900800704956, 1.0325284004211426, 1.3032691478729248, 1.2226637601852417, 1.2902042865753174, 1.0677765607833862, 1.2091699838638306, 1.122977614402771, 1.0497137308120728, 1.0619020462036133, 1.0611064434051514, 1.2090718746185303, 1.1507759094238281, 1.0522702932357788, 1.1543476581573486, 1.30501389503479, 1.280868411064148, 1.0920096635818481, 1.141392469406128, 1.2860478162765503, 1.232748031616211, 1.0695877075195312, 1.0755784511566162, 1.0095150470733643, 1.097402572631836, 1.1319735050201416, 1.0272479057312012, 1.1293971538543701, 1.025922179222107, 1.2275233268737793, 1.1149214506149292, 1.0229873657226562, 1.1717095375061035, 1.069656252861023, 1.0561283826828003, 1.1225740909576416, 1.1093806028366089, 1.1279069185256958, 1.0754027366638184, 1.2044920921325684, 1.0732011795043945, 1.3212240934371948, 1.062347650527954, 1.0968306064605713, 1.43959641456604, 1.3525779247283936, 1.6158784627914429, 1.234394907951355, 1.168695330619812, 1.1343283653259277, 1.0682984590530396, 1.082270860671997]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.757357597351074] ms
 --  Average per query NF    [1.361631155014038] ms
 --  Average per query vegas [2.395726442337036] ms
Mean [1.149]  Median [1.129]  95th [1.346]  99th [1.501]  max [1.835]
Mean [1.149]  Median [1.129]  95th [1.346]  99th [1.501]  max [1.835]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.816731 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=sample', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
Sample - START
Sample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[3.5762787e-07 1.3709068e-06 1.7881393e-07 5.9604645e-07 2.3841858e-07]
Distance score: 5.4836272056491e-07
SAUCE Drift detection: False
Detection latency: 0.0231s

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.031797 | Model-update-time: 0.000000


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=sample', '--model_update=adapt']
/home/kangping/code_copy/SAUCE/./FACE/FACE_utils/dataUtils.py:321: RuntimeWarning: invalid value encountered in cast
  oracle_cards = oracle_cards.astype(np.int32)
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.217459201812744
tensor(0.9967)
result is  tensor(457086.1562)
Enter testHyper
ReportEsts: [1.0134103298187256, 1.0691213607788086, 1.1556473970413208, 1.004499912261963, 1.0324897766113281, 1.1599764823913574, 1.2365713119506836, 1.2216598987579346, 1.088977575302124, 1.0779392719268799, 1.0538684129714966, 1.2932806015014648, 1.267175555229187, 1.189587116241455, 1.0321277379989624, 1.0137531757354736, 1.3896867036819458, 1.2010530233383179, 1.0686662197113037, 1.3311264514923096, 1.1207152605056763, 3.1081080436706543, 1.0275804996490479, 1.0689959526062012, 1.1804158687591553, 1.1994608640670776, 1.0260440111160278, 1.1564114093780518, 1.391135334968567, 1.6188714504241943, 1.115535855293274, 1.3783783912658691, 1.1469693183898926, 1.1012156009674072, 1.0365290641784668, 1.1060736179351807, 1.0407781600952148, 1.1324944496154785, 1.3291369676589966, 1.2161893844604492, 1.0361411571502686, 1.0449321269989014, 1.7632304430007935, 1.0892950296401978, 1.0260578393936157, 1.0948848724365234, 1.6589291095733643, 1.0254467725753784, 1.1720000505447388, 1.082218050956726, 1.047084927558899, 1.034018874168396, 1.0266796350479126, 1.229429006576538, 1.043526530265808, 1.3535821437835693, 1.1639643907546997, 1.0479683876037598, 1.3100985288619995, 1.1848453283309937, 1.2954092025756836, 1.0375144481658936, 1.1664496660232544, 1.8399653434753418, 1.0020599365234375, 1.0483921766281128, 1.4193998575210571, 1.0179014205932617, 1.2444827556610107, 1.054877519607544, 1.1243751049041748, 1.1541070938110352, 1.0788969993591309, 1.1918742656707764, 1.0657793283462524, 1.2878235578536987, 1.2206851243972778, 1.1855556964874268, 1.125657558441162, 1.0754411220550537, 1.0674188137054443, 1.1128737926483154, 1.1514692306518555, 1.4252294301986694, 1.3019087314605713, 1.3970037698745728, 1.444618821144104, 1.4158259630203247, 1.0091382265090942, 1.0436460971832275, 1.0706642866134644, 1.1113139390945435, 1.520658016204834, 1.2103651762008667, 1.0843870639801025, 1.0367110967636108, 1.1942816972732544, 1.2988085746765137, 4.0, 1.2076282501220703, 1.2270182371139526, 1.1002744436264038, 1.1813842058181763, 1.4430150985717773, 1.1156493425369263, 1.0509915351867676, 1.0248230695724487, 1.1702351570129395, 1.136239767074585, 1.0401626825332642, 1.0603909492492676, 1.04510498046875, 1.2505840063095093, 1.2544556856155396, 1.034583330154419, 1.0471938848495483, 1.0543988943099976, 1.234371542930603, 1.0311880111694336, 1.1219512224197388, 1.1188969612121582, 1.1623308658599854, 1.1622331142425537, 1.2445652484893799, 1.0049489736557007, 1.0201818943023682, 1.227400541305542, 1.3264330625534058, 1.0213290452957153, 1.0089833736419678, 1.0851366519927979, 1.0535683631896973, 1.1197130680084229, 1.9724310636520386, 1.7121068239212036, 1.0458393096923828, 1.0712072849273682, 1.1511610746383667, 1.0678167343139648, 1.0055831670761108, 1.0069103240966797, 1.1118533611297607, 1.027074933052063, 1.0941423177719116, 1.0020334720611572, 1.0853568315505981, 1.658227801322937, 1.0456558465957642, 1.1460639238357544, 1.0286448001861572, 1.0465205907821655, 1.2152297496795654, 1.0629485845565796, 1.0538368225097656, 1.0184988975524902, 1.0038737058639526, 1.0396124124526978, 1.330708622932434, 1.222693681716919, 1.0769798755645752, 1.0914744138717651, 1.0349650382995605, 1.4529095888137817, 1.119571328163147, 1.1788043975830078, 1.0761839151382446, 1.003829836845398, 1.332966923713684, 1.0795542001724243, 1.2921653985977173, 1.052474856376648, 1.1419700384140015, 1.3630050420761108, 1.0771102905273438, 1.0007480382919312, 1.043222427368164, 1.0952004194259644, 1.0772510766983032, 1.0201795101165771, 1.0410908460617065, 1.6976743936538696, 1.1237233877182007, 1.123210072517395, 1.6547874212265015, 1.1728622913360596, 1.0068124532699585, 1.1129032373428345, 1.0826302766799927, 1.3362524509429932, 1.088483452796936, 1.1715353727340698, 1.0276533365249634, 1.2302241325378418, 1.9482431411743164, 1.0951194763183594, 1.1013739109039307, 1.2723883390426636, 1.042479157447815, 1.3544520139694214, 1.019386887550354]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7370288372039795] ms
 --  Average per query NF    [1.3579177856445312] ms
 --  Average per query vegas [2.3791110515594482] ms
Mean [1.191]  Median [1.112]  95th [1.655]  99th [1.984]  max [4.000]
Mean [1.191]  Median [1.112]  95th [1.655]  99th [1.984]  max [4.000]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.219834 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=0 | total-time=26.127993