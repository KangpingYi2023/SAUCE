Input arguments = Namespace(data_update='sample', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 96, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.163993120193481
tensor(0.9952)
result is  tensor(380315.0938)
Enter testHyper
ReportEsts: [1.1736371517181396, 1.0678309202194214, 1.3704482316970825, 1.0349547863006592, 1.2909201383590698, 1.1378202438354492, 1.2007824182510376, 1.0147080421447754, 1.0497381687164307, 1.0679110288619995, 1.0551248788833618, 1.0911016464233398, 1.0880954265594482, 1.03125, 1.1091290712356567, 1.1226720809936523, 1.299965500831604, 1.2233966588974, 1.1514921188354492, 1.1352040767669678, 1.2944811582565308, 1.0765550136566162, 1.161026120185852, 1.1515754461288452, 1.1426937580108643, 1.068716049194336, 1.0712274312973022, 1.4715261459350586, 1.0106580257415771, 1.0192846059799194, 1.079460859298706, 1.2149842977523804, 1.1213555335998535, 1.0549278259277344, 1.0947537422180176, 1.1392103433609009, 1.116349458694458, 1.2522790431976318, 1.0895642042160034, 1.1191617250442505, 1.0228843688964844, 1.1071600914001465, 1.080849051475525, 1.1616623401641846, 1.067187786102295, 1.0413223505020142, 1.0632572174072266, 1.3700941801071167, 1.0731852054595947, 1.133671760559082, 1.1974025964736938, 1.36685049533844, 1.0437970161437988, 1.2124463319778442, 1.1494462490081787, 1.0081794261932373, 1.4121495485305786, 1.0874985456466675, 1.0299001932144165, 1.5260988473892212, 1.2711942195892334, 1.117140531539917, 1.3774641752243042, 1.1417946815490723, 1.1913357973098755, 1.2285714149475098, 1.0875976085662842, 1.0041135549545288, 1.0806832313537598, 1.3157894611358643, 1.0551782846450806, 1.0821806192398071, 1.1758068799972534, 1.0341616868972778, 1.1016175746917725, 1.1122379302978516, 2.057767391204834, 1.0069674253463745, 1.0662977695465088, 1.1776686906814575, 1.1310251951217651, 1.1074140071868896, 1.0256881713867188, 1.1864736080169678, 1.221278190612793, 1.0865013599395752, 1.003984808921814, 1.0702648162841797, 1.0553263425827026, 1.0736379623413086, 1.011183500289917, 1.2750358581542969, 1.02173912525177, 1.2808936834335327, 1.1538461446762085, 1.0601470470428467, 1.1173518896102905, 1.2848174571990967, 1.034482717514038, 1.082857370376587, 1.0650194883346558, 1.070214033126831, 1.0174474716186523, 1.0066323280334473, 1.1025104522705078, 1.0022374391555786, 1.1676356792449951, 1.2041884660720825, 1.058730959892273, 1.0477683544158936, 1.1643636226654053, 1.1569595336914062, 1.0961140394210815, 1.0029574632644653, 1.17526376247406, 1.0558139085769653, 1.0381414890289307, 1.027976632118225, 1.390568494796753, 1.119934320449829, 1.1544787883758545, 1.141023874282837, 1.1763685941696167, 1.0455211400985718, 1.2490310668945312, 1.1740610599517822, 1.183609127998352, 1.1847699880599976, 1.3365051746368408, 1.1436206102371216, 1.2128245830535889, 1.0799907445907593, 1.2700434923171997, 1.5, 1.1030540466308594, 1.1806248426437378, 1.0592354536056519, 1.0611381530761719, 1.0227670669555664, 1.1045035123825073, 1.1021952629089355, 1.081022024154663, 1.138822078704834, 1.2188478708267212, 1.012640118598938, 1.081180453300476, 1.0851809978485107, 1.5948201417922974, 1.0022121667861938, 1.118607997894287, 1.3763841390609741, 1.1801050901412964, 1.3192287683486938, 1.1670522689819336, 1.2958245277404785, 1.0263042449951172, 1.0410592555999756, 1.0079410076141357, 1.0280898809432983, 1.0861831903457642, 1.208925485610962, 1.0048738718032837, 1.1299444437026978, 1.2941988706588745, 1.2102564573287964, 1.0744377374649048, 1.1917248964309692, 1.1546956300735474, 1.1445417404174805, 1.010549783706665, 1.080759882926941, 1.0718445777893066, 1.1428571939468384, 1.2203644514083862, 1.0657356977462769, 1.0274405479431152, 1.0310981273651123, 1.280752182006836, 1.1466480493545532, 1.0486159324645996, 1.0446346998214722, 1.0655587911605835, 1.00663161277771, 1.067415714263916, 1.1361825466156006, 1.1448203325271606, 1.0269992351531982, 1.2961760759353638, 1.0771681070327759, 1.4590493440628052, 1.0041590929031372, 1.158858299255371, 1.62021005153656, 1.6375162601470947, 1.7159091234207153, 1.2059738636016846, 1.0869945287704468, 1.1176470518112183, 1.1818921566009521, 1.0906707048416138]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7551450729370117] ms
 --  Average per query NF    [1.368328332901001] ms
 --  Average per query vegas [2.3868167400360107] ms
Mean [1.148]  Median [1.111]  95th [1.392]  99th [1.638]  max [2.058]
Mean [1.148]  Median [1.111]  95th [1.392]  99th [1.638]  max [2.058]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.824005 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=sample', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
Sample - START
Sample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[1.1920929e-06 1.7881393e-07 2.9802322e-07 4.7683716e-07 6.5565109e-07]
Distance score: 5.602836381513043e-07
SAUCE Drift detection: False
Detection latency: 0.0231s

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.023970 | Model-update-time: 0.000000


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=sample', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.196302652359009
tensor(0.9937)
result is  tensor(455732.9688)
Enter testHyper
ReportEsts: [1.022904396057129, 1.029170036315918, 1.3046756982803345, 1.0487431287765503, 1.1527783870697021, 1.2918493747711182, 1.1915346384048462, 1.0281825065612793, 1.382703185081482, 1.1170916557312012, 1.1304377317428589, 1.1723982095718384, 1.1483253240585327, 1.0864677429199219, 1.000618815422058, 1.0491900444030762, 1.4105262756347656, 1.1189247369766235, 1.0075700283050537, 1.3485482931137085, 1.0516560077667236, 1.7591564655303955, 1.1411441564559937, 1.0897741317749023, 1.091891884803772, 1.144395112991333, 1.028467059135437, 1.0810433626174927, 1.3797054290771484, 1.3095952272415161, 1.0949829816818237, 1.314685344696045, 1.0826061964035034, 1.0961863994598389, 1.039573311805725, 1.2040493488311768, 1.1393191814422607, 1.215675950050354, 1.1528172492980957, 1.0086517333984375, 1.0583974123001099, 1.0447760820388794, 1.0780551433563232, 1.0309698581695557, 1.0156481266021729, 1.0003881454467773, 1.1463947296142578, 1.1030018329620361, 1.0938775539398193, 1.0102629661560059, 1.0067224502563477, 1.125915288925171, 1.0890411138534546, 1.0760771036148071, 1.0317918062210083, 1.1641713380813599, 1.271283745765686, 1.0456361770629883, 1.2278141975402832, 1.03799307346344, 1.5202864408493042, 1.025791883468628, 1.0938100814819336, 1.4746818542480469, 1.1078935861587524, 1.052995204925537, 1.2833975553512573, 1.1012266874313354, 1.2011640071868896, 1.0971368551254272, 1.0166118144989014, 1.3283129930496216, 1.1560969352722168, 1.0560905933380127, 1.0527409315109253, 1.2246242761611938, 1.3127566576004028, 1.0266804695129395, 1.2200459241867065, 1.1568230390548706, 1.2401930093765259, 1.102795958518982, 1.0516539812088013, 1.064948320388794, 1.3896678686141968, 1.3905109167099, 1.3371732234954834, 1.5109243392944336, 1.0738170146942139, 1.1157726049423218, 1.214545488357544, 1.0343291759490967, 1.272557258605957, 1.1895769834518433, 1.1352826356887817, 1.0014692544937134, 1.059320092201233, 1.195933222770691, 1.2424249649047852, 1.0705817937850952, 1.2369742393493652, 1.155734658241272, 1.1766109466552734, 1.0823460817337036, 1.108394742012024, 1.1104315519332886, 1.4064706563949585, 1.111131191253662, 1.1378378868103027, 1.1920536756515503, 1.0553359985351562, 1.0438121557235718, 1.2278324365615845, 1.2543059587478638, 1.085106372833252, 1.0788432359695435, 1.086265206336975, 1.1956424713134766, 1.0997337102890015, 1.2347825765609741, 1.002170205116272, 1.0659453868865967, 1.0279823541641235, 1.4618546962738037, 1.0081098079681396, 1.166434645652771, 1.2240389585494995, 1.2985553741455078, 1.0801312923431396, 1.0036879777908325, 1.0490258932113647, 1.1478670835494995, 1.1383774280548096, 1.8573086261749268, 1.293859601020813, 1.159313440322876, 1.146587610244751, 1.0518783330917358, 1.0993987321853638, 1.0088942050933838, 1.1130306720733643, 1.1818181276321411, 1.0249532461166382, 1.1104981899261475, 1.011564016342163, 1.2163993120193481, 1.5290697813034058, 1.1628589630126953, 1.0410690307617188, 1.0148199796676636, 1.1367169618606567, 1.033582091331482, 1.1756659746170044, 1.0523980855941772, 1.0416456460952759, 1.1635233163833618, 1.0825200080871582, 1.274193525314331, 1.2579320669174194, 1.1845812797546387, 1.0638598203659058, 1.030225396156311, 1.9444444179534912, 1.0670899152755737, 1.0912437438964844, 1.0248793363571167, 1.1737468242645264, 1.1418840885162354, 1.029909372329712, 1.3766651153564453, 1.334148645401001, 1.1636905670166016, 1.575757622718811, 1.1418979167938232, 1.048411250114441, 1.0626370906829834, 1.2221027612686157, 1.2044696807861328, 1.1584715843200684, 1.1274900436401367, 1.6279069185256958, 1.0405428409576416, 1.0501313209533691, 1.5866392850875854, 1.4560439586639404, 1.031902551651001, 1.1306114196777344, 1.1376335620880127, 1.4229390621185303, 1.0414446592330933, 1.2036089897155762, 1.1309925317764282, 1.1772414445877075, 2.0351052284240723, 1.0177021026611328, 1.010682463645935, 1.019763708114624, 1.1193058490753174, 1.3372681140899658, 1.195149540901184]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.767848014831543] ms
 --  Average per query NF    [1.3671612739562988] ms
 --  Average per query vegas [2.400686740875244] ms
Mean [1.166]  Median [1.123]  95th [1.476]  99th [1.858]  max [2.035]
Mean [1.166]  Median [1.123]  95th [1.476]  99th [1.858]  max [2.035]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.278874 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=0 | total-time=26.151878