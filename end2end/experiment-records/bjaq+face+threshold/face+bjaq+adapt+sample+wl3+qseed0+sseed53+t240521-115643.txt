Input arguments = Namespace(data_update='sample', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 53, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.166276216506958
tensor(0.9976)
result is  tensor(381260.1250)
Enter testHyper
ReportEsts: [1.184570550918579, 1.0721290111541748, 1.255203127861023, 1.0366393327713013, 1.2603024244308472, 1.1095867156982422, 1.2662131786346436, 1.0954252481460571, 1.0220900774002075, 1.120591640472412, 1.0637381076812744, 1.172669529914856, 1.0481603145599365, 1.0067415237426758, 1.1569490432739258, 1.3503649234771729, 1.314656138420105, 1.2042754888534546, 1.193655252456665, 1.2321428060531616, 1.1661239862442017, 1.1253215074539185, 1.1772677898406982, 1.0746735334396362, 1.0147839784622192, 1.1202532052993774, 1.0456081628799438, 1.316754937171936, 1.036824345588684, 1.1110771894454956, 1.0475345849990845, 1.231009840965271, 1.0681401491165161, 1.0099753141403198, 1.0772525072097778, 1.1071405410766602, 1.3834033012390137, 1.3384859561920166, 1.0408679246902466, 1.1403592824935913, 1.004966378211975, 1.1047412157058716, 1.1598505973815918, 1.0676629543304443, 1.0876822471618652, 1.0294784307479858, 1.1149739027023315, 1.055799126625061, 1.0894156694412231, 1.2030457258224487, 1.2734806537628174, 1.282020092010498, 1.002841591835022, 1.2363238334655762, 1.1357799768447876, 1.0325514078140259, 1.169158935546875, 1.1697193384170532, 1.190611720085144, 1.2858796119689941, 1.346642255783081, 1.2326273918151855, 1.4792431592941284, 1.0702117681503296, 1.3200000524520874, 1.3142857551574707, 1.1875, 1.0001556873321533, 1.1663492918014526, 1.3684210777282715, 1.2381335496902466, 1.0048811435699463, 1.155654788017273, 1.3672024011611938, 1.1376057863235474, 1.35628342628479, 1.6052496433258057, 1.0876764059066772, 1.0011545419692993, 1.2363837957382202, 1.0797033309936523, 1.0856081247329712, 1.0612504482269287, 1.2419618368148804, 1.2129722833633423, 1.0468673706054688, 1.0956532955169678, 1.189255952835083, 1.0382096767425537, 1.1423003673553467, 1.0584523677825928, 1.301274299621582, 1.0157508850097656, 1.212601900100708, 1.107954502105713, 1.0547661781311035, 1.2916871309280396, 1.4377747774124146, 1.0, 1.1306993961334229, 1.1784173250198364, 1.0682543516159058, 1.017125129699707, 1.0088626146316528, 1.162343144416809, 1.049808144569397, 1.0251487493515015, 1.2094241380691528, 1.0531623363494873, 1.0447437763214111, 1.0012638568878174, 1.1247600317001343, 1.1884351968765259, 1.0452574491500854, 1.1765388250350952, 1.1522842645645142, 1.0048730373382568, 1.058171033859253, 1.3063169717788696, 1.0281118154525757, 1.2259351015090942, 1.0864496231079102, 1.0804160833358765, 1.1025766134262085, 1.2747093439102173, 1.1903631687164307, 1.0173964500427246, 1.0783852338790894, 1.1651583909988403, 1.1179025173187256, 1.1447160243988037, 1.129150152206421, 1.2436295747756958, 1.5, 1.0989054441452026, 1.1391441822052002, 1.0105631351470947, 1.2260162830352783, 1.014243721961975, 1.1373364925384521, 1.1298222541809082, 1.0965224504470825, 1.0935349464416504, 1.4815428256988525, 1.0772631168365479, 1.0327602624893188, 1.0880954265594482, 1.4625684022903442, 1.184875726699829, 1.1409801244735718, 1.028796911239624, 1.1835662126541138, 1.294952630996704, 1.017274022102356, 1.1953932046890259, 1.0638877153396606, 1.0021549463272095, 1.0227912664413452, 1.0650835037231445, 1.092629075050354, 1.4047329425811768, 1.0290244817733765, 1.028367519378662, 1.249333381652832, 1.187421441078186, 1.0606416463851929, 1.1952451467514038, 1.2551699876785278, 1.0406694412231445, 1.056955337524414, 1.0453171730041504, 1.0429543256759644, 1.103896141052246, 1.106726884841919, 1.0194141864776611, 1.0719714164733887, 1.0791819095611572, 1.267016887664795, 1.085988998413086, 1.0025690793991089, 1.0034370422363281, 1.0710279941558838, 1.0069079399108887, 1.1092952489852905, 1.0709887742996216, 1.0697674751281738, 1.0312070846557617, 1.2919813394546509, 1.0556954145431519, 1.1920548677444458, 1.0500292778015137, 1.033463716506958, 1.5176814794540405, 1.4566223621368408, 1.974962592124939, 1.122177243232727, 1.077365517616272, 1.0555555820465088, 1.1684459447860718, 1.133466124534607]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.740319013595581] ms
 --  Average per query NF    [1.3614881038665771] ms
 --  Average per query vegas [2.378830909729004] ms
Mean [1.147]  Median [1.109]  95th [1.384]  99th [1.519]  max [1.975]
Mean [1.147]  Median [1.109]  95th [1.384]  99th [1.519]  max [1.975]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.793849 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=sample', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
Sample - START
Sample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[9.5367432e-07 2.3841858e-07 2.9802322e-07 8.9406967e-07 1.7881393e-07]
Distance score: 5.125999678057269e-07
SAUCE Drift detection: False
Detection latency: 0.0238s

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.019060 | Model-update-time: 0.000000


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=sample', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.170305967330933
tensor(0.9929)
result is  tensor(455361.3438)
Enter testHyper
ReportEsts: [1.0006892681121826, 1.0220797061920166, 1.2096316814422607, 1.3106306791305542, 1.1026684045791626, 1.110465168952942, 1.1598314046859741, 1.016934871673584, 1.2655673027038574, 1.1859794855117798, 1.0060406923294067, 1.0365562438964844, 1.2938144207000732, 1.1374222040176392, 1.100866675376892, 1.056597113609314, 1.5017064809799194, 1.1424587965011597, 1.1680488586425781, 1.3140586614608765, 1.1733407974243164, 1.6786901950836182, 1.0892903804779053, 1.1472617387771606, 1.1956677436828613, 1.0996177196502686, 1.0283583402633667, 1.1342313289642334, 1.508222222328186, 1.284552812576294, 1.0963566303253174, 1.3380281925201416, 1.0498782396316528, 1.027996301651001, 1.001079797744751, 1.0302252769470215, 1.1702526807785034, 1.0609506368637085, 1.1139951944351196, 1.0528424978256226, 1.0841271877288818, 1.0455037355422974, 1.180484652519226, 1.0621014833450317, 1.0060093402862549, 1.1049216985702515, 1.2233119010925293, 1.1076494455337524, 1.1422924995422363, 1.1816496849060059, 1.020064115524292, 1.0134223699569702, 1.011528491973877, 1.1455581188201904, 1.005174994468689, 1.4194313287734985, 1.122464895248413, 1.1763954162597656, 1.2359901666641235, 1.1971917152404785, 1.4686098098754883, 1.0062508583068848, 1.0308555364608765, 1.627856969833374, 1.1153392791748047, 1.1507816314697266, 1.4401456117630005, 1.0892717838287354, 1.1312459707260132, 1.1139369010925293, 1.0571130514144897, 1.0919569730758667, 1.0649175643920898, 1.1623374223709106, 1.1535403728485107, 1.3310521841049194, 1.1918721199035645, 1.158828854560852, 1.2500109672546387, 1.1427923440933228, 1.021897792816162, 1.2018065452575684, 1.032588005065918, 1.163517951965332, 1.3525900840759277, 1.4028269052505493, 1.2974740266799927, 1.5552892684936523, 1.1438435316085815, 1.0576947927474976, 1.0799007415771484, 1.159853458404541, 1.3904143571853638, 1.113996982574463, 1.20866060256958, 1.0254480838775635, 1.0790259838104248, 1.2729909420013428, 1.1820906400680542, 1.0523560047149658, 1.143217921257019, 1.1314237117767334, 1.20525062084198, 1.0406571626663208, 1.112572431564331, 1.0264900922775269, 1.0424383878707886, 1.0972517728805542, 1.178674340248108, 1.0682883262634277, 1.1575727462768555, 1.1137053966522217, 1.001250982284546, 1.2968121767044067, 1.156929612159729, 1.0144035816192627, 1.1289786100387573, 1.1815769672393799, 1.0120514631271362, 1.0640000104904175, 1.0633490085601807, 1.2569948434829712, 1.100724220275879, 1.516136884689331, 1.1229965686798096, 1.1778687238693237, 1.029157042503357, 1.3105690479278564, 1.1226624250411987, 1.0903795957565308, 1.2745436429977417, 1.029039978981018, 1.1850799322128296, 1.8994083404541016, 1.3095062971115112, 1.1336044073104858, 1.10855233669281, 1.0677309036254883, 1.067662239074707, 1.0157029628753662, 1.1681363582611084, 1.1511826515197754, 1.0624125003814697, 1.0438426733016968, 1.0233737230300903, 1.016725778579712, 1.3681318759918213, 1.1153875589370728, 1.0173345804214478, 1.0053536891937256, 1.092463731765747, 1.0390182733535767, 1.0921077728271484, 1.1459455490112305, 1.0320653915405273, 1.0743801593780518, 1.0030721426010132, 1.1893939971923828, 1.4280931949615479, 1.1262547969818115, 1.110288381576538, 1.0957179069519043, 1.290812611579895, 1.124396562576294, 1.2098534107208252, 1.0358080863952637, 1.0233010053634644, 1.2976791858673096, 1.0042579174041748, 1.2446978092193604, 1.083561897277832, 1.1108074188232422, 1.492763638496399, 1.0779258012771606, 1.0255931615829468, 1.104823350906372, 1.167766809463501, 1.1592129468917847, 1.101787805557251, 1.0873092412948608, 1.4166666269302368, 1.2610729932785034, 1.0583524703979492, 1.4180749654769897, 1.3179177045822144, 1.3295619487762451, 1.0398929119110107, 1.0581395626068115, 1.3994197845458984, 1.0134460926055908, 1.1171520948410034, 1.0423741340637207, 1.3637454509735107, 1.2550832033157349, 1.0937190055847168, 1.0898778438568115, 1.422917366027832, 1.3004405498504639, 1.352233648300171, 1.18533194065094]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7603962421417236] ms
 --  Average per query NF    [1.3668012619018555] ms
 --  Average per query vegas [2.393594980239868] ms
Mean [1.161]  Median [1.123]  95th [1.429]  99th [1.628]  max [1.899]
Mean [1.161]  Median [1.123]  95th [1.429]  99th [1.628]  max [1.899]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.224016 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=0 | total-time=26.101430