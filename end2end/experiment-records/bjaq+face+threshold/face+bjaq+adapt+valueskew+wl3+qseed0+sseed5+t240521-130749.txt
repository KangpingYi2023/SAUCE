Input arguments = Namespace(data_update='valueskew', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 5, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.168143510818481
tensor(0.9956)
result is  tensor(380483.1875)
Enter testHyper
ReportEsts: [1.222288966178894, 1.060247540473938, 1.2133984565734863, 1.044851541519165, 1.2547225952148438, 1.1502063274383545, 1.2448179721832275, 1.2430094480514526, 1.0633471012115479, 1.1109429597854614, 1.0714900493621826, 1.0639830827713013, 1.0518889427185059, 1.0424107313156128, 1.0670264959335327, 1.4370852708816528, 1.333185076713562, 1.149762511253357, 1.1084567308425903, 1.045918345451355, 1.244033932685852, 1.082176685333252, 1.1372466087341309, 1.0334603786468506, 1.137466311454773, 1.1220614910125732, 1.181869387626648, 1.3680644035339355, 1.0642772912979126, 1.0521818399429321, 1.0358283519744873, 1.1565449237823486, 1.13587486743927, 1.027037262916565, 1.297273874282837, 1.0457111597061157, 1.5300108194351196, 1.1525630950927734, 1.0410010814666748, 1.0125747919082642, 1.0010712146759033, 1.1342525482177734, 1.0089346170425415, 1.1027376651763916, 1.0769068002700806, 1.0626505613327026, 1.175639033317566, 1.290573000907898, 1.0647833347320557, 1.133671760559082, 1.1820513010025024, 1.357165813446045, 1.0080466270446777, 1.232087254524231, 1.0531338453292847, 1.014581322669983, 1.2803738117218018, 1.14933180809021, 1.0881136655807495, 1.45992112159729, 1.250487208366394, 1.1873621940612793, 1.1500588655471802, 1.0059937238693237, 1.1785714626312256, 1.3142857551574707, 1.1399999856948853, 1.0046465396881104, 1.1665664911270142, 1.3157894611358643, 1.1625100374221802, 1.0475342273712158, 1.2332419157028198, 1.1346495151519775, 1.1179163455963135, 1.0145000219345093, 2.038125991821289, 1.088700532913208, 1.0626658201217651, 1.5574307441711426, 1.1220802068710327, 1.151025652885437, 1.0781879425048828, 1.1908698081970215, 1.2452806234359741, 1.062085747718811, 1.1099584102630615, 1.0580075979232788, 1.0067931413650513, 1.0563894510269165, 1.0444036722183228, 1.360673427581787, 1.0187362432479858, 1.2600733041763306, 1.0103627443313599, 1.1060081720352173, 1.1431914567947388, 1.3654683828353882, 1.0909091234207153, 1.168804407119751, 1.1584157943725586, 1.0780342817306519, 1.0054380893707275, 1.004392385482788, 1.0741573572158813, 1.044042706489563, 1.184659719467163, 1.1867364645004272, 1.1103066205978394, 1.035526990890503, 1.0444852113723755, 1.1140683889389038, 1.4095600843429565, 1.0631130933761597, 1.1237974166870117, 1.0913461446762085, 1.0598708391189575, 1.0539146661758423, 1.3792247772216797, 1.010433316230774, 1.154891848564148, 1.058161973953247, 1.1549643278121948, 1.2316842079162598, 1.3149224519729614, 1.1533223390579224, 1.1887317895889282, 1.1597416400909424, 1.3160135746002197, 1.0971944332122803, 1.0875095129013062, 1.2074577808380127, 1.3011187314987183, 1.4285714626312256, 1.2741858959197998, 1.008926272392273, 1.0288417339324951, 1.1837397813796997, 1.006969928741455, 1.5218775272369385, 1.1339040994644165, 1.1628811359405518, 1.1665352582931519, 1.2252720594406128, 1.076073408126831, 1.1042455434799194, 1.1114118099212646, 1.6465036869049072, 1.0413748025894165, 1.1146306991577148, 1.204620599746704, 1.1478015184402466, 1.355531096458435, 1.10689377784729, 1.1096640825271606, 1.0042372941970825, 1.2391042709350586, 1.0303882360458374, 1.06156587600708, 1.1799463033676147, 1.2623672485351562, 1.0172302722930908, 1.1271253824234009, 1.3881481885910034, 1.2196382284164429, 1.0927656888961792, 1.242371678352356, 1.1815557479858398, 1.0792515277862549, 1.0066512823104858, 1.0388656854629517, 1.0589615106582642, 1.1753246784210205, 1.0304853916168213, 1.0098774433135986, 1.107217788696289, 1.0296404361724854, 1.120596170425415, 1.3480457067489624, 1.0407276153564453, 1.002671241760254, 1.017034649848938, 1.002118468284607, 1.1256383657455444, 1.0822166204452515, 1.1099365949630737, 1.1155306100845337, 1.2732105255126953, 1.0069361925125122, 1.3663078546524048, 1.0366637706756592, 1.0272802114486694, 1.4872329235076904, 1.397226095199585, 1.731745958328247, 1.1474244594573975, 1.0599833726882935, 1.1014492511749268, 1.0031518936157227, 1.0100265741348267]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7216389179229736] ms
 --  Average per query NF    [1.3636493682861328] ms
 --  Average per query vegas [2.357989549636841] ms
Mean [1.153]  Median [1.115]  95th [1.411]  99th [1.647]  max [2.038]
Mean [1.153]  Median [1.115]  95th [1.411]  99th [1.647]  max [2.038]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.811299 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=valueskew', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
ValueSample - START
ValueSample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[ 1.1965871e-02  5.9604645e-07  2.3841858e-07 -5.9604645e-08
  0.0000000e+00]
Distance score: 0.0023933290503919125
SAUCE Drift detection: True
Detection latency: 0.0233s

DRIFT-DETECTED after 2-th workload
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/incremental_train.py', '--dataset=bjaq', '--end2end', '--model=face', '--model_update=adapt', '--update_size=80000', '--epochs=0']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
update_size: 76433
AdaptTask - START
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
train data shape: 80000, transfer data shape:16000
Training done; evaluating likelihood on full data:
Saved to: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
AdaptTask - END

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.049273 | Model-update-time: 2.249555


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=valueskew', '--model_update=adapt']
/home/kangping/code_copy/SAUCE/./FACE/FACE_utils/dataUtils.py:321: RuntimeWarning: invalid value encountered in cast
  oracle_cards = oracle_cards.astype(np.int32)
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.170578002929688
tensor(0.9954)
result is  tensor(456483.7812)
Enter testHyper
ReportEsts: [1.0086551904678345, 1.0700693130493164, 1.0729483366012573, 1.252659797668457, 1.2151449918746948, 1.2643389701843262, 1.1584326028823853, 1.0784801244735718, 1.102927565574646, 1.1305807828903198, 1.0280591249465942, 1.0989558696746826, 2.091566324234009, 1.1223821640014648, 8502.0, 1.1080282926559448, 3.8951048851013184, 1.1239840984344482, 1.0064030885696411, 1.3063136339187622, 1.1890926361083984, 2.7167301177978516, 1.0193251371383667, 1.2014389038085938, 1.0965230464935303, 1.4215846061706543, 1.0864369869232178, 1.1692308187484741, 1.4829678535461426, 1.4638553857803345, 1.1048543453216553, 1.3138686418533325, 1.0145725011825562, 1.0790140628814697, 1.078370213508606, 1.1790173053741455, 1.1423320770263672, 1.4662641286849976, 2.2727608680725098, 1.308565378189087, 1.0550493001937866, 1.041800618171692, 239.1666717529297, 1.1548539400100708, 1.0143195390701294, 1.2829904556274414, 2.67504620552063, 1.140709638595581, 1.1343873739242554, 1.1554298400878906, 1.0046576261520386, 1.0263926982879639, 1.33466374874115, 2.200490713119507, 1.221286654472351, 1.5525405406951904, 1.141963005065918, 1.1917197704315186, 1.0391513109207153, 1.103080153465271, 1.455981969833374, 1.1093305349349976, 1.076923131942749, 1.5059150457382202, 1.2076858282089233, 1.074707269668579, 1.362305998802185, 1.0475713014602661, 1.0709891319274902, 1.253154993057251, 1.0499321222305298, 1.0453835725784302, 1.210950255393982, 1.1828677654266357, 1.070055603981018, 1.0237696170806885, 38.512046813964844, 14.0, 1.6222597360610962, 1.0362098217010498, 1.4418531656265259, 1.0465753078460693, 1.1752910614013672, 1.2709084749221802, 1.1421616077423096, 1.6255319118499756, 1.170483112335205, 1.448030948638916, 1.1193888187408447, 1.0049608945846558, 1.052363634109497, 1.3837478160858154, 1.2414764165878296, 1.1001415252685547, 1.1719549894332886, 1.0080060958862305, 1.085644245147705, 1.2500048875808716, 1.573827862739563, 2.5171186923980713, 1.3528642654418945, 1.3274046182632446, 1.0329114198684692, 1.1825909614562988, 1.0081018209457397, 1.1315789222717285, 1.0815668106079102, 1.1412171125411987, 1.1182795763015747, 1.2139720916748047, 2.1870861053466797, 1.1605184078216553, 1.0601682662963867, 1.2606416940689087, 1.0510246753692627, 1.7594099044799805, 1.0411396026611328, 1.3755559921264648, 1.059791088104248, 1.0959999561309814, 1.2696707248687744, 1.0244282484054565, 1.2833698987960815, 1.385312557220459, 1.1744142770767212, 1.0341519117355347, 1.1826757192611694, 1.068145751953125, 1.0409804582595825, 19.736841201782227, 5.084762096405029, 1.1895720958709717, 1.127150297164917, 4.121062755584717, 1.9052183628082275, 1.3237773180007935, 1.169546127319336, 1.1238778829574585, 1.3020730018615723, 1.1824787855148315, 1.021068811416626, 1.00094735622406, 1.2271193265914917, 1.1744909286499023, 1.3017611503601074, 1.1765782833099365, 1.5660377740859985, 1.2288401126861572, 1.1959631443023682, 1.2091810703277588, 1.4625506401062012, 1.116094946861267, 1.2060003280639648, 1.2116546630859375, 1.2293624877929688, 1.1591475009918213, 1.1598916053771973, 1.0959999561309814, 1.0335140228271484, 1.0268608331680298, 1.0537045001983643, 1.2994047403335571, 1.0417594909667969, 1.0289115905761719, 1.0766594409942627, 1.0546166896820068, 1.106937050819397, 1.5462286472320557, 43.648746490478516, 1.2600558996200562, 1.020436406135559, 1.0814017057418823, 1.4699527025222778, 1.2345248460769653, 1.1954545974731445, 1.1369550228118896, 4.590937614440918, 1.091549277305603, 1.220436692237854, 1.152782917022705, 1.5909091234207153, 1.2057172060012817, 1.151698112487793, 1.397721290588379, 1.1142687797546387, 9.251533508300781, 2.570631980895996, 1.2566800117492676, 1.583418607711792, 1.1488698720932007, 1.0738146305084229, 1.0573248863220215, 1.244476079940796, 2.35375714302063, 1.2282977104187012, 1.1020524501800537, 1.3955134153366089, 1.160139560699463, 1.3895652294158936, 1.4487745761871338]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.701314926147461] ms
 --  Average per query NF    [1.3558244705200195] ms
 --  Average per query vegas [2.3454904556274414] ms
Mean [45.603]  Median [1.174]  95th [3.906]  99th [45.604]  max [8502.000]
Mean [45.603]  Median [1.174]  95th [3.906]  99th [45.604]  max [8502.000]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.387872 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=1 | total-time=28.545310