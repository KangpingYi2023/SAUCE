Input arguments = Namespace(data_update='valueskew', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 42, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.198497295379639
tensor(0.9958)
result is  tensor(380567.9688)
Enter testHyper
ReportEsts: [1.1343741416931152, 1.00108802318573, 1.543170690536499, 1.0376921892166138, 1.255092978477478, 1.1235742568969727, 1.3094284534454346, 1.0079290866851807, 1.0863937139511108, 1.0600367784500122, 1.0714900493621826, 1.1459745168685913, 1.1148076057434082, 1.015625, 1.1913279294967651, 1.2373074293136597, 1.4527933597564697, 1.284916877746582, 1.246579885482788, 1.0994898080825806, 1.1020140647888184, 1.1096237897872925, 1.0891809463500977, 1.0797009468078613, 1.1697295904159546, 1.0587702989578247, 1.054617166519165, 1.4974501132965088, 1.0237607955932617, 1.142711877822876, 1.1780773401260376, 1.1869089603424072, 1.01909601688385, 1.0987790822982788, 1.1915664672851562, 1.0673854351043701, 1.5686264038085938, 1.222123146057129, 1.0672729015350342, 1.0875449180603027, 1.0699104070663452, 1.1602563858032227, 1.0286595821380615, 1.1475486755371094, 1.0623283386230469, 1.0385487079620361, 1.0894135236740112, 1.3043153285980225, 1.145955204963684, 1.1861251592636108, 1.1582914590835571, 1.2934315204620361, 1.0250827074050903, 1.4039758443832397, 1.043237566947937, 1.007002830505371, 1.2607476711273193, 1.168725848197937, 1.1160932779312134, 1.4384980201721191, 1.507590413093567, 1.1572442054748535, 1.1639385223388672, 1.2583506107330322, 1.2790697813034058, 1.2285714149475098, 1.1830189228057861, 1.0215100049972534, 1.0656776428222656, 1.3052631616592407, 1.1375703811645508, 1.0726711750030518, 1.2121614217758179, 1.319041132926941, 1.1651439666748047, 1.1559606790542603, 2.0649313926696777, 1.066998839378357, 1.078407883644104, 1.3101885318756104, 1.1902741193771362, 1.125504732131958, 1.0785791873931885, 1.2507609128952026, 1.2090133428573608, 1.1096205711364746, 1.0247313976287842, 1.1624212265014648, 1.0258179903030396, 1.0440692901611328, 1.0285595655441284, 1.2607824802398682, 1.0240029096603394, 1.3580063581466675, 1.101694941520691, 1.0249215364456177, 1.0569443702697754, 1.2530300617218018, 1.0714285373687744, 1.1617826223373413, 1.153521180152893, 1.0972955226898193, 1.011340856552124, 1.0095168352127075, 1.0793932676315308, 1.0019327402114868, 1.0743966102600098, 1.1518324613571167, 1.091646432876587, 1.0214016437530518, 1.015641450881958, 1.084181308746338, 1.193723201751709, 1.0795493125915527, 1.036976933479309, 1.213903784751892, 1.062180757522583, 1.1363343000411987, 1.3677310943603516, 1.0428440570831299, 1.243165135383606, 1.0792741775512695, 1.0525438785552979, 1.1689784526824951, 1.1710271835327148, 1.1824184656143188, 1.1659338474273682, 1.0616518259048462, 1.3365051746368408, 1.0901803970336914, 1.1154680252075195, 1.1214969158172607, 1.139527678489685, 1.4642857313156128, 1.0591996908187866, 1.113153100013733, 1.0286327600479126, 1.2972357273101807, 1.148184895515442, 1.3577004671096802, 1.1236497163772583, 1.0367586612701416, 1.3110235929489136, 1.2852731943130493, 1.2232661247253418, 1.0209598541259766, 1.0122827291488647, 1.5656020641326904, 1.0188440084457397, 1.0961648225784302, 1.1151409149169922, 1.123573899269104, 1.3570247888565063, 1.168038010597229, 1.1903603076934814, 1.0046578645706177, 1.2881942987442017, 1.0320764780044556, 1.0265324115753174, 1.1736198663711548, 1.089783787727356, 1.222586989402771, 1.0170910358428955, 1.2713704109191895, 1.1785268783569336, 1.1155476570129395, 1.1200816631317139, 1.070473074913025, 1.0587416887283325, 1.0777629613876343, 1.0579525232315063, 1.1120885610580444, 1.1428571939468384, 1.1226104497909546, 1.0926430225372314, 1.0608301162719727, 1.0204081535339355, 1.250594139099121, 1.1703788042068481, 1.172978162765503, 1.0646791458129883, 1.0259504318237305, 1.0228424072265625, 1.1205312013626099, 1.2491850852966309, 1.1310782432556152, 1.0262582302093506, 1.2167288064956665, 1.043075680732727, 1.3427482843399048, 1.0355757474899292, 1.014923334121704, 1.5685627460479736, 1.4085570573806763, 1.7498068809509277, 1.1326709985733032, 1.1342642307281494, 1.1014492511749268, 1.0123023986816406, 1.0317397117614746]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7488436698913574] ms
 --  Average per query NF    [1.3655054569244385] ms
 --  Average per query vegas [2.383338212966919] ms
Mean [1.156]  Median [1.121]  95th [1.439]  99th [1.570]  max [2.065]
Mean [1.156]  Median [1.121]  95th [1.439]  99th [1.570]  max [2.065]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.892158 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=valueskew', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
ValueSample - START
ValueSample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[8.3446503e-07 1.4305115e-06 2.3841858e-07 1.1527538e-02 0.0000000e+00]
Distance score: 0.002306008245795965
SAUCE Drift detection: True
Detection latency: 0.0236s

DRIFT-DETECTED after 2-th workload
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/incremental_train.py', '--dataset=bjaq', '--end2end', '--model=face', '--model_update=adapt', '--update_size=80000', '--epochs=0']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
update_size: 76433
AdaptTask - START
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
train data shape: 80000, transfer data shape:16000
Training done; evaluating likelihood on full data:
Saved to: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
AdaptTask - END

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.049246 | Model-update-time: 2.243189


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=valueskew', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.170101881027222
tensor(0.9929)
result is  tensor(455327.9688)
Enter testHyper
ReportEsts: [1.0616588592529297, 1.0259668827056885, 1.0028328895568848, 1.0480183362960815, 1.1586462259292603, 1.3339176177978516, 1.1048225164413452, 1.1654810905456543, 1.132993221282959, 1.5698716640472412, 1.039922833442688, 1.0329352617263794, 1.0120773315429688, 1.0304754972457886, 1.1931922435760498, 1.031899094581604, 1.289812684059143, 1.0697295665740967, 1.3200962543487549, 1.3168057203292847, 1.1087373495101929, 2.5663979053497314, 1.2582811117172241, 3.4572017192840576, 1.0575109720230103, 1.1318821907043457, 1.0779340267181396, 1.169634461402893, 1.1824569702148438, 1.1394891738891602, 1.3426573276519775, 1.4661016464233398, 1.0579543113708496, 1.0499945878982544, 1.0429097414016724, 1.0117709636688232, 1.045318841934204, 1.1332060098648071, 1.3130571842193604, 1.0946400165557861, 1.1449271440505981, 1.0667372941970825, 36.9867057800293, 1.1925816535949707, 1.0280120372772217, 1.031470775604248, 1.2971733808517456, 1.1129487752914429, 1.3571428060531616, 1.6599974632263184, 1.0124338865280151, 1.0190516710281372, 1.1797133684158325, 1.0957491397857666, 1.1290769577026367, 1.1530060768127441, 1.042730450630188, 1.042934775352478, 1.0390089750289917, 1.0438207387924194, 1.1576673984527588, 1.026658296585083, 1.047939419746399, 1.9791336059570312, 1.0465630292892456, 1.0835694074630737, 1.1527931690216064, 1.1169517040252686, 1.0050194263458252, 1.1186248064041138, 1.1513030529022217, 1.0440281629562378, 1.0483176708221436, 1.1967835426330566, 1.9356648921966553, 1.0359867811203003, 1.1934674978256226, 1.9811689853668213, 1.3727679252624512, 1.1150168180465698, 2.411792755126953, 1.2904995679855347, 1.0963562726974487, 1.2540425062179565, 1.0970306396484375, 1.3104692697525024, 1.1750036478042603, 1.3424166440963745, 1.170189380645752, 1.108809471130371, 1.081881046295166, 1.3672852516174316, 1.0590226650238037, 1.176227331161499, 53.00423049926758, 1.0229809284210205, 1.1983956098556519, 1.2051090002059937, 1.4719644784927368, 1.0548245906829834, 1.0960839986801147, 1.1735280752182007, 1.004926085472107, 1.1636947393417358, 2.8572373390197754, 1.397027611732483, 1.2071447372436523, 1.0097178220748901, 1.048710584640503, 1.015051007270813, 1.6230158805847168, 1.0822484493255615, 1.1034690141677856, 1.0319299697875977, 1.0770851373672485, 3.097014904022217, 1.092169165611267, 1.1638314723968506, 1.053601861000061, 1.2566372156143188, 1.017652988433838, 1.1461683511734009, 1.1439388990402222, 1.2961803674697876, 1.0152206420898438, 1.1481330394744873, 1.0443801879882812, 1.0959349870681763, 1.063075304031372, 1.1362581253051758, 1.0414680242538452, 1.0657281875610352, 1.1990752220153809, 1.477166771888733, 1.3396567106246948, 1.0603152513504028, 1.096168875694275, 1.9063680171966553, 1.097700834274292, 1.009243130683899, 1.0918421745300293, 1.1375548839569092, 1.0173282623291016, 1.0750609636306763, 1.0146669149398804, 2.4029579162597656, 1.3790849447250366, 1.0691636800765991, 1.0801244974136353, 1.049044132232666, 136.6456756591797, 1.3053147792816162, 1.4192068576812744, 1.016097068786621, 1.0150823593139648, 1.123226284980774, 1.139554500579834, 1.1048387289047241, 1.7516344785690308, 1.0082017183303833, 1.008374810218811, 1.001497745513916, 1.051835536956787, 1.2152971029281616, 1.0666383504867554, 1.040421962738037, 1.0973432064056396, 1.1619230508804321, 1.0616730451583862, 1.0065574645996094, 1.0670915842056274, 1.0048086643218994, 1.5510057210922241, 1.1154080629348755, 1.7098126411437988, 1.0306240320205688, 1.1680543422698975, 1.0789730548858643, 1.2251046895980835, 1.159362554550171, 1.6842105388641357, 1.3115415573120117, 1.0191199779510498, 1.470509648323059, 1.2869929075241089, 1.0913680791854858, 1.0270270109176636, 1.0225938558578491, 1.2980834245681763, 1.0853873491287231, 1.004692792892456, 1.1299712657928467, 1.3567131757736206, 2.081275701522827, 1.1305969953536987, 1.1428343057632446, 1.2956364154815674, 1.191348910331726, 1.122033953666687, 1.1511660814285278]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7449002265930176] ms
 --  Average per query NF    [1.3573253154754639] ms
 --  Average per query vegas [2.3875749111175537] ms
Mean [2.338]  Median [1.118]  95th [1.986]  99th [37.147]  max [136.646]
Mean [2.338]  Median [1.118]  95th [1.986]  99th [37.147]  max [136.646]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.408237 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=1 | total-time=28.660647