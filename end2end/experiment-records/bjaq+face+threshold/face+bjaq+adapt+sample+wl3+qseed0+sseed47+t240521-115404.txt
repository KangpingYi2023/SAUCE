Input arguments = Namespace(data_update='sample', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 47, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.161175012588501
tensor(0.9977)
result is  tensor(381295.7812)
Enter testHyper
ReportEsts: [1.1407345533370972, 1.041770577430725, 1.4295369386672974, 1.0061064958572388, 1.2877916097640991, 1.0739344358444214, 1.2310125827789307, 1.0059558153152466, 1.0370689630508423, 1.1450586318969727, 1.1335055828094482, 1.1341102123260498, 1.0739827156066895, 1.0669642686843872, 1.1511048078536987, 1.3467433452606201, 1.1733741760253906, 1.173753023147583, 1.2540209293365479, 1.1122448444366455, 1.4540936946868896, 1.0322539806365967, 1.1218496561050415, 1.1354621648788452, 1.140651822090149, 1.055153727531433, 1.0810810327529907, 1.3565728664398193, 1.158997654914856, 1.1713966131210327, 1.0727207660675049, 1.2985029220581055, 1.2399390935897827, 1.0378152132034302, 1.1301679611206055, 1.0676831007003784, 1.5274051427841187, 1.173107385635376, 1.0769120454788208, 1.0742515325546265, 1.0361214876174927, 1.0414851903915405, 1.0424461364746094, 1.0654468536376953, 1.1132473945617676, 1.0385487079620361, 1.1093531847000122, 1.2858195304870605, 1.1023050546646118, 1.0609136819839478, 1.2036553621292114, 1.337353229522705, 1.0154794454574585, 1.2587523460388184, 1.0663878917694092, 1.1010663509368896, 1.3158878087997437, 1.1374120712280273, 1.2281328439712524, 1.3637479543685913, 1.3468596935272217, 1.1865770816802979, 1.393795132637024, 1.149879813194275, 1.3200000524520874, 1.2571429014205933, 1.180790901184082, 1.0632920265197754, 1.0608569383621216, 1.3157894611358643, 1.050683856010437, 1.0249042510986328, 1.2037781476974487, 1.1651346683502197, 1.1096763610839844, 1.2742973566055298, 1.5241882801055908, 1.0202387571334839, 1.088470220565796, 1.5309555530548096, 1.2838279008865356, 1.0605717897415161, 1.1174136400222778, 1.2158793210983276, 1.2188053131103516, 1.1352672576904297, 1.0445373058319092, 1.1725598573684692, 1.013322114944458, 1.1337590217590332, 1.0479689836502075, 1.4246795177459717, 1.0083636045455933, 1.3164315223693848, 1.1538461446762085, 1.0664035081863403, 1.0068395137786865, 1.2064001560211182, 1.0, 1.0845426321029663, 1.175035834312439, 1.1810224056243896, 1.0710110664367676, 1.002196192741394, 1.0160484313964844, 1.094132661819458, 1.2061933279037476, 1.1780104637145996, 1.1348540782928467, 1.077934980392456, 1.1779457330703735, 1.0943044424057007, 1.2318224906921387, 1.0874861478805542, 1.1527761220932007, 1.1522842645645142, 1.061168909072876, 1.0135431289672852, 1.378800868988037, 1.0036709308624268, 1.2313119173049927, 1.0674761533737183, 1.0746148824691772, 1.0963952541351318, 1.4142441749572754, 1.1794263124465942, 1.1608301401138306, 1.081780195236206, 1.3399826288223267, 1.093186378479004, 1.127718210220337, 1.238612174987793, 1.23927903175354, 1.5, 1.1787699460983276, 1.1037017107009888, 1.0552845001220703, 1.1736584901809692, 1.0032633543014526, 1.056322455406189, 1.1010005474090576, 1.1168749332427979, 1.0178719758987427, 1.3593560457229614, 1.1172024011611938, 1.0580229759216309, 1.0189791917800903, 1.7643258571624756, 1.0642743110656738, 1.1567471027374268, 1.0978280305862427, 1.1581848859786987, 1.356277585029602, 1.1044713258743286, 1.2964032888412476, 1.0361944437026978, 1.097381353378296, 1.0272932052612305, 1.0264062881469727, 1.1777379512786865, 1.183547854423523, 1.0520464181900024, 1.0288960933685303, 1.2870879173278809, 1.1387213468551636, 1.0967518091201782, 1.234840989112854, 1.3052669763565063, 1.029565453529358, 1.0250197649002075, 1.1037980318069458, 1.0276950597763062, 1.1298701763153076, 1.03366219997406, 1.0442779064178467, 1.054691195487976, 1.0335277318954468, 1.2236313819885254, 1.1096432209014893, 1.005730152130127, 1.0356040000915527, 1.0386979579925537, 1.0247766971588135, 1.1430031061172485, 1.1014125347137451, 1.0708245038986206, 1.0465373992919922, 1.2943083047866821, 1.0130972862243652, 1.3655729293823242, 1.1132985353469849, 1.1007245779037476, 1.6998213529586792, 1.417675256729126, 1.8707964420318604, 1.1970351934432983, 1.1461858749389648, 1.085714340209961, 1.1123989820480347, 1.0936919450759888]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.758533000946045] ms
 --  Average per query NF    [1.3629961013793945] ms
 --  Average per query vegas [2.3955368995666504] ms
Mean [1.158]  Median [1.117]  95th [1.418]  99th [1.700]  max [1.871]
Mean [1.158]  Median [1.117]  95th [1.418]  99th [1.700]  max [1.871]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.847383 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=sample', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
Sample - START
Sample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[1.1324883e-06 1.1324883e-06 1.0132790e-06 5.9604645e-07 1.7881393e-07]
Distance score: 8.1062319168268e-07
SAUCE Drift detection: False
Detection latency: 0.0235s

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.006201 | Model-update-time: 0.000000


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=sample', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.165466785430908
tensor(0.9942)
result is  tensor(455956.3750)
Enter testHyper
ReportEsts: [1.082692265510559, 1.0379976034164429, 1.2217453718185425, 1.1116694211959839, 1.0194960832595825, 1.2764592170715332, 1.268205165863037, 1.0081528425216675, 1.1993154287338257, 1.0798230171203613, 1.12321138381958, 1.2934621572494507, 1.2051886320114136, 1.2696772813796997, 1.0197590589523315, 1.026871681213379, 1.3663403987884521, 1.1161166429519653, 1.0394915342330933, 1.3047124147415161, 1.2135895490646362, 1.1248799562454224, 1.1169217824935913, 1.0695672035217285, 1.1486454010009766, 1.1504775285720825, 1.082995891571045, 1.1462153196334839, 1.3631391525268555, 1.3701657056808472, 1.2498779296875, 1.3586206436157227, 1.0836204290390015, 1.0462226867675781, 1.0097917318344116, 1.2193653583526611, 1.076621174812317, 1.0717824697494507, 1.3381716012954712, 1.086495280265808, 1.0343554019927979, 1.0286976099014282, 1.3831241130828857, 1.15347421169281, 1.046971321105957, 1.113921880722046, 1.132981777191162, 1.1995631456375122, 1.102766752243042, 1.029807448387146, 1.0575902462005615, 1.0486726760864258, 1.0259144306182861, 1.112127661705017, 1.0954419374465942, 1.2605136632919312, 1.21429443359375, 1.1278748512268066, 1.290970802307129, 1.0557738542556763, 1.623152732849121, 1.005902647972107, 1.0830711126327515, 1.5927560329437256, 1.015792727470398, 1.0267572402954102, 1.4285634756088257, 1.1283397674560547, 1.1146005392074585, 1.047911524772644, 1.0765084028244019, 1.2200127840042114, 1.0115902423858643, 1.1085890531539917, 1.0269497632980347, 1.0490100383758545, 1.5481079816818237, 1.0561721324920654, 1.1649645566940308, 1.011849284172058, 1.22556734085083, 1.010163426399231, 1.0517020225524902, 1.2509291172027588, 1.2580353021621704, 1.3767606019973755, 1.126086950302124, 1.5053799152374268, 1.072497010231018, 1.0169241428375244, 1.0775368213653564, 1.2289611101150513, 1.6435308456420898, 1.1917439699172974, 1.4231330156326294, 1.001015543937683, 1.1547294855117798, 1.2659547328948975, 1.0384211540222168, 1.0008022785186768, 1.069474697113037, 1.1074297428131104, 1.2116788625717163, 1.0622310638427734, 1.237905740737915, 1.1725598573684692, 1.0404232740402222, 1.0534600019454956, 1.2710843086242676, 1.1107240915298462, 1.018515706062317, 1.0767794847488403, 1.2971322536468506, 1.1746115684509277, 1.055578589439392, 1.1984071731567383, 1.3197569847106934, 1.2034721374511719, 1.030533790588379, 1.2710280418395996, 1.0808838605880737, 1.1495616436004639, 1.0328904390335083, 2.54695725440979, 1.0675188302993774, 1.110698938369751, 1.2079640626907349, 1.2213855981826782, 1.218070149421692, 1.033515214920044, 1.0800528526306152, 1.063779592514038, 1.040228247642517, 1.954264521598816, 1.7425742149353027, 1.063181757926941, 1.0906774997711182, 1.0343472957611084, 1.067720890045166, 1.0407435894012451, 1.0772758722305298, 1.2190712690353394, 1.0563687086105347, 1.0533461570739746, 1.1102694272994995, 1.0711263418197632, 1.4764705896377563, 1.0609174966812134, 1.0170780420303345, 1.0258865356445312, 1.0496498346328735, 1.0313408374786377, 1.1581838130950928, 1.0947265625, 1.0065813064575195, 1.0000863075256348, 1.1914029121398926, 1.2419354915618896, 1.0298330783843994, 1.1381733417510986, 1.0563230514526367, 1.1558588743209839, 1.3235629796981812, 1.0683175325393677, 1.240402102470398, 1.279335618019104, 1.012402057647705, 1.0108832120895386, 1.1394139528274536, 1.204064965248108, 1.1286604404449463, 1.1930458545684814, 1.6359516382217407, 1.0494353771209717, 1.171549677848816, 1.0956199169158936, 1.1812399625778198, 1.244653582572937, 1.0314199924468994, 1.0014007091522217, 1.6585365533828735, 1.0839256048202515, 1.040014386177063, 1.4437803030014038, 1.2975459098815918, 1.3202155828475952, 1.1026897430419922, 1.0786175727844238, 1.5151515007019043, 1.0823945999145508, 1.143909215927124, 1.1370967626571655, 1.2651853561401367, 2.009355068206787, 1.0204931497573853, 1.0006940364837646, 1.30454683303833, 1.0171926021575928, 1.3645484447479248, 1.0975595712661743]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7491953372955322] ms
 --  Average per query NF    [1.3632416725158691] ms
 --  Average per query vegas [2.385953664779663] ms
Mean [1.172]  Median [1.111]  95th [1.517]  99th [1.955]  max [2.547]
Mean [1.172]  Median [1.111]  95th [1.517]  99th [1.955]  max [2.547]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.229769 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=0 | total-time=26.136361