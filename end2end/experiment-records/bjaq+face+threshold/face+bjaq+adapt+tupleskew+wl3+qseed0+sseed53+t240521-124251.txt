Input arguments = Namespace(data_update='tupleskew', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 53, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.167586326599121
tensor(0.9935)
result is  tensor(379696.4688)
Enter testHyper
ReportEsts: [1.1883761882781982, 1.0725736618041992, 1.2381235361099243, 1.1099178791046143, 1.2506619691848755, 1.0869420766830444, 1.21175217628479, 1.0856541395187378, 1.032322645187378, 1.0462263822555542, 1.2024117708206177, 1.1406779289245605, 1.0451544523239136, 1.0691964626312256, 1.1227824687957764, 1.3262226581573486, 1.34909188747406, 1.2725653648376465, 1.1837533712387085, 1.0153061151504517, 1.1815803050994873, 1.1339093446731567, 1.1503630876541138, 1.058228850364685, 1.1150861978530884, 1.0334539413452148, 1.0458896160125732, 1.3698049783706665, 1.1524147987365723, 1.1470857858657837, 1.1337354183197021, 1.1435790061950684, 1.0894979238510132, 1.031355619430542, 1.1019189357757568, 1.0182054042816162, 1.2520241737365723, 1.237019419670105, 1.0098810195922852, 1.062754511833191, 1.0783367156982422, 1.1089743375778198, 1.0167818069458008, 1.0402299165725708, 1.0424678325653076, 1.0782313346862793, 1.1255016326904297, 1.3933346271514893, 1.0342472791671753, 1.1302876472473145, 1.2425875663757324, 1.2189760208129883, 1.0941296815872192, 1.2456692457199097, 1.0790528059005737, 1.02106511592865, 1.241121530532837, 1.1669399738311768, 1.1368012428283691, 1.3548780679702759, 1.5760438442230225, 1.2055760622024536, 1.3717156648635864, 1.0618994235992432, 1.330645203590393, 1.2000000476837158, 1.2046109437942505, 1.0281280279159546, 1.1495766639709473, 1.4105262756347656, 1.102976679801941, 1.007611870765686, 1.2386225461959839, 1.1521155834197998, 1.0924218893051147, 1.1306771039962769, 1.480819582939148, 1.0564693212509155, 1.0361838340759277, 1.5117589235305786, 1.111399531364441, 1.189630150794983, 1.0109150409698486, 1.1696995496749878, 1.2604371309280396, 1.0805913209915161, 1.0364514589309692, 1.0137704610824585, 1.0430045127868652, 1.0523260831832886, 1.1159480810165405, 1.3679399490356445, 1.0126217603683472, 1.273189902305603, 1.1963189840316772, 1.046134114265442, 1.1864597797393799, 1.18683922290802, 1.034482717514038, 1.099897027015686, 1.13434898853302, 1.14501953125, 1.0218093395233154, 1.0095168352127075, 1.015401005744934, 1.0583046674728394, 1.1763378381729126, 1.1518324613571167, 1.0582222938537598, 1.0595266819000244, 1.165352463722229, 1.1004694700241089, 1.2442644834518433, 1.0057144165039062, 1.1375912427902222, 1.1127450466156006, 1.0940722227096558, 1.0131561756134033, 1.2624006271362305, 1.029899001121521, 1.2226850986480713, 1.0923830270767212, 1.1143561601638794, 1.265182614326477, 1.3410853147506714, 1.2140940427780151, 1.138153076171875, 1.2423807382583618, 1.2550771236419678, 1.1078823804855347, 1.184690237045288, 1.3416043519973755, 1.1970168352127075, 1.4642857313156128, 1.0777394771575928, 1.2173799276351929, 1.0219756364822388, 1.0578861236572266, 1.02000093460083, 1.3973703384399414, 1.1796505451202393, 1.0230298042297363, 1.1562892198562622, 1.2286361455917358, 1.1196434497833252, 1.037930965423584, 1.0864300727844238, 1.205016851425171, 1.1026586294174194, 1.1012073755264282, 1.1478692293167114, 1.1563901901245117, 1.320643424987793, 1.0682108402252197, 1.0806632041931152, 1.0402405261993408, 1.0366443395614624, 1.0177265405654907, 1.0407222509384155, 1.124201774597168, 1.0428611040115356, 1.0103346109390259, 1.0231657028198242, 1.2560322284698486, 1.2519893646240234, 1.128104329109192, 1.060766577720642, 1.2697455883026123, 1.0173100233078003, 1.0255228281021118, 1.0813254117965698, 1.0309847593307495, 1.1363636255264282, 1.06905198097229, 1.0231608152389526, 1.023107886314392, 1.0269460678100586, 1.3391163349151611, 1.130738615989685, 1.0732496976852417, 1.1744581460952759, 1.002700924873352, 1.0480741262435913, 1.1399387121200562, 1.0945309400558472, 1.1067652702331543, 1.007122278213501, 1.224608063697815, 1.0085417032241821, 1.3766810894012451, 1.1030539274215698, 1.1740472316741943, 1.6092472076416016, 1.6590908765792847, 1.9300060272216797, 1.1313484907150269, 1.0971237421035767, 1.085714340209961, 1.2308982610702515, 1.082470178604126]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.761376142501831] ms
 --  Average per query NF    [1.3595831394195557] ms
 --  Average per query vegas [2.4017930030822754] ms
Mean [1.149]  Median [1.116]  95th [1.378]  99th [1.610]  max [1.930]
Mean [1.149]  Median [1.116]  95th [1.378]  99th [1.610]  max [1.930]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.844590 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=tupleskew', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
TupleSkewSample - START
0.001
TupleSkewSample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[1.1605024e-04 3.0946732e-04 1.6450882e-05 1.0609627e-05 7.4267387e-05]
Distance score: 0.00010536909394431859
SAUCE Drift detection: True
Detection latency: 0.0233s

DRIFT-DETECTED after 2-th workload
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/incremental_train.py', '--dataset=bjaq', '--end2end', '--model=face', '--model_update=adapt', '--update_size=80000', '--epochs=0']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
update_size: 76433
AdaptTask - START
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
train data shape: 80000, transfer data shape:16000
Training done; evaluating likelihood on full data:
Saved to: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
AdaptTask - END

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.004041 | Model-update-time: 2.226114


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=tupleskew', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.166711568832397
tensor(0.9921)
result is  tensor(454992.1250)
Enter testHyper
ReportEsts: [1.1201163530349731, 1.0141600370407104, 1.2643356323242188, 1.8108384609222412, 1.1238478422164917, 1.027271032333374, 1.3192062377929688, 1.0971465110778809, 1.0349042415618896, 1.0583828687667847, 1.1619852781295776, 1.0115537643432617, 1.1766109466552734, 1.061004400253296, 1.2811847925186157, 1.0490349531173706, 1.1594737768173218, 1.0715609788894653, 1.0851260423660278, 1.374407410621643, 1.1316611766815186, 2.1159753799438477, 1.185887336730957, 1.1307902336120605, 1.029784083366394, 1.3203191757202148, 1.0463770627975464, 1.2159838676452637, 1.2921110391616821, 1.3400321006774902, 1.3543306589126587, 1.508474588394165, 1.0896010398864746, 1.0726855993270874, 1.1255943775177002, 1.0687408447265625, 1.0655417442321777, 1.0281002521514893, 1.2202998399734497, 1.0186405181884766, 1.1651511192321777, 1.3793489933013916, 1.1712383031845093, 1.0723947286605835, 1.0974323749542236, 1.0193496942520142, 1.1855767965316772, 1.045082688331604, 1.2142857313156128, 1.078081727027893, 1.0709538459777832, 1.013562798500061, 1.130078911781311, 1.0085391998291016, 1.0371416807174683, 1.1999458074569702, 1.2842552661895752, 1.0784250497817993, 1.11521315574646, 1.2264240980148315, 1.8091787099838257, 1.02787184715271, 1.1004575490951538, 1.5041362047195435, 1.1055171489715576, 1.0772156715393066, 1.2790666818618774, 1.012769341468811, 1.176444411277771, 1.0798624753952026, 1.117159366607666, 1.113194465637207, 1.0421137809753418, 1.1388092041015625, 1.1095091104507446, 1.0088183879852295, 1.0971649885177612, 1.00141441822052, 1.1085284948349, 1.0807620286941528, 1.2469983100891113, 1.1841249465942383, 1.2065480947494507, 1.3166935443878174, 1.3236364126205444, 1.578723430633545, 1.1873208284378052, 1.4388012886047363, 1.4516847133636475, 1.0912801027297974, 1.150328516960144, 1.0938804149627686, 1.4643752574920654, 1.0939604043960571, 1.0450398921966553, 1.0001050233840942, 1.035466194152832, 1.0923596620559692, 1.4463034868240356, 1.0231741666793823, 1.0660507678985596, 1.1200281381607056, 1.3632184267044067, 1.0537536144256592, 1.1583549976348877, 1.0120856761932373, 1.0704364776611328, 1.0491302013397217, 1.0687679052352905, 1.0723118782043457, 1.018617033958435, 1.073483943939209, 1.1768072843551636, 1.2510277032852173, 1.127265453338623, 1.1168581247329712, 1.0526078939437866, 1.3931219577789307, 1.2093982696533203, 1.0796459913253784, 1.064401626586914, 1.2635513544082642, 1.077830195426941, 1.1292644739151, 1.0379146337509155, 1.2408227920532227, 1.1910427808761597, 1.0597484111785889, 1.0580978393554688, 1.0402979850769043, 1.1229758262634277, 1.1735751628875732, 1.0942769050598145, 1.327309250831604, 1.7312819957733154, 1.1567208766937256, 1.0243589878082275, 1.0625299215316772, 1.0215630531311035, 1.0382510423660278, 1.0669708251953125, 1.1404750347137451, 1.1150624752044678, 1.0107439756393433, 1.0332615375518799, 1.0369343757629395, 2.497109889984131, 1.0083690881729126, 1.0456348657608032, 1.0787782669067383, 1.3287439346313477, 1.2069355249404907, 1.1514358520507812, 1.04738450050354, 1.0748202800750732, 1.0222442150115967, 1.2374032735824585, 1.0620155334472656, 1.3030551671981812, 1.167150616645813, 1.0369796752929688, 1.2857142686843872, 1.1131384372711182, 1.248215675354004, 1.089465618133545, 1.103009581565857, 1.0324509143829346, 1.3294180631637573, 1.1691641807556152, 1.349139928817749, 1.0801011323928833, 1.022923231124878, 1.3300000429153442, 1.0420341491699219, 1.0772193670272827, 1.0014365911483765, 1.0544936656951904, 1.114780306816101, 1.0233803987503052, 1.0296341180801392, 1.7894736528396606, 1.0704153776168823, 1.0259517431259155, 1.4375637769699097, 1.2301936149597168, 1.1475896835327148, 1.0000993013381958, 1.018348217010498, 1.4992222785949707, 1.0026261806488037, 1.1273051500320435, 1.0236150026321411, 1.1198043823242188, 2.0328094959259033, 1.0189343690872192, 1.9566115140914917, 1.1516830921173096, 1.016574740409851, 2.189328670501709, 1.1034095287322998]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7286245822906494] ms
 --  Average per query NF    [1.3568651676177979] ms
 --  Average per query vegas [2.3717594146728516] ms
Mean [1.176]  Median [1.104]  95th [1.512]  99th [2.117]  max [2.497]
Mean [1.176]  Median [1.104]  95th [1.512]  99th [2.117]  max [2.497]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.387317 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=1 | total-time=28.497278