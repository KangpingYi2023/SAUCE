Input arguments = Namespace(data_update='valueskew', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 54, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.16324520111084
tensor(0.9953)
result is  tensor(380365.3750)
Enter testHyper
ReportEsts: [1.1400952339172363, 1.029123306274414, 1.3323413133621216, 1.1499263048171997, 1.248824954032898, 1.0749918222427368, 1.2278163433074951, 1.0864371061325073, 1.1142327785491943, 1.0760722160339355, 1.1757105588912964, 1.0985169410705566, 1.0691962242126465, 1.0245535373687744, 1.1480774879455566, 1.5376203060150146, 1.2190709114074707, 1.2049881219863892, 1.1383203268051147, 1.040816307067871, 1.0920982360839844, 1.0783239603042603, 1.1406183242797852, 1.0376958847045898, 1.063056468963623, 1.1075949668884277, 1.0608108043670654, 1.5748414993286133, 1.0525761842727661, 1.0446546077728271, 1.1596311330795288, 1.017419695854187, 1.2117769718170166, 1.0639712810516357, 1.1332976818084717, 1.1230196952819824, 1.1999918222427368, 1.1650152206420898, 1.0214154720306396, 1.0519022941589355, 1.0599710941314697, 1.0731736421585083, 1.1671788692474365, 1.288841962814331, 1.11007821559906, 1.1746032238006592, 1.1561590433120728, 1.2771172523498535, 1.051751732826233, 1.0575295686721802, 1.1912144422531128, 1.3766742944717407, 1.0321599245071411, 1.2444933652877808, 1.1032633781433105, 1.0288575887680054, 1.1934579610824585, 1.0796823501586914, 1.0964438915252686, 1.3004292249679565, 1.1479289531707764, 1.1618646383285522, 1.328439474105835, 1.0682801008224487, 1.25, 1.2000000476837158, 1.1287128925323486, 1.0007781982421875, 1.0039968490600586, 1.399999976158142, 1.1671361923217773, 1.0499016046524048, 1.2204811573028564, 1.2299174070358276, 1.1300299167633057, 1.0827107429504395, 1.9703137874603271, 1.0060542821884155, 1.0105030536651611, 1.1893126964569092, 1.1672725677490234, 1.104506492614746, 1.030502438545227, 1.1324479579925537, 1.227817416191101, 1.0969480276107788, 1.0384044647216797, 1.1565195322036743, 1.0201810598373413, 1.0496724843978882, 1.0464744567871094, 1.498562216758728, 1.0003606081008911, 1.3107882738113403, 1.0833333730697632, 1.0166157484054565, 1.187578558921814, 1.3204582929611206, 1.034482717514038, 1.173204779624939, 1.1904069185256958, 1.1013829708099365, 1.119776725769043, 1.0036603212356567, 1.1246862411499023, 1.0124845504760742, 1.0304787158966064, 1.1972076892852783, 1.0713716745376587, 1.0126640796661377, 1.2181370258331299, 1.1035782098770142, 1.1755437850952148, 1.049630045890808, 1.16726553440094, 1.1293532848358154, 1.0460094213485718, 1.0175416469573975, 1.3075861930847168, 1.1274211406707764, 1.2763391733169556, 1.1109424829483032, 1.130426049232483, 1.2424538135528564, 1.2407945394515991, 1.1718943119049072, 1.1486930847167969, 1.0772194862365723, 1.355263113975525, 1.1092184782028198, 1.0411465167999268, 1.122198224067688, 1.2557488679885864, 1.4285714626312256, 1.3078969717025757, 1.0939115285873413, 1.05745267868042, 1.0416259765625, 1.238974690437317, 1.0015681982040405, 1.1527204513549805, 1.10611891746521, 1.217999815940857, 1.3807467222213745, 1.0936429500579834, 1.0394065380096436, 1.0991637706756592, 1.368558645248413, 1.08643639087677, 1.0556107759475708, 1.3034234046936035, 1.1604923009872437, 1.3291958570480347, 1.1677873134613037, 1.1223064661026, 1.0077080726623535, 1.0281476974487305, 1.0045019388198853, 1.0228886604309082, 1.1718889474868774, 1.2232733964920044, 1.0938327312469482, 1.0146242380142212, 1.2818057537078857, 1.1053863763809204, 1.098086953163147, 1.132360577583313, 1.368099331855774, 1.0618259906768799, 1.0168869495391846, 1.074597954750061, 1.0350600481033325, 1.0909091234207153, 1.2112244367599487, 1.0940054655075073, 1.288195013999939, 1.0336514711380005, 1.1573370695114136, 1.0823160409927368, 1.028016448020935, 1.075717568397522, 1.0238502025604248, 1.057566523551941, 1.1021450757980347, 1.1336472034454346, 1.1289640665054321, 1.0162134170532227, 1.2651408910751343, 1.057108998298645, 1.5299222469329834, 1.0180017948150635, 1.013999342918396, 1.6822870969772339, 1.3929756879806519, 1.9775490760803223, 1.1399999856948853, 1.0971654653549194, 1.085714340209961, 1.0583345890045166, 1.1316733360290527]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7368595600128174] ms
 --  Average per query NF    [1.3585364818572998] ms
 --  Average per query vegas [2.3783230781555176] ms
Mean [1.150]  Median [1.113]  95th [1.381]  99th [1.685]  max [1.978]
Mean [1.150]  Median [1.113]  95th [1.381]  99th [1.685]  max [1.978]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.819247 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=valueskew', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
ValueSample - START
ValueSample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[7.1525574e-07 1.0728836e-06 9.6883178e-03 7.7486038e-07 1.7881393e-07]
Distance score: 0.001938211964443326
SAUCE Drift detection: True
Detection latency: 0.0232s

DRIFT-DETECTED after 2-th workload
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/incremental_train.py', '--dataset=bjaq', '--end2end', '--model=face', '--model_update=adapt', '--update_size=80000', '--epochs=0']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
update_size: 76433
AdaptTask - START
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
train data shape: 80000, transfer data shape:16000
Training done; evaluating likelihood on full data:
Saved to: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
AdaptTask - END

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.043447 | Model-update-time: 2.228047


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=valueskew', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.227097272872925
tensor(0.9962)
result is  tensor(456843.8438)
Enter testHyper
ReportEsts: [5.0611796379089355, 1.5313409566879272, 1.0099149942398071, 1.5082873106002808, 1.1182230710983276, 1.3859939575195312, 1.0162748098373413, 1.1432254314422607, 1.0715677738189697, 1.1863354444503784, 1.1613940000534058, 1.1946512460708618, 1.1173814535140991, 2.872096061706543, 1.058968186378479, 1.0800962448120117, 1.2999999523162842, 1.3205231428146362, 1.0030736923217773, 1.090132474899292, 1.2698725461959839, 1.1422309875488281, 1.2026894092559814, 3.9070796966552734, 1.0386263132095337, 1.4251940250396729, 1.107862949371338, 1.254075288772583, 1.09678053855896, 1.442136526107788, 1.2685409784317017, 1.3644068241119385, 1.1429250240325928, 10.697737693786621, 1.1838703155517578, 1.1467243432998657, 1.1333054304122925, 1.059019684791565, 1.270023226737976, 1.1831859350204468, 1.0903334617614746, 1.2132822275161743, 1.131818175315857, 1.0115150213241577, 1.1174441576004028, 1.0342087745666504, 1.371959924697876, 1.0433087348937988, 1.1457489728927612, 1.1740092039108276, 1.173639178276062, 1.0015324354171753, 1.0194023847579956, 1.509940505027771, 1.0930331945419312, 1.5907890796661377, 1.1299513578414917, 1.094748854637146, 1.2860386371612549, 1.2481683492660522, 1.3201969861984253, 1.2158159017562866, 1.2181252241134644, 1.5815231800079346, 1.0860297679901123, 2.1996240615844727, 1.1594197750091553, 1.2081462144851685, 1.083858609199524, 1.1471519470214844, 1.4762589931488037, 1.0547233819961548, 1.1665793657302856, 1.105605125427246, 1.1120291948318481, 1.4602091312408447, 10.837897300720215, 1.268092393875122, 1.3328754901885986, 1.099220633506775, 1.6383812427520752, 1.2567282915115356, 1.1671319007873535, 1.0319112539291382, 1.2637288570404053, 1.45195734500885, 1.2361739873886108, 1.4531047344207764, 2.074165105819702, 1.0319583415985107, 1.160354495048523, 1.231095790863037, 1.3943499326705933, 1.1108088493347168, 1.648280143737793, 1.0251553058624268, 2.8195958137512207, 1.2475579977035522, 1.1470270156860352, 1.281940221786499, 1.0465420484542847, 1.044866919517517, 1.0784313678741455, 1.013187289237976, 1.1978328227996826, 2.4007065296173096, 1.0952215194702148, 1.1862879991531372, 1.0028653144836426, 1.1332993507385254, 1.0165969133377075, 1.0714526176452637, 1.1152034997940063, 1.4374620914459229, 1.0296822786331177, 1.0766723155975342, 1.11588716506958, 1.308061122894287, 1.153687834739685, 1.1061947345733643, 1.1282353401184082, 1.2853583097457886, 3.2256641387939453, 1.980865240097046, 1.1766456365585327, 1.1498841047286987, 1.1391273736953735, 1.0749601125717163, 1.0258656740188599, 1.0247441530227661, 1.283163070678711, 1.0976253747940063, 1.1397745609283447, 2.3383991718292236, 1.496468186378479, 1.2682584524154663, 1.1944836378097534, 1.6730355024337769, 1.0871800184249878, 1.2077109813690186, 1.0931577682495117, 1.0837606191635132, 1.0267750024795532, 1.1483898162841797, 1.5137795209884644, 1.1154091358184814, 1.4880952835083008, 1.0230809450149536, 1.140278697013855, 1.0881693363189697, 7.12662935256958, 1.0037569999694824, 1.1041964292526245, 1.0804446935653687, 1.0432517528533936, 1.3021210432052612, 1.076825499534607, 1.284615397453308, 1.0003374814987183, 1.0227599143981934, 1.156496286392212, 1.0625, 1.7219418287277222, 1.1514190435409546, 1.1818487644195557, 1.2592506408691406, 1.7954494953155518, 1.1033319234848022, 26.0, 1.150795817375183, 1.105022668838501, 1.1316686868667603, 1.423405647277832, 1.1376404762268066, 1.017344355583191, 1.052590250968933, 1.0298335552215576, 1.0381503105163574, 1.0774171352386475, 1.0712896585464478, 1.372549057006836, 1.325464129447937, 2.9170305728912354, 1.057410717010498, 1.288617730140686, 1.3317316770553589, 1.3776624202728271, 1.017557144165039, 2.9208273887634277, 1.1642839908599854, 1.1680666208267212, 1.1931183338165283, 1.2934751510620117, 1.5055432319641113, 3.652189016342163, 1.4709292650222778, 1.2994493246078491, 1.1222914457321167, 1.1402002573013306, 1.043770670890808]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7470757961273193] ms
 --  Average per query NF    [1.3682806491851807] ms
 --  Average per query vegas [2.3787951469421387] ms
Mean [1.558]  Median [1.158]  95th [2.874]  99th [10.699]  max [26.000]
Mean [1.558]  Median [1.158]  95th [2.874]  99th [10.699]  max [26.000]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.469573 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=1 | total-time=28.600417