Input arguments = Namespace(data_update='sample', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 90, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.156963586807251
tensor(0.9933)
result is  tensor(379601.6250)
Enter testHyper
ReportEsts: [1.1138789653778076, 1.0459699630737305, 1.4558603763580322, 1.192461609840393, 1.2742805480957031, 1.0798648595809937, 1.1192283630371094, 1.1882673501968384, 1.090661883354187, 1.0505391359329224, 1.198966383934021, 1.0345338582992554, 1.0201107263565063, 1.0401785373687744, 1.034347414970398, 1.406043291091919, 1.364872694015503, 1.1948931217193604, 1.0987941026687622, 1.0612244606018066, 1.2304739952087402, 1.0346866846084595, 1.15703547000885, 1.1988288164138794, 1.090664029121399, 1.1943942308425903, 1.1751126050949097, 1.2766798734664917, 1.1051545143127441, 1.060115933418274, 1.1411848068237305, 1.1322264671325684, 1.0302823781967163, 1.062979817390442, 1.1237852573394775, 1.1496262550354004, 1.2983964681625366, 1.0185023546218872, 1.1069849729537964, 1.0920958518981934, 1.0270717144012451, 1.057813286781311, 1.0184270143508911, 1.1281757354736328, 1.077118158340454, 1.0243902206420898, 1.0429250001907349, 1.2454513311386108, 1.1012177467346191, 1.1133671998977661, 1.2068063020706177, 1.3038365840911865, 1.053418517112732, 1.233239769935608, 1.2391022443771362, 1.0155308246612549, 1.278504729270935, 1.0733028650283813, 1.1731524467468262, 1.3417874574661255, 1.366570234298706, 1.1799452304840088, 1.2751168012619019, 1.0664564371109009, 1.2087912559509277, 1.085714340209961, 1.2379071712493896, 1.0108953714370728, 1.117843508720398, 1.378947377204895, 1.1660412549972534, 1.115018367767334, 1.1093295812606812, 1.2177760601043701, 1.1211713552474976, 1.2339972257614136, 1.9016284942626953, 1.065213680267334, 1.0616278648376465, 1.2362377643585205, 1.0800176858901978, 1.0746244192123413, 1.1421949863433838, 1.1286749839782715, 1.292057991027832, 1.0781059265136719, 1.011496663093567, 1.061286211013794, 1.0985028743743896, 1.1238908767700195, 1.0149624347686768, 1.3434971570968628, 1.0007212162017822, 1.245530605316162, 1.107954502105713, 1.1263362169265747, 1.1265466213226318, 1.3184906244277954, 1.0909091234207153, 1.2694504261016846, 1.1234568357467651, 1.0254157781600952, 1.0094223022460938, 1.0014641284942627, 1.0405857563018799, 1.036181092262268, 1.0425130128860474, 1.1902269124984741, 1.079871654510498, 1.027199625968933, 1.2656855583190918, 1.1015037298202515, 1.2052593231201172, 1.1236621141433716, 1.0927320718765259, 1.1237623691558838, 1.0059988498687744, 1.0297949314117432, 1.161411166191101, 1.0879582166671753, 1.2438836097717285, 1.099351406097412, 1.0341331958770752, 1.1797904968261719, 1.260658860206604, 1.1811803579330444, 1.0430625677108765, 1.3204667568206787, 1.2013996839523315, 1.0955244302749634, 1.1072036027908325, 1.1839287281036377, 1.2069607973098755, 1.5, 1.1931196451187134, 1.2039905786514282, 1.0078343152999878, 1.212357759475708, 1.102614164352417, 1.350035309791565, 1.1408730745315552, 1.01456618309021, 1.0431782007217407, 1.2486048936843872, 1.0502063035964966, 1.0081169605255127, 1.0615522861480713, 1.3498817682266235, 1.090532898902893, 1.0495028495788574, 1.0711443424224854, 1.1299833059310913, 1.3073248863220215, 1.1090905666351318, 1.156406044960022, 1.0305277109146118, 1.077725887298584, 1.0036578178405762, 1.0879149436950684, 1.2504923343658447, 1.121538758277893, 1.017087697982788, 1.2005990743637085, 1.3404864072799683, 1.1198102235794067, 1.1044254302978516, 1.3419102430343628, 1.165595293045044, 1.0621954202651978, 1.036005973815918, 1.0157010555267334, 1.0668652057647705, 1.1168831586837769, 1.176001787185669, 1.017677664756775, 1.039475917816162, 1.0087463855743408, 1.2601219415664673, 1.2386788129806519, 1.0874865055084229, 1.0481023788452148, 1.0401326417922974, 1.0067692995071411, 1.0071501731872559, 1.105034351348877, 1.1342494487762451, 1.0893436670303345, 1.2372589111328125, 1.0306949615478516, 1.4726766347885132, 1.0541423559188843, 1.0001217126846313, 1.6449568271636963, 1.354032278060913, 1.7249633073806763, 1.1611742973327637, 1.066235899925232, 1.1176470518112183, 1.0001270771026611, 1.119289517402649]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7616050243377686] ms
 --  Average per query NF    [1.3651776313781738] ms
 --  Average per query vegas [2.3964273929595947] ms
Mean [1.146]  Median [1.114]  95th [1.355]  99th [1.646]  max [1.902]
Mean [1.146]  Median [1.114]  95th [1.355]  99th [1.646]  max [1.902]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.800905 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=sample', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
Sample - START
Sample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[ 5.9604645e-08  1.6689301e-06  0.0000000e+00  1.3113022e-06
 -2.9802322e-08]
Distance score: 6.020069349688129e-07
SAUCE Drift detection: False
Detection latency: 0.0233s

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.017110 | Model-update-time: 0.000000


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=sample', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.206617593765259
tensor(0.9998)
result is  tensor(458514.5938)
Enter testHyper
ReportEsts: [1.0460623502731323, 1.021893858909607, 1.0864661931991577, 1.126939296722412, 1.094839334487915, 1.0821614265441895, 1.2412768602371216, 1.016414999961853, 1.1645920276641846, 1.0641402006149292, 1.0364927053451538, 1.106743335723877, 1.2853598594665527, 1.0805190801620483, 1.0391181707382202, 1.1496740579605103, 1.1498079299926758, 1.146240234375, 1.1652003526687622, 1.3864692449569702, 1.1175507307052612, 1.2092300653457642, 1.0466102361679077, 1.1869851350784302, 1.2615360021591187, 1.179189920425415, 1.0452477931976318, 1.2116183042526245, 1.3182679414749146, 1.482964277267456, 1.0310077667236328, 1.2127659320831299, 1.0343947410583496, 1.051076054573059, 1.083781361579895, 1.2354000806808472, 1.0873243808746338, 1.3366190195083618, 1.2527391910552979, 1.1451053619384766, 1.0560632944107056, 1.007383942604065, 1.0300178527832031, 1.0164378881454468, 1.0255836248397827, 1.1920511722564697, 1.1941182613372803, 1.0191090106964111, 1.13178288936615, 1.1663105487823486, 1.001265048980713, 1.094521403312683, 1.1720150709152222, 1.049078345298767, 1.0229939222335815, 1.4479212760925293, 1.1846193075180054, 1.1571550369262695, 1.2355018854141235, 1.106317162513733, 1.3312757015228271, 1.1017261743545532, 1.0129684209823608, 1.916223406791687, 1.1528209447860718, 1.0352059602737427, 1.2643487453460693, 1.108433723449707, 1.169514536857605, 1.1167901754379272, 1.1502094268798828, 1.244619369506836, 1.0645995140075684, 1.1769649982452393, 1.042009711265564, 1.0389899015426636, 1.0400900840759277, 1.0415738821029663, 1.1368274688720703, 1.1092886924743652, 1.1684659719467163, 1.2360423803329468, 1.0754517316818237, 1.2098087072372437, 1.3129346370697021, 1.3378839492797852, 1.2960094213485718, 1.5610606670379639, 1.0234336853027344, 1.1870167255401611, 1.1860082149505615, 1.0839204788208008, 1.4679020643234253, 1.0796372890472412, 1.1560823917388916, 1.0692716836929321, 1.0960050821304321, 1.1636483669281006, 1.348185658454895, 1.1615116596221924, 1.233903408050537, 1.096402645111084, 1.2105263471603394, 1.0648037195205688, 1.215895175933838, 1.000610113143921, 1.01164972782135, 1.1603776216506958, 1.209302306175232, 1.0316038131713867, 1.0323376655578613, 1.0559028387069702, 1.1920280456542969, 1.2006428241729736, 1.1642043590545654, 1.2548329830169678, 1.0930794477462769, 1.1033084392547607, 1.0809820890426636, 1.1355931758880615, 1.0643336772918701, 1.1435950994491577, 1.2035441398620605, 1.3005036115646362, 1.0682119131088257, 1.1798311471939087, 1.0179939270019531, 1.2426127195358276, 1.183868408203125, 1.0258145332336426, 1.1267175674438477, 1.0738621950149536, 1.0246437788009644, 1.7853881120681763, 1.75, 1.1195411682128906, 1.015770435333252, 1.2198888063430786, 1.1010819673538208, 1.0133949518203735, 1.075874924659729, 1.2016003131866455, 1.0112062692642212, 1.0987838506698608, 1.060113549232483, 1.1163731813430786, 1.470588207244873, 1.066989541053772, 1.0587762594223022, 1.0327987670898438, 1.225667953491211, 1.0841500759124756, 1.0838453769683838, 1.1466854810714722, 1.037324070930481, 1.091813087463379, 1.111995816230774, 1.2442748546600342, 1.0243852138519287, 1.213826060295105, 1.0084928274154663, 1.0437242984771729, 1.0465694665908813, 1.2496001720428467, 1.1302143335342407, 1.0077464580535889, 1.0027565956115723, 1.0011155605316162, 1.0191011428833008, 1.206482172012329, 1.1007921695709229, 1.144176721572876, 1.3447630405426025, 1.0424778461456299, 1.0677965879440308, 1.0096503496170044, 1.0944700241088867, 1.0976659059524536, 1.0225721597671509, 1.128834843635559, 1.4893616437911987, 1.173376202583313, 1.000953197479248, 1.5051647424697876, 1.3177977800369263, 1.2842767238616943, 1.2473245859146118, 1.0245461463928223, 1.3629642724990845, 1.0743666887283325, 1.0997008085250854, 1.120449423789978, 1.081140398979187, 1.683799386024475, 1.003146767616272, 1.0329915285110474, 1.1949505805969238, 1.106870174407959, 1.3355704545974731, 1.023922085762024]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.734595775604248] ms
 --  Average per query NF    [1.3588488101959229] ms
 --  Average per query vegas [2.375746965408325] ms
Mean [1.152]  Median [1.114]  95th [1.449]  99th [1.750]  max [1.916]
Mean [1.152]  Median [1.114]  95th [1.449]  99th [1.750]  max [1.916]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.267374 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=0 | total-time=26.141785