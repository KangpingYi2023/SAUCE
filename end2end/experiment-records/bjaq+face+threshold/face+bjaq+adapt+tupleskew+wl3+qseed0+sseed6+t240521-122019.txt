Input arguments = Namespace(data_update='tupleskew', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 6, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.20762300491333
tensor(0.9958)
result is  tensor(380555.1875)
Enter testHyper
ReportEsts: [1.060740351676941, 1.2021836042404175, 1.3854084014892578, 1.1547694206237793, 1.2632986307144165, 1.0798648595809937, 1.0686320066452026, 1.049298882484436, 1.0776351690292358, 1.129850149154663, 1.1050817966461182, 1.1434322595596313, 1.0328441858291626, 1.0223214626312256, 1.1434217691421509, 1.2741899490356445, 1.3296371698379517, 1.1076009273529053, 1.1476479768753052, 1.0714285373687744, 1.177125096321106, 1.088158130645752, 1.1567869186401367, 1.1208035945892334, 1.1030793190002441, 1.1202532052993774, 1.057150959968567, 1.3463943004608154, 1.0783926248550415, 1.1119927167892456, 1.212486743927002, 1.091133713722229, 1.136687159538269, 1.0316487550735474, 1.0619750022888184, 1.0753480195999146, 1.4048726558685303, 1.1823556423187256, 1.0859957933425903, 1.164790391921997, 1.0434316396713257, 1.2489114999771118, 1.0544439554214478, 1.0675580501556396, 1.07521653175354, 1.182539701461792, 1.0417304039001465, 1.2972872257232666, 1.2747904062271118, 1.1404399871826172, 1.277008295059204, 1.4174234867095947, 1.0246673822402954, 1.2054251432418823, 1.1947455406188965, 1.0169216394424438, 1.1710280179977417, 1.207403540611267, 1.3183211088180542, 1.3841361999511719, 1.3954499959945679, 1.2464691400527954, 1.4087907075881958, 1.150026798248291, 1.330645203590393, 1.2571429014205933, 1.1410373449325562, 1.0460540056228638, 1.0685876607894897, 1.3368420600891113, 1.1496379375457764, 1.0886976718902588, 1.266323208808899, 1.1664330959320068, 1.1033779382705688, 1.1394075155258179, 2.2670023441314697, 1.032137155532837, 1.1124005317687988, 1.4177143573760986, 1.194995403289795, 1.038927435874939, 1.0349737405776978, 1.1221575736999512, 1.213736653327942, 1.0716713666915894, 1.0965807437896729, 1.0756620168685913, 1.054409146308899, 1.036736011505127, 1.0461204051971436, 1.3360148668289185, 1.0420894622802734, 1.2708381414413452, 1.0955055952072144, 1.0847855806350708, 1.1351546049118042, 1.2462819814682007, 1.0, 1.026589274406433, 1.27173912525177, 1.2073947191238403, 1.2070138454437256, 1.0, 1.1031380891799927, 1.002882719039917, 1.261756181716919, 1.1972076892852783, 1.0931732654571533, 1.002763032913208, 1.2158435583114624, 1.0831793546676636, 1.1611394882202148, 1.0268265008926392, 1.1039758920669556, 1.0133928060531616, 1.025512933731079, 1.0371906757354736, 1.1824108362197876, 1.0104939937591553, 1.2229167222976685, 1.1284669637680054, 1.3127292394638062, 1.1238183975219727, 1.1351743936538696, 1.180870771408081, 1.1855249404907227, 1.2373812198638916, 1.3037974834442139, 1.1356045007705688, 1.214582920074463, 1.1849509477615356, 1.261653184890747, 1.5, 1.0547089576721191, 1.1388815641403198, 1.0077062845230103, 1.0468292236328125, 1.0404199361801147, 1.0765334367752075, 1.1676042079925537, 1.063289761543274, 1.2741931676864624, 1.3266137838363647, 1.0419681072235107, 1.0698047876358032, 1.0155749320983887, 1.4584506750106812, 1.1140059232711792, 1.0909091234207153, 1.0205515623092651, 1.1563901901245117, 1.3415032625198364, 1.1096919775009155, 1.1698908805847168, 1.1570100784301758, 1.0359784364700317, 1.023353934288025, 1.1562514305114746, 1.170337200164795, 1.1300601959228516, 1.0185058116912842, 1.0028270483016968, 1.2696477174758911, 1.20561945438385, 1.0263328552246094, 1.1913135051727295, 1.2374945878982544, 1.1465716361999512, 1.0337855815887451, 1.0444155931472778, 1.027610421180725, 1.1103895902633667, 1.1180962324142456, 1.136239767074585, 1.0840411186218262, 1.024781346321106, 1.2579313516616821, 1.1367818117141724, 1.0152199268341064, 1.1760228872299194, 1.0205203294754028, 1.0374873876571655, 1.0827374458312988, 1.1633466482162476, 1.0940803289413452, 1.0303195714950562, 1.315635323524475, 1.0272966623306274, 1.1521285772323608, 1.1184006929397583, 1.0517160892486572, 1.6160815954208374, 1.3012140989303589, 1.523274302482605, 1.1955583095550537, 1.068361759185791, 1.1176470518112183, 1.1932286024093628, 1.1260623931884766]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7688076496124268] ms
 --  Average per query NF    [1.3597702980041504] ms
 --  Average per query vegas [2.4090373516082764] ms
Mean [1.155]  Median [1.129]  95th [1.386]  99th [1.524]  max [2.267]
Mean [1.155]  Median [1.129]  95th [1.386]  99th [1.524]  max [2.267]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.916867 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=tupleskew', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
TupleSkewSample - START
0.001
TupleSkewSample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[5.0723553e-05 1.4042854e-04 2.7179718e-05 3.7235022e-04 5.1736832e-05]
Distance score: 0.00012848377809859812
SAUCE Drift detection: True
Detection latency: 0.0228s

DRIFT-DETECTED after 2-th workload
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/incremental_train.py', '--dataset=bjaq', '--end2end', '--model=face', '--model_update=adapt', '--update_size=80000', '--epochs=0']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
update_size: 76433
AdaptTask - START
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
train data shape: 80000, transfer data shape:16000
Training done; evaluating likelihood on full data:
Saved to: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
AdaptTask - END

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 1.994074 | Model-update-time: 2.233676


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=tupleskew', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.173237800598145
tensor(0.9941)
result is  tensor(455901.7812)
Enter testHyper
ReportEsts: [1.1263728141784668, 1.058057188987732, 1.04283607006073, 1.7885905504226685, 1.1351683139801025, 1.0356553792953491, 1.2843536138534546, 1.146787405014038, 1.3571878671646118, 1.098658561706543, 1.096494436264038, 1.210947871208191, 1.427570104598999, 1.3682310581207275, 1.105306625366211, 1.0601524114608765, 1.0577396154403687, 1.2333093881607056, 1.0411995649337769, 1.1839830875396729, 1.1801013946533203, 1.6920634508132935, 1.4961568117141724, 1.0639406442642212, 1.0480833053588867, 1.2399638891220093, 1.001281976699829, 1.047118067741394, 1.1666666269302368, 1.5553746223449707, 1.4102563858032227, 1.460829496383667, 1.0182195901870728, 1.032950758934021, 1.0302573442459106, 1.0539132356643677, 1.1717181205749512, 1.1455938816070557, 2.8235294818878174, 1.003152847290039, 1.0262447595596313, 1.2758620977401733, 1.1029342412948608, 1.122360348701477, 1.0423842668533325, 1.2682271003723145, 1.299272060394287, 1.0943117141723633, 1.3476190567016602, 1.0018994808197021, 1.016730785369873, 1.019386649131775, 1.192764163017273, 1.061618685722351, 1.09812593460083, 1.0697886943817139, 1.2312391996383667, 1.171431064605713, 1.4052674770355225, 1.0382099151611328, 1.1477515697479248, 1.1268975734710693, 1.122676134109497, 1.1735522747039795, 1.0249781608581543, 1.0404763221740723, 1.4823614358901978, 1.0840327739715576, 1.132866382598877, 1.0821977853775024, 1.036621332168579, 1.306854486465454, 1.072418451309204, 1.1576974391937256, 1.7401574850082397, 1.015292763710022, 1.1036977767944336, 1.0582829713821411, 1.2729414701461792, 1.0269290208816528, 1.1736900806427002, 1.0902999639511108, 1.0377241373062134, 1.090744972229004, 1.4257783889770508, 1.6510637998580933, 1.0458831787109375, 1.6772540807724, 1.0515550374984741, 1.189071536064148, 1.2013837099075317, 1.2589040994644165, 1.3212538957595825, 1.1737780570983887, 1.2240729331970215, 1.0918586254119873, 1.0730727910995483, 1.3305891752243042, 1.1284011602401733, 1.1374601125717163, 1.1626701354980469, 1.0380531549453735, 1.4188861846923828, 1.142432451248169, 1.049012541770935, 1.210907220840454, 1.121912956237793, 1.0615187883377075, 1.0286532640457153, 1.048867106437683, 1.1334434747695923, 1.052933692932129, 1.0960699319839478, 1.1329199075698853, 1.0396982431411743, 1.0261999368667603, 1.2085801362991333, 1.4166589975357056, 1.067221999168396, 1.212389349937439, 1.04192316532135, 1.1748878955841064, 1.0517531633377075, 1.560226321220398, 1.0221210718154907, 1.332621455192566, 1.1236366033554077, 1.0449612140655518, 1.0520944595336914, 1.142109990119934, 1.148363471031189, 1.085459589958191, 1.0822347402572632, 2.1863980293273926, 1.265965461730957, 1.301224946975708, 1.0518968105316162, 1.4147554636001587, 1.015631914138794, 1.0564298629760742, 1.036834955215454, 1.0665956735610962, 1.0698182582855225, 1.0112051963806152, 1.0337724685668945, 1.201012372970581, 2.3389830589294434, 1.048377513885498, 1.2322735786437988, 1.0057480335235596, 1.0066255331039429, 1.086998701095581, 1.1724181175231934, 1.082452654838562, 1.091618299484253, 1.0689178705215454, 1.0929220914840698, 1.0223881006240845, 1.3699826002120972, 1.2393921613693237, 1.000630259513855, 1.156508207321167, 1.410833477973938, 1.1674896478652954, 1.2095342874526978, 1.1044049263000488, 1.018385410308838, 1.2766724824905396, 1.1187007427215576, 1.31806218624115, 1.0343475341796875, 1.105364441871643, 1.6265140771865845, 1.0219818353652954, 1.084316611289978, 1.0535961389541626, 1.1964539289474487, 1.0342158079147339, 1.1055477857589722, 1.0875555276870728, 1.763157844543457, 1.1285178661346436, 1.289727807044983, 1.5102717876434326, 1.3320142030715942, 1.2246320247650146, 1.1034783124923706, 1.2139594554901123, 1.3830740451812744, 1.0222480297088623, 1.1010832786560059, 1.0990098714828491, 1.2290266752243042, 2.151528835296631, 1.115978479385376, 1.0735907554626465, 1.7284729480743408, 1.1718614101409912, 1.0541400909423828, 1.0149284601211548]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.71920108795166] ms
 --  Average per query NF    [1.361006498336792] ms
 --  Average per query vegas [2.358194589614868] ms
Mean [1.195]  Median [1.120]  95th [1.652]  99th [2.188]  max [2.824]
Mean [1.195]  Median [1.120]  95th [1.652]  99th [2.188]  max [2.824]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.375294 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=1 | total-time=28.544537