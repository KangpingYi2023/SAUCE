Input arguments = Namespace(data_update='valueskew', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 69, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.164470672607422
tensor(0.9963)
result is  tensor(380771.6562)
Enter testHyper
ReportEsts: [1.1449071168899536, 1.02082359790802, 1.320886254310608, 1.1888818740844727, 1.2444379329681396, 1.128704309463501, 1.2782624959945679, 1.0612801313400269, 1.0418591499328613, 1.0068566799163818, 1.0274336338043213, 1.1866525411605835, 1.0674010515213013, 1.046875, 1.1496894359588623, 1.2726285457611084, 1.3184959888458252, 1.2033253908157349, 1.2556865215301514, 1.0586735010147095, 1.238573431968689, 1.0511212348937988, 1.1457136869430542, 1.0814319849014282, 1.0722862482070923, 1.14647376537323, 1.0084459781646729, 1.3916414976119995, 1.0060629844665527, 1.110263466835022, 1.115643858909607, 1.135119080543518, 1.0551127195358276, 1.1523832082748413, 1.1289325952529907, 1.0238336324691772, 1.4571222066879272, 1.2178293466567993, 1.040155053138733, 1.1056287288665771, 1.0549620389938354, 1.1676342487335205, 1.0295631885528564, 1.051450490951538, 1.0935981273651123, 1.0793651342391968, 1.1965869665145874, 1.4008828401565552, 1.0500553846359253, 1.1353638172149658, 1.1820513010025024, 1.365079402923584, 1.0153287649154663, 1.0998331308364868, 1.1383129358291626, 1.0421881675720215, 1.241121530532837, 1.1277563571929932, 1.061390995979309, 1.4409856796264648, 1.3580421209335327, 1.1236693859100342, 1.3687430620193481, 1.1386442184448242, 1.235954999923706, 1.2000000476837158, 1.2342519760131836, 1.0275315046310425, 1.1545528173446655, 1.3263157606124878, 1.0560747385025024, 1.0169748067855835, 1.1899118423461914, 1.0666728019714355, 1.0214753150939941, 1.0851718187332153, 1.9196034669876099, 1.0181629657745361, 1.0652894973754883, 1.3189070224761963, 1.1363445520401, 1.0266516208648682, 1.0387260913848877, 1.1682277917861938, 1.2452806234359741, 1.002716064453125, 1.0696189403533936, 1.2143253087997437, 1.087942123413086, 1.0261216163635254, 1.0092425346374512, 1.351063847541809, 1.0248827934265137, 1.2711316347122192, 1.1538461446762085, 1.129858374595642, 1.0232549905776978, 1.3927133083343506, 1.0526316165924072, 1.2138376235961914, 1.1767241954803467, 1.1878347396850586, 1.0323306322097778, 1.0051507949829102, 1.0363143682479858, 1.0514554977416992, 1.2425388097763062, 1.1832460165023804, 1.0279604196548462, 1.0895634889602661, 1.422202467918396, 1.0902326107025146, 1.167156457901001, 1.0463718175888062, 1.1256520748138428, 1.1293532848358154, 1.109167218208313, 1.0015501976013184, 1.2714887857437134, 1.0984880924224854, 1.1897917985916138, 1.0678901672363281, 1.180769443511963, 1.3630009889602661, 1.2761627435684204, 1.2111018896102905, 1.1748396158218384, 1.3253129720687866, 1.355263113975525, 1.1312625408172607, 1.140554428100586, 1.1040887832641602, 1.264139175415039, 1.4285714626312256, 1.1773806810379028, 1.0157521963119507, 1.074041724205017, 1.119674801826477, 1.0051132440567017, 1.2519633769989014, 1.1361939907073975, 1.1101433038711548, 1.050015926361084, 1.2278776168823242, 1.1989681720733643, 1.025917410850525, 1.2941604852676392, 1.2425013780593872, 1.1645159721374512, 1.0689630508422852, 1.1360228061676025, 1.2425329685211182, 1.2915574312210083, 1.0879573822021484, 1.1510865688323975, 1.082654595375061, 1.032412052154541, 1.05543053150177, 1.0579373836517334, 1.158758521080017, 1.216843605041504, 1.0580159425735474, 1.113558292388916, 1.329077959060669, 1.2259740829467773, 1.137657642364502, 1.3217463493347168, 1.1946622133255005, 1.1503441333770752, 1.0499976873397827, 1.02707040309906, 1.0283904075622559, 1.1688311100006104, 1.0185030698776245, 1.053133487701416, 1.0266497135162354, 1.0167983770370483, 1.3384971618652344, 1.0928959846496582, 1.0709216594696045, 1.0412094593048096, 1.0268816947937012, 1.01676344871521, 1.18079674243927, 1.1542918682098389, 1.1088794469833374, 1.2994567155838013, 1.2536636590957642, 1.0477782487869263, 1.3537756204605103, 1.048670768737793, 1.1859947443008423, 1.378411054611206, 1.5370765924453735, 1.6808905601501465, 1.1667670011520386, 1.1431013345718384, 1.1014492511749268, 1.2051242589950562, 1.1489708423614502]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7835419178009033] ms
 --  Average per query NF    [1.368640661239624] ms
 --  Average per query vegas [2.4149012565612793] ms
Mean [1.156]  Median [1.135]  95th [1.379]  99th [1.539]  max [1.920]
Mean [1.156]  Median [1.135]  95th [1.379]  99th [1.539]  max [1.920]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.831102 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=valueskew', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
ValueSample - START
ValueSample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[5.9604645e-08 2.9802322e-07 3.5762787e-07 7.7486038e-07 1.6690135e-02]
Distance score: 0.0033383250702172518
SAUCE Drift detection: True
Detection latency: 0.0233s

DRIFT-DETECTED after 2-th workload
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/incremental_train.py', '--dataset=bjaq', '--end2end', '--model=face', '--model_update=adapt', '--update_size=80000', '--epochs=0']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
update_size: 76433
AdaptTask - START
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
train data shape: 80000, transfer data shape:16000
Training done; evaluating likelihood on full data:
Saved to: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
AdaptTask - END

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.046215 | Model-update-time: 2.228292


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=valueskew', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.170197010040283
tensor(0.9982)
result is  tensor(457775.9688)
Enter testHyper
ReportEsts: [1.1621099710464478, 1.0879297256469727, 1.1988716125488281, 6.057029724121094, 1.0144251585006714, 2.7647924423217773, 1.2722104787826538, 1.199886441230774, 1.1559175252914429, 1.0584192276000977, 1.0070950984954834, 1.3145968914031982, 1.0320197343826294, 1.1661708354949951, 1.146026849746704, 1.2421793937683105, 10.101075172424316, 1.0912482738494873, 1.0023198127746582, 1.0950851440429688, 1.0837551355361938, 9.598326683044434, 3.8118813037872314, 1.0521334409713745, 1.0640438795089722, 1.4571377038955688, 1.1022260189056396, 1.318718433380127, 1.9819587469100952, 1.4962025880813599, 1.4562937021255493, 1.5593219995498657, 1.1484087705612183, 114.62616729736328, 1.0106364488601685, 1.0067918300628662, 1.2353391647338867, 1.1181970834732056, 1.087416172027588, 1.1847697496414185, 1.025935173034668, 1.200510859489441, 63.81904602050781, 1.106881022453308, 1.3111997842788696, 1.1922969818115234, 1.0046747922897339, 1.118952751159668, 1.2857142686843872, 1.163313627243042, 1.0928447246551514, 1.2295377254486084, 1.1419769525527954, 1.2312270402908325, 1.1342573165893555, 1.492935061454773, 1.0316728353500366, 1.08029043674469, 1.2675679922103882, 1.1153161525726318, 3.7605321407318115, 1.0135059356689453, 1.0964018106460571, 2.787060260772705, 1.010103702545166, 1.0752651691436768, 1.4201949834823608, 1.0736743211746216, 1.2497445344924927, 1.0984605550765991, 1.112076759338379, 1.0307844877243042, 1.1849204301834106, 1.2297874689102173, 1.0065158605575562, 1.209175705909729, 1.1665363311767578, 1.0919004678726196, 1.246107578277588, 1.1080938577651978, 1.1890532970428467, 1.0232292413711548, 1.3850637674331665, 1.3380166292190552, 1.4604233503341675, 1.612765908241272, 1.49893319606781, 1.6375765800476074, 1.1728184223175049, 17.64200210571289, 1.0842105150222778, 1.0472640991210938, 2.287872076034546, 1.126700758934021, 1.3011776208877563, 1.0297693014144897, 1.025555968284607, 1.3388466835021973, 1.6128631830215454, 1.8260478973388672, 1.444547176361084, 1.1173113584518433, 1.2617801427841187, 1.4235432147979736, 1.0083341598510742, 1.074751853942871, 1.0303435325622559, 1.0829265117645264, 1.1243094205856323, 1.1150381565093994, 1.0839340686798096, 1.105308175086975, 1.046356201171875, 1.3186993598937988, 1.3512293100357056, 1.304822325706482, 1.369912028312683, 1.3752377033233643, 1.5146547555923462, 1.1415929794311523, 1.0223363637924194, 1.1540848016738892, 1.1105046272277832, 3.58479380607605, 1.0106415748596191, 1.1935945749282837, 1.225183129310608, 1.284810185432434, 1.2670738697052002, 1.5972883701324463, 1.1381585597991943, 1.3093243837356567, 1.0976086854934692, 5.538601398468018, 1.4570248126983643, 1.2609055042266846, 1.2324377298355103, 1.0445688962936401, 1.0147595405578613, 1.0015815496444702, 1.1587533950805664, 1.090742826461792, 1.0133479833602905, 1.1175155639648438, 1.002518653869629, 1.3336211442947388, 1.2196531295776367, 1.0328760147094727, 1.2682768106460571, 1.2323087453842163, 1.264713168144226, 1.0382636785507202, 1.2848562002182007, 1.0347908735275269, 1.0031986236572266, 1.0296809673309326, 1.2758466005325317, 1.3279999494552612, 2.2023463249206543, 1.1375713348388672, 1.0962845087051392, 1.3321428298950195, 3.0553359985351562, 1.0286201238632202, 1.2287760972976685, 1.9121339321136475, 1.279378056526184, 1.1055063009262085, 1.2432368993759155, 1.3764424324035645, 1.0386072397232056, 1.076226830482483, 1.2697182893753052, 1.2545901536941528, 1.080814003944397, 1.1439971923828125, 1.132112741470337, 1.2426022291183472, 1.0422521829605103, 1.4374834299087524, 1.605263113975525, 1.2267539501190186, 1.0624526739120483, 1.6488171815872192, 2.4441633224487305, 1.2954940795898438, 4.26311731338501, 1.053283929824829, 2.446058511734009, 1.0146795511245728, 1.1262174844741821, 1.0908942222595215, 1.2019007205963135, 1.5623562335968018, 1.1091679334640503, 1.5873903036117554, 1.215217113494873, 1.0462394952774048, 2.0924370288848877, 1.0558949708938599]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7379372119903564] ms
 --  Average per query NF    [1.362447738647461] ms
 --  Average per query vegas [2.3754894733428955] ms
Mean [2.403]  Median [1.185]  95th [3.594]  99th [18.104]  max [114.626]
Mean [2.403]  Median [1.185]  95th [3.594]  99th [18.104]  max [114.626]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.393822 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=1 | total-time=28.524259