Input arguments = Namespace(data_update='valueskew', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 53, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.163225650787354
tensor(0.9943)
result is  tensor(379974.6250)
Enter testHyper
ReportEsts: [1.1629036664962769, 1.009324550628662, 1.4764496088027954, 1.2680563926696777, 1.2093883752822876, 1.1464823484420776, 1.0830587148666382, 1.2063450813293457, 1.066489338874817, 1.1130682229995728, 1.140396237373352, 1.072245717048645, 1.1517906188964844, 1.0491071939468384, 1.0606776475906372, 1.2246073484420776, 1.3583711385726929, 1.322921633720398, 1.0883580446243286, 1.0280612707138062, 1.0034499168395996, 1.0673624277114868, 1.1102865934371948, 1.0019558668136597, 1.2468348741531372, 1.0967450141906738, 1.0489864349365234, 1.3709677457809448, 1.0316122770309448, 1.0049842596054077, 1.0986164808273315, 1.0629642009735107, 1.2541269063949585, 1.0213720798492432, 1.1491929292678833, 1.1167223453521729, 1.4461698532104492, 1.2141960859298706, 1.22925865650177, 1.2148503065109253, 1.0210341215133667, 1.0919206142425537, 1.0017240047454834, 1.0091135501861572, 1.0504964590072632, 1.231292486190796, 1.00704026222229, 1.3562548160552979, 1.1965444087982178, 1.1421319246292114, 1.249322533607483, 1.335234522819519, 1.004441261291504, 1.2117034196853638, 1.173008918762207, 1.1161335706710815, 1.2009345293045044, 1.1478304862976074, 1.2965601682662964, 1.3300080299377441, 1.3746017217636108, 1.1333683729171753, 1.255436897277832, 1.286237120628357, 1.2992125749588013, 1.3428571224212646, 1.0654205083847046, 1.005625605583191, 1.1735819578170776, 1.4631578922271729, 1.023045301437378, 1.0516245365142822, 1.3086949586868286, 1.098544955253601, 1.112945318222046, 1.1004745960235596, 1.926034688949585, 1.0062663555145264, 1.0025228261947632, 1.1748130321502686, 1.3267546892166138, 1.1061217784881592, 1.006471037864685, 1.1962683200836182, 1.2192682027816772, 1.1591782569885254, 1.183560848236084, 1.0838840007781982, 1.1078102588653564, 1.0437017679214478, 1.0994962453842163, 1.3109819889068604, 1.0018031597137451, 1.255760908126831, 1.1271675825119019, 1.0357469320297241, 1.0977444648742676, 1.3706319332122803, 1.0526316165924072, 1.1435258388519287, 1.27173912525177, 1.1295469999313354, 1.1088720560073853, 1.0234260559082031, 1.0879707336425781, 1.0831220149993896, 1.0119521617889404, 1.2181501388549805, 1.0412136316299438, 1.0123542547225952, 1.0135071277618408, 1.0882079601287842, 1.1107982397079468, 1.0888392925262451, 1.1140605211257935, 1.2010581493377686, 1.012374997138977, 1.0689369440078735, 1.3298616409301758, 1.1827270984649658, 1.2999799251556396, 1.099420428276062, 1.0470761060714722, 1.1267497539520264, 1.2034883499145508, 1.2194592952728271, 1.1323713064193726, 1.0811388492584229, 1.3446475267410278, 1.1092184782028198, 1.0171736478805542, 1.1663209199905396, 1.2495338916778564, 1.4285714626312256, 1.0446059703826904, 1.1186662912368774, 1.0374590158462524, 1.1931707859039307, 1.1186624765396118, 1.0094987154006958, 1.0845736265182495, 1.106199860572815, 1.1293641328811646, 1.3037145137786865, 1.0971096754074097, 1.0422706604003906, 1.0791783332824707, 1.529433250427246, 1.0261465311050415, 1.063068151473999, 1.2928433418273926, 1.1616458892822266, 1.3017970323562622, 1.176641583442688, 1.0616130828857422, 1.0069961547851562, 1.017989158630371, 1.0073696374893188, 1.0166666507720947, 1.1898537874221802, 1.1605629920959473, 1.0521708726882935, 1.1449211835861206, 1.1951531171798706, 1.106682300567627, 1.1179178953170776, 1.3017749786376953, 1.3212803602218628, 1.0960302352905273, 1.0521388053894043, 1.0189751386642456, 1.0403038263320923, 1.103896141052246, 1.066265344619751, 1.0262261629104614, 1.0444964170455933, 1.0612244606018066, 1.1629167795181274, 1.2113322019577026, 1.3289474248886108, 1.05757474899292, 1.1418545246124268, 1.010776400566101, 1.1021450757980347, 1.1318362951278687, 1.121564507484436, 1.0730546712875366, 1.2882753610610962, 1.0242105722427368, 1.3151323795318604, 1.0278838872909546, 1.038056492805481, 1.479906678199768, 1.2716485261917114, 1.625736951828003, 1.1577061414718628, 1.0860358476638794, 1.085714340209961, 1.1008082628250122, 1.124668002128601]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.76196026802063] ms
 --  Average per query NF    [1.3569283485412598] ms
 --  Average per query vegas [2.40503191947937] ms
Mean [1.151]  Median [1.114]  95th [1.371]  99th [1.530]  max [1.926]
Mean [1.151]  Median [1.114]  95th [1.371]  99th [1.530]  max [1.926]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.820193 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=valueskew', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
ValueSample - START
ValueSample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[9.5367432e-07 1.1920929e-07 3.5762787e-07 1.2031019e-02 1.7881393e-07]
Distance score: 0.00240652565844357
SAUCE Drift detection: True
Detection latency: 0.0233s

DRIFT-DETECTED after 2-th workload
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/incremental_train.py', '--dataset=bjaq', '--end2end', '--model=face', '--model_update=adapt', '--update_size=80000', '--epochs=0']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
update_size: 76433
AdaptTask - START
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
train data shape: 80000, transfer data shape:16000
Training done; evaluating likelihood on full data:
Saved to: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
AdaptTask - END

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.048956 | Model-update-time: 2.224466


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=valueskew', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.170188426971436
tensor(0.9993)
result is  tensor(458298.7812)
Enter testHyper
ReportEsts: [1.224514126777649, 1.0126549005508423, 1.938524603843689, 2.203662395477295, 1.16960871219635, 1.256208896636963, 1.2924593687057495, 1.0696682929992676, 1.1396652460098267, 1.0449851751327515, 1.019973874092102, 1.9959361553192139, 1.0219511985778809, 1.2805105447769165, 1.0205954313278198, 1.0529470443725586, 3.8888888359069824, 1.276513934135437, 1.3185973167419434, 1.2910518646240234, 1.3487133979797363, 1.8085601329803467, 1.150274395942688, 1.0993154048919678, 1.0980786085128784, 1.1760737895965576, 1.0868669748306274, 1.1676729917526245, 2.909911632537842, 1.7680569887161255, 1.6037296056747437, 1.0279330015182495, 1.0683071613311768, 1.0291757583618164, 1.0262703895568848, 1.1504098176956177, 1.3434600830078125, 1.1005645990371704, 1.1233372688293457, 1.068611741065979, 1.1868497133255005, 1.0732557773590088, 15.091863632202148, 1.0524239540100098, 1.0494869947433472, 1.072994589805603, 1.1922626495361328, 1.1333004236221313, 1.3904762268066406, 1.23099684715271, 1.0604749917984009, 1.174058198928833, 1.1315317153930664, 1.0088870525360107, 1.0007531642913818, 5.294770240783691, 1.0382628440856934, 1.176618218421936, 1.1060760021209717, 1.075330138206482, 1.954787254333496, 1.0007333755493164, 1.0486725568771362, 3.1516611576080322, 1.0925105810165405, 1.1444079875946045, 1.399032473564148, 1.0127347707748413, 1.0256255865097046, 1.037979006767273, 1.3744604587554932, 1.5922516584396362, 1.00273859500885, 1.0355829000473022, 1.1027501821517944, 8.283387184143066, 1.2783136367797852, 1.267875075340271, 1.1788794994354248, 1.1321178674697876, 1.0325534343719482, 1.1799381971359253, 1.065141201019287, 1.2859967947006226, 1.116611123085022, 1.2862191200256348, 1.7393157482147217, 2.266317844390869, 1.5178873538970947, 2.5636751651763916, 2.298065185546875, 1.5852375030517578, 1.0527608394622803, 1.4336602687835693, 10.925714492797852, 1.0459715127944946, 1.0012028217315674, 1.2632337808609009, 1.3519248962402344, 1.1292134523391724, 1.1870497465133667, 1.1025168895721436, 1.0073529481887817, 1.1237223148345947, 1.030247688293457, 1.6011601686477661, 1.1937434673309326, 1.1116571426391602, 1.0264705419540405, 1.1187331676483154, 1.3408677577972412, 1.0776418447494507, 1.3240491151809692, 1.1925872564315796, 1.2597014904022217, 1.1716816425323486, 1.1447908878326416, 1.5866767168045044, 1.1073405742645264, 1.0884956121444702, 1.0263421535491943, 1.2629283666610718, 1.0894875526428223, 1.4203227758407593, 1.0918021202087402, 1.3234280347824097, 1.1628202199935913, 1.3706070184707642, 1.0558735132217407, 1.0557360649108887, 1.0598891973495483, 1.1283034086227417, 1.0471522808074951, 1.5056284666061401, 1.2483165264129639, 1.1968580484390259, 1.0670528411865234, 1.1852833032608032, 1.0824880599975586, 1.0229135751724243, 1.0868974924087524, 1.1290677785873413, 1.0488083362579346, 1.03045654296875, 1.0051933526992798, 1.2660818099975586, 1.2267441749572754, 1.0915791988372803, 1.0351386070251465, 1.0636903047561646, 11.596634864807129, 1.2182434797286987, 1.2872439622879028, 1.0125771760940552, 1.0099655389785767, 1.5357142686843872, 1.2666758298873901, 1.4365079402923584, 1.4067933559417725, 1.09821617603302, 1.0044697523117065, 1.0148261785507202, 1.1423394680023193, 1.1900973320007324, 1.1326282024383545, 1.0084433555603027, 1.0380827188491821, 1.2465574741363525, 1.0550463199615479, 1.4017099142074585, 1.1400848627090454, 1.360385775566101, 1.3682880401611328, 2.3280251026153564, 1.4984924793243408, 1.1267937421798706, 1.1706596612930298, 1.0740667581558228, 1.187873363494873, 1.2200967073440552, 1.736842155456543, 1.2683615684509277, 1.0141034126281738, 1.6886895895004272, 1.3996449708938599, 1.541314721107483, 1.1102099418640137, 1.2686617374420166, 1.4775077104568481, 1.2242631912231445, 1.0200990438461304, 1.1626484394073486, 1.1643472909927368, 2.3556969165802, 1.2638195753097534, 1.0372508764266968, 2.780756950378418, 6.038167953491211, 1.1201353073120117, 1.0948103666305542]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.725937604904175] ms
 --  Average per query NF    [1.355806589126587] ms
 --  Average per query vegas [2.370131015777588] ms
Mean [1.525]  Median [1.163]  95th [2.575]  99th [10.932]  max [15.092]
Mean [1.525]  Median [1.163]  95th [2.575]  99th [10.932]  max [15.092]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.365757 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=1 | total-time=28.499936