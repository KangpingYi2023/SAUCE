Input arguments = Namespace(data_update='sample', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 48, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.165439367294312
tensor(0.9959)
result is  tensor(380617.3125)
Enter testHyper
ReportEsts: [1.131849765777588, 1.0779833793640137, 1.131956934928894, 1.058959722518921, 1.2750450372695923, 1.0988844633102417, 1.3167951107025146, 1.0879850387573242, 1.1211556196212769, 1.192551612854004, 1.0430662631988525, 1.0298728942871094, 1.0874440670013428, 1.0424107313156128, 1.0341577529907227, 1.1735624074935913, 1.3445924520492554, 1.2306413650512695, 1.1630016565322876, 1.1607142686843872, 1.0981870889663696, 1.056054711341858, 1.123956561088562, 1.0831998586654663, 1.1597647666931152, 1.1220614910125732, 1.042511224746704, 1.3514643907546997, 1.022113561630249, 1.0199190378189087, 1.134799599647522, 1.1988942623138428, 1.241742730140686, 1.0495589971542358, 1.0969362258911133, 1.16533625125885, 1.4424484968185425, 1.1079072952270508, 1.0704666376113892, 1.0816766023635864, 1.0334104299545288, 1.1282051801681519, 1.068387746810913, 1.01118803024292, 1.0346503257751465, 1.0512515306472778, 1.1112492084503174, 1.4757978916168213, 1.2687805891036987, 1.1218273639678955, 1.1943005323410034, 1.3589165210723877, 1.000704288482666, 1.3828670978546143, 1.2287936210632324, 1.018080711364746, 1.3037383556365967, 1.0439437627792358, 1.0994175672531128, 1.3761354684829712, 1.2159168720245361, 1.2374439239501953, 1.21316659450531, 1.1710447072982788, 1.3200000524520874, 1.2857142686843872, 1.1931493282318115, 1.0263268947601318, 1.1604869365692139, 1.3157894611358643, 1.0289734601974487, 1.2382560968399048, 1.2288426160812378, 1.1352461576461792, 1.0536203384399414, 1.307134747505188, 1.967512607574463, 1.0003459453582764, 1.239303469657898, 1.2623642683029175, 1.2518210411071777, 1.183653712272644, 1.0465011596679688, 1.1994162797927856, 1.2669034004211426, 1.0947507619857788, 1.096418857574463, 1.2216898202896118, 1.0391196012496948, 1.0592918395996094, 1.087388515472412, 1.3475701808929443, 1.0243812799453735, 1.366434931755066, 1.0317460298538208, 1.0276157855987549, 1.115867018699646, 1.2350261211395264, 1.01694917678833, 1.1613144874572754, 1.2409090995788574, 1.0971835851669312, 1.0664247274398804, 1.002196192741394, 1.0345200300216675, 1.0106855630874634, 1.1644418239593506, 1.1727749109268188, 1.0412583351135254, 1.0830423831939697, 1.0721654891967773, 1.1109005212783813, 1.010851502418518, 1.0256105661392212, 1.0985279083251953, 1.140703558921814, 1.0747708082199097, 1.0844833850860596, 1.3317039012908936, 1.2560498714447021, 1.4231871366500854, 1.0882433652877808, 1.0976195335388184, 1.110223650932312, 1.2562984228134155, 1.1733388900756836, 1.220423698425293, 1.0910004377365112, 1.2789734601974487, 1.12625253200531, 1.239317774772644, 1.166175127029419, 1.1942200660705566, 1.5, 1.0297750234603882, 1.0438435077667236, 1.1078968048095703, 1.0591869354248047, 1.052248239517212, 1.1393686532974243, 1.1069241762161255, 1.1603349447250366, 1.1239535808563232, 1.1883423328399658, 1.1130176782608032, 1.0356780290603638, 1.0731064081192017, 1.8010681867599487, 1.0027446746826172, 1.150781273841858, 1.1775025129318237, 1.2185617685317993, 1.306631326675415, 1.1347177028656006, 1.1674755811691284, 1.0055890083312988, 1.2624953985214233, 1.0672482252120972, 1.033983588218689, 1.193613886833191, 1.105724811553955, 1.1903891563415527, 1.0671306848526, 1.2818057537078857, 1.1712158918380737, 1.0585079193115234, 1.0785903930664062, 1.317028284072876, 1.0306161642074585, 1.046271562576294, 1.0744497776031494, 1.0348833799362183, 1.1558442115783691, 1.1548793315887451, 1.0841280221939087, 1.025206208229065, 1.033132553100586, 1.3228976726531982, 1.0990262031555176, 1.260164737701416, 1.1854318380355835, 1.063938021659851, 1.0118359327316284, 1.046986699104309, 1.1807316541671753, 1.0961945056915283, 1.0241975784301758, 1.3161171674728394, 1.1312662363052368, 1.3618367910385132, 1.0085333585739136, 1.0836660861968994, 1.6907583475112915, 1.2079136371612549, 1.5358906984329224, 1.1653637886047363, 1.0313464403152466, 1.1515151262283325, 1.0198304653167725, 1.1225099563598633]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.74994158744812] ms
 --  Average per query NF    [1.3614583015441895] ms
 --  Average per query vegas [2.3884832859039307] ms
Mean [1.156]  Median [1.122]  95th [1.367]  99th [1.692]  max [1.968]
Mean [1.156]  Median [1.122]  95th [1.367]  99th [1.692]  max [1.968]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.816147 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=sample', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
Sample - START
Sample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[3.7550926e-06 6.5565109e-07 1.4901161e-06 2.2053719e-06 5.9604645e-08]
Distance score: 1.6331672441083356e-06
SAUCE Drift detection: False
Detection latency: 0.0234s

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.028723 | Model-update-time: 0.000000


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=sample', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.217384815216064
tensor(0.9938)
result is  tensor(455735.2812)
Enter testHyper
ReportEsts: [1.1051840782165527, 1.0326716899871826, 1.2609351873397827, 1.2248061895370483, 1.0283406972885132, 1.3731547594070435, 1.200530767440796, 1.0484437942504883, 1.268599271774292, 1.206556797027588, 1.087991714477539, 1.2997353076934814, 1.1792452335357666, 1.1837983131408691, 1.0734449625015259, 1.1010801792144775, 1.261295199394226, 1.1014553308486938, 1.0674681663513184, 1.446397066116333, 1.1098357439041138, 1.7634161710739136, 1.021238923072815, 1.219106912612915, 1.302600383758545, 1.2129545211791992, 1.0010533332824707, 1.1419203281402588, 1.1189619302749634, 1.3668500185012817, 1.0259041786193848, 1.165467619895935, 1.1874209642410278, 1.054824709892273, 1.0217504501342773, 1.0861117839813232, 1.1223710775375366, 1.1885515451431274, 1.2006158828735352, 1.0483942031860352, 1.020006775856018, 1.046637773513794, 1.2425262928009033, 1.1523025035858154, 1.0958194732666016, 1.0942542552947998, 1.1534504890441895, 1.069466471672058, 1.0520000457763672, 1.1018518209457397, 1.083983302116394, 1.0278154611587524, 1.1606723070144653, 1.1161446571350098, 1.0729546546936035, 1.2230408191680908, 1.3141651153564453, 1.0611263513565063, 1.2365649938583374, 1.1839237213134766, 1.4168514013290405, 1.010669469833374, 1.0298545360565186, 1.4252020120620728, 1.0911974906921387, 1.0514334440231323, 1.2808916568756104, 1.012434482574463, 1.1371996402740479, 1.123915672302246, 1.1154425144195557, 1.138452172279358, 1.051995873451233, 1.150312900543213, 1.0058616399765015, 1.0377472639083862, 1.260168433189392, 1.1882964372634888, 1.197339415550232, 1.1447713375091553, 1.099537968635559, 1.0158649682998657, 1.1004458665847778, 1.1601405143737793, 1.3106412887573242, 1.2832764387130737, 1.2168912887573242, 1.5390410423278809, 1.0413784980773926, 1.168283224105835, 1.1696741580963135, 1.1659749746322632, 1.2379337549209595, 1.2113581895828247, 1.1928184032440186, 1.0238274335861206, 1.0295658111572266, 1.1898324489593506, 1.3888300657272339, 1.0562714338302612, 1.296303153038025, 1.0834683179855347, 1.1734939813613892, 1.1537597179412842, 1.1053721904754639, 1.132445216178894, 1.0612752437591553, 1.2247651815414429, 1.1190476417541504, 1.1429437398910522, 1.0689088106155396, 1.033254623413086, 1.0145291090011597, 1.2698768377304077, 1.0504376888275146, 1.0811320543289185, 1.1056504249572754, 1.0856974124908447, 1.0568733215332031, 1.0940171480178833, 1.0208643674850464, 1.1130614280700684, 1.0651296377182007, 1.1813137531280518, 1.0145708322525024, 1.073580265045166, 1.0643640756607056, 1.2887096405029297, 1.0502413511276245, 1.188584327697754, 1.1608877182006836, 1.0856162309646606, 1.0393893718719482, 1.5737051963806152, 1.2552891969680786, 1.054281234741211, 1.0221999883651733, 1.0848805904388428, 1.0541963577270508, 1.0515810251235962, 1.0635032653808594, 1.2169111967086792, 1.0886095762252808, 1.028513789176941, 1.0748400688171387, 1.0178992748260498, 1.418994426727295, 1.1045503616333008, 1.0192917585372925, 1.1417115926742554, 1.0516027212142944, 1.0421981811523438, 1.1526157855987549, 1.1128195524215698, 1.034824013710022, 1.1388459205627441, 1.083385944366455, 1.330708622932434, 1.2399171590805054, 1.202523946762085, 1.028813123703003, 1.0054917335510254, 1.307970643043518, 1.0820711851119995, 1.1035678386688232, 1.0734834671020508, 1.0106089115142822, 1.2475301027297974, 1.1673945188522339, 1.2309895753860474, 1.0745928287506104, 1.1086124181747437, 1.3126521110534668, 1.065910816192627, 1.1501519680023193, 1.004563570022583, 1.1552306413650513, 1.0806443691253662, 1.037183165550232, 1.0537046194076538, 1.545454502105713, 1.0957034826278687, 1.0213615894317627, 1.3307372331619263, 1.3846583366394043, 1.3583183288574219, 1.3486238718032837, 1.1673802137374878, 1.436249017715454, 1.0882481336593628, 1.0724172592163086, 1.0101947784423828, 1.284365177154541, 1.8097560405731201, 1.0234893560409546, 1.3308823108673096, 1.3869905471801758, 1.0513648986816406, 1.2734627723693848, 1.0021666288375854]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7550079822540283] ms
 --  Average per query NF    [1.3620388507843018] ms
 --  Average per query vegas [2.3929691314697266] ms
Mean [1.153]  Median [1.111]  95th [1.390]  99th [1.576]  max [1.810]
Mean [1.153]  Median [1.111]  95th [1.390]  99th [1.576]  max [1.810]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.255322 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=0 | total-time=26.146808