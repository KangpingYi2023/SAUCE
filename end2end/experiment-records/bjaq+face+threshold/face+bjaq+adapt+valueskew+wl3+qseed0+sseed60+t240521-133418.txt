Input arguments = Namespace(data_update='valueskew', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 60, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.213935375213623
tensor(0.9961)
result is  tensor(380669.3750)
Enter testHyper
ReportEsts: [1.2102915048599243, 1.0203789472579956, 1.1936111450195312, 1.0977047681808472, 1.2625482082366943, 1.067894697189331, 1.2370343208312988, 1.0859079360961914, 1.1023212671279907, 1.0918071269989014, 1.0559861660003662, 1.1661016941070557, 1.013037919998169, 1.0647321939468384, 1.0767453908920288, 1.250239372253418, 1.2872698307037354, 1.163539171218872, 1.155185580253601, 1.1938775777816772, 1.139004111289978, 1.019681453704834, 1.1447396278381348, 1.1105095148086548, 1.2135097980499268, 1.08589506149292, 1.0304054021835327, 1.4148050546646118, 1.0348246097564697, 1.0431288480758667, 1.171337366104126, 1.112486720085144, 1.2963736057281494, 1.0181716680526733, 1.0987480878829956, 1.0197726488113403, 1.1912137269973755, 1.2921786308288574, 1.1108317375183105, 1.0770059823989868, 1.0321639776229858, 1.1428399085998535, 1.08794105052948, 1.1191258430480957, 1.079864740371704, 1.0589568614959717, 1.1379474401474, 1.2766501903533936, 1.0575478076934814, 1.0490694046020508, 1.2068063020706177, 1.3185231685638428, 1.099928379058838, 1.1081535816192627, 1.2196041345596313, 1.0136277675628662, 1.289719581604004, 1.0006649494171143, 1.2877707481384277, 1.4207161664962769, 1.5006296634674072, 1.2003344297409058, 1.1968492269515991, 1.090580701828003, 1.217712163925171, 1.085714340209961, 1.0866551399230957, 1.0208144187927246, 1.0068855285644531, 1.4105262756347656, 1.0796459913253784, 1.1122652292251587, 1.3301774263381958, 1.0244691371917725, 1.2012118101119995, 1.1548792123794556, 2.304471254348755, 1.0341681241989136, 1.0495355129241943, 1.3212049007415771, 1.0469614267349243, 1.020998239517212, 1.0799192190170288, 1.1375868320465088, 1.1955064535140991, 1.148319125175476, 1.0320072174072266, 1.0603783130645752, 1.0176537036895752, 1.059043049812317, 1.0126351118087769, 1.323611855506897, 1.0083636045455933, 1.294754147529602, 1.1818181276321411, 1.0951684713363647, 1.05216646194458, 1.3103358745574951, 1.034482717514038, 1.1290141344070435, 1.1886792182922363, 1.1291364431381226, 1.085492491722107, 1.0051507949829102, 1.1139121055603027, 1.0203012228012085, 1.16399347782135, 1.205933690071106, 1.0580836534500122, 1.0145061016082764, 1.236910343170166, 1.084181308746338, 1.0452648401260376, 1.0128848552703857, 1.0658397674560547, 1.15816330909729, 1.0078190565109253, 1.0065780878067017, 1.0885692834854126, 1.1492537260055542, 1.2259351015090942, 1.0883814096450806, 1.0480762720108032, 1.157784104347229, 1.2596899271011353, 1.1729260683059692, 1.1418708562850952, 1.1294283866882324, 1.39945650100708, 1.1249165534973145, 1.167164921760559, 1.034566044807434, 1.1438782215118408, 1.4642857313156128, 1.0966874361038208, 1.1740614175796509, 1.0782804489135742, 1.2669918537139893, 1.1051502227783203, 1.2873486280441284, 1.1381850242614746, 1.1660683155059814, 1.2452443838119507, 1.3339295387268066, 1.0907608270645142, 1.082288384437561, 1.0550987720489502, 1.2634966373443604, 1.0350252389907837, 1.0339488983154297, 1.144839882850647, 1.1834380626678467, 1.3171123266220093, 1.0646440982818604, 1.1073499917984009, 1.0487425327301025, 1.1999266147613525, 1.0405176877975464, 1.0013580322265625, 1.1880035400390625, 1.0504258871078491, 1.0318371057510376, 1.0461633205413818, 1.2377806901931763, 1.0571109056472778, 1.1102514266967773, 1.2242764234542847, 1.255060076713562, 1.0037649869918823, 1.0116729736328125, 1.0685484409332275, 1.1007108688354492, 1.1428571939468384, 1.1640751361846924, 1.039850115776062, 1.1714177131652832, 1.040330410003662, 1.3381876945495605, 1.0929909944534302, 1.1502516269683838, 1.0311237573623657, 1.0370632410049438, 1.0732502937316895, 1.0868233442306519, 1.1637088060379028, 1.1120507717132568, 1.015486478805542, 1.2791029214859009, 1.0253127813339233, 1.338006615638733, 1.0496283769607544, 1.047001838684082, 1.388807773590088, 1.4920023679733276, 1.6499297618865967, 1.1611742973327637, 1.1496456861495972, 1.2459015846252441, 1.0087692737579346, 1.1359894275665283]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.724607229232788] ms
 --  Average per query NF    [1.3638925552368164] ms
 --  Average per query vegas [2.3607146739959717] ms
Mean [1.145]  Median [1.111]  95th [1.341]  99th [1.502]  max [2.304]
Mean [1.145]  Median [1.111]  95th [1.341]  99th [1.502]  max [2.304]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.872252 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=valueskew', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
ValueSample - START
ValueSample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[3.5762787e-07 2.3841858e-07 8.8620186e-03 2.9802322e-07 2.3841858e-07]
Distance score: 0.0017726302612572908
SAUCE Drift detection: True
Detection latency: 0.0234s

DRIFT-DETECTED after 2-th workload
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/incremental_train.py', '--dataset=bjaq', '--end2end', '--model=face', '--model_update=adapt', '--update_size=80000', '--epochs=0']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
update_size: 76433
AdaptTask - START
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
train data shape: 80000, transfer data shape:16000
Training done; evaluating likelihood on full data:
Saved to: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
AdaptTask - END

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.043543 | Model-update-time: 2.218130


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=valueskew', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.170403718948364
tensor(0.9958)
result is  tensor(456656.9375)
Enter testHyper
ReportEsts: [1.418878436088562, 1.2020761966705322, 1.711229920387268, 1.069685697555542, 1.014975666999817, 1.320052981376648, 1.0741171836853027, 1.3692139387130737, 1.3008129596710205, 1.042256236076355, 1.1775416135787964, 1.4031503200531006, 1.2531017065048218, 1.2290267944335938, 1.0963143110275269, 1.0314304828643799, 1.8097448348999023, 1.2601499557495117, 1.0300734043121338, 1.0636504888534546, 1.1691957712173462, 1.312152624130249, 1.3336321115493774, 1.1453232765197754, 1.2302746772766113, 1.0714675188064575, 1.1549434661865234, 1.3198425769805908, 1.3491153717041016, 2.783259868621826, 1.2829457521438599, 1.4237288236618042, 1.034066915512085, 17.11821746826172, 1.3159936666488647, 1.0297023057937622, 1.1984726190567017, 1.1084238290786743, 1.4767448902130127, 1.1968472003936768, 1.0249441862106323, 1.1484622955322266, 1.465044617652893, 1.0313249826431274, 1.0389180183410645, 1.0028119087219238, 1.4674566984176636, 1.0417503118515015, 1.1679999828338623, 1.0836433172225952, 1.2212715148925781, 1.0236462354660034, 1.1828588247299194, 1.2907038927078247, 1.620383620262146, 6.066708564758301, 1.2981370687484741, 1.1836837530136108, 1.212358832359314, 1.1198699474334717, 6.847494602203369, 1.0642259120941162, 6.637404441833496, 1.6354680061340332, 1.0206085443496704, 1.1338402032852173, 1.1888107061386108, 1.0179197788238525, 1.0340038537979126, 1.0671993494033813, 1.4494603872299194, 1.11659574508667, 1.0207892656326294, 1.1360929012298584, 1.0249040126800537, 19.271730422973633, 17.22304344177246, 1.144952654838562, 1.0679090023040771, 1.7973295450210571, 3.9906249046325684, 1.8320015668869019, 1.0646113157272339, 1.3216718435287476, 1.3384212255477905, 1.3626760244369507, 1.349148154258728, 1.4342021942138672, 1.1261733770370483, 1.022554874420166, 1.1535401344299316, 1.0847718715667725, 1.3878376483917236, 1.151820421218872, 1.3714596033096313, 1.1212282180786133, 1.127761960029602, 1.1502830982208252, 1.1520509719848633, 1.0403311252593994, 1.0832818746566772, 1.0088762044906616, 1.0416666269302368, 1.058514952659607, 1.1072213649749756, 2.6992084980010986, 1.0274406671524048, 1.0857343673706055, 1.0234603881835938, 1.0689855813980103, 1.0576943159103394, 1.0472291707992554, 1.0535213947296143, 1.2560700178146362, 1.0058798789978027, 1.067895531654358, 1.0807381868362427, 1.3521519899368286, 1.0418249368667603, 1.0442477464675903, 1.2064212560653687, 1.372585654258728, 1.2351628541946411, 1.834831953048706, 1.128300428390503, 1.156801700592041, 1.3711978197097778, 1.0698412656784058, 1.048452615737915, 1.3280977010726929, 1.4302680492401123, 1.0825068950653076, 1.1802241802215576, 2.1625940799713135, 3.589686155319214, 1.228450894355774, 1.3595774173736572, 5.008364200592041, 1.0894099473953247, 1.2494474649429321, 1.1973661184310913, 1.261025309562683, 1.237809419631958, 1.4402046203613281, 1.1873478889465332, 1.1265134811401367, 1.459302306175232, 1.0672918558120728, 1.0882879495620728, 1.0258779525756836, 22.50444793701172, 1.0988906621932983, 1.152978539466858, 1.1228437423706055, 1.0032421350479126, 1.684673547744751, 1.0265012979507446, 1.3492063283920288, 1.1708624362945557, 1.1686149835586548, 1.0977153778076172, 1.0257185697555542, 1.5125807523727417, 1.090976595878601, 1.2370787858963013, 1.0245342254638672, 1.3076727390289307, 1.1945701837539673, 18.29540252685547, 1.325110912322998, 1.2856526374816895, 1.0870503187179565, 1.5275813341140747, 1.064549207687378, 1.0680949687957764, 1.0233279466629028, 1.0495988130569458, 1.040562391281128, 1.1566051244735718, 1.2831192016601562, 1.1451612710952759, 1.3696529865264893, 1.1462379693984985, 1.0130811929702759, 1.4190787076950073, 2.681159496307373, 1.2627880573272705, 1.0318500995635986, 1.1287328004837036, 1.133296012878418, 1.2002551555633545, 1.1709601879119873, 1.4623874425888062, 1.3845840692520142, 1.2304929494857788, 1.1277532577514648, 1.7186601161956787, 1.0220040082931519, 1.3572649955749512, 1.0239498615264893]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7362027168273926] ms
 --  Average per query NF    [1.3575184345245361] ms
 --  Average per query vegas [2.3786842823028564] ms
Mean [1.798]  Median [1.169]  95th [3.610]  99th [18.305]  max [22.504]
Mean [1.798]  Median [1.169]  95th [3.610]  99th [18.305]  max [22.504]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.383228 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=1 | total-time=28.562579