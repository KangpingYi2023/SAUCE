Input arguments = Namespace(data_update='tupleskew', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 43, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.165493249893188
tensor(0.9958)
result is  tensor(380552.5312)
Enter testHyper
ReportEsts: [1.198527216911316, 1.005439043045044, 1.3947021961212158, 1.1040219068527222, 1.2792657613754272, 1.0958514213562012, 1.2394859790802002, 1.133284568786621, 1.1006404161453247, 1.1360312700271606, 1.0430662631988525, 1.0936440229415894, 1.0267925262451172, 1.0401785373687744, 1.0484544038772583, 1.2219548225402832, 1.2073506116867065, 1.2732778787612915, 1.2376043796539307, 1.0208333730697632, 1.1826541423797607, 1.0011441707611084, 1.0804413557052612, 1.048579216003418, 1.1083067655563354, 1.2224231958389282, 1.085585594177246, 1.5344418287277222, 1.0135624408721924, 1.004170536994934, 1.2146151065826416, 1.2119548320770264, 1.0103070735931396, 1.0320650339126587, 1.201614260673523, 1.2449229955673218, 1.3286082744598389, 1.177863597869873, 1.0936886072158813, 1.0458416938781738, 1.0149966478347778, 1.060957908630371, 1.0673407316207886, 1.0405035018920898, 1.0616945028305054, 1.064625859260559, 1.1689139604568481, 1.2438981533050537, 1.0971848964691162, 1.098138689994812, 1.1700507402420044, 1.244536280632019, 1.0525351762771606, 1.151047706604004, 1.2596018314361572, 1.1031525135040283, 1.326168179512024, 1.2256345748901367, 1.1686980724334717, 1.4323163032531738, 1.6182347536087036, 1.2023450136184692, 1.2623741626739502, 1.1699178218841553, 1.4285714626312256, 1.3142857551574707, 1.1942857503890991, 1.0330545902252197, 1.0905338525772095, 1.4315789937973022, 1.2542237043380737, 1.1678591966629028, 1.341819167137146, 1.128514289855957, 1.1117712259292603, 1.0958682298660278, 1.8943018913269043, 1.055312156677246, 1.0133346319198608, 1.291242003440857, 1.0560412406921387, 1.068163514137268, 1.038838267326355, 1.2167054414749146, 1.2438331842422485, 1.072167158126831, 1.0402121543884277, 1.085587501525879, 1.0080965757369995, 1.0791109800338745, 1.019501805305481, 1.3616541624069214, 1.0105684995651245, 1.2252893447875977, 1.1470588445663452, 1.1921147108078003, 1.3017444610595703, 1.2769100666046143, 1.0166666507720947, 1.082389235496521, 1.1852388381958008, 1.008109450340271, 1.1146296262741089, 1.000732660293579, 1.141631841659546, 1.0697487592697144, 1.10432767868042, 1.2146596908569336, 1.09425950050354, 1.0281723737716675, 1.1639492511749268, 1.1098484992980957, 1.1374865770339966, 1.0330686569213867, 1.1017735004425049, 1.0861244201660156, 1.000192403793335, 1.0197290182113647, 1.2564605474472046, 1.0902284383773804, 1.211444616317749, 1.0865185260772705, 1.365339756011963, 1.2090829610824585, 1.338178277015686, 1.1674576997756958, 1.2785536050796509, 1.2063829898834229, 1.2601957321166992, 1.087842345237732, 1.117578148841858, 1.1058157682418823, 1.1662523746490479, 1.4642857313156128, 1.1285573244094849, 1.097663402557373, 1.028355360031128, 1.1570731401443481, 1.1034770011901855, 1.3321727514266968, 1.1368908882141113, 1.0956077575683594, 1.0700393915176392, 1.3270071744918823, 1.1420234441757202, 1.089619755744934, 1.0353114604949951, 1.5490951538085938, 1.0510425567626953, 1.0405539274215698, 1.2141430377960205, 1.1667734384536743, 1.3241935968399048, 1.0260196924209595, 1.161217212677002, 1.0390233993530273, 1.0046366453170776, 1.0216656923294067, 1.0885289907455444, 1.1579827070236206, 1.160978078842163, 1.0648062229156494, 1.0960267782211304, 1.295988917350769, 1.2843537330627441, 1.0210219621658325, 1.2292526960372925, 1.320549488067627, 1.0538893938064575, 1.0155051946640015, 1.007179856300354, 1.103454351425171, 1.1428571939468384, 1.1297441720962524, 1.085149884223938, 1.2939375638961792, 1.0310981273651123, 1.259847640991211, 1.2519766092300415, 1.0205295085906982, 1.0073697566986084, 1.0238502025604248, 1.0499999523162842, 1.160367727279663, 1.107569694519043, 1.161733627319336, 1.0164715051651, 1.2620302438735962, 1.0381197929382324, 1.430680751800537, 1.0304663181304932, 1.0885586738586426, 1.4768434762954712, 1.4845269918441772, 1.7923355102539062, 1.1709970235824585, 1.107336401939392, 1.0704225301742554, 1.1728178262710571, 1.1066733598709106]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7609827518463135] ms
 --  Average per query NF    [1.3640940189361572] ms
 --  Average per query vegas [2.3968887329101562] ms
Mean [1.158]  Median [1.113]  95th [1.431]  99th [1.620]  max [1.894]
Mean [1.158]  Median [1.113]  95th [1.431]  99th [1.620]  max [1.894]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.839718 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=tupleskew', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
TupleSkewSample - START
0.001
TupleSkewSample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[1.7523766e-04 5.4210424e-04 1.6474724e-04 1.2528896e-04 3.9339066e-06]
Distance score: 0.00020226239576004446
SAUCE Drift detection: True
Detection latency: 0.0227s

DRIFT-DETECTED after 2-th workload
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/incremental_train.py', '--dataset=bjaq', '--end2end', '--model=face', '--model_update=adapt', '--update_size=80000', '--epochs=0']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
update_size: 76433
AdaptTask - START
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
train data shape: 80000, transfer data shape:16000
Training done; evaluating likelihood on full data:
Saved to: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
AdaptTask - END

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.003382 | Model-update-time: 2.210836


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=tupleskew', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.163134098052979
tensor(0.9970)
result is  tensor(457220.7188)
Enter testHyper
ReportEsts: [1.0525054931640625, 1.071245551109314, 1.459944725036621, 1.3307936191558838, 1.013464093208313, 1.3186296224594116, 1.3560583591461182, 1.018204927444458, 1.1009464263916016, 1.1084606647491455, 1.0526280403137207, 1.4572619199752808, 1.0214797258377075, 1.0011507272720337, 1.2979354858398438, 1.1367350816726685, 1.321350336074829, 1.1108912229537964, 1.0113681554794312, 1.3413907289505005, 1.2964763641357422, 1.316243052482605, 1.519820213317871, 1.1683194637298584, 1.1089836359024048, 1.1989619731903076, 1.0869743824005127, 1.1689560413360596, 1.412233591079712, 1.0341047048568726, 1.1739578247070312, 1.6694915294647217, 1.1183929443359375, 1.1466927528381348, 1.0441476106643677, 1.1000860929489136, 1.0729193687438965, 1.0138301849365234, 1.3243776559829712, 1.122937798500061, 1.014513373374939, 1.1421856880187988, 1.6606557369232178, 1.0614906549453735, 1.084564447402954, 1.1638813018798828, 1.2000685930252075, 1.0900025367736816, 1.3576159477233887, 1.165558099746704, 1.0310895442962646, 1.0032579898834229, 1.0289133787155151, 1.1371537446975708, 1.024496078491211, 1.1050626039505005, 1.0173090696334839, 1.0905680656433105, 1.2592953443527222, 1.2053877115249634, 1.414247989654541, 1.0389018058776855, 1.7347630262374878, 1.6164740324020386, 1.0182769298553467, 1.1053798198699951, 1.2880134582519531, 1.016079306602478, 1.0867048501968384, 1.0142545700073242, 1.1679050922393799, 1.2388240098953247, 1.064300775527954, 1.099249243736267, 1.2797095775604248, 1.0839731693267822, 6.0, 1.1258039474487305, 1.2766648530960083, 1.2353204488754272, 1.1912966966629028, 1.0826987028121948, 1.2013829946517944, 1.2263656854629517, 1.3445417881011963, 1.5191489458084106, 1.4863951206207275, 1.1859416961669922, 1.2452517747879028, 1.2979830503463745, 1.0185542106628418, 1.016953468322754, 1.4696083068847656, 1.1421266794204712, 1.056714653968811, 1.0512771606445312, 1.051984190940857, 1.3317310810089111, 1.0753613710403442, 1.1359807252883911, 1.1155859231948853, 1.2259974479675293, 1.5248042345046997, 1.0047063827514648, 1.128219485282898, 1.614736795425415, 1.2593588829040527, 1.0221701860427856, 1.031518578529358, 1.0254387855529785, 1.0938537120819092, 1.1548149585723877, 1.2698252201080322, 1.27522611618042, 1.3371801376342773, 1.0834753513336182, 1.1691774129867554, 1.1972897052764893, 1.0887562036514282, 1.0619468688964844, 1.0070922374725342, 1.121095895767212, 1.1180459260940552, 1.3035224676132202, 1.0101572275161743, 1.0123062133789062, 1.1487091779708862, 1.0385208129882812, 1.159648060798645, 1.310990571975708, 1.104559063911438, 1.1223708391189575, 1.0176687240600586, 1.4727272987365723, 1.9213389158248901, 1.016522765159607, 1.0242767333984375, 1.08865225315094, 1.1367729902267456, 1.0452252626419067, 1.0597225427627563, 1.1648648977279663, 1.0296063423156738, 1.0567641258239746, 1.2030353546142578, 1.0082913637161255, 1.1988636255264282, 1.2611172199249268, 1.1289982795715332, 1.0471420288085938, 1.044108510017395, 1.1064053773880005, 1.1484882831573486, 1.0277754068374634, 1.014072299003601, 1.0656949281692505, 1.1119505167007446, 1.078740119934082, 1.0908610820770264, 1.3582757711410522, 1.1696197986602783, 1.1220238208770752, 1.2465826272964478, 1.0283219814300537, 1.2203145027160645, 1.126068353652954, 1.01975417137146, 1.3676764965057373, 1.0053499937057495, 1.137183666229248, 1.1579878330230713, 1.1420892477035522, 1.345198154449463, 1.037320852279663, 1.0749567747116089, 1.0047017335891724, 1.1251040697097778, 1.111686110496521, 1.0882412195205688, 1.0386661291122437, 1.9210525751113892, 1.0124826431274414, 1.0059394836425781, 1.5041275024414062, 1.201359748840332, 1.5873140096664429, 1.032914400100708, 1.1138235330581665, 1.4284545183181763, 1.0292863845825195, 1.1672872304916382, 1.1619153022766113, 1.108760952949524, 1.474013328552246, 1.1017789840698242, 1.0156121253967285, 1.5378247499465942, 1.1882911920547485, 1.4457236528396606, 1.1215518712997437]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.731926679611206] ms
 --  Average per query NF    [1.35697603225708] ms
 --  Average per query vegas [2.374950647354126] ms
Mean [1.202]  Median [1.123]  95th [1.525]  99th [1.921]  max [6.000]
Mean [1.202]  Median [1.123]  95th [1.525]  99th [1.921]  max [6.000]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.360268 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=1 | total-time=28.439173