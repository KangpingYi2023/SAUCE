Input arguments = Namespace(data_update='tupleskew', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 57, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.16199016571045
tensor(0.9962)
result is  tensor(380714.9062)
Enter testHyper
ReportEsts: [1.1609129905700684, 1.029049277305603, 1.54043447971344, 1.176037073135376, 1.2606761455535889, 1.141289234161377, 1.2139018774032593, 1.1924105882644653, 1.0696502923965454, 1.1477222442626953, 1.0148601531982422, 1.1332627534866333, 1.0897326469421387, 1.0669642686843872, 1.1001540422439575, 1.4058269262313843, 1.390785574913025, 1.1717339754104614, 1.1978143453598022, 1.0535714626312256, 1.0498417615890503, 1.037276029586792, 1.109600305557251, 1.0439386367797852, 1.0762068033218384, 1.1745027303695679, 1.088400959968567, 1.3721325397491455, 1.0034582614898682, 1.0055944919586182, 1.1734657287597656, 1.1516529321670532, 1.091659426689148, 1.0767210721969604, 1.1253912448883057, 1.1994569301605225, 1.2625446319580078, 1.102094054222107, 1.034744381904602, 1.0941317081451416, 1.0241503715515137, 1.079463005065918, 1.058763027191162, 1.0457500219345093, 1.0906401872634888, 1.0952380895614624, 1.17621910572052, 1.4096506834030151, 1.0665427446365356, 1.1082910299301147, 1.1974025964736938, 1.3369289636611938, 1.1090013980865479, 1.2774547338485718, 1.1596959829330444, 1.01315176486969, 1.399999976158142, 1.1571732759475708, 1.0446016788482666, 1.4021875858306885, 1.2888705730438232, 1.179040789604187, 1.3723585605621338, 1.113418698310852, 1.3095238208770752, 1.1142857074737549, 1.1977077722549438, 1.0486736297607422, 1.1434838771820068, 1.263157844543457, 1.0715516805648804, 1.0720993280410767, 1.3441632986068726, 1.075122594833374, 1.1180411577224731, 1.4734930992126465, 1.8497599363327026, 1.0266389846801758, 1.0263056755065918, 1.5455619096755981, 1.2400528192520142, 1.1699241399765015, 1.1024932861328125, 1.1787745952606201, 1.2504544258117676, 1.0027964115142822, 1.1042205095291138, 1.0876671075820923, 1.0577870607376099, 1.0029853582382202, 1.0113099813461304, 1.3538475036621094, 1.0072648525238037, 1.3107882738113403, 1.0833333730697632, 1.006113886833191, 1.1063588857650757, 1.2362948656082153, 1.01694917678833, 1.127422571182251, 1.129655122756958, 1.1023162603378296, 1.2117246389389038, 1.0081180334091187, 1.0366108417510986, 1.00361967086792, 1.2513351440429688, 1.1972076892852783, 1.0504226684570312, 1.0262287855148315, 1.080672264099121, 1.1490195989608765, 1.2648087739944458, 1.0115151405334473, 1.0605076551437378, 1.0861244201660156, 1.0057706832885742, 1.0746808052062988, 1.1113845109939575, 1.0603777170181274, 1.224540114402771, 1.109493613243103, 1.1434286832809448, 1.1906450986862183, 1.3071705102920532, 1.1740610599517822, 1.3256053924560547, 1.1490627527236938, 1.176694631576538, 1.0895123481750488, 1.1836352348327637, 1.1951488256454468, 1.2361714839935303, 1.5357142686843872, 1.1072341203689575, 1.098451018333435, 1.0239289999008179, 1.1489430665969849, 1.1268631219863892, 1.2787432670593262, 1.1497834920883179, 1.0684800148010254, 1.0887207984924316, 1.1797271966934204, 1.0012528896331787, 1.1079758405685425, 1.036279320716858, 1.630952000617981, 1.0614886283874512, 1.0723721981048584, 1.3857214450836182, 1.1610050201416016, 1.3407729864120483, 1.036569595336914, 1.1613720655441284, 1.0358694791793823, 1.0463628768920898, 1.024198055267334, 1.0042279958724976, 1.1708146333694458, 1.1989516019821167, 1.1691601276397705, 1.0783190727233887, 1.276566743850708, 1.1934260129928589, 1.0357611179351807, 1.1156091690063477, 1.2739238739013672, 1.002340316772461, 1.0063835382461548, 1.0542641878128052, 1.0336437225341797, 1.1298701763153076, 1.1060023307800293, 1.0858310461044312, 1.068463921546936, 1.0193164348602295, 1.2462862730026245, 1.0410404205322266, 1.1107361316680908, 1.0061105489730835, 1.0107758045196533, 1.057877779006958, 1.155260443687439, 1.1361825466156006, 1.1035940647125244, 1.0246336460113525, 1.2952414751052856, 1.0492477416992188, 1.3271644115447998, 1.0272945165634155, 1.0400390625, 1.585996150970459, 1.4293416738510132, 1.5909091234207153, 1.1433628797531128, 1.0679032802581787, 1.1515151262283325, 1.0367292165756226, 1.0446547269821167]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7595009803771973] ms
 --  Average per query NF    [1.3634216785430908] ms
 --  Average per query vegas [2.3960793018341064] ms
Mean [1.151]  Median [1.110]  95th [1.406]  99th [1.591]  max [1.850]
Mean [1.151]  Median [1.110]  95th [1.406]  99th [1.591]  max [1.850]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.842353 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=tupleskew', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
TupleSkewSample - START
0.001
TupleSkewSample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[1.0728836e-06 2.2947788e-05 1.6349554e-04 3.3438206e-05 6.9677830e-05]
Distance score: 5.81264503125567e-05
SAUCE Drift detection: True
Detection latency: 0.0227s

DRIFT-DETECTED after 2-th workload
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/incremental_train.py', '--dataset=bjaq', '--end2end', '--model=face', '--model_update=adapt', '--update_size=80000', '--epochs=0']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
update_size: 76433
AdaptTask - START
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
train data shape: 80000, transfer data shape:16000
Training done; evaluating likelihood on full data:
Saved to: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
AdaptTask - END

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.010430 | Model-update-time: 2.308334


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=tupleskew', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.16394853591919
tensor(0.9971)
result is  tensor(457287.5938)
Enter testHyper
ReportEsts: [1.1850467920303345, 1.193006992340088, 1.084485411643982, 1.102440595626831, 1.0445328950881958, 1.0530457496643066, 1.1990021467208862, 1.1490540504455566, 1.0599182844161987, 1.0507078170776367, 1.130513072013855, 1.1683619022369385, 1.4373522996902466, 1.1058791875839233, 1.006358027458191, 1.0088517665863037, 1.0072849988937378, 1.1367430686950684, 1.0301882028579712, 1.1489843130111694, 1.0474658012390137, 1.4615432024002075, 1.1626555919647217, 1.0606733560562134, 1.0295934677124023, 1.1821413040161133, 1.0346693992614746, 1.0029106140136719, 1.2549256086349487, 1.4757084846496582, 1.0304770469665527, 1.4067796468734741, 1.0570050477981567, 1.0011957883834839, 1.0021017789840698, 1.0697897672653198, 1.041716456413269, 1.316136121749878, 1.2603687047958374, 1.0654170513153076, 1.1887483596801758, 1.0768386125564575, 1.3425071239471436, 1.0700815916061401, 1.0417286157608032, 1.2353955507278442, 1.0958212614059448, 1.1382542848587036, 1.399999976158142, 1.1567447185516357, 1.0157394409179688, 1.0267704725265503, 1.0404936075210571, 1.0818668603897095, 1.1192482709884644, 1.0368269681930542, 1.0889027118682861, 1.0077236890792847, 1.4087698459625244, 1.130884051322937, 1.0894309282302856, 1.057085394859314, 1.0398317575454712, 1.1948747634887695, 1.0174636840820312, 1.0830411911010742, 1.324339509010315, 1.1015536785125732, 1.133349895477295, 1.064103603363037, 1.1416040658950806, 1.0696607828140259, 1.046216607093811, 1.1660887002944946, 1.0987164974212646, 1.2876020669937134, 3.9125683307647705, 1.0270963907241821, 1.2803096771240234, 1.0278722047805786, 1.120083212852478, 1.0821224451065063, 1.0682272911071777, 1.2687777280807495, 1.3306113481521606, 1.6510637998580933, 1.3250905275344849, 1.7319587469100952, 1.3523591756820679, 1.0969700813293457, 1.234871745109558, 1.3072417974472046, 1.3560293912887573, 1.0884737968444824, 1.2115424871444702, 1.0361379384994507, 1.100178837776184, 1.2118037939071655, 1.0097770690917969, 1.1710623502731323, 1.3842226266860962, 1.14888596534729, 1.0793651342391968, 1.1586776971817017, 1.132749319076538, 1.006727933883667, 1.1157983541488647, 1.1194002628326416, 1.0115941762924194, 1.0553202629089355, 1.125531792640686, 1.07231605052948, 1.2175657749176025, 1.288117527961731, 1.1061224937438965, 1.0295917987823486, 1.055798888206482, 1.3257006406784058, 1.1360379457473755, 2.663865566253662, 1.023730754852295, 1.1309523582458496, 1.0304043292999268, 1.1900452375411987, 1.0995699167251587, 1.1258277893066406, 1.0927834510803223, 1.0749601125717163, 1.1168216466903687, 1.0971132516860962, 1.1669247150421143, 1.1371394395828247, 1.000757098197937, 1.4721603393554688, 1.4017013311386108, 1.1582565307617188, 1.0118067264556885, 1.0886850357055664, 1.1000787019729614, 1.0417476892471313, 1.069906234741211, 1.2133169174194336, 1.1134225130081177, 1.0901445150375366, 1.0792442560195923, 1.1194474697113037, 1.3105590343475342, 1.0082058906555176, 1.168967843055725, 1.0315121412277222, 1.3399807214736938, 1.0311896800994873, 1.097883701324463, 1.0123776197433472, 1.0037668943405151, 2.0600461959838867, 1.0405733585357666, 2.5190839767456055, 1.2696952819824219, 1.0047543048858643, 1.0673811435699463, 1.2891120910644531, 1.164745807647705, 1.04314386844635, 1.1665568351745605, 1.0399291515350342, 1.274534821510315, 1.236796498298645, 1.078036904335022, 1.3095141649246216, 1.098251223564148, 1.0047165155410767, 1.2468879222869873, 1.1148897409439087, 1.0158652067184448, 1.0743122100830078, 1.0118247270584106, 1.0816636085510254, 1.0906739234924316, 1.0264066457748413, 1.8157894611358643, 1.1788966655731201, 1.072243094444275, 1.45816969871521, 1.2814366817474365, 1.2891336679458618, 1.0808076858520508, 1.314982533454895, 1.4750092029571533, 1.0129252672195435, 1.088746190071106, 1.0324655771255493, 1.226707100868225, 1.6845974922180176, 1.042687177658081, 1.0309339761734009, 1.2445611953735352, 1.251185655593872, 1.0677419900894165, 1.1139874458312988]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.692653179168701] ms
 --  Average per query NF    [1.354670524597168] ms
 --  Average per query vegas [2.337982654571533] ms
Mean [1.182]  Median [1.102]  95th [1.472]  99th [2.521]  max [3.913]
Mean [1.182]  Median [1.102]  95th [1.472]  99th [2.521]  max [3.913]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.352194 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=1 | total-time=28.559413