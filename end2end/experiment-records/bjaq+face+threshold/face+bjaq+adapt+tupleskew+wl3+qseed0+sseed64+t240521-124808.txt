Input arguments = Namespace(data_update='tupleskew', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 64, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.210143804550171
tensor(0.9966)
result is  tensor(380852.7812)
Enter testHyper
ReportEsts: [1.136592149734497, 1.1007089614868164, 1.3209818601608276, 1.108654499053955, 1.27734375, 1.1591613292694092, 1.197962999343872, 1.2079920768737793, 1.0394585132598877, 1.1551601886749268, 1.0447889566421509, 1.2269067764282227, 1.0158275365829468, 1.0357142686843872, 1.1003795862197876, 1.2522952556610107, 1.4253928661346436, 1.0964370965957642, 1.2194453477859497, 1.1760203838348389, 1.0112067461013794, 1.0705546140670776, 1.122083306312561, 1.0455039739608765, 1.0861717462539673, 1.141048789024353, 1.111204981803894, 1.2656739950180054, 1.0370795726776123, 1.075068712234497, 1.1120964288711548, 1.1113771200180054, 1.0375105142593384, 1.0730534791946411, 1.196713924407959, 1.0262393951416016, 1.3879485130310059, 1.0152266025543213, 1.073909878730774, 1.1108155250549316, 1.0361214876174927, 1.219279170036316, 1.0104589462280273, 1.014356017112732, 1.0794422626495361, 1.0181405544281006, 1.0870126485824585, 1.1096630096435547, 1.0262731313705444, 1.1201353073120117, 1.2036553621292114, 1.2824102640151978, 1.0495429039001465, 1.0623153448104858, 1.122408151626587, 1.0138660669326782, 1.3214952945709229, 1.1818602085113525, 1.173622488975525, 1.3515814542770386, 1.4052445888519287, 1.2392956018447876, 1.3529337644577026, 1.1062986850738525, 1.3043478727340698, 1.0571428537368774, 1.1156584024429321, 1.0465896129608154, 1.1107075214385986, 1.221052646636963, 1.1649484634399414, 1.1382668018341064, 1.2185122966766357, 1.2522341012954712, 1.2244236469268799, 1.1951111555099487, 1.925836205482483, 1.1121585369110107, 1.0736218690872192, 1.404811143875122, 1.1853597164154053, 1.1159747838974, 1.0020185708999634, 1.2918169498443604, 1.2208137512207031, 1.1040410995483398, 1.1220072507858276, 1.1588398218154907, 1.0233429670333862, 1.1416369676589966, 1.121249794960022, 1.2682946920394897, 1.0234403610229492, 1.2526172399520874, 1.015625, 1.0498932600021362, 1.1195480823516846, 1.3567241430282593, 1.01694917678833, 1.0801422595977783, 1.117326021194458, 1.1597267389297485, 1.0361565351486206, 1.0197657346725464, 1.0963302850723267, 1.026833176612854, 1.2120215892791748, 1.169284462928772, 1.044670581817627, 1.0978261232376099, 1.0627355575561523, 1.0712980031967163, 1.2492600679397583, 1.0238875150680542, 1.2219774723052979, 1.1464647054672241, 1.0245023965835571, 1.033664345741272, 1.3960788249969482, 1.0307202339172363, 1.1748543977737427, 1.1001794338226318, 1.1871041059494019, 1.1501370668411255, 1.30571711063385, 1.1651878356933594, 1.094343662261963, 1.0847582817077637, 1.366047739982605, 1.1259185075759888, 1.1158783435821533, 1.122738242149353, 1.2215662002563477, 1.4642857313156128, 1.0866456031799316, 1.0259910821914673, 1.0478394031524658, 1.1665040254592896, 1.0769320726394653, 1.3664286136627197, 1.165712594985962, 1.141135573387146, 1.0891681909561157, 1.1060307025909424, 1.0934480428695679, 1.0673117637634277, 1.096526861190796, 1.5141780376434326, 1.0728769302368164, 1.2126420736312866, 1.1350725889205933, 1.1929240226745605, 1.3349593877792358, 1.2436496019363403, 1.156191110610962, 1.0156697034835815, 1.1135469675064087, 1.0680923461914062, 1.0210555791854858, 1.14789617061615, 1.0143795013427734, 1.0388356447219849, 1.0175315141677856, 1.3031989336013794, 1.1859296560287476, 1.1199007034301758, 1.187239408493042, 1.3897351026535034, 1.0024808645248413, 1.003656029701233, 1.2479573488235474, 1.0104986429214478, 1.1558442115783691, 1.2154043912887573, 1.087193489074707, 1.1349334716796875, 1.0456753969192505, 1.256566047668457, 1.1078474521636963, 1.174953579902649, 1.0796489715576172, 1.0117456912994385, 1.010500192642212, 1.0745658874511719, 1.177109718322754, 1.0951374769210815, 1.0322954654693604, 1.2389655113220215, 1.0044281482696533, 1.3291099071502686, 1.0861704349517822, 1.0088276863098145, 1.5032920837402344, 1.3178963661193848, 1.8557968139648438, 1.2463022470474243, 1.1949561834335327, 1.1014492511749268, 1.0226221084594727, 1.1362550258636475]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7859368324279785] ms
 --  Average per query NF    [1.3603687286376953] ms
 --  Average per query vegas [2.425568103790283] ms
Mean [1.151]  Median [1.117]  95th [1.388]  99th [1.518]  max [1.926]
Mean [1.151]  Median [1.117]  95th [1.388]  99th [1.518]  max [1.926]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.907917 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=tupleskew', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
TupleSkewSample - START
0.001
TupleSkewSample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[2.9325485e-05 6.7055225e-05 1.1742115e-04 1.8918514e-04 4.3332577e-05]
Distance score: 8.926391456043348e-05
SAUCE Drift detection: True
Detection latency: 0.0228s

DRIFT-DETECTED after 2-th workload
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/incremental_train.py', '--dataset=bjaq', '--end2end', '--model=face', '--model_update=adapt', '--update_size=80000', '--epochs=0']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
update_size: 76433
AdaptTask - START
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
train data shape: 80000, transfer data shape:16000
Training done; evaluating likelihood on full data:
Saved to: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
AdaptTask - END

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.002036 | Model-update-time: 2.226590


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=tupleskew', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.172233819961548
tensor(0.9945)
result is  tensor(456072.8750)
Enter testHyper
ReportEsts: [1.1238471269607544, 1.0033267736434937, 1.0056657791137695, 1.0293169021606445, 1.0055866241455078, 1.1110137701034546, 1.1909278631210327, 1.0133243799209595, 1.2092320919036865, 3.370786428451538, 1.0052891969680786, 1.081102728843689, 1.0143197774887085, 1.0941102504730225, 1.075978398323059, 1.0885409116744995, 1.0164821147918701, 1.183295488357544, 1.0033624172210693, 1.3257427215576172, 1.1441656351089478, 1.0085431337356567, 1.0382657051086426, 1.065687656402588, 1.2008126974105835, 1.208802580833435, 1.0470796823501587, 1.4367622137069702, 1.0944232940673828, 1.202751636505127, 1.1315042972564697, 1.4322034120559692, 1.019020676612854, 1.0429902076721191, 1.086666464805603, 1.0352957248687744, 1.1653032302856445, 1.0143812894821167, 1.0112615823745728, 1.048341989517212, 1.0674079656600952, 1.236270785331726, 1.1157974004745483, 1.0743250846862793, 1.0333009958267212, 1.011208176612854, 1.827544927597046, 1.198227047920227, 1.3714286088943481, 1.102516531944275, 1.0826482772827148, 1.074745535850525, 1.0217653512954712, 1.1855379343032837, 1.0488723516464233, 1.5233328342437744, 1.1696195602416992, 1.047655701637268, 1.1178474426269531, 1.2383357286453247, 1.2044943571090698, 1.0160433053970337, 1.0344990491867065, 1.448999047279358, 1.0021216869354248, 1.058950424194336, 1.2806166410446167, 1.0131829977035522, 1.1273542642593384, 1.080979585647583, 1.0136985778808594, 1.0759810209274292, 1.1838126182556152, 1.138896107673645, 1.167042851448059, 1.2021360397338867, 1.2213430404663086, 1.1572128534317017, 1.2986881732940674, 1.1431663036346436, 1.187021255493164, 1.1693460941314697, 1.0082324743270874, 1.1980009078979492, 1.2093520164489746, 1.634042501449585, 1.2599637508392334, 1.6835236549377441, 1.0123562812805176, 1.1505684852600098, 1.1404656171798706, 1.2367959022521973, 1.4908077716827393, 1.1729363203048706, 1.0925277471542358, 1.1091004610061646, 1.0979565382003784, 1.1453547477722168, 1.0253612995147705, 1.755422592163086, 1.2106683254241943, 1.0578997135162354, 1.034313678741455, 1.101320505142212, 1.1169880628585815, 1.2070783376693726, 1.1819064617156982, 1.010167121887207, 1.936813235282898, 1.1775542497634888, 1.0160162448883057, 1.097281575202942, 1.047746181488037, 1.2275689840316772, 1.3079726696014404, 1.0742632150650024, 1.1861830949783325, 1.0325454473495483, 1.1030426025390625, 2.047297239303589, 1.100815773010254, 1.1626213788986206, 1.0097131729125977, 1.0356643199920654, 1.0442026853561401, 1.0773378610610962, 1.145150899887085, 1.0766773223876953, 1.0284171104431152, 1.141685962677002, 1.33965003490448, 1.1408369541168213, 1.065718412399292, 2.056422472000122, 1.6238136291503906, 1.0653241872787476, 1.1280564069747925, 1.0901051759719849, 1.1296730041503906, 1.0470811128616333, 1.0133404731750488, 1.1238834857940674, 1.0223692655563354, 1.0502281188964844, 1.0407313108444214, 1.036283016204834, 2.5705127716064453, 1.046439528465271, 1.2016788721084595, 1.1751282215118408, 1.1065120697021484, 1.051563024520874, 1.087160587310791, 1.0087031126022339, 1.1015663146972656, 1.2940703630447388, 1.312447428703308, 1.1048387289047241, 1.459147334098816, 1.0468577146530151, 1.0342481136322021, 1.0460636615753174, 1.132457971572876, 1.1334636211395264, 1.2118887901306152, 1.2272727489471436, 1.000387191772461, 1.3034883737564087, 1.1143171787261963, 1.1489969491958618, 1.0928269624710083, 1.1157044172286987, 1.5678430795669556, 1.022291898727417, 1.3130664825439453, 1.1971126794815063, 1.4890778064727783, 1.0486544370651245, 1.0113623142242432, 1.1171951293945312, 1.763157844543457, 1.2268673181533813, 1.028428554534912, 1.5855027437210083, 1.3137043714523315, 1.4181331396102905, 1.046047329902649, 1.059556007385254, 1.3538932800292969, 1.0033173561096191, 1.2317142486572266, 1.0235446691513062, 1.3303292989730835, 1.450419545173645, 1.0222105979919434, 3.674999952316284, 1.3077497482299805, 1.026790738105774, 1.0105739831924438, 1.0137165784835815]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.626432418823242] ms
 --  Average per query NF    [1.3556790351867676] ms
 --  Average per query vegas [2.2707533836364746] ms
Mean [1.197]  Median [1.113]  95th [1.637]  99th [2.579]  max [3.675]
Mean [1.197]  Median [1.113]  95th [1.637]  99th [2.579]  max [3.675]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.340852 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=1 | total-time=28.543421