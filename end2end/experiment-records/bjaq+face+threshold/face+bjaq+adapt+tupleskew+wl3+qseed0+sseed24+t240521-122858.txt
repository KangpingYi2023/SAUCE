Input arguments = Namespace(data_update='tupleskew', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 24, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.170048713684082
tensor(0.9969)
result is  tensor(380969.4062)
Enter testHyper
ReportEsts: [1.1420150995254517, 1.0781091451644897, 1.2072958946228027, 1.023932695388794, 1.27734375, 1.1462817192077637, 1.1993463039398193, 1.0102577209472656, 1.0624079704284668, 1.0921744108200073, 1.0378984212875366, 1.0639830827713013, 1.1097049713134766, 1.0446428060531616, 1.1409733295440674, 1.4038833379745483, 1.2247538566589355, 1.2352731227874756, 1.1844948530197144, 1.0025510787963867, 1.12464439868927, 1.213592290878296, 1.1125800609588623, 1.0423040390014648, 1.0759618282318115, 1.1301989555358887, 1.0720720291137695, 1.33415949344635, 1.0301324129104614, 1.1476960182189941, 1.1706278324127197, 1.2749806642532349, 1.0486005544662476, 1.0114260911941528, 1.0270960330963135, 1.0642859935760498, 1.1896580457687378, 1.2057075500488281, 1.0397231578826904, 1.1019161939620972, 1.0196603536605835, 1.0591436624526978, 1.0236872434616089, 1.020996332168579, 1.0908514261245728, 1.0011337995529175, 1.1003923416137695, 1.3754925727844238, 1.0089356899261475, 1.027072787284851, 1.1974025964736938, 1.1747978925704956, 1.0074915885925293, 1.2511863708496094, 1.097254991531372, 1.057352900505066, 1.2700934410095215, 1.1654202938079834, 1.247314453125, 1.3904881477355957, 1.4278541803359985, 1.1821476221084595, 1.1594557762145996, 1.110230803489685, 1.2406015396118164, 1.1428571939468384, 1.152573585510254, 1.0073376893997192, 1.1843044757843018, 1.3894736766815186, 1.0255775451660156, 1.0003989934921265, 1.196031093597412, 1.1284958124160767, 1.2204681634902954, 1.0690200328826904, 2.119271755218506, 1.0425608158111572, 1.094049096107483, 1.1590944528579712, 1.1626566648483276, 1.1019221544265747, 1.020484447479248, 1.1963825225830078, 1.1737964153289795, 1.0642805099487305, 1.0571624040603638, 1.0173518657684326, 1.0187666416168213, 1.0576332807540894, 1.0742156505584717, 1.280545711517334, 1.0079970359802246, 1.366434931755066, 1.0955055952072144, 1.093213677406311, 1.0651881694793701, 1.2157115936279297, 1.0, 1.1068252325057983, 1.0790513753890991, 1.055693507194519, 1.0190238952636719, 1.0175695419311523, 1.0433263778686523, 1.0940676927566528, 1.1409051418304443, 1.1500872373580933, 1.1082242727279663, 1.1003293991088867, 1.2399338483810425, 1.063520908355713, 1.2219477891921997, 1.0738897323608398, 1.0857771635055542, 1.1182266473770142, 1.0459392070770264, 1.0292789936065674, 1.399301290512085, 1.0720185041427612, 1.2173831462860107, 1.0901062488555908, 1.0918183326721191, 1.0868576765060425, 1.3197674751281738, 1.1539413928985596, 1.1096601486206055, 1.2139637470245361, 1.328460931777954, 1.1145625114440918, 1.0987046957015991, 1.189087986946106, 1.1886265277862549, 1.3928571939468384, 1.138974666595459, 1.039380431175232, 1.000197410583496, 1.2273170948028564, 1.0711525678634644, 1.347183108329773, 1.1089153289794922, 1.216944694519043, 1.1360101699829102, 1.3324400186538696, 1.0362366437911987, 1.053350806236267, 1.1296623945236206, 1.2102410793304443, 1.022367000579834, 1.0565340518951416, 1.2336006164550781, 1.1522881984710693, 1.3004224300384521, 1.1568615436553955, 1.1714962720870972, 1.0058256387710571, 1.0186710357666016, 1.0520540475845337, 1.0715018510818481, 1.1366755962371826, 1.062700629234314, 1.0350706577301025, 1.0686283111572266, 1.3215796947479248, 1.280868411064148, 1.0636792182922363, 1.2988643646240234, 1.208062767982483, 1.0586763620376587, 1.0509212017059326, 1.0755525827407837, 1.1390398740768433, 1.1168831586837769, 1.1119099855422974, 1.0023841857910156, 1.0146143436431885, 1.0539358854293823, 1.1612838506698608, 1.2907968759536743, 1.1948720216751099, 1.0511893033981323, 1.1085036993026733, 1.0326231718063354, 1.0520939826965332, 1.1249547004699707, 1.1226215362548828, 1.0172139406204224, 1.2175533771514893, 1.0282150506973267, 1.4391156435012817, 1.090440273284912, 1.0058082342147827, 1.6478060483932495, 1.0617622137069702, 1.9304760694503784, 1.232824444770813, 1.1673613786697388, 1.1014492511749268, 1.3070255517959595, 1.058764934539795]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.775252103805542] ms
 --  Average per query NF    [1.362680196762085] ms
 --  Average per query vegas [2.412571907043457] ms
Mean [1.143]  Median [1.108]  95th [1.376]  99th [1.651]  max [2.119]
Mean [1.143]  Median [1.108]  95th [1.376]  99th [1.651]  max [2.119]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.864346 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=tupleskew', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
TupleSkewSample - START
0.001
TupleSkewSample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[3.5762787e-06 2.1517277e-05 1.3715029e-04 9.7095966e-05 2.1398067e-05]
Distance score: 5.614757537841797e-05
SAUCE Drift detection: True
Detection latency: 0.0228s

DRIFT-DETECTED after 2-th workload
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/incremental_train.py', '--dataset=bjaq', '--end2end', '--model=face', '--model_update=adapt', '--update_size=80000', '--epochs=0']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
update_size: 76433
AdaptTask - START
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
train data shape: 80000, transfer data shape:16000
Training done; evaluating likelihood on full data:
Saved to: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
AdaptTask - END

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.000226 | Model-update-time: 2.214702


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=tupleskew', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.210922002792358
tensor(0.9982)
result is  tensor(457755.6250)
Enter testHyper
ReportEsts: [1.0582396984100342, 1.0013295412063599, 1.035410761833191, 2.686274528503418, 1.0637434720993042, 1.0371952056884766, 1.0103895664215088, 1.0898524522781372, 1.2559380531311035, 1.041312336921692, 1.1467829942703247, 1.0267561674118042, 1.0143197774887085, 1.0450596809387207, 1.004631519317627, 1.0102968215942383, 1.0598297119140625, 1.1359411478042603, 1.0166335105895996, 1.4980593919754028, 1.106863021850586, 1.5894339084625244, 2.414292812347412, 1.5068492889404297, 1.0038738250732422, 1.0982537269592285, 1.2705631256103516, 1.3799887895584106, 1.4126125574111938, 1.06190824508667, 1.0788631439208984, 1.51694917678833, 1.0209219455718994, 1.250977873802185, 1.009252667427063, 1.042775273323059, 1.0794134140014648, 1.0012619495391846, 1.282697319984436, 1.0562853813171387, 1.0037883520126343, 1.2107279300689697, 1.4767441749572754, 1.165460228919983, 1.0364506244659424, 1.008664846420288, 1.102748155593872, 1.07942533493042, 1.3095238208770752, 1.1094117164611816, 1.0236350297927856, 1.144794225692749, 1.1022694110870361, 1.3122186660766602, 1.1839561462402344, 1.2745710611343384, 1.334966778755188, 1.0195344686508179, 1.2071380615234375, 1.1269899606704712, 1.5133470296859741, 1.0375758409500122, 1.143696904182434, 1.5159306526184082, 1.0384491682052612, 1.0602729320526123, 1.2706834077835083, 1.0313067436218262, 1.2451794147491455, 1.0827280282974243, 1.0582658052444458, 1.1241282224655151, 1.1832472085952759, 1.1141400337219238, 1.096947193145752, 1.2095941305160522, 1.1193302869796753, 1.4248000383377075, 1.2919234037399292, 1.0452907085418701, 1.0982683897018433, 1.0804638862609863, 1.1717408895492554, 1.1747686862945557, 1.45885169506073, 1.578723430633545, 1.2930234670639038, 1.4897470474243164, 1.1272579431533813, 1.1849879026412964, 1.0920917987823486, 1.1565409898757935, 1.38233482837677, 1.0169258117675781, 1.0451772212982178, 1.0185205936431885, 1.176897644996643, 1.1561040878295898, 1.1078344583511353, 1.043697476387024, 1.020180344581604, 1.1284137964248657, 1.031862735748291, 1.147990107536316, 1.277703881263733, 1.042665958404541, 1.0156211853027344, 1.1282949447631836, 1.56521737575531, 1.0144200325012207, 1.2683035135269165, 1.1425230503082275, 1.2508258819580078, 1.1317248344421387, 1.0373831987380981, 1.2291830778121948, 1.0592396259307861, 1.1043317317962646, 1.030495047569275, 1.2920353412628174, 1.0297566652297974, 1.0273793935775757, 1.0059776306152344, 1.0521824359893799, 1.042472243309021, 1.1060314178466797, 1.204787254333496, 1.0369230508804321, 1.1830241680145264, 1.0306776762008667, 1.1434987783432007, 1.0790863037109375, 1.080970287322998, 2.261932373046875, 1.2884448766708374, 1.0392074584960938, 1.0484700202941895, 1.010546088218689, 1.1332334280014038, 1.030153512954712, 1.1121816635131836, 1.2261911630630493, 1.0007604360580444, 1.0131754875183105, 1.0781649351119995, 1.0302728414535522, 1.2485207319259644, 1.072541356086731, 1.0129948854446411, 1.0308183431625366, 1.1242541074752808, 1.0298742055892944, 1.0196975469589233, 1.2452784776687622, 1.063323736190796, 1.2351857423782349, 1.1749340295791626, 1.1610169410705566, 1.0860182046890259, 1.0325872898101807, 1.1220111846923828, 1.3338249921798706, 1.2316781282424927, 1.0674771070480347, 1.2071952819824219, 1.1223372220993042, 1.0340487957000732, 1.006062626838684, 1.3036229610443115, 1.1265028715133667, 1.2748109102249146, 1.0646753311157227, 1.2756860256195068, 1.2045568227767944, 1.022386908531189, 1.0029047727584839, 1.66476571559906, 1.04679536819458, 1.0742840766906738, 1.05251145362854, 1.8684210777282715, 1.0869977474212646, 1.1536624431610107, 1.5344680547714233, 1.2891381978988647, 1.2324339151382446, 1.0412896871566772, 1.044940710067749, 1.4976298809051514, 1.0117015838623047, 1.1467782258987427, 1.0564042329788208, 1.1135119199752808, 1.5976331233978271, 1.146187424659729, 5.539999961853027, 1.5049158334732056, 1.1370575428009033, 1.5236427783966064, 1.0423833131790161]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7131381034851074] ms
 --  Average per query NF    [1.3574349880218506] ms
 --  Average per query vegas [2.355703115463257] ms
Mean [1.198]  Median [1.109]  95th [1.536]  99th [2.417]  max [5.540]
Mean [1.198]  Median [1.109]  95th [1.536]  99th [2.417]  max [5.540]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.436107 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=1 | total-time=28.575491