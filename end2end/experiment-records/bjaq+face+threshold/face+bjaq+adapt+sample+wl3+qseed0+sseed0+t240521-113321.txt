Input arguments = Namespace(data_update='sample', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 0, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.192356586456299
tensor(0.9953)
result is  tensor(380355.3438)
Enter testHyper
ReportEsts: [1.1471666097640991, 1.0007658004760742, 1.3372732400894165, 1.2417351007461548, 1.2685765027999878, 1.1030476093292236, 1.1982591152191162, 1.2918955087661743, 1.0877034664154053, 1.0753779411315918, 1.087855339050293, 1.2786016464233398, 1.1524708271026611, 1.0379464626312256, 1.0103497505187988, 1.2586420774459839, 1.3602359294891357, 1.2505937814712524, 1.149916410446167, 1.0739796161651611, 1.1041388511657715, 1.0963386297225952, 1.136286973953247, 1.0405687093734741, 1.0639549493789673, 1.1600362062454224, 1.087837815284729, 1.315146565437317, 1.0563745498657227, 1.09464430809021, 1.1557289361953735, 1.08198881149292, 1.2583398818969727, 1.0733641386032104, 1.0810409784317017, 1.1748738288879395, 1.2353365421295166, 1.1274276971817017, 1.165283441543579, 1.008819580078125, 1.0463531017303467, 1.1331640481948853, 1.1182944774627686, 1.0324534177780151, 1.0870484113693237, 1.0327868461608887, 1.1067781448364258, 1.2855827808380127, 1.134686827659607, 1.1404399871826172, 1.2131578922271729, 1.37982976436615, 1.1843587160110474, 1.1594840288162231, 1.196336030960083, 1.0554009675979614, 1.399999976158142, 1.1954498291015625, 1.0516793727874756, 1.4721730947494507, 1.2043890953063965, 1.1983305215835571, 1.3282203674316406, 1.1194316148757935, 1.1870503425598145, 1.2857142686843872, 1.0493724346160889, 1.0887237787246704, 1.1445218324661255, 1.3894736766815186, 1.1883364915847778, 1.0501809120178223, 1.2877947092056274, 1.084643006324768, 1.0640344619750977, 1.0183186531066895, 1.9654428958892822, 1.0463348627090454, 1.0079774856567383, 1.2957826852798462, 1.264797329902649, 1.1366499662399292, 1.077232837677002, 1.225089192390442, 1.2262541055679321, 1.0490700006484985, 1.0135302543640137, 1.013392686843872, 1.0170024633407593, 1.0795257091522217, 1.0572112798690796, 1.3561557531356812, 1.0054093599319458, 1.3011820316314697, 1.0209424495697021, 1.0340824127197266, 1.1795090436935425, 1.1691279411315918, 1.034482717514038, 1.1377211809158325, 1.3083066940307617, 1.0191305875778198, 1.0128114223480225, 1.000732660293579, 1.0430986881256104, 1.0454516410827637, 1.1436030864715576, 1.1832460165023804, 1.0832029581069946, 1.029634952545166, 1.1429420709609985, 1.137864112854004, 1.2189373970031738, 1.1019905805587769, 1.0931957960128784, 1.1884816884994507, 1.0252432823181152, 1.060166835784912, 1.2395645380020142, 1.035019040107727, 1.2458035945892334, 1.101904273033142, 1.0888844728469849, 1.1155128479003906, 1.3507752418518066, 1.1663227081298828, 1.1333726644515991, 1.039321780204773, 1.2479805946350098, 1.0978623628616333, 1.1574350595474243, 1.2289559841156006, 1.259477972984314, 1.4285714626312256, 1.2282768487930298, 1.0586436986923218, 1.019015908241272, 1.0910569429397583, 1.074666142463684, 1.187461256980896, 1.1794514656066895, 1.0717782974243164, 1.059516429901123, 1.362045407295227, 1.103632926940918, 1.0870712995529175, 1.033603549003601, 1.4809750318527222, 1.0145463943481445, 1.029616117477417, 1.1812231540679932, 1.1672862768173218, 1.290880560874939, 1.1810269355773926, 1.171118140220642, 1.0058468580245972, 1.1008024215698242, 1.0005627870559692, 1.0405926704406738, 1.1514174938201904, 1.2604666948318481, 1.0766332149505615, 1.0364316701889038, 1.3482013940811157, 1.2536520957946777, 1.0954198837280273, 1.3205267190933228, 1.1394479274749756, 1.0361322164535522, 1.021968126296997, 1.0655829906463623, 1.0716533660888672, 1.1298701763153076, 1.0419105291366577, 1.0786784887313843, 1.13596510887146, 1.0058308839797974, 1.1552584171295166, 1.2901502847671509, 1.0149093866348267, 1.0893540382385254, 1.050161361694336, 1.0025856494903564, 1.0694586038589478, 1.0782325267791748, 1.1236786842346191, 1.0058413743972778, 1.2571728229522705, 1.0452957153320312, 1.4493862390518188, 1.0218520164489746, 1.0344820022583008, 1.388469934463501, 1.2320826053619385, 1.8377281427383423, 1.1406710147857666, 1.1393496990203857, 1.1343283653259277, 1.055564045906067, 1.0358566045761108]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.746776580810547] ms
 --  Average per query NF    [1.361992359161377] ms
 --  Average per query vegas [2.38478422164917] ms
Mean [1.148]  Median [1.119]  95th [1.363]  99th [1.485]  max [1.965]
Mean [1.148]  Median [1.119]  95th [1.363]  99th [1.485]  max [1.965]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.879210 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=sample', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
Sample - START
Sample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[1.6093254e-06 9.5367432e-07 2.9802322e-07 1.7881393e-07 3.5762787e-07]
Distance score: 6.794929277020856e-07
SAUCE Drift detection: False
Detection latency: 0.0234s

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.029658 | Model-update-time: 0.000000


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=sample', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.196372032165527
tensor(0.9976)
result is  tensor(457488.5312)
Enter testHyper
ReportEsts: [1.2482383251190186, 1.0234503746032715, 1.2552238702774048, 1.0099958181381226, 1.0601873397827148, 1.2875767946243286, 1.2722431421279907, 1.0357416868209839, 1.0347661972045898, 1.09183669090271, 1.1187022924423218, 1.4241758584976196, 1.144859790802002, 1.0801045894622803, 1.1025187969207764, 1.0121713876724243, 1.0231428146362305, 1.0620167255401611, 1.020174503326416, 1.2884217500686646, 1.0534878969192505, 1.103574514389038, 1.0979195833206177, 1.1267606019973755, 1.138899803161621, 1.2430111169815063, 1.008095622062683, 1.1165094375610352, 1.1177376508712769, 1.6931166648864746, 1.223192572593689, 1.1292517185211182, 1.1692276000976562, 1.0684810876846313, 1.0231467485427856, 1.0686956644058228, 1.0462530851364136, 1.0664945840835571, 1.10354483127594, 1.1020666360855103, 1.0058091878890991, 1.1120283603668213, 1.2899750471115112, 1.0811265707015991, 1.1356121301651, 1.1246485710144043, 1.3312315940856934, 1.0612518787384033, 1.1422924995422363, 1.0182758569717407, 1.0168789625167847, 1.0014623403549194, 1.198256254196167, 1.3013770580291748, 1.073357105255127, 1.237524390220642, 1.271406888961792, 1.1258231401443481, 1.267680287361145, 1.1396301984786987, 1.6113861799240112, 1.0040456056594849, 1.0318338871002197, 1.716662883758545, 1.020204782485962, 1.1107105016708374, 1.3569791316986084, 1.0678918361663818, 1.1230295896530151, 1.0925551652908325, 1.0738295316696167, 1.2819955348968506, 1.0188628435134888, 1.1584761142730713, 1.0451061725616455, 1.002314805984497, 1.2192796468734741, 1.1504727602005005, 1.4515912532806396, 1.1562528610229492, 1.0783659219741821, 1.1481835842132568, 1.1758742332458496, 1.1934266090393066, 1.3743340969085693, 1.3229166269302368, 1.4053618907928467, 1.520121693611145, 1.1382533311843872, 1.0175565481185913, 1.1443299055099487, 1.1202341318130493, 1.2433183193206787, 1.1092402935028076, 1.2626347541809082, 1.089806079864502, 1.0270968675613403, 1.3085360527038574, 1.1400917768478394, 1.317663311958313, 1.1163815259933472, 1.1107842922210693, 1.1714975833892822, 1.1376855373382568, 1.0385499000549316, 1.247046709060669, 1.091963529586792, 1.0657516717910767, 1.1260273456573486, 1.079084038734436, 1.072699785232544, 1.1102352142333984, 1.0644115209579468, 1.0266814231872559, 1.136824369430542, 1.2334047555923462, 1.0789345502853394, 1.0376818180084229, 1.1908279657363892, 1.1190476417541504, 1.0195724964141846, 1.0611604452133179, 1.0456767082214355, 1.1360080242156982, 1.0591132640838623, 1.1434751749038696, 1.2796827554702759, 1.2659409046173096, 1.0871448516845703, 1.0440375804901123, 1.0776636600494385, 1.0492230653762817, 1.0749260187149048, 1.845886468887329, 1.6431881189346313, 1.071552038192749, 1.011772632598877, 1.0129444599151611, 1.1130098104476929, 1.0042191743850708, 1.128275990486145, 1.1305420398712158, 1.0045483112335205, 1.0167315006256104, 1.0162888765335083, 1.111539602279663, 1.4457142353057861, 1.1030206680297852, 1.0416336059570312, 1.0945264101028442, 1.014100432395935, 1.016078233718872, 1.0925569534301758, 1.0758947134017944, 1.060010552406311, 1.202449083328247, 1.2070785760879517, 1.3359375, 1.291488528251648, 1.1481554508209229, 1.1873060464859009, 1.1603937149047852, 1.1921249628067017, 1.1005213260650635, 1.043225884437561, 1.045513391494751, 1.0078026056289673, 1.2414627075195312, 1.2574764490127563, 1.4315568208694458, 1.1845591068267822, 1.041896939277649, 1.526462435722351, 1.0159870386123657, 1.2506564855575562, 1.091025710105896, 1.1512162685394287, 1.103100299835205, 1.0683238506317139, 1.005049705505371, 1.7272727489471436, 1.1167001724243164, 1.0410147905349731, 1.433569073677063, 1.3305556774139404, 1.890002727508545, 1.2652174234390259, 1.0847585201263428, 1.3589088916778564, 1.0487685203552246, 1.1263571977615356, 1.0157256126403809, 1.154159426689148, 1.8746544122695923, 1.0125187635421753, 1.1131781339645386, 1.1511067152023315, 1.0150094032287598, 1.3220911026000977, 1.1453040838241577]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.642498254776001] ms
 --  Average per query NF    [1.35978102684021] ms
 --  Average per query vegas [2.282717227935791] ms
Mean [1.161]  Median [1.115]  95th [1.455]  99th [1.846]  max [1.890]
Mean [1.161]  Median [1.115]  95th [1.455]  99th [1.846]  max [1.890]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.178897 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=0 | total-time=26.112090