Input arguments = Namespace(data_update='sample', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 35, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.16069769859314
tensor(0.9943)
result is  tensor(379972.9062)
Enter testHyper
ReportEsts: [1.2128167152404785, 1.0122774839401245, 1.3873838186264038, 1.0069974660873413, 1.2484581470489502, 1.125504732131958, 1.3314296007156372, 1.2052756547927856, 1.0923123359680176, 1.0979491472244263, 1.0641613006591797, 1.12627112865448, 1.1317423582077026, 1.0669642686843872, 1.016449213027954, 1.2405321598052979, 1.375551462173462, 1.2536816596984863, 1.102799654006958, 1.0739796161651611, 1.0713069438934326, 1.1613330841064453, 1.1454700231552124, 1.0562399625778198, 1.1269296407699585, 1.1139240264892578, 1.0563063621520996, 1.4098646640777588, 1.0246087312698364, 1.1130098104476929, 1.1234480142593384, 1.2533138990402222, 1.062880516052246, 1.0023670196533203, 1.021166205406189, 1.201967716217041, 1.4715029001235962, 1.0130796432495117, 1.0549120903015137, 1.0210778713226318, 1.0187944173812866, 1.1973875761032104, 1.0535304546356201, 1.086167812347412, 1.10564124584198, 1.0283446311950684, 1.2035338878631592, 1.3695566654205322, 1.030029296875, 1.1319797039031982, 1.1943005323410034, 1.3471866846084595, 1.0759650468826294, 1.1450492143630981, 1.2690857648849487, 1.0060268640518188, 1.330841064453125, 1.226881980895996, 1.1816715002059937, 1.3772727251052856, 1.3186153173446655, 1.1584893465042114, 1.4100240468978882, 1.0889173746109009, 1.1870503425598145, 1.1142857074737549, 1.0791738033294678, 1.0358861684799194, 1.2098582983016968, 1.642105221748352, 1.0196882486343384, 1.0997703075408936, 1.2558728456497192, 1.0986672639846802, 1.2418904304504395, 1.1538243293762207, 1.7601865530014038, 1.0797439813613892, 1.0144447088241577, 1.35283625125885, 1.1481603384017944, 1.1061217784881592, 1.0539772510528564, 1.2282103300094604, 1.3202192783355713, 1.1647340059280396, 1.0302002429962158, 1.021740198135376, 1.1384148597717285, 1.1157641410827637, 1.0321980714797974, 1.4144127368927002, 1.0353407859802246, 1.219858169555664, 1.1607142686843872, 1.0969620943069458, 1.1203004121780396, 1.2224795818328857, 1.01694917678833, 1.1475517749786377, 1.1203830242156982, 1.026036262512207, 1.0496379137039185, 1.0088626146316528, 1.0019874572753906, 1.0267680883407593, 1.2106622457504272, 1.2006981372833252, 1.060817003250122, 1.0158876180648804, 1.2127065658569336, 1.0821791887283325, 1.183124303817749, 1.0725126266479492, 1.0831111669540405, 1.0809524059295654, 1.0052207708358765, 1.0878369808197021, 1.235173225402832, 1.0672849416732788, 1.2720645666122437, 1.1377121210098267, 1.150230050086975, 1.1356288194656372, 1.2863372564315796, 1.1804580688476562, 1.0951228141784668, 1.015291452407837, 1.3037974834442139, 1.1282565593719482, 1.1692163944244385, 1.188179612159729, 1.1016159057617188, 1.5, 1.06544828414917, 1.1758991479873657, 1.0468363761901855, 1.0604877471923828, 1.180423617362976, 1.330319881439209, 1.1924934387207031, 1.13325834274292, 1.1450634002685547, 1.4325730800628662, 1.0001641511917114, 1.0589462518692017, 1.0227265357971191, 1.3675529956817627, 1.0787760019302368, 1.048295497894287, 1.188877820968628, 1.164594292640686, 1.372909665107727, 1.1951100826263428, 1.0156993865966797, 1.1290034055709839, 1.0353490114212036, 1.0087993144989014, 1.0392124652862549, 1.189137578010559, 1.055843472480774, 1.0687609910964966, 1.1107391119003296, 1.2153048515319824, 1.0776255130767822, 1.0882453918457031, 1.0001022815704346, 1.3182404041290283, 1.1192303895950317, 1.0367368459701538, 1.047060251235962, 1.0383411645889282, 1.1558442115783691, 1.121105670928955, 1.028610348701477, 1.0795021057128906, 1.0019474029541016, 1.2773610353469849, 1.1008316278457642, 1.0340863466262817, 1.1443915367126465, 1.0018969774246216, 1.0609791278839111, 1.1164453029632568, 1.174574375152588, 1.0866807699203491, 1.0490351915359497, 1.270958662033081, 1.0983853340148926, 1.3893388509750366, 1.0210245847702026, 1.0156513452529907, 1.6734095811843872, 1.319968581199646, 1.6611660718917847, 1.1453900337219238, 1.0573571920394897, 1.1176470518112183, 1.0905648469924927, 1.0110435485839844]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.763335943222046] ms
 --  Average per query NF    [1.3635313510894775] ms
 --  Average per query vegas [2.3998045921325684] ms
Mean [1.149]  Median [1.116]  95th [1.390]  99th [1.661]  max [1.760]
Mean [1.149]  Median [1.116]  95th [1.390]  99th [1.661]  max [1.760]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.819613 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=sample', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
Sample - START
Sample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[2.5033951e-06 1.0132790e-06 3.5762787e-07 1.7881393e-07 1.1920929e-07]
Distance score: 8.344650268554688e-07
SAUCE Drift detection: False
Detection latency: 0.0235s

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.026758 | Model-update-time: 0.000000


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=sample', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.158035039901733
tensor(0.9966)
result is  tensor(457055.7188)
Enter testHyper
ReportEsts: [1.0695281028747559, 1.038484811782837, 1.2176387310028076, 1.0784013271331787, 1.114918828010559, 1.2935943603515625, 1.0966979265213013, 1.1182817220687866, 1.1799718141555786, 1.2875343561172485, 1.0105468034744263, 1.127307653427124, 1.2277227640151978, 1.1168880462646484, 1.0695115327835083, 1.1212599277496338, 1.2713068723678589, 1.1219992637634277, 1.0804864168167114, 1.3234611749649048, 1.1702035665512085, 1.7103365659713745, 1.0594319105148315, 1.0700753927230835, 1.1428556442260742, 1.1632791757583618, 1.0174049139022827, 1.102659821510315, 1.2357382774353027, 1.555069923400879, 1.1261523962020874, 1.2313432693481445, 1.044989824295044, 1.0172443389892578, 1.0202898979187012, 1.151415228843689, 1.1431835889816284, 1.247841477394104, 1.1902525424957275, 1.0164090394973755, 1.057539701461792, 1.035908579826355, 1.1780359745025635, 1.1051923036575317, 1.0965566635131836, 1.1706005334854126, 1.5151169300079346, 1.0044736862182617, 1.0645161867141724, 1.027683973312378, 1.0770381689071655, 1.131565809249878, 1.0776022672653198, 1.053274393081665, 1.1018952131271362, 1.0252346992492676, 1.0529475212097168, 1.0220495462417603, 1.2919914722442627, 1.0844534635543823, 1.5563725233078003, 1.0070319175720215, 1.08171808719635, 1.5755378007888794, 1.065171718597412, 1.0673048496246338, 1.334331750869751, 1.071691870689392, 1.1187679767608643, 1.0804935693740845, 1.0545644760131836, 1.1852713823318481, 1.007436752319336, 1.058821201324463, 1.0491032600402832, 1.130328893661499, 1.1849498748779297, 1.2196171283721924, 1.4432636499404907, 1.1294264793395996, 1.259297490119934, 1.12567937374115, 1.0420058965682983, 1.4147664308547974, 1.322695016860962, 1.3617020845413208, 1.4462748765945435, 1.6865839958190918, 1.110636830329895, 1.0841144323349, 1.195338487625122, 1.0656249523162842, 1.5048094987869263, 1.1428124904632568, 1.2088342905044556, 1.0886170864105225, 1.0570632219314575, 1.1557279825210571, 1.3445310592651367, 1.1199530363082886, 1.1876163482666016, 1.1175389289855957, 1.2247474193572998, 1.1298624277114868, 1.0275753736495972, 1.228947401046753, 1.1277337074279785, 1.1496785879135132, 1.1777777671813965, 1.0158228874206543, 1.1502126455307007, 1.0890552997589111, 1.1125837564468384, 1.3795089721679688, 1.0965862274169922, 1.3129438161849976, 1.3279285430908203, 1.2944130897521973, 1.2587370872497559, 1.0303030014038086, 1.0219658613204956, 1.1341077089309692, 1.0091044902801514, 1.2125710248947144, 1.0223071575164795, 1.1810247898101807, 1.135802149772644, 1.284810185432434, 1.2022062540054321, 1.143674373626709, 1.18523371219635, 1.1055684089660645, 1.1666057109832764, 1.5279383659362793, 1.7149806022644043, 1.1661033630371094, 1.0264317989349365, 1.0398880243301392, 1.1362061500549316, 1.0552897453308105, 1.0241299867630005, 1.052536129951477, 1.0215537548065186, 1.110353708267212, 1.0489425659179688, 1.0267910957336426, 1.4450548887252808, 1.125381588935852, 1.013961911201477, 1.056892991065979, 1.1457970142364502, 1.071608066558838, 1.1182888746261597, 1.036803126335144, 1.0071067810058594, 1.0171571969985962, 1.0860545635223389, 1.234375, 1.0282307863235474, 1.1813545227050781, 1.075931429862976, 1.0772895812988281, 1.1095954179763794, 1.0855857133865356, 1.025249719619751, 1.1102361679077148, 1.076535940170288, 1.0658973455429077, 1.0660605430603027, 1.313254952430725, 1.2075403928756714, 1.0990955829620361, 1.7991596460342407, 1.0733972787857056, 1.0769577026367188, 1.0819061994552612, 1.1669410467147827, 1.2258124351501465, 1.0137288570404053, 1.1207302808761597, 1.704545497894287, 1.2414729595184326, 1.00296950340271, 1.561608076095581, 1.195467472076416, 1.128861427307129, 1.2783890962600708, 1.140239953994751, 1.387821078300476, 1.030038595199585, 1.1358680725097656, 1.0338650941848755, 1.1432222127914429, 2.0469460487365723, 1.0038448572158813, 1.041664719581604, 1.6692910194396973, 1.0344940423965454, 1.2066246271133423, 1.1403868198394775]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.675333261489868] ms
 --  Average per query NF    [1.3666248321533203] ms
 --  Average per query vegas [2.308708429336548] ms
Mean [1.167]  Median [1.120]  95th [1.555]  99th [1.716]  max [2.047]
Mean [1.167]  Median [1.120]  95th [1.555]  99th [1.716]  max [2.047]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.147395 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=0 | total-time=26.049870