Input arguments = Namespace(data_update='sample', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 22, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.162619829177856
tensor(0.9925)
result is  tensor(379300.3438)
Enter testHyper
ReportEsts: [1.1887233257293701, 1.1590297222137451, 1.211625576019287, 1.1461360454559326, 1.2229573726654053, 1.105654001235962, 1.1597790718078613, 1.06797456741333, 1.0555717945098877, 1.1131888628005981, 1.0104438066482544, 1.1463983058929443, 1.111731767654419, 1.0535714626312256, 1.1193052530288696, 1.3036718368530273, 1.0694553852081299, 1.1946555376052856, 1.200857400894165, 1.1760203838348389, 1.0560334920883179, 1.0746451616287231, 1.1291404962539673, 1.0548588037490845, 1.1157395839691162, 1.2386980056762695, 1.0250563621520996, 1.4628623723983765, 1.102441430091858, 1.2363951206207275, 1.1390564441680908, 1.1927928924560547, 1.1579515933990479, 1.0319418907165527, 1.0859825611114502, 1.1669546365737915, 1.4245778322219849, 1.0446557998657227, 1.105431318283081, 1.089940071105957, 1.0902717113494873, 1.228229284286499, 1.0518985986709595, 1.1176010370254517, 1.0688780546188354, 1.0952380895614624, 1.2067830562591553, 1.3549388647079468, 1.076130747795105, 1.0879864692687988, 1.1820513010025024, 1.323492407798767, 1.0525554418563843, 1.185907006263733, 1.1163407564163208, 1.0188946723937988, 1.2738317251205444, 1.3167948722839355, 1.1577014923095703, 1.3626328706741333, 1.239033579826355, 1.1749236583709717, 1.3765811920166016, 1.143943428993225, 1.0679612159729004, 1.1142857074737549, 1.2294117212295532, 1.0519015789031982, 1.168623685836792, 1.24210524559021, 1.1214803457260132, 1.0556702613830566, 1.1810526847839355, 1.1745842695236206, 1.0710350275039673, 1.0165106058120728, 2.055051326751709, 1.0947933197021484, 1.1420828104019165, 1.4188292026519775, 1.2034224271774292, 1.1489259004592896, 1.0702003240585327, 1.1617851257324219, 1.2049293518066406, 1.0386916399002075, 1.1558254957199097, 1.0054476261138916, 1.0717161893844604, 1.1453685760498047, 1.0819499492645264, 1.3001548051834106, 1.0093761682510376, 1.3089179992675781, 1.0893855094909668, 1.123794436454773, 1.2023675441741943, 1.18212890625, 1.0166666507720947, 1.066941261291504, 1.1082544326782227, 1.0587916374206543, 1.0902032852172852, 1.005890965461731, 1.0412133932113647, 1.0224039554595947, 1.1895785331726074, 1.1832460165023804, 1.132043719291687, 1.0697044134140015, 1.2004029750823975, 1.084181308746338, 1.0106992721557617, 1.0302766561508179, 1.0811406373977661, 1.1349999904632568, 1.0574992895126343, 1.0402424335479736, 1.353562355041504, 1.05912184715271, 1.1357959508895874, 1.115841031074524, 1.1819030046463013, 1.1405781507492065, 1.2902132272720337, 1.2152290344238281, 1.1784400939941406, 1.0657756328582764, 1.3458187580108643, 1.1092184782028198, 1.1977609395980835, 1.1337043046951294, 1.1650093793869019, 1.4642857313156128, 1.1172194480895996, 1.1286426782608032, 1.0536038875579834, 1.0959349870681763, 1.010266900062561, 1.4340330362319946, 1.1121011972427368, 1.119243860244751, 1.0988390445709229, 1.1855089664459229, 1.1498286724090576, 1.1631368398666382, 1.1760869026184082, 1.3791892528533936, 1.0424808263778687, 1.0441761016845703, 1.090288758277893, 1.1328034400939941, 1.2929134368896484, 1.0758706331253052, 1.2036212682724, 1.0128356218338013, 1.1060471534729004, 1.0309510231018066, 1.0474181175231934, 1.1440763473510742, 1.096186876296997, 1.1250606775283813, 1.0768214464187622, 1.201282024383545, 1.3409091234207153, 1.1388888359069824, 1.3212106227874756, 1.3374416828155518, 1.0061874389648438, 1.0409941673278809, 1.0382182598114014, 1.0373514890670776, 1.0779221057891846, 1.2016385793685913, 1.0272479057312012, 1.0002408027648926, 1.025922179222107, 1.1474727392196655, 1.0541667938232422, 1.0184231996536255, 1.016703724861145, 1.043212652206421, 1.069549798965454, 1.0776302814483643, 1.103223443031311, 1.071881651878357, 1.0420184135437012, 1.255854606628418, 1.1057146787643433, 1.4301166534423828, 1.0184129476547241, 1.2445931434631348, 1.5565857887268066, 1.0515657663345337, 1.5535740852355957, 1.234394907951355, 1.015923261642456, 1.1343283653259277, 1.0300031900405884, 1.088512659072876]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.759247064590454] ms
 --  Average per query NF    [1.360234022140503] ms
 --  Average per query vegas [2.399013042449951] ms
Mean [1.147]  Median [1.117]  95th [1.377]  99th [1.554]  max [2.055]
Mean [1.147]  Median [1.117]  95th [1.377]  99th [1.554]  max [2.055]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.812944 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=sample', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
Sample - START
Sample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[6.5565109e-07 5.9604645e-07 9.5367432e-07 5.3644180e-06 5.9604645e-08]
Distance score: 1.5258789289873675e-06
SAUCE Drift detection: False
Detection latency: 0.0235s

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.027978 | Model-update-time: 0.000000


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=sample', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.205073833465576
tensor(0.9993)
result is  tensor(458267.9688)
Enter testHyper
ReportEsts: [1.3328726291656494, 1.0792399644851685, 1.2157143354415894, 1.3013274669647217, 1.066148281097412, 1.334086298942566, 1.1707305908203125, 1.1012017726898193, 1.191916823387146, 1.0560747385025024, 1.115649938583374, 1.3997223377227783, 1.1148648262023926, 1.080736517906189, 1.06212317943573, 1.0119200944900513, 1.2603591680526733, 1.1473064422607422, 1.060282826423645, 1.2667667865753174, 1.0392183065414429, 1.7284895181655884, 1.1116365194320679, 1.2126550674438477, 1.1678733825683594, 1.1008586883544922, 1.0116938352584839, 1.1375515460968018, 1.2659127712249756, 1.821649432182312, 1.0817490816116333, 1.2147650718688965, 1.0429638624191284, 1.0036290884017944, 1.0798851251602173, 1.1751868724822998, 1.1480439901351929, 1.1675046682357788, 1.397183895111084, 1.0488139390945435, 1.0759838819503784, 1.0213446617126465, 1.5419048070907593, 1.0474638938903809, 1.0413316488265991, 1.0971735715866089, 1.247032642364502, 1.0498604774475098, 1.0650407075881958, 1.2573013305664062, 1.0510023832321167, 1.0097004175186157, 1.16265869140625, 1.0202895402908325, 1.0441921949386597, 1.5162158012390137, 1.0645709037780762, 1.0861016511917114, 1.2519041299819946, 1.1967896223068237, 1.4872390031814575, 1.017120122909546, 1.1061643362045288, 1.4918758869171143, 1.0721256732940674, 1.1071817874908447, 1.3857455253601074, 1.0143859386444092, 1.1021740436553955, 1.0788065195083618, 1.053941249847412, 1.249620795249939, 1.0843148231506348, 1.253875970840454, 1.0730336904525757, 1.0565708875656128, 1.0529886484146118, 1.304932713508606, 1.1732205152511597, 1.1301817893981934, 1.1579270362854004, 1.1258277893066406, 1.0187442302703857, 1.1279107332229614, 1.363242745399475, 1.4178571701049805, 1.242870569229126, 1.3919334411621094, 1.0515304803848267, 1.1420356035232544, 1.1161667108535767, 1.1635411977767944, 1.3482441902160645, 1.0853080749511719, 1.1609599590301514, 1.048780083656311, 1.0463608503341675, 1.2497141361236572, 1.1785248517990112, 1.1072430610656738, 1.091370701789856, 1.1122480630874634, 1.2014925479888916, 1.0613853931427002, 1.2851768732070923, 1.065773606300354, 1.022641897201538, 1.165237307548523, 1.2579710483551025, 1.053587555885315, 1.0811926126480103, 1.02705979347229, 1.0035521984100342, 1.5678907632827759, 1.162310242652893, 1.02506685256958, 1.0924869775772095, 1.2174313068389893, 1.0578997135162354, 1.125, 1.0867871046066284, 1.1598745584487915, 1.156145691871643, 1.200971245765686, 1.0665557384490967, 1.0480625629425049, 1.0043359994888306, 1.2531249523162842, 1.149278163909912, 1.1238350868225098, 1.3005906343460083, 1.0854418277740479, 1.1116465330123901, 1.8779621124267578, 1.505128264427185, 1.0555708408355713, 1.0151199102401733, 1.0030487775802612, 1.0706510543823242, 1.0087006092071533, 1.0367151498794556, 1.1007875204086304, 1.022592544555664, 1.1097568273544312, 1.0280879735946655, 1.3032491207122803, 1.625, 1.0231908559799194, 1.1222063302993774, 1.0856883525848389, 1.2104487419128418, 1.0556291341781616, 1.1782091856002808, 1.0983495712280273, 1.0185497999191284, 1.1537178754806519, 1.0408719778060913, 1.2014925479888916, 1.0533809661865234, 1.0530956983566284, 1.1245410442352295, 1.0115869045257568, 1.1080222129821777, 1.013210654258728, 1.112882137298584, 1.084538221359253, 1.019400715827942, 1.2671513557434082, 1.008643388748169, 1.1429578065872192, 1.1803035736083984, 1.1415174007415771, 1.6133041381835938, 1.0129399299621582, 1.146948218345642, 1.0067025423049927, 1.1828434467315674, 1.0207631587982178, 1.087241530418396, 1.1696152687072754, 1.5681818723678589, 1.0392156839370728, 1.1226452589035034, 1.5059489011764526, 1.461917519569397, 1.0676319599151611, 1.2057762145996094, 1.0689283609390259, 1.4212743043899536, 1.0067881345748901, 1.2366384267807007, 1.0378092527389526, 1.2841384410858154, 1.9427480697631836, 1.037573218345642, 1.3614457845687866, 1.252439260482788, 1.2645957469940186, 1.2692307233810425, 1.087790608406067]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.663814067840576] ms
 --  Average per query NF    [1.3589942455291748] ms
 --  Average per query vegas [2.3048198223114014] ms
Mean [1.166]  Median [1.112]  95th [1.506]  99th [1.822]  max [1.943]
Mean [1.166]  Median [1.112]  95th [1.506]  99th [1.822]  max [1.943]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.211556 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=0 | total-time=26.107649