Input arguments = Namespace(data_update='tupleskew', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 91, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.159002542495728
tensor(0.9976)
result is  tensor(381239.0625)
Enter testHyper
ReportEsts: [1.1873358488082886, 1.070029377937317, 1.4156982898712158, 1.0972836017608643, 1.2236615419387817, 1.0510187149047852, 1.3275095224380493, 1.150736927986145, 1.0469974279403687, 1.160791277885437, 1.059431552886963, 1.0917372703552246, 1.0830515623092651, 1.0379464626312256, 1.1467965841293335, 1.1781920194625854, 1.2645200490951538, 1.2454869747161865, 1.103926420211792, 1.045918345451355, 1.0594834089279175, 1.2291244268417358, 1.1384484767913818, 1.0975267887115479, 1.1171281337738037, 1.1211572885513306, 1.0298423767089844, 1.343593955039978, 1.012998104095459, 1.141796350479126, 1.128769040107727, 1.3342913389205933, 1.112744927406311, 1.128016710281372, 1.1333388090133667, 1.1133661270141602, 1.4416637420654297, 1.1490949392318726, 1.0267572402954102, 1.3179640769958496, 1.0079505443572998, 1.0596275329589844, 1.0140630006790161, 1.0382360219955444, 1.0834566354751587, 1.0566893815994263, 1.1654852628707886, 1.2478998899459839, 1.0361326932907104, 1.1116751432418823, 1.1820513010025024, 1.399999976158142, 1.0437519550323486, 1.1687352657318115, 1.06815505027771, 1.0006959438323975, 1.2990654706954956, 1.154708981513977, 1.2430115938186646, 1.358190655708313, 1.1476657390594482, 1.190513014793396, 1.2843188047409058, 1.162540078163147, 1.330645203590393, 1.1428571939468384, 1.1730589866638184, 1.0330642461776733, 1.1015334129333496, 1.4631578922271729, 1.037562608718872, 1.0262751579284668, 1.2584067583084106, 1.1581224203109741, 1.1494919061660767, 1.0354682207107544, 2.059241771697998, 1.0469032526016235, 1.0315097570419312, 1.449124813079834, 1.079062581062317, 1.0712324380874634, 1.0180379152297974, 1.2047770023345947, 1.1723675727844238, 1.0579290390014648, 1.204079270362854, 1.0640101432800293, 1.0888276100158691, 1.0271166563034058, 1.0563338994979858, 1.4079560041427612, 1.0047101974487305, 1.258920431137085, 1.1470588445663452, 1.1246440410614014, 1.1055927276611328, 1.2694742679595947, 1.0, 1.1223667860031128, 1.3125, 1.0487877130508423, 1.059844732284546, 1.0036603212356567, 1.01077401638031, 1.043776273727417, 1.191430687904358, 1.169284462928772, 1.0549508333206177, 1.0389952659606934, 1.3328592777252197, 1.089219331741333, 1.228588342666626, 1.0619524717330933, 1.0035933256149292, 1.0707547664642334, 1.0569976568222046, 1.10537850856781, 1.3815468549728394, 1.0523113012313843, 1.216694951057434, 1.0936939716339111, 1.074081540107727, 1.0096862316131592, 1.1613372564315796, 1.180974006652832, 1.1981770992279053, 1.1813691854476929, 1.2389734983444214, 1.0774883031845093, 1.153214931488037, 1.1184055805206299, 1.1876941919326782, 1.4642857313156128, 1.1658353805541992, 1.1121028661727905, 1.043194055557251, 1.1151219606399536, 1.0283445119857788, 1.2951929569244385, 1.110558032989502, 1.0628408193588257, 1.1686228513717651, 1.2794853448867798, 1.00516939163208, 1.1037284135818481, 1.0661323070526123, 1.6677619218826294, 1.0598500967025757, 1.0654829740524292, 1.2949895858764648, 1.1757466793060303, 1.4261724948883057, 1.1283611059188843, 1.0353100299835205, 1.0005918741226196, 1.2819530963897705, 1.0036578178405762, 1.0567779541015625, 1.1515368223190308, 1.2719628810882568, 1.0366003513336182, 1.0034358501434326, 1.2476698160171509, 1.388235330581665, 1.0602854490280151, 1.1605380773544312, 1.2246922254562378, 1.077012538909912, 1.0042287111282349, 1.0401474237442017, 1.1329727172851562, 1.0909091234207153, 1.117037296295166, 1.0330381393432617, 1.001375436782837, 1.0315788984298706, 1.1938544511795044, 1.2554250955581665, 1.0993858575820923, 1.14005708694458, 1.0105044841766357, 1.0042369365692139, 1.2073544263839722, 1.165881872177124, 1.1374207735061646, 1.0894248485565186, 1.2957086563110352, 1.0256608724594116, 1.3080172538757324, 1.0088907480239868, 1.0334421396255493, 1.5209165811538696, 1.338559627532959, 1.7601021528244019, 1.1150747537612915, 1.1120049953460693, 1.085714340209961, 1.0578007698059082, 1.1182271242141724]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.762538433074951] ms
 --  Average per query NF    [1.3611221313476562] ms
 --  Average per query vegas [2.401416301727295] ms
Mean [1.151]  Median [1.116]  95th [1.408]  99th [1.669]  max [2.059]
Mean [1.151]  Median [1.116]  95th [1.408]  99th [1.669]  max [2.059]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.800076 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=tupleskew', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
TupleSkewSample - START
0.001
TupleSkewSample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[5.0783157e-04 1.8984079e-04 2.9206276e-06 3.2551289e-03 4.9471855e-06]
Distance score: 0.0007921337964944541
SAUCE Drift detection: True
Detection latency: 0.0228s

DRIFT-DETECTED after 2-th workload
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/incremental_train.py', '--dataset=bjaq', '--end2end', '--model=face', '--model_update=adapt', '--update_size=80000', '--epochs=0']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
update_size: 76433
AdaptTask - START
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
train data shape: 80000, transfer data shape:16000
Training done; evaluating likelihood on full data:
Saved to: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
AdaptTask - END

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 1.993334 | Model-update-time: 2.214461


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=tupleskew', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.168118953704834
tensor(0.9953)
result is  tensor(456447.3750)
Enter testHyper
ReportEsts: [1.0498137474060059, 1.0013761520385742, 1.5790960788726807, 1.2754477262496948, 1.0267635583877563, 1.0377843379974365, 1.2064485549926758, 1.004500389099121, 1.2330138683319092, 1.3172961473464966, 1.0144187211990356, 1.0401427745819092, 1.0644391775131226, 1.1600732803344727, 1.1188310384750366, 1.0067576169967651, 1.1293447017669678, 1.0766757726669312, 1.0059415102005005, 1.400295615196228, 1.080923080444336, 1.0343109369277954, 1.4258233308792114, 1.1991679668426514, 1.0883077383041382, 1.071912407875061, 1.0091838836669922, 1.1963746547698975, 1.2304562330245972, 1.6937119960784912, 1.0926098823547363, 1.6271185874938965, 1.20615816116333, 2.1361095905303955, 1.0228246450424194, 1.0570094585418701, 1.1072895526885986, 1.1642094850540161, 1.906329870223999, 1.0852184295654297, 1.0348341464996338, 1.089186191558838, 1.2429172992706299, 1.3148339986801147, 1.0234886407852173, 1.2195407152175903, 1.2361652851104736, 1.121409296989441, 1.514285683631897, 1.0807442665100098, 1.0297130346298218, 1.0102404356002808, 1.126914143562317, 1.001777172088623, 1.0743061304092407, 1.232590913772583, 1.212182641029358, 1.0928915739059448, 1.2177824974060059, 1.0941094160079956, 1.199105143547058, 1.1096258163452148, 1.0462579727172852, 1.768265962600708, 1.0162776708602905, 1.1248852014541626, 1.4581583738327026, 1.0608881711959839, 1.1425601243972778, 1.1552128791809082, 1.0873202085494995, 1.2104321718215942, 1.0743980407714844, 1.1414532661437988, 1.0119479894638062, 1.2621132135391235, 1.1523250341415405, 1.0205940008163452, 1.0450340509414673, 1.2050617933273315, 1.2966101169586182, 1.2728561162948608, 1.238510012626648, 1.0610880851745605, 1.079132080078125, 1.0266343355178833, 1.3636826276779175, 1.431968331336975, 1.082509994506836, 1.5310519933700562, 1.0433411598205566, 1.1480993032455444, 1.2583502531051636, 1.0815246105194092, 1.1433454751968384, 1.138113021850586, 1.1899441480636597, 1.2063846588134766, 1.0044620037078857, 1.1705280542373657, 1.2244949340820312, 1.1086242198944092, 1.0074074268341064, 1.1834816932678223, 1.007125973701477, 1.1588650941848755, 1.1257729530334473, 1.0646333694458008, 1.0888252258300781, 1.0392122268676758, 1.0610088109970093, 1.044093132019043, 1.1127228736877441, 1.2002204656600952, 1.1263459920883179, 1.0927268266677856, 1.2114208936691284, 1.1604493856430054, 1.189765214920044, 1.1150442361831665, 1.0034538507461548, 1.0389610528945923, 1.0500526428222656, 1.0634688138961792, 1.0538709163665771, 1.3256278038024902, 1.0027464628219604, 1.0766773223876953, 1.0914185047149658, 1.140271544456482, 1.1246918439865112, 1.1665030717849731, 1.2562150955200195, 1.276061773300171, 1.7584905624389648, 1.144264578819275, 1.1246469020843506, 1.1281408071517944, 1.0509674549102783, 1.0102952718734741, 1.026354432106018, 1.2776522636413574, 1.0907877683639526, 1.0666002035140991, 1.10056734085083, 1.030413031578064, 1.192090392112732, 1.0023207664489746, 1.0603642463684082, 1.0331205129623413, 1.2846680879592896, 1.1549803018569946, 1.1817182302474976, 1.0402982234954834, 1.017781138420105, 1.9682151079177856, 1.231359601020813, 2.6111111640930176, 3.6091954708099365, 1.0436577796936035, 1.0003337860107422, 1.1894179582595825, 1.215660810470581, 1.0364829301834106, 1.1482030153274536, 1.1353496313095093, 1.0403978824615479, 1.1441175937652588, 1.16510808467865, 1.3509262800216675, 1.176866054534912, 1.1688323020935059, 1.2477508783340454, 1.1113032102584839, 1.3616352081298828, 1.0459226369857788, 1.0432862043380737, 1.1259887218475342, 1.0517596006393433, 1.101752758026123, 1.8157894611358643, 1.2198845148086548, 1.0208340883255005, 1.664046049118042, 1.4122107028961182, 1.203781247138977, 1.0203779935836792, 1.0545309782028198, 1.270370364189148, 1.0113636255264282, 1.2046767473220825, 1.0074728727340698, 1.3660311698913574, 1.9383753538131714, 1.1081922054290771, 1.453112006187439, 1.1626383066177368, 1.0350193977355957, 1.1533100605010986, 1.1892985105514526]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7317276000976562] ms
 --  Average per query NF    [1.360384225845337] ms
 --  Average per query vegas [2.3713433742523193] ms
Mean [1.193]  Median [1.126]  95th [1.666]  99th [2.141]  max [3.609]
Mean [1.193]  Median [1.126]  95th [1.666]  99th [2.141]  max [3.609]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.375939 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=1 | total-time=28.409081