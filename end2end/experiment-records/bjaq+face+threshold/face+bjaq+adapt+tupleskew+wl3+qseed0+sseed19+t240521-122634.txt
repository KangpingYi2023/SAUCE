Input arguments = Namespace(data_update='tupleskew', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 19, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.15808629989624
tensor(0.9941)
result is  tensor(379911.8438)
Enter testHyper
ReportEsts: [1.124343752861023, 1.053800344467163, 1.3820499181747437, 1.1562434434890747, 1.21875, 1.1484923362731934, 1.2332442998886108, 1.1949923038482666, 1.1108033657073975, 1.1164534091949463, 1.0232558250427246, 1.0879237651824951, 1.0163323879241943, 1.0647321939468384, 1.1472049951553345, 1.3448407649993896, 1.1810072660446167, 1.2459620237350464, 1.0686731338500977, 1.0103092193603516, 1.0737310647964478, 1.0552057027816772, 1.1592768430709839, 1.0597940683364868, 1.0878052711486816, 1.135623812675476, 1.1835585832595825, 1.3514643907546997, 1.0192323923110962, 1.1458650827407837, 1.0500177145004272, 1.276688814163208, 1.0717731714248657, 1.0046488046646118, 1.1226733922958374, 1.0248690843582153, 1.494513988494873, 1.2082507610321045, 1.0374257564544678, 1.0310180187225342, 1.0229105949401855, 1.1199806928634644, 1.071418046951294, 1.030885934829712, 1.0604268312454224, 1.040816307067871, 1.1439539194107056, 1.3447611331939697, 1.0755178928375244, 1.1099830865859985, 1.188144326210022, 1.3907591104507446, 1.0164119005203247, 1.1697722673416138, 1.2263784408569336, 1.0101993083953857, 1.2598130702972412, 1.1888049840927124, 1.0943164825439453, 1.3933945894241333, 1.2695820331573486, 1.1967322826385498, 1.264703631401062, 1.1573950052261353, 1.375, 1.2000000476837158, 1.1117020845413208, 1.0952461957931519, 1.1542096138000488, 1.1578947305679321, 1.0096540451049805, 1.081489086151123, 1.3211482763290405, 1.1697710752487183, 1.1428000926971436, 1.0323072671890259, 1.952298879623413, 1.0817739963531494, 1.0937464237213135, 1.120713710784912, 1.1938844919204712, 1.1754158735275269, 1.0459405183792114, 1.1615159511566162, 1.2304842472076416, 1.0115059614181519, 1.0399208068847656, 1.0022194385528564, 1.0360037088394165, 1.0511651039123535, 1.0686453580856323, 1.2052794694900513, 1.0003606081008911, 1.3098524808883667, 1.0540540218353271, 1.1006938219070435, 1.2236279249191284, 1.1499559879302979, 1.034482717514038, 1.0852916240692139, 1.2484755516052246, 1.0383325815200806, 1.055570125579834, 1.0131771564483643, 1.1028242111206055, 1.104628086090088, 1.2440475225448608, 1.1937172412872314, 1.0604920387268066, 1.0525933504104614, 1.1701791286468506, 1.084181308746338, 1.380325198173523, 1.1411622762680054, 1.1222904920578003, 1.1822916269302368, 1.0120543241500854, 1.0014208555221558, 1.3979350328445435, 1.0813409090042114, 1.382063388824463, 1.1415067911148071, 1.0997532606124878, 1.1744800806045532, 1.3313953876495361, 1.1946966648101807, 1.2315638065338135, 1.218798041343689, 1.3505244255065918, 1.1265865564346313, 1.078717589378357, 1.2577427625656128, 1.2560596466064453, 1.3928571939468384, 1.0673030614852905, 1.144394874572754, 1.16290283203125, 1.046504020690918, 1.1024456024169922, 1.571898102760315, 1.071681022644043, 1.1183221340179443, 1.1434231996536255, 1.3586337566375732, 1.1417028903961182, 1.0021052360534668, 1.0578744411468506, 1.2365086078643799, 1.012946605682373, 1.158593773841858, 1.0234788656234741, 1.172285556793213, 1.346637487411499, 1.115338683128357, 1.2373117208480835, 1.0265930891036987, 1.1919547319412231, 1.0396735668182373, 1.0534082651138306, 1.2019695043563843, 1.265012502670288, 1.052904486656189, 1.065016269683838, 1.24105966091156, 1.0350877046585083, 1.0807942152023315, 1.2601701021194458, 1.1822383403778076, 1.0139509439468384, 1.033697485923767, 1.0178059339523315, 1.019174575805664, 1.1688311100006104, 1.0841554403305054, 1.233310580253601, 1.0331462621688843, 1.0379009246826172, 1.1694949865341187, 1.1476637125015259, 1.0772823095321655, 1.0037001371383667, 1.1505045890808105, 1.0026782751083374, 1.1164453029632568, 1.1626222133636475, 1.124735713005066, 1.0748372077941895, 1.277284026145935, 1.1263432502746582, 1.1951414346694946, 1.1171711683273315, 1.0289698839187622, 1.522945523262024, 1.2684462070465088, 1.7622541189193726, 1.2242577075958252, 1.080867052078247, 1.1692308187484741, 1.014230489730835, 1.005677342414856]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7502825260162354] ms
 --  Average per query NF    [1.359405517578125] ms
 --  Average per query vegas [2.3908770084381104] ms
Mean [1.150]  Median [1.124]  95th [1.382]  99th [1.574]  max [1.952]
Mean [1.150]  Median [1.124]  95th [1.382]  99th [1.574]  max [1.952]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.832816 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=tupleskew', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
TupleSkewSample - START
0.001
TupleSkewSample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[2.0188093e-04 4.2915344e-04 1.6808510e-05 4.0400028e-04 6.3180923e-06]
Distance score: 0.00021163225756026804
SAUCE Drift detection: True
Detection latency: 0.0228s

DRIFT-DETECTED after 2-th workload
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/incremental_train.py', '--dataset=bjaq', '--end2end', '--model=face', '--model_update=adapt', '--update_size=80000', '--epochs=0']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
update_size: 76433
AdaptTask - START
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
train data shape: 80000, transfer data shape:16000
Training done; evaluating likelihood on full data:
Saved to: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
AdaptTask - END

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.006666 | Model-update-time: 2.248086


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=tupleskew', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.169413089752197
tensor(0.9957)
result is  tensor(456636.3125)
Enter testHyper
ReportEsts: [1.0476561784744263, 1.0118412971496582, 1.2031872272491455, 1.8262966871261597, 1.0331311225891113, 1.250674843788147, 1.0493780374526978, 1.0145350694656372, 1.0949116945266724, 1.0463687181472778, 1.0305862426757812, 1.1085532903671265, 1.0477327108383179, 1.0727163553237915, 1.177040457725525, 1.0581392049789429, 1.0930743217468262, 1.1354336738586426, 1.1180033683776855, 1.2606420516967773, 1.049582839012146, 1.1394857168197632, 1.036272644996643, 1.1061716079711914, 1.05647873878479, 1.1038343906402588, 1.0245436429977417, 1.018074631690979, 1.219160556793213, 1.6341270208358765, 1.2756410837173462, 1.3728814125061035, 1.0154714584350586, 1.4561041593551636, 1.1828422546386719, 1.0822104215621948, 1.051429033279419, 1.0014021396636963, 1.1367470026016235, 1.049232006072998, 1.0375401973724365, 1.3526140451431274, 1.0466643571853638, 1.0602920055389404, 1.066723108291626, 1.1289180517196655, 1.170681118965149, 1.067794680595398, 1.3238095045089722, 1.1774996519088745, 1.072672724723816, 1.0925034284591675, 1.0064561367034912, 1.0988831520080566, 1.0434998273849487, 1.1363117694854736, 1.2039347887039185, 1.0003236532211304, 1.1805497407913208, 1.1533961296081543, 1.235023021697998, 1.01675283908844, 1.1214693784713745, 1.2225821018218994, 1.0692991018295288, 1.060378074645996, 1.2879163026809692, 1.0576540231704712, 1.1418060064315796, 1.0847800970077515, 1.1598877906799316, 1.1200671195983887, 1.1526505947113037, 1.0662542581558228, 1.2476940155029297, 1.0640201568603516, 1.174294114112854, 1.0293333530426025, 1.4682925939559937, 1.10957670211792, 1.0849342346191406, 1.0195335149765015, 1.245880365371704, 1.0703344345092773, 1.312456727027893, 1.536170244216919, 1.048875093460083, 1.410963535308838, 1.133437156677246, 1.33984375, 1.0281859636306763, 1.272325038909912, 1.2645821571350098, 1.130285620689392, 1.227540373802185, 1.0082498788833618, 1.002924919128418, 1.2041763067245483, 1.6184766292572021, 1.0482048988342285, 1.1213834285736084, 1.1897116899490356, 1.0099010467529297, 1.021162748336792, 1.3889564275741577, 1.1010401248931885, 1.0090292692184448, 1.0874305963516235, 1.017192006111145, 1.079910397529602, 1.014933705329895, 1.1621088981628418, 1.0945454835891724, 1.2106372117996216, 1.023201823234558, 1.0746288299560547, 1.024829387664795, 1.014286756515503, 1.3533581495285034, 1.017699122428894, 1.034433126449585, 1.0722771883010864, 1.0171334743499756, 1.3920212984085083, 1.216867446899414, 1.1205765008926392, 1.0052409172058105, 1.7255216836929321, 1.2180906534194946, 1.0200464725494385, 1.1506438255310059, 1.0013768672943115, 1.0428743362426758, 1.4688091278076172, 1.5566914081573486, 1.0077723264694214, 1.0079679489135742, 1.0356416702270508, 1.1160025596618652, 1.1459858417510986, 1.0857760906219482, 1.2433801889419556, 1.0816326141357422, 1.0209161043167114, 1.0234118700027466, 1.0743602514266968, 1.2710843086242676, 1.0949621200561523, 1.204149842262268, 1.0199062824249268, 1.0063334703445435, 1.1405045986175537, 1.2023143768310547, 1.045082688331604, 1.0642691850662231, 1.073554515838623, 1.0742764472961426, 1.1048387289047241, 1.7316559553146362, 1.1635916233062744, 1.1078182458877563, 1.0139410495758057, 1.2413184642791748, 1.0624951124191284, 1.1755061149597168, 1.1227773427963257, 1.3057911396026611, 1.2432947158813477, 1.0987951755523682, 1.175571322441101, 1.1014262437820435, 1.0672681331634521, 1.5581761598587036, 1.1157704591751099, 1.0844004154205322, 1.005924105644226, 1.1975666284561157, 1.116674780845642, 1.164659023284912, 1.141168236732483, 1.7105263471603394, 1.1455210447311401, 1.1298898458480835, 1.3283658027648926, 1.4019885063171387, 1.249252200126648, 1.0216699838638306, 1.0206180810928345, 1.2816137075424194, 1.0301710367202759, 1.1332995891571045, 1.011921763420105, 1.1287192106246948, 1.6511434316635132, 1.0018094778060913, 1.2461844682693481, 1.2836898565292358, 1.0220794677734375, 1.4488054513931274, 1.0146840810775757]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7535369396209717] ms
 --  Average per query NF    [1.3608002662658691] ms
 --  Average per query vegas [2.3927366733551025] ms
Mean [1.152]  Median [1.104]  95th [1.472]  99th [1.726]  max [1.826]
Mean [1.152]  Median [1.104]  95th [1.472]  99th [1.726]  max [1.826]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.389559 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=1 | total-time=28.501859