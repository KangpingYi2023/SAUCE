Input arguments = Namespace(data_update='tupleskew', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 86, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.177212715148926
tensor(0.9966)
result is  tensor(380883.1875)
Enter testHyper
ReportEsts: [1.1268346309661865, 1.0393251180648804, 1.1761435270309448, 1.0789639949798584, 1.2149184942245483, 1.0805773735046387, 1.0219382047653198, 1.0899207592010498, 1.023539423942566, 1.2023394107818604, 1.1085271835327148, 1.1927965879440308, 1.093826174736023, 1.0200892686843872, 1.2036558389663696, 1.2674044370651245, 1.2192744016647339, 1.1610450744628906, 1.1716499328613281, 1.086734652519226, 1.0199687480926514, 1.0511746406555176, 1.1307998895645142, 1.1132349967956543, 1.100547194480896, 1.1907775402069092, 1.0619369745254517, 1.5157203674316406, 1.0710428953170776, 1.0227850675582886, 1.1010997295379639, 1.1427128314971924, 1.128798246383667, 1.0546224117279053, 1.2150386571884155, 1.148821234703064, 1.4103785753250122, 1.2623200416564941, 1.063495397567749, 1.1342514753341675, 1.0017528533935547, 1.0686986446380615, 1.0647162199020386, 1.023693323135376, 1.107965350151062, 1.014959692955017, 1.015764832496643, 1.256433367729187, 1.0948323011398315, 1.0406091213226318, 1.2163587808609009, 1.2012542486190796, 1.0693635940551758, 1.1238988637924194, 1.0291588306427002, 1.1050069332122803, 1.172897219657898, 1.1418014764785767, 1.227717638015747, 1.4535542726516724, 1.4023311138153076, 1.1906447410583496, 1.3945192098617554, 1.1151024103164673, 1.166077733039856, 1.0, 1.1621872186660767, 1.0043100118637085, 1.1027157306671143, 1.24210524559021, 1.054706335067749, 1.0208964347839355, 1.2607769966125488, 1.2100330591201782, 1.2163902521133423, 1.2872323989868164, 1.7594406604766846, 1.0539653301239014, 1.0106678009033203, 1.1495957374572754, 1.350844144821167, 1.0780165195465088, 1.0469871759414673, 1.2366317510604858, 1.2657378911972046, 1.1143828630447388, 1.1273475885391235, 1.0361160039901733, 1.0497413873672485, 1.0595406293869019, 1.0321179628372192, 1.2345205545425415, 1.0401350259780884, 1.3430942296981812, 1.0205128192901611, 1.1577128171920776, 1.157196283340454, 1.436813473701477, 1.01694917678833, 1.150079607963562, 1.038022756576538, 1.0530058145523071, 1.0808688402175903, 1.0007320642471313, 1.022241234779358, 1.0860481262207031, 1.0331732034683228, 1.1727749109268188, 1.068159818649292, 1.0116468667984009, 1.1689953804016113, 1.0902326107025146, 1.2967067956924438, 1.028446912765503, 1.0905296802520752, 1.1884816884994507, 1.0671958923339844, 1.0377459526062012, 1.3024485111236572, 1.074771761894226, 1.1957406997680664, 1.0775493383407593, 1.183103322982788, 1.1390275955200195, 1.2180233001708984, 1.1560049057006836, 1.0711748600006104, 1.095645546913147, 1.2853577136993408, 1.0627923011779785, 1.1140613555908203, 1.2335368394851685, 1.2666252851486206, 1.4642857313156128, 1.0953879356384277, 1.027303695678711, 1.0423015356063843, 1.0549592971801758, 1.0946831703186035, 1.3184010982513428, 1.1479417085647583, 1.0988359451293945, 1.204239010810852, 1.1599273681640625, 1.0234936475753784, 1.1038392782211304, 1.0713021755218506, 1.4725120067596436, 1.082790493965149, 1.0730071067810059, 1.0846425294876099, 1.1635687351226807, 1.4010238647460938, 1.1056324243545532, 1.200270175933838, 1.0467064380645752, 1.1216237545013428, 1.0079410076141357, 1.0868773460388184, 1.3367352485656738, 1.0281769037246704, 1.0093010663986206, 1.0339176654815674, 1.3086591958999634, 1.2339869737625122, 1.0931440591812134, 1.2400346994400024, 1.1670197248458862, 1.167035698890686, 1.0319091081619263, 1.0239245891571045, 1.1174625158309937, 1.1103895902633667, 1.1472440958023071, 1.0723155736923218, 1.2629551887512207, 1.1030126810073853, 1.1720995903015137, 1.313625693321228, 1.195917010307312, 1.0160058736801147, 1.0474997758865356, 1.0239554643630981, 1.1542390584945679, 1.137269139289856, 1.1553910970687866, 1.025191307067871, 1.287813663482666, 1.116974949836731, 1.5072137117385864, 1.0304350852966309, 1.081951379776001, 1.5882025957107544, 1.2178432941436768, 1.7178611755371094, 1.1017624139785767, 1.2743643522262573, 1.1014492511749268, 1.0960551500320435, 1.1076360940933228]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7905848026275635] ms
 --  Average per query NF    [1.3634634017944336] ms
 --  Average per query vegas [2.42712140083313] ms
Mean [1.147]  Median [1.109]  95th [1.403]  99th [1.589]  max [1.759]
Mean [1.147]  Median [1.109]  95th [1.403]  99th [1.589]  max [1.759]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.840720 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=tupleskew', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
TupleSkewSample - START
0.001
TupleSkewSample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[2.1636486e-05 2.1278858e-05 4.9650669e-05 1.1265278e-05 3.0994415e-06]
Distance score: 2.1386145817814395e-05
SAUCE Drift detection: True
Detection latency: 0.0230s

DRIFT-DETECTED after 2-th workload
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/incremental_train.py', '--dataset=bjaq', '--end2end', '--model=face', '--model_update=adapt', '--update_size=80000', '--epochs=0']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
update_size: 76433
AdaptTask - START
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
train data shape: 80000, transfer data shape:16000
Training done; evaluating likelihood on full data:
Saved to: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
AdaptTask - END

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.004512 | Model-update-time: 2.212321


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=tupleskew', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.170269966125488
tensor(0.9948)
result is  tensor(456236.0938)
Enter testHyper
ReportEsts: [1.0160191059112549, 1.0325353145599365, 1.0664652585983276, 1.14897620677948, 1.0330029726028442, 1.072139859199524, 1.3528807163238525, 1.0733033418655396, 1.0671015977859497, 1.1147778034210205, 1.0091743469238281, 2.5634920597076416, 1.0, 1.1046298742294312, 1.006629228591919, 1.0366289615631104, 1.0025190114974976, 1.0478787422180176, 1.1323847770690918, 1.1971219778060913, 1.2544554471969604, 1.377591848373413, 1.2932442426681519, 1.0740572214126587, 1.1609787940979004, 1.1674953699111938, 1.0195029973983765, 1.0417035818099976, 1.472334623336792, 1.4139692783355713, 1.2233874797821045, 1.5254237651824951, 1.0617493391036987, 1.0785508155822754, 1.0749722719192505, 1.0111898183822632, 1.2385081052780151, 1.1019724607467651, 1.0163453817367554, 1.1331086158752441, 1.0398870706558228, 1.0975877046585083, 1.0609161853790283, 1.0462899208068848, 1.0060465335845947, 1.0235246419906616, 1.0320570468902588, 1.1608941555023193, 1.3333333730697632, 1.3475855588912964, 1.0657978057861328, 1.0329256057739258, 1.0423015356063843, 1.02494478225708, 1.1953858137130737, 1.4982244968414307, 1.2679307460784912, 1.1659101247787476, 1.3054323196411133, 1.19027841091156, 1.175438642501831, 1.0667431354522705, 1.137269139289856, 1.3383351564407349, 1.0362600088119507, 1.1430964469909668, 1.2910130023956299, 1.0549757480621338, 1.2228683233261108, 1.0007305145263672, 1.2622324228286743, 1.3574016094207764, 1.1093369722366333, 1.1080988645553589, 1.0767241716384888, 1.1771347522735596, 1.0332796573638916, 1.1481423377990723, 1.0630062818527222, 1.1366920471191406, 1.0173227787017822, 1.1306393146514893, 1.168503999710083, 1.2618781328201294, 1.318509578704834, 1.578723430633545, 1.396030306816101, 1.3286542892456055, 1.5385081768035889, 1.4970452785491943, 1.1861885786056519, 1.0891495943069458, 1.4461696147918701, 1.1141736507415771, 1.0627480745315552, 1.0160870552062988, 1.1375876665115356, 1.3468434810638428, 1.3008618354797363, 1.0015723705291748, 1.1906046867370605, 1.0630477666854858, 1.4423528909683228, 1.0660781860351562, 1.1605368852615356, 1.3096916675567627, 1.0411456823349, 1.1167713403701782, 1.0804953575134277, 1.2327868938446045, 1.08846914768219, 1.0057621002197266, 1.4914124011993408, 1.3859161138534546, 1.007285237312317, 1.079598307609558, 1.010269045829773, 1.2388312816619873, 1.0488165616989136, 1.0619468688964844, 1.0061571598052979, 1.0429853200912476, 1.0732427835464478, 1.6227221488952637, 1.0918469429016113, 1.0267761945724487, 1.2313953638076782, 1.4217252731323242, 1.0591462850570679, 1.0137537717819214, 1.213411808013916, 1.1128169298171997, 1.2005151510238647, 1.7383918762207031, 1.416107416152954, 1.0792948007583618, 1.0046775341033936, 1.0196226835250854, 1.1134730577468872, 1.0087302923202515, 1.0331716537475586, 1.2496525049209595, 1.0342693328857422, 1.1177659034729004, 1.0301514863967896, 1.0170425176620483, 1.2057143449783325, 1.0360585451126099, 1.0202971696853638, 1.17664635181427, 1.2829086780548096, 1.1008079051971436, 1.1691921949386597, 1.0218042135238647, 1.0373735427856445, 1.2336037158966064, 1.125990867614746, 1.0959999561309814, 1.525429129600525, 1.3201154470443726, 1.0656723976135254, 1.2074270248413086, 1.8538446426391602, 1.159321904182434, 1.1412968635559082, 1.2116460800170898, 1.0838947296142578, 1.1146219968795776, 1.121314525604248, 1.291815996170044, 1.1876670122146606, 1.1324162483215332, 1.476961374282837, 1.085716962814331, 1.0238736867904663, 1.0483016967773438, 1.571123719215393, 1.0043087005615234, 1.0310420989990234, 1.0499526262283325, 1.8684210777282715, 1.0217851400375366, 1.1129240989685059, 1.3362339735031128, 1.202965259552002, 1.2941603660583496, 1.1109845638275146, 1.0566608905792236, 1.4019253253936768, 1.0004206895828247, 1.1731140613555908, 1.0736421346664429, 1.0803022384643555, 1.715447187423706, 1.1017251014709473, 1.0350373983383179, 1.3709988594055176, 1.0028772354125977, 1.253787875175476, 1.1439329385757446]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.732560873031616] ms
 --  Average per query NF    [1.3568460941314697] ms
 --  Average per query vegas [2.3757147789001465] ms
Mean [1.177]  Median [1.114]  95th [1.525]  99th [1.854]  max [2.563]
Mean [1.177]  Median [1.114]  95th [1.525]  99th [1.854]  max [2.563]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.389894 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=1 | total-time=28.502177