Input arguments = Namespace(data_update='tupleskew', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 84, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.181975603103638
tensor(0.9911)
result is  tensor(378769.1250)
Enter testHyper
ReportEsts: [1.1645678281784058, 1.0233430862426758, 1.4022327661514282, 1.06380295753479, 1.264050006866455, 1.0863112211227417, 1.0964832305908203, 1.2824736833572388, 1.0795692205429077, 1.0529425144195557, 1.1033592224121094, 1.1457626819610596, 1.0499202013015747, 1.03125, 1.2145090103149414, 1.4179984331130981, 1.3733701705932617, 1.1684085130691528, 1.1249442100524902, 1.038265347480774, 1.0119378566741943, 1.0359364748001099, 1.1632829904556274, 1.0206618309020996, 1.1380380392074585, 1.2884267568588257, 1.0982545614242554, 1.4000866413116455, 1.0071691274642944, 1.0983623266220093, 1.112805962562561, 1.2675498723983765, 1.0008879899978638, 1.0159766674041748, 1.1435924768447876, 1.2554020881652832, 1.5232148170471191, 1.1689456701278687, 1.0325063467025757, 1.0283832550048828, 1.0104299783706665, 1.1549346446990967, 1.0024774074554443, 1.008198618888855, 1.0553560256958008, 1.0396825075149536, 1.1752526760101318, 1.4384013414382935, 1.0937647819519043, 1.1675126552581787, 1.1641414165496826, 1.2681312561035156, 1.1258381605148315, 1.2105907201766968, 1.1703581809997559, 1.0375521183013916, 1.258878469467163, 1.1529748439788818, 1.166835904121399, 1.423142671585083, 1.2286920547485352, 1.246180534362793, 1.3823705911636353, 1.1171795129776, 1.3924050331115723, 1.0285714864730835, 1.1708683967590332, 1.021902084350586, 1.1640210151672363, 1.263157844543457, 1.1058719158172607, 1.017143726348877, 1.2993592023849487, 1.1192262172698975, 1.1739563941955566, 1.2059435844421387, 1.6736987829208374, 1.0188548564910889, 1.036313533782959, 1.3268669843673706, 1.1609971523284912, 1.0612179040908813, 1.1187688112258911, 1.0961042642593384, 1.219422698020935, 1.00801420211792, 1.1768181324005127, 1.235107183456421, 1.0365594625473022, 1.1258810758590698, 1.0815657377243042, 1.3962490558624268, 1.0115398168563843, 1.3014897108078003, 1.167664647102356, 1.0031179189682007, 1.2274972200393677, 1.1563652753829956, 1.034482717514038, 1.1145024299621582, 1.1784173250198364, 1.0980421304702759, 1.1005845069885254, 1.010354995727539, 1.0316945314407349, 1.2376834154129028, 1.2315276861190796, 1.2111692428588867, 1.0785256624221802, 1.0628976821899414, 1.288877010345459, 1.0902326107025146, 1.1775848865509033, 1.0410035848617554, 1.105366826057434, 1.1237623691558838, 1.0975369215011597, 1.0592029094696045, 1.107944369316101, 1.205767273902893, 1.382063388824463, 1.1114253997802734, 1.1134893894195557, 1.1781549453735352, 1.3173449039459229, 1.199133276939392, 1.28775954246521, 1.3623429536819458, 1.2601957321166992, 1.1018704175949097, 1.1143543720245361, 1.0904650688171387, 1.1995028257369995, 1.5, 1.0785088539123535, 1.0126017332077026, 1.0207018852233887, 1.0237398147583008, 1.069757103919983, 1.238369107246399, 1.15456223487854, 1.1510059833526611, 1.0351048707962036, 1.3441466093063354, 1.0182665586471558, 1.0173773765563965, 1.149196743965149, 1.3569538593292236, 1.0969234704971313, 1.1096590757369995, 1.2326489686965942, 1.157415747642517, 1.3185224533081055, 1.0779170989990234, 1.105718970298767, 1.0115838050842285, 1.089998483657837, 1.0377039909362793, 1.078972339630127, 1.1468218564987183, 1.1450051069259644, 1.0931239128112793, 1.0722403526306152, 1.295988917350769, 1.0339540243148804, 1.1177200078964233, 1.2671101093292236, 1.429969072341919, 1.1401617527008057, 1.0212326049804688, 1.022522211074829, 1.1044223308563232, 1.1948051452636719, 1.0779690742492676, 1.0708446502685547, 1.1713145971298218, 1.000971794128418, 1.2881619930267334, 1.158881664276123, 1.302227258682251, 1.0509567260742188, 1.2933454513549805, 1.0232799053192139, 1.1664963960647583, 1.120970606803894, 1.1575052738189697, 1.0515018701553345, 1.3356877565383911, 1.0393683910369873, 1.4076744318008423, 1.0747289657592773, 1.0750558376312256, 1.4605937004089355, 1.1036372184753418, 1.6001412868499756, 1.2584415674209595, 1.1715714931488037, 1.20634925365448, 1.1439937353134155, 1.0437582731246948]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.726773262023926] ms
 --  Average per query NF    [1.359649896621704] ms
 --  Average per query vegas [2.3671233654022217] ms
Mean [1.158]  Median [1.125]  95th [1.403]  99th [1.524]  max [1.674]
Mean [1.158]  Median [1.125]  95th [1.403]  99th [1.524]  max [1.674]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.872090 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=tupleskew', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
TupleSkewSample - START
0.001
TupleSkewSample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[2.8729439e-05 1.5902519e-04 1.6272068e-05 5.0663948e-06 2.9802322e-07]
Distance score: 4.187822196399793e-05
SAUCE Drift detection: True
Detection latency: 0.0229s

DRIFT-DETECTED after 2-th workload
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/incremental_train.py', '--dataset=bjaq', '--end2end', '--model=face', '--model_update=adapt', '--update_size=80000', '--epochs=0']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
update_size: 76433
AdaptTask - START
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
train data shape: 80000, transfer data shape:16000
Training done; evaluating likelihood on full data:
Saved to: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
AdaptTask - END

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 1.997373 | Model-update-time: 2.238168


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=tupleskew', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.164619445800781
tensor(0.9935)
result is  tensor(455623.4375)
Enter testHyper
ReportEsts: [1.0197951793670654, 1.1253119707107544, 1.309696078300476, 1.2704837322235107, 1.0317742824554443, 1.0312049388885498, 1.2553175687789917, 1.00887930393219, 1.1338424682617188, 1.1222797632217407, 1.038609504699707, 1.149290919303894, 1.0023866891860962, 1.205925703048706, 1.115203857421875, 1.0460686683654785, 1.0864297151565552, 1.1907172203063965, 1.0100585222244263, 1.2667652368545532, 1.0838263034820557, 1.1764628887176514, 1.4604899883270264, 1.0011769533157349, 1.0135035514831543, 1.095658779144287, 1.0090538263320923, 1.088421106338501, 1.0297960042953491, 1.4086956977844238, 1.0702905654907227, 1.5847457647323608, 1.0199710130691528, 1.2221158742904663, 1.0848603248596191, 1.0129998922348022, 1.1226145029067993, 1.0838019847869873, 1.1769375801086426, 1.1836228370666504, 1.0072261095046997, 1.8275058269500732, 1.0977087020874023, 1.0753437280654907, 1.1610198020935059, 1.410825490951538, 1.266386866569519, 1.0758183002471924, 1.4952380657196045, 1.2734053134918213, 1.0674299001693726, 1.0308841466903687, 1.045576810836792, 1.0852811336517334, 1.1724987030029297, 1.4035041332244873, 1.1140987873077393, 1.0614370107650757, 1.306639313697815, 1.0687155723571777, 1.1601731777191162, 1.0182970762252808, 1.0852484703063965, 1.2702265977859497, 1.0065717697143555, 1.0092777013778687, 1.3092516660690308, 1.1898809671401978, 1.0858955383300781, 1.0280500650405884, 1.0872607231140137, 1.2518064975738525, 1.120648980140686, 1.1134181022644043, 1.053336501121521, 1.4311240911483765, 2.698653221130371, 1.033896565437317, 1.117281436920166, 1.2431479692459106, 1.0349496603012085, 1.331295132637024, 1.0064408779144287, 1.198573350906372, 1.3166627883911133, 1.5829787254333496, 1.337255597114563, 1.462486743927002, 1.427135705947876, 1.2355155944824219, 1.0923476219177246, 1.1365450620651245, 1.2815717458724976, 1.0570353269577026, 1.2479195594787598, 1.1714524030685425, 1.1084507703781128, 1.3613044023513794, 1.4542208909988403, 1.1450358629226685, 1.0421404838562012, 1.1852837800979614, 1.5012531280517578, 1.076757550239563, 1.0582242012023926, 1.157823085784912, 1.0825128555297852, 1.032838225364685, 1.0086705684661865, 1.0788620710372925, 1.002677321434021, 1.0128557682037354, 1.1963040828704834, 1.0852116346359253, 1.0284043550491333, 1.0345656871795654, 1.139101266860962, 1.0531938076019287, 1.0458459854125977, 1.046296238899231, 1.0647461414337158, 1.491588830947876, 1.1144437789916992, 1.72494375705719, 1.200203537940979, 1.058811068534851, 1.1433844566345215, 1.3313343524932861, 1.0248496532440186, 1.1800217628479004, 1.1054130792617798, 1.0251331329345703, 1.0067521333694458, 1.3792470693588257, 1.4524976015090942, 1.0480448007583618, 1.0476924180984497, 1.1200000047683716, 1.1550087928771973, 1.0674346685409546, 1.01698637008667, 1.161304235458374, 1.014129400253296, 1.1007298231124878, 1.052410364151001, 1.1119643449783325, 2.34883713722229, 1.014120101928711, 1.1169447898864746, 1.1227890253067017, 1.2091113328933716, 1.0442975759506226, 1.1253290176391602, 1.0769853591918945, 1.0608515739440918, 1.116593837738037, 1.0689077377319336, 1.0873016119003296, 1.3076236248016357, 1.001768708229065, 1.1373484134674072, 1.0624682903289795, 1.6754777431488037, 1.0986957550048828, 1.0141137838363647, 1.0956246852874756, 1.1180049180984497, 1.2403119802474976, 1.258873462677002, 1.2661426067352295, 1.1495122909545898, 1.1782171726226807, 1.433227300643921, 1.3430500030517578, 1.0914504528045654, 1.1079437732696533, 1.0456981658935547, 1.016809344291687, 1.1170834302902222, 1.0793579816818237, 1.8684210777282715, 1.04150390625, 1.0084601640701294, 1.7092835903167725, 1.4778105020523071, 1.4305123090744019, 1.2346081733703613, 1.09781813621521, 1.350746989250183, 1.0564996004104614, 1.0848994255065918, 1.1185740232467651, 1.1655975580215454, 1.643965244293213, 1.0441100597381592, 1.1071569919586182, 1.0961862802505493, 1.1226509809494019, 1.814685344696045, 1.185086727142334]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7126171588897705] ms
 --  Average per query NF    [1.3540053367614746] ms
 --  Average per query vegas [2.358611822128296] ms
Mean [1.183]  Median [1.114]  95th [1.583]  99th [1.873]  max [2.699]
Mean [1.183]  Median [1.114]  95th [1.583]  99th [1.873]  max [2.699]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.376610 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=1 | total-time=28.531992