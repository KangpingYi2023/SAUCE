Input arguments = Namespace(data_update='sample', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 67, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.156912326812744
tensor(0.9936)
result is  tensor(379731.)
Enter testHyper
ReportEsts: [1.0949946641921997, 1.0998443365097046, 1.1620593070983887, 1.2126764059066772, 1.2850664854049683, 1.0709497928619385, 1.306971549987793, 1.143677830696106, 1.0802154541015625, 1.0422658920288086, 1.0714900493621826, 1.1832627058029175, 1.1395070552825928, 1.015625, 1.1222695112228394, 1.1465312242507935, 1.3338695764541626, 1.0638954639434814, 1.1754740476608276, 1.1122448444366455, 1.1564252376556396, 1.0752321481704712, 1.127721905708313, 1.145977258682251, 1.1560075283050537, 1.1283905506134033, 1.0157657861709595, 1.4898524284362793, 1.124246597290039, 1.0742548704147339, 1.1677900552749634, 1.084922432899475, 1.11421799659729, 1.023773431777954, 1.0419206619262695, 1.0996137857437134, 1.1461994647979736, 1.0102721452713013, 1.1350003480911255, 1.0538922548294067, 1.0134215354919434, 1.0558780431747437, 1.0593734979629517, 1.0306122303009033, 1.0688780546188354, 1.0850340127944946, 1.1824419498443604, 1.2801613807678223, 1.0520915985107422, 1.0930626392364502, 1.152500033378601, 1.3775743246078491, 1.1360667943954468, 1.310904860496521, 1.1923892498016357, 1.0020862817764282, 1.277570128440857, 1.1425437927246094, 1.0502521991729736, 1.4010088443756104, 1.2376242876052856, 1.146157145500183, 1.4215984344482422, 1.063883662223816, 1.2840466499328613, 1.085714340209961, 1.155760407447815, 1.0055811405181885, 1.0231637954711914, 1.2526315450668335, 1.1693320274353027, 1.002806305885315, 1.249146580696106, 1.3061448335647583, 1.2428926229476929, 1.0024703741073608, 1.9009512662887573, 1.0365787744522095, 1.1469842195510864, 1.2438490390777588, 1.4310930967330933, 1.002266526222229, 1.06875479221344, 1.1671943664550781, 1.2483474016189575, 1.140387773513794, 1.1590380668640137, 1.0734202861785889, 1.0161274671554565, 1.1019984483718872, 1.0582282543182373, 1.3207200765609741, 1.0054093599319458, 1.2749594449996948, 1.0955055952072144, 1.0568976402282715, 1.0794811248779297, 1.262654185295105, 1.034482717514038, 1.236869215965271, 1.0890957117080688, 1.12142813205719, 1.1106481552124023, 1.0036603212356567, 1.0272942781448364, 1.017174482345581, 1.3094768524169922, 1.1902269124984741, 1.0014467239379883, 1.0865648984909058, 1.1137875318527222, 1.0654546022415161, 1.1231369972229004, 1.0668814182281494, 1.112089991569519, 1.0707547664642334, 1.0220853090286255, 1.055591344833374, 1.307840347290039, 1.0924986600875854, 1.1789300441741943, 1.1288808584213257, 1.0379409790039062, 1.1783461570739746, 1.3909883499145508, 1.2213165760040283, 1.1148076057434082, 1.0354043245315552, 1.2918059825897217, 1.1606546640396118, 1.0674052238464355, 1.2111246585845947, 1.2834059000015259, 1.3928571939468384, 1.0643869638442993, 1.099238634109497, 1.0035871267318726, 1.1804877519607544, 1.166603684425354, 1.4223048686981201, 1.121857762336731, 1.12855863571167, 1.0372776985168457, 1.201664924621582, 1.0451178550720215, 1.08269464969635, 1.1179001331329346, 1.4772740602493286, 1.2539838552474976, 1.0426846742630005, 1.0451533794403076, 1.190360188484192, 1.31993567943573, 1.0916578769683838, 1.1185295581817627, 1.060230016708374, 1.0017831325531006, 1.011254906654358, 1.0405926704406738, 1.2843329906463623, 1.1753031015396118, 1.0268253087997437, 1.0695973634719849, 1.24105966091156, 1.1105881929397583, 1.0049097537994385, 1.2791270017623901, 1.3947420120239258, 1.0725622177124023, 1.086220145225525, 1.1053298711776733, 1.0388306379318237, 1.0909091234207153, 1.1300785541534424, 1.1287466287612915, 1.0240870714187622, 1.0167983770370483, 1.2330138683319092, 1.076614260673523, 1.0145618915557861, 1.1184269189834595, 1.0468169450759888, 1.0088422298431396, 1.280898928642273, 1.1039478778839111, 1.1353065967559814, 1.0881109237670898, 1.2462712526321411, 1.053794026374817, 1.3443838357925415, 1.0834819078445435, 1.1098179817199707, 1.4121721982955933, 1.1336934566497803, 1.963589072227478, 1.213525414466858, 1.1768237352371216, 1.0270270109176636, 1.0299222469329834, 1.069223165512085]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.79327654838562] ms
 --  Average per query NF    [1.3628935813903809] ms
 --  Average per query vegas [2.4303829669952393] ms
Mean [1.146]  Median [1.114]  95th [1.393]  99th [1.494]  max [1.964]
Mean [1.146]  Median [1.114]  95th [1.393]  99th [1.494]  max [1.964]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.832954 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=sample', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
Sample - START
Sample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[5.9604645e-07 5.9604645e-08 7.7486038e-07 3.5762787e-07 1.7881393e-07]
Distance score: 3.9339064983323624e-07
SAUCE Drift detection: False
Detection latency: 0.0236s

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.032682 | Model-update-time: 0.000000


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=sample', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.163858413696289
tensor(0.9959)
result is  tensor(456701.9062)
Enter testHyper
ReportEsts: [1.0464296340942383, 1.0766279697418213, 1.2051650285720825, 1.015570878982544, 1.0223580598831177, 1.2942625284194946, 1.3266956806182861, 1.0979812145233154, 1.0666297674179077, 1.004195213317871, 1.1356905698776245, 1.367164969444275, 1.2047618627548218, 1.0181773900985718, 1.0044437646865845, 1.0751630067825317, 1.3002159595489502, 1.053033471107483, 1.0402683019638062, 1.1561691761016846, 1.0724523067474365, 1.5811514854431152, 1.036996841430664, 1.0413223505020142, 1.0612452030181885, 1.1438978910446167, 1.0076242685317993, 1.0894538164138794, 1.5161033868789673, 1.746268630027771, 1.234211802482605, 1.1643835306167603, 1.0605989694595337, 1.017698884010315, 1.0966196060180664, 1.0813045501708984, 1.0720728635787964, 1.0996731519699097, 1.4689290523529053, 1.010189414024353, 1.061086654663086, 1.0149413347244263, 1.2699803113937378, 1.1923694610595703, 1.0639832019805908, 1.0702444314956665, 1.280290126800537, 1.088661789894104, 1.1875, 1.0935534238815308, 1.0332552194595337, 1.0256272554397583, 1.0097205638885498, 1.0295426845550537, 1.1458721160888672, 1.3660494089126587, 1.2474913597106934, 1.129378318786621, 1.2714425325393677, 1.138032078742981, 1.5059101581573486, 1.0817968845367432, 1.015936255455017, 1.93269944190979, 1.0624831914901733, 1.0672271251678467, 1.1604588031768799, 1.0603742599487305, 1.193122148513794, 1.0783692598342896, 1.0959088802337646, 1.182652473449707, 1.1107161045074463, 1.0228110551834106, 1.028629183769226, 1.1548479795455933, 1.02350652217865, 1.193558931350708, 1.3401538133621216, 1.0781952142715454, 1.052343487739563, 1.0642368793487549, 1.155448317527771, 1.1691443920135498, 1.2630630731582642, 1.3550724983215332, 1.2372311353683472, 1.4088654518127441, 1.1151727437973022, 1.1854767799377441, 1.1476190090179443, 1.0650887489318848, 1.4652341604232788, 1.1415045261383057, 1.445616364479065, 1.088395357131958, 1.0174636840820312, 1.255692958831787, 1.3417590856552124, 1.0545505285263062, 1.2441078424453735, 1.0964618921279907, 1.2696335315704346, 1.065518856048584, 1.132878303527832, 1.1118077039718628, 1.1240620613098145, 1.1166621446609497, 1.0992166996002197, 1.0537545680999756, 1.0017071962356567, 1.0545357465744019, 1.3103067874908447, 1.2114697694778442, 1.056509017944336, 1.1184113025665283, 1.0280098915100098, 1.2264596223831177, 1.0740852355957031, 1.0888888835906982, 1.0100873708724976, 1.2324857711791992, 1.0172522068023682, 1.3050044775009155, 1.0797587633132935, 1.093146800994873, 1.2326792478561401, 1.2805070877075195, 1.0007582902908325, 1.0573909282684326, 1.2138220071792603, 1.0370022058486938, 1.0062350034713745, 1.6028512716293335, 1.5849056243896484, 1.0076760053634644, 1.0565909147262573, 1.0953693389892578, 1.076777458190918, 1.0058351755142212, 1.0710818767547607, 1.1670361757278442, 1.0236366987228394, 1.075801134109497, 1.099696397781372, 1.0087515115737915, 1.4939024448394775, 1.0430307388305664, 1.0202261209487915, 1.1221389770507812, 1.058872938156128, 1.0232704877853394, 1.117825984954834, 1.0442867279052734, 1.0425885915756226, 1.0530627965927124, 1.102936029434204, 1.2366411685943604, 1.1111564636230469, 1.2375656366348267, 1.0620942115783691, 1.0364431142807007, 1.151564359664917, 1.1792442798614502, 1.2183358669281006, 1.02445387840271, 1.0540359020233154, 1.3547821044921875, 1.170568585395813, 1.1280403137207031, 1.1049714088439941, 1.1208606958389282, 1.203954815864563, 1.0343903303146362, 1.1472723484039307, 1.002579689025879, 1.5220088958740234, 1.086337685585022, 1.1116174459457397, 1.1907505989074707, 1.4693877696990967, 1.1733604669570923, 1.0238609313964844, 1.6180438995361328, 1.4034509658813477, 1.1207579374313354, 1.3081148862838745, 1.0367350578308105, 1.581390619277954, 1.0794848203659058, 1.1784918308258057, 1.0989654064178467, 1.0975219011306763, 1.78587007522583, 1.0336835384368896, 1.0037716627120972, 1.393354892730713, 1.2333089113235474, 1.2835570573806763, 1.0696293115615845]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.734191656112671] ms
 --  Average per query NF    [1.3572490215301514] ms
 --  Average per query vegas [2.3769426345825195] ms
Mean [1.159]  Median [1.099]  95th [1.506]  99th [1.747]  max [1.933]
Mean [1.159]  Median [1.099]  95th [1.506]  99th [1.747]  max [1.933]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.223217 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=0 | total-time=26.137549