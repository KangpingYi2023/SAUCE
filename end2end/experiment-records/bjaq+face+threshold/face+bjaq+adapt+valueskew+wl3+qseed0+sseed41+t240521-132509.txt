Input arguments = Namespace(data_update='valueskew', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 41, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.16223669052124
tensor(0.9944)
result is  tensor(380015.4062)
Enter testHyper
ReportEsts: [1.1825051307678223, 1.010275959968567, 1.343947410583496, 1.07706880569458, 1.2364747524261475, 1.09713613986969, 1.2714861631393433, 1.148745059967041, 1.0831332206726074, 1.0488953590393066, 1.0542635917663574, 1.2086864709854126, 1.019020676612854, 1.0647321939468384, 1.2487376928329468, 1.2611083984375, 1.2460565567016602, 1.1118764877319336, 1.1560684442520142, 1.0484694242477417, 1.1330636739730835, 1.0283174514770508, 1.1300880908966064, 1.1503047943115234, 1.0764518976211548, 1.1030741930007935, 1.0261824131011963, 1.2651782035827637, 1.0151891708374023, 1.1090428829193115, 1.1614047288894653, 1.180274486541748, 1.0824487209320068, 1.0005191564559937, 1.183989405632019, 1.0074015855789185, 1.235074758529663, 1.1138525009155273, 1.0249693393707275, 1.059520959854126, 1.00223970413208, 1.1263909339904785, 1.043409824371338, 1.044682264328003, 1.062117099761963, 1.0, 1.1871525049209595, 1.3248577117919922, 1.0583584308624268, 1.0727580785751343, 1.2131578922271729, 1.4032634496688843, 1.1165168285369873, 1.3001314401626587, 1.0021251440048218, 1.0222748517990112, 1.3102803230285645, 1.2089545726776123, 1.3223912715911865, 1.3587443828582764, 1.6684000492095947, 1.2003344297409058, 1.393976092338562, 1.181813359260559, 1.1262798309326172, 1.1714285612106323, 1.2127659320831299, 1.0731875896453857, 1.1093178987503052, 1.2736842632293701, 1.0163532495498657, 1.073655366897583, 1.2478023767471313, 1.076596975326538, 1.0751181840896606, 1.122855544090271, 2.440214157104492, 1.0001729726791382, 1.0074962377548218, 1.216238260269165, 1.0640534162521362, 1.027136206626892, 1.0681146383285522, 1.1597964763641357, 1.2105329036712646, 1.1477609872817993, 1.0823570489883423, 1.0498864650726318, 1.0151047706604004, 1.1674268245697021, 1.0229754447937012, 1.512207269668579, 1.0205553770065308, 1.3385213613510132, 1.1538461446762085, 1.0511457920074463, 1.2503254413604736, 1.281697392463684, 1.01694917678833, 1.2302218675613403, 1.1835260391235352, 1.3420369625091553, 1.0174474716186523, 1.016369104385376, 1.0888382196426392, 1.0051368474960327, 1.1603739261627197, 1.1867364645004272, 1.0461862087249756, 1.0380018949508667, 1.2434850931167603, 1.0673952102661133, 1.2401487827301025, 1.1110402345657349, 1.0055639743804932, 1.1073170900344849, 1.095455527305603, 1.0669418573379517, 1.383336067199707, 1.1438438892364502, 1.324784517288208, 1.115772008895874, 1.1933053731918335, 1.087091326713562, 1.2640503644943237, 1.2688815593719482, 1.0962154865264893, 1.1188160181045532, 1.2983193397521973, 1.1175684928894043, 1.1324658393859863, 1.0872381925582886, 1.240832805633545, 1.3928571939468384, 1.0085481405258179, 1.133105754852295, 1.000727891921997, 1.0738211870193481, 1.0049022436141968, 1.1889371871948242, 1.1904524564743042, 1.1074976921081543, 1.002598762512207, 1.2910205125808716, 1.1095330715179443, 1.0511287450790405, 1.0714062452316284, 1.4015005826950073, 1.0990127325057983, 1.1126420497894287, 1.071132779121399, 1.2491987943649292, 1.3668146133422852, 1.0526658296585083, 1.167099952697754, 1.030217170715332, 1.2651702165603638, 1.0500843524932861, 1.0795297622680664, 1.1018203496932983, 1.1348035335540771, 1.037048101425171, 1.0223363637924194, 1.3520923852920532, 1.2637215852737427, 1.084134578704834, 1.4092426300048828, 1.159932017326355, 1.0961679220199585, 1.0157948732376099, 1.0826666355133057, 1.1024881601333618, 1.1298701763153076, 1.1620687246322632, 1.0415040254592896, 1.0904420614242554, 1.0305458307266235, 1.2659085988998413, 1.1408405303955078, 1.0883212089538574, 1.0372555255889893, 1.0369148254394531, 1.00156831741333, 1.133810043334961, 1.1130025386810303, 1.1279069185256958, 1.0139565467834473, 1.2519164085388184, 1.0367951393127441, 1.2965933084487915, 1.0522280931472778, 1.0471473932266235, 1.5076597929000854, 1.280701756477356, 1.7146100997924805, 1.1809872388839722, 1.0431846380233765, 1.0704225301742554, 1.102789044380188, 1.2611886262893677]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7668240070343018] ms
 --  Average per query NF    [1.364595890045166] ms
 --  Average per query vegas [2.4022281169891357] ms
Mean [1.152]  Median [1.112]  95th [1.384]  99th [1.669]  max [2.440]
Mean [1.152]  Median [1.112]  95th [1.384]  99th [1.669]  max [2.440]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.861187 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=valueskew', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
ValueSample - START
ValueSample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[1.1920929e-07 5.3644180e-07 3.5762787e-07 2.1103442e-02 2.3841858e-07]
Distance score: 0.00422093877568841
SAUCE Drift detection: True
Detection latency: 0.0244s

DRIFT-DETECTED after 2-th workload
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/incremental_train.py', '--dataset=bjaq', '--end2end', '--model=face', '--model_update=adapt', '--update_size=80000', '--epochs=0']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
update_size: 76433
AdaptTask - START
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
train data shape: 80000, transfer data shape:16000
Training done; evaluating likelihood on full data:
Saved to: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
AdaptTask - END

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.055361 | Model-update-time: 2.252285


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=valueskew', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.168652296066284
tensor(0.9945)
result is  tensor(456076.5938)
Enter testHyper
ReportEsts: [1.0271780490875244, 1.0501701831817627, 1.0459259748458862, 1.0650473833084106, 1.2917697429656982, 1.3472660779953003, 1.0270097255706787, 1.002008080482483, 1.1871447563171387, 1.918552041053772, 1.0716909170150757, 1.143118977546692, 1.0477327108383179, 1.268373966217041, 1.0227147340774536, 1.0557000637054443, 1.6017135381698608, 1.3236223459243774, 1.1970359086990356, 1.3848652839660645, 1.0220367908477783, 1.1237332820892334, 1.1762570142745972, 6.9558916091918945, 1.1064410209655762, 1.1579740047454834, 1.0773742198944092, 1.091417908668518, 1.2584125995635986, 1.4901793003082275, 2.1151463985443115, 1.5423728227615356, 1.1061124801635742, 1.0047506093978882, 1.1494615077972412, 1.0214334726333618, 1.01213538646698, 1.1971863508224487, 1.2632478475570679, 1.0455020666122437, 1.1914175748825073, 1.0257234573364258, 122.84756469726562, 1.1597684621810913, 1.0957951545715332, 1.1056277751922607, 1.0558799505233765, 1.1581082344055176, 1.3285714387893677, 3.4631783962249756, 1.0486522912979126, 1.0304315090179443, 1.0294164419174194, 1.037571668624878, 1.0603479146957397, 1.1978768110275269, 1.0385278463363647, 1.1075693368911743, 1.0249797105789185, 1.1665672063827515, 1.2378753423690796, 1.0061290264129639, 1.0592443943023682, 1.6447218656539917, 1.0123955011367798, 1.036709189414978, 1.1841504573822021, 1.1997442245483398, 1.020646333694458, 1.1204743385314941, 1.08543062210083, 1.0319565534591675, 1.156078815460205, 1.0639787912368774, 1.7897460460662842, 1.0340183973312378, 1.007083773612976, 1.647338628768921, 1.3946017026901245, 1.172876000404358, 1.7973097562789917, 1.010446548461914, 1.0061572790145874, 1.0356968641281128, 1.110795497894287, 1.3344827890396118, 1.0048372745513916, 1.2112585306167603, 1.1057451963424683, 1.1369050741195679, 1.0550484657287598, 1.664312720298767, 1.1682817935943604, 1.0743441581726074, 86.83928680419922, 1.085738182067871, 1.0278087854385376, 1.1997017860412598, 1.2655922174453735, 1.0828149318695068, 1.1108131408691406, 1.1081676483154297, 1.0174564123153687, 1.0370501279830933, 3.4814655780792236, 1.875, 1.0632213354110718, 1.1131919622421265, 1.0264705419540405, 1.0069804191589355, 1.2957398891448975, 1.1192798614501953, 1.1433714628219604, 1.0290346145629883, 1.1443384885787964, 1.8041225671768188, 1.0884464979171753, 1.1147785186767578, 1.0103600025177002, 1.0619468688964844, 1.0150165557861328, 1.2443552017211914, 1.0107048749923706, 1.3209338188171387, 1.0425735712051392, 1.263761281967163, 1.051432490348816, 1.0698412656784058, 1.1956337690353394, 1.0714765787124634, 1.1375112533569336, 1.099035620689392, 1.1109195947647095, 1.7443366050720215, 1.1779190301895142, 1.1721233129501343, 1.2542340755462646, 1.594002366065979, 1.1036328077316284, 1.043414831161499, 1.1117035150527954, 1.1514065265655518, 1.0145984888076782, 1.069678783416748, 1.0230605602264404, 1.9100337028503418, 1.2267441749572754, 1.0622539520263672, 1.1188932657241821, 1.0138189792633057, 172.10000610351562, 1.2201281785964966, 1.4201022386550903, 1.0595630407333374, 1.0878534317016602, 1.1614196300506592, 1.0892302989959717, 1.0538461208343506, 1.4655061960220337, 1.064383864402771, 1.0073466300964355, 1.006961703300476, 1.1487396955490112, 1.0226258039474487, 1.1348340511322021, 1.2210636138916016, 1.052291750907898, 1.2582567930221558, 1.091688632965088, 1.0066442489624023, 1.1069841384887695, 1.0767974853515625, 1.6821346282958984, 1.0056873559951782, 1.4771219491958618, 1.0282832384109497, 1.2598347663879395, 1.10624361038208, 1.1302796602249146, 1.0155413150787354, 1.894736886024475, 1.4200968742370605, 1.1030405759811401, 1.6743178367614746, 1.3144153356552124, 1.1904832124710083, 1.2498575448989868, 1.1508980989456177, 1.409347653388977, 1.0375628471374512, 1.1032555103302002, 1.016987681388855, 1.2697104215621948, 1.6697998046875, 1.0483053922653198, 1.0318864583969116, 1.1723737716674805, 1.0267226696014404, 1.1533100605010986, 1.3438551425933838]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.755084276199341] ms
 --  Average per query NF    [1.3651847839355469] ms
 --  Average per query vegas [2.389899492263794] ms
Mean [3.126]  Median [1.111]  95th [1.876]  99th [87.199]  max [172.100]
Mean [3.126]  Median [1.111]  95th [1.876]  99th [87.199]  max [172.100]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.406444 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=1 | total-time=28.642579