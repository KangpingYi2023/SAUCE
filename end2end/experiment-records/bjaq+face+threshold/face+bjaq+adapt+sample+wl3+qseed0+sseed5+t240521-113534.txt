Input arguments = Namespace(data_update='sample', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 5, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.154284477233887
tensor(0.9984)
result is  tensor(381560.0312)
Enter testHyper
ReportEsts: [1.2186282873153687, 1.0627670288085938, 1.3351935148239136, 1.0541166067123413, 1.295641541481018, 1.0969524383544922, 1.272571086883545, 1.0089695453643799, 1.1264045238494873, 1.1160897016525269, 1.0559861660003662, 1.1406779289245605, 1.0385149717330933, 1.046875, 1.0470607280731201, 1.3597679138183594, 1.3712278604507446, 1.1579571962356567, 1.2208232879638672, 1.0892857313156128, 1.0589008331298828, 1.1432926654815674, 1.148400902748108, 1.0377510786056519, 1.0477007627487183, 1.0650994777679443, 1.0208333730697632, 1.363444447517395, 1.0710532665252686, 1.0448580980300903, 1.127350091934204, 1.3019108772277832, 1.0262070894241333, 1.0491353273391724, 1.1155493259429932, 1.2310000658035278, 1.3021084070205688, 1.1216144561767578, 1.0222976207733154, 1.0870980024337769, 1.0806310176849365, 1.1748911142349243, 1.147864818572998, 1.1745250225067139, 1.0532431602478027, 1.1621315479278564, 1.2254968881607056, 1.3060232400894165, 1.2170053720474243, 1.1996616125106812, 1.1790281534194946, 1.3589165210723877, 1.017673373222351, 1.1437246799468994, 1.104794979095459, 1.0667593479156494, 1.1962616443634033, 1.268426775932312, 1.327378749847412, 1.2326183319091797, 1.511323094367981, 1.1808511018753052, 1.3087393045425415, 1.0621000528335571, 1.2840466499328613, 1.2000000476837158, 1.1536338329315186, 1.0698941946029663, 1.1640000343322754, 1.4631578922271729, 1.023045301437378, 1.0211869478225708, 1.1507765054702759, 1.1549856662750244, 1.0546191930770874, 1.0112124681472778, 1.8271478414535522, 1.0326902866363525, 1.090430736541748, 1.3404293060302734, 1.1259632110595703, 1.0742669105529785, 1.008597493171692, 1.1542428731918335, 1.2667368650436401, 1.1244250535964966, 1.0443321466445923, 1.1158638000488281, 1.1717578172683716, 1.0911352634429932, 1.0348445177078247, 1.4701361656188965, 1.0194735527038574, 1.2886911630630493, 1.101694941520691, 1.0806608200073242, 1.2455031871795654, 1.1830122470855713, 1.01694917678833, 1.2053178548812866, 1.1818181276321411, 1.0511207580566406, 1.0683066844940186, 1.000732660293579, 1.0135983228683472, 1.183106780052185, 1.1336946487426758, 1.1954624652862549, 1.0487403869628906, 1.0193414688110352, 1.2401939630508423, 1.1119544506072998, 1.0557585954666138, 1.1010184288024902, 1.1184653043746948, 1.1761658191680908, 1.0323691368103027, 1.0391368865966797, 1.3451743125915527, 1.2175047397613525, 1.3776402473449707, 1.0836207866668701, 1.0625619888305664, 1.1464834213256836, 1.2107558250427246, 1.199133276939392, 1.0656089782714844, 1.167465329170227, 1.3193851709365845, 1.1189044713974, 1.214348554611206, 1.167984962463379, 1.2952144145965576, 1.4642857313156128, 1.053614616394043, 1.0693094730377197, 1.0176798105239868, 1.0793496370315552, 1.1442153453826904, 1.3396358489990234, 1.1093136072158813, 1.080596685409546, 1.1905847787857056, 1.3094366788864136, 1.0489859580993652, 1.128455638885498, 1.0676937103271484, 1.5207312107086182, 1.0209741592407227, 1.0600851774215698, 1.2303680181503296, 1.1481860876083374, 1.320643424987793, 1.033771276473999, 1.1630162000656128, 1.0267101526260376, 1.0053495168685913, 1.001126766204834, 1.0349652767181396, 1.111130952835083, 1.1289005279541016, 1.0540238618850708, 1.0334771871566772, 1.2696477174758911, 1.1456310749053955, 1.1315412521362305, 1.2861371040344238, 1.2930132150650024, 1.0662206411361694, 1.063624382019043, 1.0835046768188477, 1.1970727443695068, 1.201298713684082, 1.2710249423980713, 1.108310580253601, 1.0579415559768677, 1.0612244606018066, 1.20881187915802, 1.190214991569519, 1.0398327112197876, 1.0237234830856323, 1.0184698104858398, 1.0183848142623901, 1.1113381385803223, 1.1206084489822388, 1.1120507717132568, 1.016829013824463, 1.2183791399002075, 1.0675251483917236, 1.2066736221313477, 1.0265105962753296, 1.0246310234069824, 1.6670560836791992, 1.4608469009399414, 1.6928250789642334, 1.189686894416809, 1.0733639001846313, 1.0270270109176636, 1.1815617084503174, 1.1088645458221436]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.788655996322632] ms
 --  Average per query NF    [1.3758039474487305] ms
 --  Average per query vegas [2.4128520488739014] ms
Mean [1.154]  Median [1.123]  95th [1.372]  99th [1.667]  max [1.827]
Mean [1.154]  Median [1.123]  95th [1.372]  99th [1.667]  max [1.827]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.847262 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=sample', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
Sample - START
Sample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[5.9604645e-08 6.5565109e-07 1.7881393e-07 0.0000000e+00 5.9604645e-08]
Distance score: 1.9073486612342094e-07
SAUCE Drift detection: False
Detection latency: 0.0231s

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.028195 | Model-update-time: 0.000000


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=sample', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.151115655899048
tensor(0.9937)
result is  tensor(455701.2812)
Enter testHyper
ReportEsts: [1.0773197412490845, 1.1907819509506226, 1.2861446142196655, 1.15904700756073, 1.0204726457595825, 1.3301869630813599, 1.250891923904419, 1.0570228099822998, 1.1242324113845825, 1.1388355493545532, 1.007733941078186, 1.0558134317398071, 1.1985981464385986, 1.1203304529190063, 1.0362260341644287, 1.069157600402832, 1.2081784009933472, 1.1334575414657593, 1.0006952285766602, 1.222936749458313, 1.1889406442642212, 2.9647302627563477, 1.0543347597122192, 1.104831337928772, 1.1550010442733765, 1.2628291845321655, 1.0423997640609741, 1.09883451461792, 1.5134865045547485, 1.4583333730697632, 1.070873737335205, 1.459854006767273, 1.0149481296539307, 1.0213578939437866, 1.048940896987915, 1.0122013092041016, 1.189263105392456, 1.0810292959213257, 1.3093360662460327, 1.0984628200531006, 1.0057997703552246, 1.029801368713379, 1.0008070468902588, 1.0915868282318115, 1.0344473123550415, 1.1754159927368164, 1.1857223510742188, 1.170133352279663, 1.08695650100708, 1.1090137958526611, 1.0423815250396729, 1.0946003198623657, 1.0816785097122192, 1.0783342123031616, 1.0109010934829712, 1.465428113937378, 1.1822290420532227, 1.2379810810089111, 1.2675317525863647, 1.0706926584243774, 1.4461883306503296, 1.030495047569275, 1.0934114456176758, 1.4510087966918945, 1.1702665090560913, 1.0337458848953247, 1.25226628780365, 1.1394518613815308, 1.1357609033584595, 1.072585105895996, 1.0660732984542847, 1.0405064821243286, 1.1854530572891235, 1.0111539363861084, 1.0236214399337769, 1.0893123149871826, 1.209655523300171, 1.0869373083114624, 1.3877438306808472, 1.0034124851226807, 1.1609236001968384, 1.1458778381347656, 1.3414736986160278, 1.104643702507019, 1.3362435102462769, 1.3848921060562134, 1.2925313711166382, 1.6713860034942627, 1.0697587728500366, 1.0801836252212524, 1.073973298072815, 1.2267946004867554, 1.5750000476837158, 1.1402653455734253, 1.1477676630020142, 1.0203691720962524, 1.0432469844818115, 1.208721399307251, 1.0515252351760864, 1.09356689453125, 1.1793078184127808, 1.0913540124893188, 1.114416480064392, 1.1652498245239258, 1.1794670820236206, 1.1598260402679443, 1.2616084814071655, 1.1523834466934204, 1.1397260427474976, 1.202147126197815, 1.1087615489959717, 1.097011923789978, 1.2808655500411987, 1.3329362869262695, 1.0757005214691162, 1.0409529209136963, 1.1259238719940186, 1.3930180072784424, 1.1724720001220703, 1.0703125, 1.0058095455169678, 1.065488576889038, 1.1687753200531006, 1.0404738187789917, 1.004346489906311, 1.0198394060134888, 1.2515778541564941, 1.3195548057556152, 1.036861777305603, 1.2473326921463013, 1.0571341514587402, 1.108775019645691, 1.0142812728881836, 1.7332613468170166, 1.7677865028381348, 1.1329271793365479, 1.0694410800933838, 1.0931519269943237, 1.0818126201629639, 1.0131901502609253, 1.0016834735870361, 1.0773169994354248, 1.0351097583770752, 1.1104377508163452, 1.0613133907318115, 1.1357922554016113, 1.4147727489471436, 1.0966299772262573, 1.1405936479568481, 1.0305982828140259, 1.1293119192123413, 1.0208467245101929, 1.184859275817871, 1.0407936573028564, 1.0322201251983643, 1.04643976688385, 1.0873984098434448, 1.357723593711853, 1.1410012245178223, 1.1119216680526733, 1.0805041790008545, 1.031346321105957, 1.1483255624771118, 1.0196810960769653, 1.029409646987915, 1.0564651489257812, 1.072785496711731, 1.1374174356460571, 1.25143563747406, 1.0938100814819336, 1.0769087076187134, 1.0273677110671997, 1.4819605350494385, 1.085383415222168, 1.1054621934890747, 1.1741304397583008, 1.0508712530136108, 1.0667296648025513, 1.0752317905426025, 1.1878576278686523, 1.5, 1.1034541130065918, 1.0327988862991333, 1.6556776762008667, 1.4425855875015259, 1.1967203617095947, 1.045616626739502, 1.1296123266220093, 1.3801409006118774, 1.0677568912506104, 1.1457682847976685, 1.0346437692642212, 1.3108751773834229, 1.7506449222564697, 1.0720360279083252, 1.1169354915618896, 1.3477718830108643, 1.1644518375396729, 1.3565365076065063, 1.1500203609466553]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7358736991882324] ms
 --  Average per query NF    [1.3576710224151611] ms
 --  Average per query vegas [2.3782026767730713] ms
Mean [1.167]  Median [1.109]  95th [1.466]  99th [1.751]  max [2.965]
Mean [1.167]  Median [1.109]  95th [1.466]  99th [1.751]  max [2.965]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.163881 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=0 | total-time=26.090892