Input arguments = Namespace(data_update='sample', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 10, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.173705577850342
tensor(1.0026)
result is  tensor(383172.4688)
Enter testHyper
ReportEsts: [1.1334261894226074, 1.0068143606185913, 1.699226975440979, 1.0772794485092163, 1.2389973402023315, 1.1222269535064697, 1.1632235050201416, 1.1287637948989868, 1.0883594751358032, 1.0154271125793457, 1.0318690538406372, 1.1254236698150635, 1.0838290452957153, 1.0401785373687744, 1.1417373418807983, 1.1982744932174683, 1.3556305170059204, 1.2457244396209717, 1.2091127634048462, 1.0688775777816772, 1.1006660461425781, 1.0974080562591553, 1.1263070106506348, 1.026481032371521, 1.1899044513702393, 1.1030741930007935, 1.1427364349365234, 1.3622944355010986, 1.0658700466156006, 1.0163341760635376, 1.1383469104766846, 1.2654680013656616, 1.0830957889556885, 1.0160961151123047, 1.127244234085083, 1.069373369216919, 1.1993252038955688, 1.2623860836029053, 1.0826547145843506, 1.0863473415374756, 1.0591099262237549, 1.1354620456695557, 1.1157615184783936, 1.1358979940414429, 1.0504964590072632, 1.0680272579193115, 1.1270091533660889, 1.2692238092422485, 1.0330934524536133, 1.248731017112732, 1.2005208730697632, 1.3981419801712036, 1.0362762212753296, 1.2076336145401, 1.0987275838851929, 1.0739452838897705, 1.3981308937072754, 1.1244527101516724, 1.0778837203979492, 1.2231192588806152, 1.2704198360443115, 1.1274346113204956, 1.3660728931427002, 1.0534932613372803, 1.325301170349121, 1.2857142686843872, 1.1048457622528076, 1.0610343217849731, 1.008621096611023, 1.2842105627059937, 1.086082100868225, 1.0018620491027832, 1.305188775062561, 1.3312135934829712, 1.155395269393921, 1.043858528137207, 1.8290259838104248, 1.0572421550750732, 1.0284968614578247, 1.2100504636764526, 1.138518214225769, 1.0780165195465088, 1.0590656995773315, 1.1424078941345215, 1.199825644493103, 1.0928388833999634, 1.0960572957992554, 1.0492749214172363, 1.0045249462127686, 1.136661410331726, 1.004852294921875, 1.1689225435256958, 1.018362045288086, 1.2594965696334839, 1.0714285373687744, 1.0966154336929321, 1.163909673690796, 1.3187217712402344, 1.0526316165924072, 1.1036419868469238, 1.1633522510528564, 1.05339777469635, 1.0455378293991089, 1.0051244497299194, 1.0269631147384644, 1.0120726823806763, 1.1553398370742798, 1.1902269124984741, 1.0541704893112183, 1.0064890384674072, 1.1612932682037354, 1.0984067916870117, 1.1905447244644165, 1.1487233638763428, 1.1490669250488281, 1.1522842645645142, 1.0850145816802979, 1.1074422597885132, 1.2235839366912842, 1.2121431827545166, 1.2121268510818481, 1.098454475402832, 1.2637194395065308, 1.0570342540740967, 1.260658860206604, 1.1718943119049072, 1.0595893859863281, 1.137689232826233, 1.2612245082855225, 1.1165664196014404, 1.0862200260162354, 1.255948543548584, 1.2557488679885864, 1.4285714626312256, 1.10185706615448, 1.003150463104248, 1.0140128135681152, 1.2162601947784424, 1.0275300741195679, 1.3443429470062256, 1.1229528188705444, 1.0598204135894775, 1.070678472518921, 1.2880477905273438, 1.0279390811920166, 1.051005482673645, 1.074008584022522, 1.6626298427581787, 1.0138052701950073, 1.081463098526001, 1.1220368146896362, 1.1684399843215942, 1.3495889902114868, 1.2824912071228027, 1.1456650495529175, 1.0022975206375122, 1.0475167036056519, 1.0334833860397339, 1.00448739528656, 1.2216055393218994, 1.3742212057113647, 1.127299189567566, 1.0341819524765015, 1.2280471324920654, 1.1079812049865723, 1.0178967714309692, 1.1919912099838257, 1.1779605150222778, 1.1198889017105103, 1.017798662185669, 1.1064023971557617, 1.0937618017196655, 1.1818181276321411, 1.0413532257080078, 1.0715259313583374, 1.1098312139511108, 1.0558794736862183, 1.2007882595062256, 1.0819709300994873, 1.1053420305252075, 1.0399196147918701, 1.0667729377746582, 1.0166682004928589, 1.155260443687439, 1.1763854026794434, 1.1046512126922607, 1.0840229988098145, 1.2841315269470215, 1.0302540063858032, 1.4237802028656006, 1.0025702714920044, 1.0073773860931396, 1.6902576684951782, 1.1547455787658691, 1.747877836227417, 1.2503225803375244, 1.119508147239685, 1.1176470518112183, 1.1753597259521484, 1.0432270765304565]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.8004565238952637] ms
 --  Average per query NF    [1.3654136657714844] ms
 --  Average per query vegas [2.4350428581237793] ms
Mean [1.148]  Median [1.117]  95th [1.366]  99th [1.700]  max [1.829]
Mean [1.148]  Median [1.117]  95th [1.366]  99th [1.700]  max [1.829]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.844540 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=sample', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
Sample - START
Sample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[3.5762787e-07 5.9604645e-08 5.9604645e-08 3.5762787e-07 5.3644180e-07]
Distance score: 2.74181360282455e-07
SAUCE Drift detection: False
Detection latency: 0.0232s

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.027598 | Model-update-time: 0.000000


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=sample', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.217288255691528
tensor(0.9902)
result is  tensor(454129.1250)
Enter testHyper
ReportEsts: [1.1077531576156616, 1.0218247175216675, 1.2914798259735107, 1.0651174783706665, 1.0192224979400635, 1.3697657585144043, 1.2280840873718262, 1.048030972480774, 1.2591743469238281, 1.1526498794555664, 1.0626318454742432, 1.1119917631149292, 1.2326732873916626, 1.0880224704742432, 1.0009098052978516, 1.0174627304077148, 1.2870639562606812, 1.1359304189682007, 1.0183476209640503, 1.2569016218185425, 1.0840723514556885, 2.0, 1.1603429317474365, 1.1944055557250977, 1.1047717332839966, 1.1291754245758057, 1.0876092910766602, 1.1676056385040283, 1.1630996465682983, 1.5286957025527954, 1.183098554611206, 1.2027971744537354, 1.1337814331054688, 1.0281977653503418, 1.1325697898864746, 1.1278434991836548, 1.103234052658081, 1.021324872970581, 1.1294598579406738, 1.1453946828842163, 1.0093843936920166, 1.0331858396530151, 1.5789828300476074, 1.217347502708435, 1.0365214347839355, 1.1567002534866333, 1.17002534866333, 1.072041392326355, 1.11328125, 1.221146583557129, 1.0087342262268066, 1.0295302867889404, 1.0895947217941284, 1.0367141962051392, 1.1116985082626343, 1.075872778892517, 1.1998329162597656, 1.1489721536636353, 1.2624083757400513, 1.0955880880355835, 1.4736841917037964, 1.0125212669372559, 1.0525164604187012, 1.8168572187423706, 1.005489706993103, 1.0999932289123535, 1.3817424774169922, 1.0795522928237915, 1.1197999715805054, 1.1265449523925781, 1.026119351387024, 1.0325005054473877, 1.1396903991699219, 1.0804481506347656, 1.1010929346084595, 1.152130365371704, 1.064045786857605, 1.1006776094436646, 1.39682936668396, 1.1296921968460083, 1.074803113937378, 1.2613731622695923, 1.332000494003296, 1.0867960453033447, 1.2979015111923218, 1.4375, 1.0920779705047607, 1.5592105388641357, 1.0811595916748047, 1.1776094436645508, 1.1712512969970703, 1.2582719326019287, 1.4020618200302124, 1.016054630279541, 1.3682711124420166, 1.026521921157837, 1.1785930395126343, 1.1802027225494385, 1.4949268102645874, 1.1140884160995483, 1.1091512441635132, 1.1098413467407227, 1.1165919303894043, 1.3252211809158325, 1.103074073791504, 1.2459087371826172, 1.2981458902359009, 1.1346869468688965, 1.0957447290420532, 1.0750596523284912, 1.1196566820144653, 1.0751721858978271, 1.0592544078826904, 1.2581981420516968, 1.0310142040252686, 1.071898102760315, 1.007257342338562, 1.0327415466308594, 1.123914122581482, 1.0234375, 1.1112273931503296, 1.0446841716766357, 1.0250217914581299, 1.6280193328857422, 1.1357592344284058, 1.1088333129882812, 1.2865623235702515, 1.2803149223327637, 1.0270987749099731, 1.1059473752975464, 1.16657292842865, 1.15140700340271, 1.063574194908142, 1.8761792182922363, 1.7414299249649048, 1.1017861366271973, 1.0379620790481567, 1.279107689857483, 1.004359245300293, 1.0095431804656982, 1.0920072793960571, 1.1563254594802856, 1.060488224029541, 1.1011465787887573, 1.0765266418457031, 1.1398406028747559, 1.4879517555236816, 1.0010064840316772, 1.268149971961975, 1.022705078125, 1.1271694898605347, 1.028598666191101, 1.2811598777770996, 1.0328470468521118, 1.0258206129074097, 1.0261565446853638, 1.1795332431793213, 1.191176414489746, 1.3294405937194824, 1.1391440629959106, 1.063867449760437, 1.1101369857788086, 1.2680470943450928, 1.1598963737487793, 1.2055121660232544, 1.01924467086792, 1.0002131462097168, 1.4872275590896606, 1.0472266674041748, 1.2926477193832397, 1.002066969871521, 1.0785863399505615, 1.5506418943405151, 1.0676720142364502, 1.067718505859375, 1.0656239986419678, 1.0280729532241821, 1.060462474822998, 1.035409688949585, 1.039733648300171, 1.5319149494171143, 1.1880427598953247, 1.0630093812942505, 1.633922815322876, 1.351776123046875, 1.0124207735061646, 1.0956971645355225, 1.0668132305145264, 1.3143366575241089, 1.0635759830474854, 1.238729476928711, 1.046791911125183, 1.1578788757324219, 1.4834485054016113, 1.0099999904632568, 1.1474225521087646, 1.1671282052993774, 1.033731460571289, 1.3350340127944946, 1.0641260147094727]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7520694732666016] ms
 --  Average per query NF    [1.3567864894866943] ms
 --  Average per query vegas [2.3952829837799072] ms
Mean [1.166]  Median [1.112]  95th [1.529]  99th [1.817]  max [2.000]
Mean [1.166]  Median [1.112]  95th [1.529]  99th [1.817]  max [2.000]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.285244 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=0 | total-time=26.201277