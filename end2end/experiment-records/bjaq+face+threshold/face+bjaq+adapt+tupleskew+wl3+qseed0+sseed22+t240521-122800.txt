Input arguments = Namespace(data_update='tupleskew', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 22, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.207470655441284
tensor(0.9954)
result is  tensor(380401.5312)
Enter testHyper
ReportEsts: [1.0970611572265625, 1.0264555215835571, 1.4814552068710327, 1.0033690929412842, 1.2644259929656982, 1.1853795051574707, 1.2037397623062134, 1.0628026723861694, 1.0802154541015625, 1.1049124002456665, 1.0275624990463257, 1.0868643522262573, 1.16664457321167, 1.0067415237426758, 1.1167351007461548, 1.2172025442123413, 1.3705848455429077, 1.176247000694275, 1.1573067903518677, 1.2142857313156128, 1.124393105506897, 1.0889103412628174, 1.1515928506851196, 1.0487818717956543, 1.1562525033950806, 1.028933048248291, 1.0501126050949097, 1.2631990909576416, 1.0316470861434937, 1.1057878732681274, 1.2582476139068604, 1.2216243743896484, 1.2088513374328613, 1.016021966934204, 1.1892192363739014, 1.1634865999221802, 1.4715399742126465, 1.2515853643417358, 1.0338562726974487, 1.010895848274231, 1.007653832435608, 1.1055878400802612, 1.0094881057739258, 1.0638048648834229, 1.0931755304336548, 1.1519274711608887, 1.115060806274414, 1.313393473625183, 1.1051913499832153, 1.1505922079086304, 1.1820513010025024, 1.2966153621673584, 1.067680835723877, 1.1639199256896973, 1.0894792079925537, 1.0375521183013916, 1.3401869535446167, 1.222583532333374, 1.1563892364501953, 1.3980704545974731, 1.182032823562622, 1.2097753286361694, 1.405532717704773, 1.1287578344345093, 1.2890625, 1.2000000476837158, 1.1578947305679321, 1.080017328262329, 1.1491684913635254, 1.2315789461135864, 1.1974952220916748, 1.0769537687301636, 1.2174131870269775, 1.2488837242126465, 1.2250229120254517, 1.0630853176116943, 1.9333091974258423, 1.0640530586242676, 1.067970871925354, 1.5181187391281128, 1.1220802068710327, 1.1303504705429077, 1.1057744026184082, 1.299720048904419, 1.230641484260559, 1.1369483470916748, 1.0575426816940308, 1.1471879482269287, 1.0079549551010132, 1.0854963064193726, 1.1217148303985596, 1.2409064769744873, 1.0168683528900146, 1.294754147529602, 1.0833333730697632, 1.0230448246002197, 1.0780848264694214, 1.1718147993087769, 1.034482717514038, 1.1665574312210083, 1.151898741722107, 1.0884861946105957, 1.0846201181411743, 1.016837477684021, 1.1460250616073608, 1.000455379486084, 1.2102986574172974, 1.1867364645004272, 1.0804977416992188, 1.067338466644287, 1.2411553859710693, 1.0963517427444458, 1.24470055103302, 1.1471775770187378, 1.1167265176773071, 1.1127450466156006, 1.0041204690933228, 1.0310847759246826, 1.2782516479492188, 1.1166497468948364, 1.2803887128829956, 1.118255853652954, 1.0208985805511475, 1.1407057046890259, 1.4055233001708984, 1.2439124584197998, 1.1218818426132202, 1.2038625478744507, 1.2571196556091309, 1.1245825290679932, 1.058320164680481, 1.1021850109100342, 1.092604160308838, 1.4285714626312256, 1.1780749559402466, 1.2438960075378418, 1.0353895425796509, 1.0783740282058716, 1.038435697555542, 1.100690484046936, 1.1726815700531006, 1.1703150272369385, 1.2439237833023071, 1.273840069770813, 1.1895320415496826, 1.0087929964065552, 1.099892497062683, 1.3730837106704712, 1.0784482955932617, 1.1298295259475708, 1.0094867944717407, 1.1733111143112183, 1.305938482284546, 1.1646382808685303, 1.0557185411453247, 1.1008329391479492, 1.0082865953445435, 1.0014069080352783, 1.0642696619033813, 1.149865746498108, 1.0822131633758545, 1.0668954849243164, 1.0111883878707886, 1.2924138307571411, 1.2984869480133057, 1.1277014017105103, 1.2933382987976074, 1.1752543449401855, 1.0838948488235474, 1.0460312366485596, 1.0371850728988647, 1.1145049333572388, 1.103896141052246, 1.1512010097503662, 1.1110354661941528, 1.0675843954086304, 1.0279719829559326, 1.1192961931228638, 1.1449897289276123, 1.0718352794647217, 1.0400887727737427, 1.0171335935592651, 1.0013835430145264, 1.1562819480895996, 1.055776834487915, 1.0856236219406128, 1.0588818788528442, 1.245407223701477, 1.0163486003875732, 1.245205283164978, 1.0428135395050049, 1.0172514915466309, 1.4950236082077026, 1.3106948137283325, 1.5901910066604614, 1.213525414466858, 1.0241351127624512, 1.1515151262283325, 1.2216460704803467, 1.1446878910064697]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.764934539794922] ms
 --  Average per query NF    [1.3688123226165771] ms
 --  Average per query vegas [2.3961222171783447] ms
Mean [1.151]  Median [1.124]  95th [1.374]  99th [1.519]  max [1.933]
Mean [1.151]  Median [1.124]  95th [1.374]  99th [1.519]  max [1.933]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.877044 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=tupleskew', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
TupleSkewSample - START
0.001
TupleSkewSample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[6.3300133e-05 3.9696693e-05 2.2351742e-05 9.9539757e-06 5.1975250e-05]
Distance score: 3.745556023204699e-05
SAUCE Drift detection: True
Detection latency: 0.0231s

DRIFT-DETECTED after 2-th workload
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/incremental_train.py', '--dataset=bjaq', '--end2end', '--model=face', '--model_update=adapt', '--update_size=80000', '--epochs=0']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
update_size: 76433
AdaptTask - START
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
train data shape: 80000, transfer data shape:16000
Training done; evaluating likelihood on full data:
Saved to: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
AdaptTask - END

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.000737 | Model-update-time: 2.228926


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=tupleskew', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.16735553741455
tensor(0.9988)
result is  tensor(458033.9688)
Enter testHyper
ReportEsts: [1.1205525398254395, 1.0303646326065063, 1.012747883796692, 1.0880918502807617, 1.0191941261291504, 1.0750874280929565, 1.2943706512451172, 1.0404107570648193, 1.049718976020813, 1.1654707193374634, 1.0139509439468384, 1.1842526197433472, 1.3220338821411133, 1.015689492225647, 1.2684465646743774, 1.0184086561203003, 1.0687274932861328, 1.0226386785507202, 1.1634854078292847, 1.2498788833618164, 1.0131940841674805, 1.0369958877563477, 1.1877802610397339, 1.1119470596313477, 1.1450233459472656, 1.4625346660614014, 1.01841402053833, 1.1196893453598022, 1.433739185333252, 1.0150891542434692, 1.1733967065811157, 1.491525411605835, 1.0306730270385742, 1.1522852182388306, 1.0476821660995483, 1.0587965250015259, 1.0764259099960327, 1.0742523670196533, 1.1215471029281616, 1.0783441066741943, 1.0099339485168457, 1.2688171863555908, 1.0672342777252197, 1.0384093523025513, 1.116599202156067, 1.0739977359771729, 1.229995608329773, 1.057050347328186, 1.3952380418777466, 1.1404049396514893, 1.011631965637207, 1.1412208080291748, 1.1299492120742798, 1.072021245956421, 1.074769139289856, 1.4421459436416626, 1.2002403736114502, 1.051375150680542, 1.3472944498062134, 1.0318019390106201, 1.2552692890167236, 1.0241632461547852, 1.0780246257781982, 1.8649179935455322, 1.0998443365097046, 1.0376914739608765, 1.3732150793075562, 1.0260310173034668, 1.142914056777954, 1.0737812519073486, 1.1944183111190796, 1.176206111907959, 1.022287130355835, 1.126240849494934, 1.0881422758102417, 1.39286470413208, 1.167776346206665, 1.055721640586853, 1.3310385942459106, 1.1278133392333984, 1.1005929708480835, 1.2806323766708374, 1.002049446105957, 1.2169519662857056, 1.357177734375, 1.6042553186416626, 1.1739270687103271, 1.4899497032165527, 1.0759917497634888, 1.9662446975708008, 1.1544517278671265, 1.106251835823059, 1.475941777229309, 1.248845100402832, 1.1277430057525635, 1.0404973030090332, 1.056172251701355, 1.2204004526138306, 1.535560965538025, 1.4384585618972778, 1.06624174118042, 1.0731983184814453, 1.4349881410598755, 1.2340785264968872, 1.1130846738815308, 1.1092145442962646, 1.0143001079559326, 1.1252778768539429, 1.4682539701461792, 1.1295995712280273, 1.1770275831222534, 1.0768704414367676, 1.2608306407928467, 1.259562373161316, 1.1501597166061401, 1.0844842195510864, 1.0700907707214355, 1.3347350358963013, 1.2302777767181396, 2.6576576232910156, 1.1608667373657227, 1.1174200773239136, 1.102899432182312, 1.0411534309387207, 1.1303784847259521, 1.0209015607833862, 1.0698961019515991, 1.0941557884216309, 1.010155439376831, 1.0315337181091309, 1.0645891427993774, 1.095301628112793, 1.1460052728652954, 1.145580530166626, 1.4466437101364136, 1.1234803199768066, 1.1454578638076782, 1.0982691049575806, 1.0503264665603638, 1.0443590879440308, 1.069954752922058, 1.2581957578659058, 1.0196939706802368, 1.0873656272888184, 1.0523825883865356, 1.0221678018569946, 3.9689440727233887, 1.0607240200042725, 1.123514175415039, 1.0689547061920166, 1.0963727235794067, 1.1214680671691895, 1.0258021354675293, 1.042954444885254, 1.020490050315857, 1.079063057899475, 1.0102239847183228, 1.13223135471344, 1.034709095954895, 1.1632314920425415, 1.0611885786056519, 1.172619104385376, 1.5292013883590698, 1.0326104164123535, 1.2347419261932373, 1.0971592664718628, 1.2455010414123535, 1.2708779573440552, 1.1234688758850098, 1.3052263259887695, 1.095216989517212, 1.1127434968948364, 1.5624113082885742, 1.0425254106521606, 1.010475516319275, 1.0728938579559326, 1.0540978908538818, 1.0713554620742798, 1.0079327821731567, 1.0659044981002808, 1.7894736528396606, 1.099125862121582, 1.0784244537353516, 1.7652380466461182, 1.2707537412643433, 1.020902395248413, 1.0402016639709473, 1.0039067268371582, 1.3903504610061646, 1.0383858680725098, 1.1971014738082886, 1.2388083934783936, 1.2750767469406128, 1.7506515979766846, 1.0891450643539429, 4.704917907714844, 1.2413514852523804, 1.1152406930923462, 1.2214021682739258, 1.085932731628418]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.715968132019043] ms
 --  Average per query NF    [1.3556170463562012] ms
 --  Average per query vegas [2.360351085662842] ms
Mean [1.203]  Median [1.112]  95th [1.537]  99th [2.671]  max [4.705]
Mean [1.203]  Median [1.112]  95th [1.537]  99th [2.671]  max [4.705]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.389022 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=1 | total-time=28.539937