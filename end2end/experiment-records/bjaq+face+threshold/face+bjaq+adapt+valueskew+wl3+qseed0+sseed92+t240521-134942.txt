Input arguments = Namespace(data_update='valueskew', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 92, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.211229801177979
tensor(0.9952)
result is  tensor(380352.1562)
Enter testHyper
ReportEsts: [1.1394567489624023, 1.0109124183654785, 1.5251102447509766, 1.2341545820236206, 1.3112276792526245, 1.0983318090438843, 1.1570911407470703, 1.159425139427185, 1.0986301898956299, 1.1606383323669434, 1.1033592224121094, 1.1038135290145874, 1.2293602228164673, 1.03125, 1.132114291191101, 1.3737486600875854, 1.4022789001464844, 1.1817102432250977, 1.2277597188949585, 1.0612244606018066, 1.0196268558502197, 1.0701181888580322, 1.1237220764160156, 1.0230742692947388, 1.081924319267273, 1.1672694683074951, 1.0444819927215576, 1.4477812051773071, 1.0478013753890991, 1.1648865938186646, 1.171337366104126, 1.3874595165252686, 1.122478723526001, 1.071987509727478, 1.1289738416671753, 1.128833532333374, 1.3061635494232178, 1.1578147411346436, 1.0532481670379639, 1.0773652791976929, 1.0370632410049438, 1.0653120279312134, 1.0738826990127563, 1.0234967470169067, 1.109021782875061, 1.0680272579193115, 1.204851746559143, 1.2204160690307617, 1.0716495513916016, 1.160744547843933, 1.2561308145523071, 1.3875534534454346, 1.0711126327514648, 1.22559654712677, 1.0837063789367676, 1.048105001449585, 1.286915898323059, 1.0908492803573608, 1.1278350353240967, 1.3278884887695312, 1.3050007820129395, 1.1680407524108887, 1.3196231126785278, 1.2085169553756714, 1.3924050331115723, 1.1428571939468384, 1.0866551399230957, 1.1335690021514893, 1.0790736675262451, 1.2947368621826172, 1.0627514123916626, 1.0009052753448486, 1.2452921867370605, 1.184757113456726, 1.208096981048584, 1.089981198310852, 1.9633774757385254, 1.049564242362976, 1.0328969955444336, 1.3256232738494873, 1.0192599296569824, 1.191568374633789, 1.0749387741088867, 1.2809913158416748, 1.2798670530319214, 1.1574416160583496, 1.1098309755325317, 1.1296342611312866, 1.0490237474441528, 1.0275222063064575, 1.0085493326187134, 1.2522164583206177, 1.0187362432479858, 1.249489188194275, 1.167664647102356, 1.0911619663238525, 1.2678202390670776, 1.418253779411316, 1.01694917678833, 1.1733920574188232, 1.1617021560668945, 1.0574291944503784, 1.115837574005127, 1.0139092206954956, 1.0137858390808105, 1.1776014566421509, 1.1540164947509766, 1.1710296869277954, 1.055226445198059, 1.0432380437850952, 1.1659624576568604, 1.0625566244125366, 1.2616629600524902, 1.0460659265518188, 1.1155674457550049, 1.1464647054672241, 1.0162862539291382, 1.0014208555221558, 1.2214739322662354, 1.0690385103225708, 1.278613805770874, 1.1220505237579346, 1.138761043548584, 1.1817660331726074, 1.288759708404541, 1.1953157186508179, 1.0180025100708008, 1.074703574180603, 1.228139877319336, 1.1416165828704834, 1.0338197946548462, 1.1566071510314941, 1.291796088218689, 1.4642857313156128, 1.0923166275024414, 1.1157784461975098, 1.052802562713623, 1.1830893754959106, 1.0102946758270264, 1.500392198562622, 1.2339588403701782, 1.0952104330062866, 1.0547661781311035, 1.301628828048706, 1.09650456905365, 1.0999058485031128, 1.137746810913086, 1.4027917385101318, 1.1761500835418701, 1.1243607997894287, 1.2743011713027954, 1.1777976751327515, 1.304555058479309, 1.1416590213775635, 1.102024793624878, 1.00784170627594, 1.0409455299377441, 1.024198055267334, 1.0001994371414185, 1.0955535173416138, 1.1300265789031982, 1.0311532020568848, 1.188001036643982, 1.2594085931777954, 1.1002330780029297, 1.0159292221069336, 1.2815858125686646, 1.1841931343078613, 1.106972098350525, 1.1216403245925903, 1.2260154485702515, 1.1895318031311035, 1.1558442115783691, 1.1745527982711792, 1.0868529081344604, 1.0629796981811523, 1.0053449869155884, 1.252217173576355, 1.4531160593032837, 1.2137353420257568, 1.0224177837371826, 1.0341073274612427, 1.000184178352356, 1.1389172077178955, 1.2126041650772095, 1.0866807699203491, 1.0296459197998047, 1.2818409204483032, 1.2359521389007568, 1.4484765529632568, 1.1230649948120117, 1.0546979904174805, 1.5802879333496094, 1.2694052457809448, 1.6805342435836792, 1.1273996829986572, 1.0622342824935913, 1.0270270109176636, 1.1220070123672485, 1.0871845483779907]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.742337226867676] ms
 --  Average per query NF    [1.3604998588562012] ms
 --  Average per query vegas [2.3818373680114746] ms
Mean [1.161]  Median [1.130]  95th [1.404]  99th [1.581]  max [1.963]
Mean [1.161]  Median [1.130]  95th [1.404]  99th [1.581]  max [1.963]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.890038 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=valueskew', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
ValueSample - START
ValueSample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[5.9604645e-08 1.7881393e-07 2.2004724e-02 8.9406967e-07 1.1920929e-07]
Distance score: 0.004401194863021374
SAUCE Drift detection: True
Detection latency: 0.0232s

DRIFT-DETECTED after 2-th workload
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/incremental_train.py', '--dataset=bjaq', '--end2end', '--model=face', '--model_update=adapt', '--update_size=80000', '--epochs=0']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
update_size: 76433
AdaptTask - START
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
train data shape: 80000, transfer data shape:16000
Training done; evaluating likelihood on full data:
Saved to: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
AdaptTask - END

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.049069 | Model-update-time: 2.279360


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=valueskew', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.163245916366577
tensor(0.9950)
result is  tensor(456309.0625)
Enter testHyper
ReportEsts: [1.3972116708755493, 1.1721649169921875, 1.157377004623413, 1.176375389099121, 1.238250494003296, 1.2664936780929565, 1.0784971714019775, 1.1564053297042847, 1.1377410888671875, 1.129320740699768, 1.2020926475524902, 1.0214682817459106, 1.049896001815796, 1.272486925125122, 1.2108138799667358, 1.0561476945877075, 1.4350690841674805, 1.2986425161361694, 1.0128761529922485, 1.15761137008667, 1.1260862350463867, 2.2608695030212402, 2.211278200149536, 1.8692432641983032, 1.0672199726104736, 1.402544617652893, 1.127028226852417, 1.2726250886917114, 1.2741531133651733, 1.1112804412841797, 1.2084343433380127, 1.4406780004501343, 1.1166338920593262, 22.156784057617188, 1.001120686531067, 1.048723816871643, 1.3613008260726929, 1.082382082939148, 1.1764436960220337, 1.4362545013427734, 1.126361608505249, 1.2567049264907837, 1.3962758779525757, 1.1082196235656738, 1.029695987701416, 1.1506682634353638, 1.1968530416488647, 1.0635300874710083, 1.2137404680252075, 2.7153685092926025, 1.224990963935852, 1.0119009017944336, 1.0178200006484985, 1.3326579332351685, 1.1885364055633545, 2.0975940227508545, 1.0138013362884521, 1.098763346672058, 1.2581446170806885, 1.1085230112075806, 1.2611764669418335, 1.1419665813446045, 1.2107776403427124, 1.6508538722991943, 1.0900245904922485, 2.7128946781158447, 1.1142051219940186, 1.0490754842758179, 1.02273428440094, 1.1178878545761108, 1.2474820613861084, 1.284658432006836, 1.0250825881958008, 1.1242108345031738, 1.1263132095336914, 1.2827879190444946, 885.6666870117188, 1.0704779624938965, 1.0460927486419678, 1.0873408317565918, 1.1228941679000854, 1.0361380577087402, 1.0395921468734741, 1.103452205657959, 1.3354610204696655, 1.3239436149597168, 1.3373609781265259, 1.535433053970337, 1.1835427284240723, 1.0165483951568604, 1.1372289657592773, 1.0700151920318604, 1.5094380378723145, 1.2140817642211914, 1.1626343727111816, 1.0790505409240723, 1.3439655303955078, 1.2526105642318726, 1.1903681755065918, 1.0694667100906372, 1.4420287609100342, 1.0252125263214111, 1.0465686321258545, 1.3180880546569824, 1.0546146631240845, 1.14040207862854, 1.105370044708252, 1.1273877620697021, 1.1031519174575806, 1.1332449913024902, 1.1325615644454956, 1.0647799968719482, 1.0029501914978027, 1.0363842248916626, 1.0509045124053955, 1.0273005962371826, 1.0541244745254517, 1.2290610074996948, 1.1187461614608765, 1.0088495016098022, 1.1811739206314087, 1.3152648210525513, 1.0484824180603027, 2.698113203048706, 1.1204909086227417, 1.2368935346603394, 1.1476548910140991, 2.8919804096221924, 1.060652494430542, 1.016753911972046, 1.0252816677093506, 1.4258724451065063, 1.2456541061401367, 1.4448087215423584, 1.297462821006775, 1.2961831092834473, 1.239780306816101, 1.0826077461242676, 1.0283942222595215, 1.2015879154205322, 1.1016072034835815, 1.060800313949585, 1.204988718032837, 1.028215765953064, 1.247480034828186, 1.0117299556732178, 1.365168571472168, 1.131913423538208, 1.0903003215789795, 1.0064696073532104, 18.732316970825195, 1.0458686351776123, 1.205480694770813, 1.01051926612854, 1.0188170671463013, 1.4776569604873657, 1.0475049018859863, 1.2325581312179565, 1.0925776958465576, 1.0143530368804932, 1.066901445388794, 1.0379496812820435, 2.7829580307006836, 1.1777567863464355, 1.0287531614303589, 1.0236486196517944, 1.4096354246139526, 1.634778618812561, 19.787992477416992, 1.2723993062973022, 1.6099797487258911, 1.0112110376358032, 1.5256140232086182, 1.1205028295516968, 1.0964412689208984, 1.0294889211654663, 1.2034220695495605, 1.382592797279358, 1.0407041311264038, 1.3719981908798218, 1.894736886024475, 1.400524616241455, 1.2684468030929565, 1.6029925346374512, 1.180578351020813, 3.0520520210266113, 1.2072852849960327, 1.156126618385315, 1.262513518333435, 1.2147592306137085, 1.0479743480682373, 1.0961989164352417, 1.1398417949676514, 1.490342378616333, 1.1730194091796875, 1.112705111503601, 1.5148111581802368, 1.4244272708892822, 1.3492333889007568, 1.1512056589126587]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7417256832122803] ms
 --  Average per query NF    [1.357513666152954] ms
 --  Average per query vegas [2.384212017059326] ms
Mean [5.960]  Median [1.157]  95th [2.283]  99th [19.812]  max [885.667]
Mean [5.960]  Median [1.157]  95th [2.283]  99th [19.812]  max [885.667]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.415478 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=1 | total-time=28.659184