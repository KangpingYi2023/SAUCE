Input arguments = Namespace(data_update='valueskew', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 40, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.209345579147339
tensor(0.9972)
result is  tensor(381100.4062)
Enter testHyper
ReportEsts: [1.1807893514633179, 1.040079116821289, 1.347670316696167, 1.0825437307357788, 1.2532429695129395, 1.1309452056884766, 1.2069870233535767, 1.0950593948364258, 1.0379637479782104, 1.1512787342071533, 1.0129199028015137, 1.1548728942871094, 1.0021846294403076, 1.0022321939468384, 1.076521396636963, 1.3717279434204102, 1.3444842100143433, 1.1571259498596191, 1.1476479768753052, 1.0357142686843872, 1.0715469121932983, 1.1127595901489258, 1.1703606843948364, 1.043257236480713, 1.0359388589859009, 1.2097649574279785, 1.0534909963607788, 1.3380281925201416, 1.0475797653198242, 1.020766258239746, 1.115643858909607, 1.231491208076477, 1.2528878450393677, 1.000105857849121, 1.1594053506851196, 1.1437487602233887, 1.3078924417495728, 1.23114013671875, 1.0091348886489868, 1.142155647277832, 1.0006821155548096, 1.104378342628479, 1.1265813112258911, 1.0345832109451294, 1.1062750816345215, 1.0499999523162842, 1.12789785861969, 1.3994789123535156, 1.1463110446929932, 1.1049069166183472, 1.1850899457931519, 1.2586618661880493, 1.0047093629837036, 1.2172976732254028, 1.2145382165908813, 1.0560964345932007, 1.2289719581604004, 1.1462339162826538, 1.1241905689239502, 1.3992443084716797, 1.3396499156951904, 1.1985973119735718, 1.1587049961090088, 1.1192644834518433, 1.2741312980651855, 1.1714285612106323, 1.0220048427581787, 1.056944727897644, 1.1318989992141724, 1.4947367906570435, 1.0913081169128418, 1.0563520193099976, 1.1259111166000366, 1.145695447921753, 1.131434679031372, 1.2197175025939941, 1.8380225896835327, 1.0501362085342407, 1.0114318132400513, 1.3343108892440796, 1.2026513814926147, 1.1263123750686646, 1.0423893928527832, 1.2248497009277344, 1.2043266296386719, 1.0117696523666382, 1.0903443098068237, 1.0407565832138062, 1.034709095954895, 1.0877352952957153, 1.0003236532211304, 1.2792450189590454, 1.017614722251892, 1.2740740776062012, 1.048387050628662, 1.154689908027649, 1.161726713180542, 1.2855861186981201, 1.034482717514038, 1.1057953834533691, 1.1327800750732422, 1.0149459838867188, 1.12300443649292, 1.0044118165969849, 1.087228536605835, 1.0303877592086792, 1.2593379020690918, 1.2303664684295654, 1.0858243703842163, 1.0025328397750854, 1.3475368022918701, 1.0722781419754028, 1.103649377822876, 1.043252944946289, 1.04462730884552, 1.0460829734802246, 1.0079493522644043, 1.0524958372116089, 1.3138411045074463, 1.037192702293396, 1.248694658279419, 1.0847246646881104, 1.0418083667755127, 1.2422839403152466, 1.3129844665527344, 1.1772595643997192, 1.2596019506454468, 1.125065803527832, 1.3636363744735718, 1.0741482973098755, 1.0188734531402588, 1.1813210248947144, 1.2296457290649414, 1.4285714626312256, 1.1059491634368896, 1.1210291385650635, 1.0605288743972778, 1.1385365724563599, 1.0095114707946777, 1.3752695322036743, 1.1445567607879639, 1.1294447183609009, 1.0310784578323364, 1.3325393199920654, 1.030732274055481, 1.1144946813583374, 1.0732104778289795, 1.452254295349121, 1.00618577003479, 1.1127841472625732, 1.2251793146133423, 1.1607486009597778, 1.337859869003296, 1.1609629392623901, 1.0382726192474365, 1.004787564277649, 1.0106467008590698, 1.020258903503418, 1.060667634010315, 1.1603103876113892, 1.0064605474472046, 1.089243769645691, 1.0686283111572266, 1.3013888597488403, 1.2227978706359863, 1.0880578756332397, 1.3078980445861816, 1.1706440448760986, 1.1422523260116577, 1.0152850151062012, 1.061811089515686, 1.0808063745498657, 1.103896141052246, 1.0459232330322266, 1.0478229522705078, 1.1900897026062012, 1.0140913724899292, 1.0284242630004883, 1.0718261003494263, 1.1833479404449463, 1.0131092071533203, 1.0081082582473755, 1.01876699924469, 1.1297242641448975, 1.0818543434143066, 1.1363636255264282, 1.0770783424377441, 1.3175650835037231, 1.026473045349121, 1.3854718208312988, 1.0156935453414917, 1.1866364479064941, 1.4895615577697754, 1.4503310918807983, 1.6495006084442139, 1.1339964866638184, 1.0447269678115845, 1.1176470518112183, 1.042194128036499, 1.1679283380508423]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.738124370574951] ms
 --  Average per query NF    [1.3564717769622803] ms
 --  Average per query vegas [2.381652593612671] ms
Mean [1.145]  Median [1.120]  95th [1.376]  99th [1.496]  max [1.838]
Mean [1.145]  Median [1.120]  95th [1.376]  99th [1.496]  max [1.838]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.870636 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=valueskew', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
ValueSample - START
ValueSample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[8.6820126e-03 1.2516975e-06 5.3644180e-07 2.0265579e-06 3.5762787e-07]
Distance score: 0.0017372369766235352
SAUCE Drift detection: True
Detection latency: 0.0232s

DRIFT-DETECTED after 2-th workload
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/incremental_train.py', '--dataset=bjaq', '--end2end', '--model=face', '--model_update=adapt', '--update_size=80000', '--epochs=0']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
update_size: 76433
AdaptTask - START
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
train data shape: 80000, transfer data shape:16000
Training done; evaluating likelihood on full data:
Saved to: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
AdaptTask - END

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.050358 | Model-update-time: 2.227698


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=valueskew', '--model_update=adapt']
/home/kangping/code_copy/SAUCE/./FACE/FACE_utils/dataUtils.py:321: RuntimeWarning: invalid value encountered in cast
  oracle_cards = oracle_cards.astype(np.int32)
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.170394659042358
tensor(0.9975)
result is  tensor(457458.8438)
Enter testHyper
ReportEsts: [1.0472302436828613, 1.0275530815124512, 1.0584707260131836, 1.2518877983093262, 1.1984484195709229, 1.5019333362579346, 1.2078970670700073, 1.0416876077651978, 1.1245698928833008, 1.0544781684875488, 1.012129545211792, 1.0032051801681519, 2.1855669021606445, 1.0219810009002686, 1367.0, 1.1410630941390991, 3.6432039737701416, 1.0683281421661377, 1.0741721391677856, 1.3857370615005493, 1.0619101524353027, 1.3537614345550537, 1.1570178270339966, 1.1640089750289917, 1.2915618419647217, 1.4811406135559082, 1.0604537725448608, 1.102865219116211, 1.0873521566390991, 1.4378697872161865, 1.0366032123565674, 1.234482765197754, 1.009968876838684, 1.116120457649231, 1.0043690204620361, 1.10811185836792, 1.1466213464736938, 1.1033343076705933, 1.4647451639175415, 1.5676183700561523, 1.0264527797698975, 1.0635592937469482, 69.58333587646484, 1.008575439453125, 1.0718226432800293, 1.1216274499893188, 2.022902727127075, 1.2473523616790771, 1.0281124114990234, 1.2985610961914062, 1.0349619388580322, 1.0131218433380127, 2.0081169605255127, 1.3840699195861816, 1.4522186517715454, 1.4508088827133179, 1.309918761253357, 1.0746703147888184, 1.385249137878418, 1.1128324270248413, 1.313645601272583, 1.2684937715530396, 1.3161027431488037, 1.7656766176223755, 1.011979579925537, 1.082895278930664, 1.2517865896224976, 1.061773657798767, 1.0476280450820923, 1.2802624702453613, 1.1412962675094604, 1.2892119884490967, 1.073105812072754, 1.1103782653808594, 1.103546142578125, 1.0750133991241455, 25.539474487304688, 9.109375, 1.4599262475967407, 1.1445542573928833, 1.0620026588439941, 1.0132626295089722, 1.1439980268478394, 1.280110239982605, 1.144111156463623, 1.634042501449585, 1.3328511714935303, 1.496641993522644, 1.062342643737793, 1.2678871154785156, 1.0612043142318726, 1.2128169536590576, 1.2227694988250732, 1.4436604976654053, 1.4333925247192383, 1.052722454071045, 1.1903693675994873, 1.3657618761062622, 1.2220209836959839, 1.5444591045379639, 1.0138169527053833, 1.021456003189087, 1.0196079015731812, 1.0286667346954346, 1.1706782579421997, 1.0164917707443237, 1.041905403137207, 1.1906827688217163, 1.1404958963394165, 1.0587668418884277, 2.7199110984802246, 1.125331997871399, 1.3685139417648315, 1.1212507486343384, 1.028704047203064, 1.9082353115081787, 1.1004327535629272, 1.1868884563446045, 1.135969638824463, 1.0, 1.1147990226745605, 1.1176162958145142, 1.1452693939208984, 1.4772692918777466, 1.1651171445846558, 1.1886810064315796, 1.0133880376815796, 1.051482081413269, 1.0060060024261475, 1.8592677116394043, 2.066254138946533, 1.0721180438995361, 1.021831750869751, 1.4527472257614136, 1.594618797302246, 1.1884500980377197, 1.110085129737854, 1.179213523864746, 1.321857213973999, 1.1974835395812988, 1.0142568349838257, 1.0182148218154907, 1.1768567562103271, 1.0731418132781982, 1.2587765455245972, 1.039743185043335, 1.4519773721694946, 1.1083626747131348, 1.140758752822876, 1.0977568626403809, 1.0951306819915771, 1.2231435775756836, 1.0863572359085083, 1.2217559814453125, 1.2818269729614258, 1.0530965328216553, 1.0485013723373413, 1.1048387289047241, 1.385587453842163, 1.0226463079452515, 1.0809032917022705, 1.1142857074737549, 1.0630459785461426, 1.1222392320632935, 1.1830030679702759, 13.931034088134766, 1.0600976943969727, 1.2360303401947021, 35.599998474121094, 1.1978684663772583, 1.0821067094802856, 1.1868536472320557, 1.6481339931488037, 1.0550366640090942, 1.0275853872299194, 1.0952335596084595, 1.785645604133606, 1.1372684240341187, 1.0273624658584595, 1.1476421356201172, 1.60869562625885, 1.1718592643737793, 1.0845158100128174, 1.0743621587753296, 1.0389682054519653, 1.8261494636535645, 1.3041549921035767, 1.3098948001861572, 1.4289554357528687, 1.239277958869934, 1.021691918373108, 1.0726627111434937, 1.3960310220718384, 1.5806950330734253, 1.183396577835083, 1.1369683742523193, 1.2902543544769287, 1.0388082265853882, 1.2840532064437866, 1.4059360027313232]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.730214834213257] ms
 --  Average per query NF    [1.3583636283874512] ms
 --  Average per query vegas [2.3718512058258057] ms
Mean [8.801]  Median [1.144]  95th [2.025]  99th [35.940]  max [1367.000]
Mean [8.801]  Median [1.144]  95th [2.025]  99th [35.940]  max [1367.000]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.374108 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=1 | total-time=28.590564