Input arguments = Namespace(data_update='sample', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 97, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.170023679733276
tensor(0.9974)
result is  tensor(381162.5000)
Enter testHyper
ReportEsts: [1.203490138053894, 1.0456981658935547, 1.4564415216445923, 1.0178985595703125, 1.2152658700942993, 1.076316475868225, 1.214231252670288, 1.0851470232009888, 1.0482137203216553, 1.128320574760437, 1.0155038833618164, 1.1358051300048828, 1.0355546474456787, 1.0133928060531616, 1.2213046550750732, 1.1189881563186646, 1.1593419313430786, 1.175771951675415, 1.1789555549621582, 1.0535714626312256, 1.0742429494857788, 1.1040235757827759, 1.1260714530944824, 1.0365725755691528, 1.3473005294799805, 1.0406872034072876, 1.03125, 1.4086350202560425, 1.0868921279907227, 1.0119011402130127, 1.146151065826416, 1.0640417337417603, 1.1066526174545288, 1.0525418519973755, 1.0233486890792847, 1.1495496034622192, 1.2903211116790771, 1.153752088546753, 1.0759094953536987, 1.018922209739685, 1.0282403230667114, 1.0559990406036377, 1.1201740503311157, 1.0231448411941528, 1.0416226387023926, 1.0022727251052856, 1.0415786504745483, 1.2953617572784424, 1.0646053552627563, 1.0930626392364502, 1.2195767164230347, 1.3695157766342163, 1.0167704820632935, 1.194142460823059, 1.0918354988098145, 1.0193761587142944, 1.2887850999832153, 1.2238452434539795, 1.0220038890838623, 1.3818408250808716, 1.458561658859253, 1.103515386581421, 1.1929486989974976, 1.1241034269332886, 1.375, 1.3428571224212646, 1.1730589866638184, 1.0399583578109741, 1.1296974420547485, 1.4315789937973022, 1.0756235122680664, 1.0559797286987305, 1.2640095949172974, 1.027677297592163, 1.1575326919555664, 1.1910772323608398, 2.107795476913452, 1.1302052736282349, 1.0832228660583496, 1.284679651260376, 1.0547175407409668, 1.1447261571884155, 1.0157744884490967, 1.2331644296646118, 1.1689525842666626, 1.0627532005310059, 1.0334062576293945, 1.149760365486145, 1.0117311477661133, 1.0936230421066284, 1.071445107460022, 1.2237247228622437, 1.011305570602417, 1.2511934041976929, 1.1206896305084229, 1.1076446771621704, 1.0722312927246094, 1.1978498697280884, 1.01694917678833, 1.1923977136611938, 1.1683309078216553, 1.1474084854125977, 1.0496292114257812, 1.0234260559082031, 1.1390167474746704, 1.1142899990081787, 1.254841685295105, 1.1780104637145996, 1.0526132583618164, 1.0442414283752441, 1.328309178352356, 1.084181308746338, 1.0783343315124512, 1.0228533744812012, 1.016575813293457, 1.15816330909729, 1.0179492235183716, 1.0513349771499634, 1.3245998620986938, 1.0897454023361206, 1.2564700841903687, 1.0674761533737183, 1.108755111694336, 1.1804277896881104, 1.2514535188674927, 1.1665290594100952, 1.1090201139450073, 1.095491647720337, 1.3931469917297363, 1.1189044713974, 1.0189906358718872, 1.1474486589431763, 1.3822250366210938, 1.4642857313156128, 1.0418294668197632, 1.0853242874145508, 1.027212381362915, 1.1112195253372192, 1.1069984436035156, 1.1700305938720703, 1.165015697479248, 1.0448633432388306, 1.0228139162063599, 1.1872388124465942, 1.0615500211715698, 1.0292519330978394, 1.167586088180542, 1.4741103649139404, 1.0924173593521118, 1.080468773841858, 1.314038634300232, 1.169337272644043, 1.3017970323562622, 1.0609186887741089, 1.1945732831954956, 1.0430883169174194, 1.287092924118042, 1.0410804748535156, 1.0633217096328735, 1.165144681930542, 1.0353420972824097, 1.0170503854751587, 1.0253722667694092, 1.2713704109191895, 1.0763968229293823, 1.0078212022781372, 1.2553436756134033, 1.2386717796325684, 1.0071429014205933, 1.1009162664413452, 1.0715774297714233, 1.0365060567855835, 1.1558442115783691, 1.0901744365692139, 1.00754976272583, 1.0816340446472168, 1.0563653707504272, 1.2465547323226929, 1.3458051681518555, 1.154022455215454, 1.022042155265808, 1.1531697511672974, 1.0281845331192017, 1.1787538528442383, 1.1539297103881836, 1.1173361539840698, 1.0070115327835083, 1.30275559425354, 1.034680962562561, 1.4178954362869263, 1.0001322031021118, 1.141855239868164, 1.5044807195663452, 1.3258752822875977, 1.901991367340088, 1.234394907951355, 1.1959567070007324, 1.1875, 1.0992578268051147, 1.0514276027679443]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7699413299560547] ms
 --  Average per query NF    [1.3661956787109375] ms
 --  Average per query vegas [2.403745651245117] ms
Mean [1.147]  Median [1.109]  95th [1.394]  99th [1.508]  max [2.108]
Mean [1.147]  Median [1.109]  95th [1.394]  99th [1.508]  max [2.108]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.839499 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=sample', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
Sample - START
Sample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[4.7683716e-07 1.7881393e-07 7.7486038e-07 4.1723251e-07 0.0000000e+00]
Distance score: 3.695487862387381e-07
SAUCE Drift detection: False
Detection latency: 0.0233s

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.024653 | Model-update-time: 0.000000


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=sample', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.164573431015015
tensor(0.9933)
result is  tensor(455526.8438)
Enter testHyper
ReportEsts: [1.0626084804534912, 1.1016159057617188, 1.2823179960250854, 1.3212121725082397, 1.1272445917129517, 1.0905179977416992, 1.2787257432937622, 1.003287672996521, 1.055363655090332, 1.1409621238708496, 1.0654239654541016, 1.1922202110290527, 1.2904040813446045, 1.100244164466858, 1.0935176610946655, 1.0450299978256226, 1.2883895635604858, 1.1494348049163818, 1.092639446258545, 1.2908573150634766, 1.1260699033737183, 1.5454988479614258, 1.0043684244155884, 1.2667651176452637, 1.1504491567611694, 1.2051069736480713, 1.112902283668518, 1.1272811889648438, 1.296325922012329, 1.6109057664871216, 1.2260702848434448, 1.3426573276519775, 1.0507216453552246, 1.2156734466552734, 1.0577762126922607, 1.0188395977020264, 1.220258355140686, 1.1950868368148804, 1.0376780033111572, 1.008855938911438, 1.0380144119262695, 1.0629067420959473, 1.545744776725769, 1.0156303644180298, 1.172182559967041, 1.1596070528030396, 1.778234839439392, 1.0458502769470215, 1.1507936716079712, 1.2694214582443237, 1.0456980466842651, 1.064756989479065, 1.0844045877456665, 1.079714298248291, 1.2000000476837158, 1.2903790473937988, 1.0236543416976929, 1.172347903251648, 1.2071021795272827, 1.100853443145752, 1.4170305728912354, 1.0100499391555786, 1.1895641088485718, 1.8595088720321655, 1.0474799871444702, 1.0165342092514038, 1.606916069984436, 1.0020356178283691, 1.1362987756729126, 1.1262046098709106, 1.0386357307434082, 1.1175419092178345, 1.045710802078247, 1.22910737991333, 1.0911545753479004, 1.1651842594146729, 1.0533708333969116, 1.1609188318252563, 1.3153966665267944, 1.0692036151885986, 1.1614350080490112, 1.0199984312057495, 1.2947001457214355, 1.2458032369613647, 1.2670849561691284, 1.3451957702636719, 1.1406325101852417, 1.4716796875, 1.0124428272247314, 1.0521438121795654, 1.1064262390136719, 1.1478118896484375, 1.3878252506256104, 1.1033313274383545, 1.0673102140426636, 1.0155293941497803, 1.1137453317642212, 1.187852382659912, 1.11110520362854, 1.0996642112731934, 1.0699840784072876, 1.1223082542419434, 1.1547343730926514, 1.199673056602478, 1.0959635972976685, 1.0987415313720703, 1.027107834815979, 1.0184017419815063, 1.0813648700714111, 1.1768754720687866, 1.2083382606506348, 1.2145837545394897, 1.1466097831726074, 1.2754826545715332, 1.1155129671096802, 1.0016907453536987, 1.0681473016738892, 1.2090892791748047, 1.032418131828308, 1.0924370288848877, 1.0804498195648193, 1.1236952543258667, 1.2005839347839355, 1.203071117401123, 1.04388427734375, 1.2786316871643066, 1.0244051218032837, 1.269592523574829, 1.1300100088119507, 1.1676784753799438, 1.1433011293411255, 1.102373719215393, 1.159450650215149, 1.7549889087677002, 1.7748743295669556, 1.127172827720642, 1.1248247623443604, 1.25257408618927, 1.0445140600204468, 1.0333220958709717, 1.0283660888671875, 1.203128457069397, 1.0362443923950195, 1.0309847593307495, 1.0315850973129272, 1.0054535865783691, 1.4147727489471436, 1.1473195552825928, 1.0725631713867188, 1.0448863506317139, 1.0739786624908447, 1.0331783294677734, 1.0569019317626953, 1.030867576599121, 1.0372108221054077, 1.0852662324905396, 1.1075857877731323, 1.263157844543457, 1.0337531566619873, 1.0438737869262695, 1.0737632513046265, 1.082109808921814, 1.0214844942092896, 1.076322078704834, 1.2011334896087646, 1.0554062128067017, 1.066063404083252, 1.2036304473876953, 1.0210239887237549, 1.2437527179718018, 1.1363303661346436, 1.2105962038040161, 1.6595256328582764, 1.0593726634979248, 1.1291273832321167, 1.1767587661743164, 1.1078766584396362, 1.1568034887313843, 1.1056782007217407, 1.1645748615264893, 1.6666666269302368, 1.067907452583313, 1.0005707740783691, 1.5167185068130493, 1.4371426105499268, 1.2018420696258545, 1.1611319780349731, 1.019715428352356, 1.2279423475265503, 1.0796918869018555, 1.1957907676696777, 1.0795283317565918, 1.3191707134246826, 1.916048288345337, 1.0360764265060425, 1.051690936088562, 1.335927963256836, 1.0800548791885376, 1.3153594732284546, 1.1233937740325928]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.6875176429748535] ms
 --  Average per query NF    [1.3614678382873535] ms
 --  Average per query vegas [2.3260498046875] ms
Mean [1.167]  Median [1.124]  95th [1.546]  99th [1.779]  max [1.916]
Mean [1.167]  Median [1.124]  95th [1.546]  99th [1.779]  max [1.916]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.167913 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=0 | total-time=26.064595