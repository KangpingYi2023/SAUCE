Input arguments = Namespace(data_update='sample', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 79, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.169204473495483
tensor(0.9961)
result is  tensor(380678.2500)
Enter testHyper
ReportEsts: [1.107813835144043, 1.087024211883545, 1.3231614828109741, 1.087597370147705, 1.2254252433776855, 1.1261818408966064, 1.0654802322387695, 1.0835227966308594, 1.0750670433044434, 1.192943811416626, 1.3118001222610474, 1.1872881650924683, 1.0153712034225464, 1.0290178060531616, 1.088111400604248, 1.3564176559448242, 1.4316589832305908, 1.164014220237732, 1.1729217767715454, 1.1020407676696777, 1.0779099464416504, 1.1443809270858765, 1.123956561088562, 1.0067214965820312, 1.0445152521133423, 1.1763110160827637, 1.0382882356643677, 1.3952484130859375, 1.0320547819137573, 1.134269118309021, 1.2146151065826416, 1.0025609731674194, 1.2878375053405762, 1.0219838619232178, 1.2289985418319702, 1.150240421295166, 1.6088420152664185, 1.0107675790786743, 1.0440583229064941, 1.0810461044311523, 1.0117241144180298, 1.1675132513046265, 1.0080071687698364, 1.0579476356506348, 1.0766955614089966, 1.0736961364746094, 1.0107405185699463, 1.3151252269744873, 1.0631425380706787, 1.1099830865859985, 1.2359249591827393, 1.2761962413787842, 1.0160136222839355, 1.2180473804473877, 1.0523091554641724, 1.0425326824188232, 1.2037383317947388, 1.2073734998703003, 1.2256792783737183, 1.36766517162323, 1.323636770248413, 1.2425850629806519, 1.3731191158294678, 1.077879786491394, 1.2890625, 1.3428571224212646, 1.1665116548538208, 1.0574418306350708, 1.2960553169250488, 1.263157844543457, 1.0255775451660156, 1.0404585599899292, 1.2333343029022217, 1.040987253189087, 1.1414320468902588, 1.08895742893219, 1.8083139657974243, 1.1030337810516357, 1.2254642248153687, 1.1482586860656738, 1.0063517093658447, 1.0172832012176514, 1.090983271598816, 1.24436616897583, 1.2771515846252441, 1.0340702533721924, 1.0449934005737305, 1.0760151147842407, 1.0158900022506714, 1.0051413774490356, 1.032148838043213, 1.5207284688949585, 1.0142648220062256, 1.33462655544281, 1.107954502105713, 1.1188215017318726, 1.209720253944397, 1.2125266790390015, 1.0909091234207153, 1.105514407157898, 1.2115384340286255, 1.0574105978012085, 1.123353362083435, 1.0111029148101807, 1.1539748907089233, 1.0181171894073486, 1.1872888803482056, 1.2111692428588867, 1.0761781930923462, 1.04600191116333, 1.357474684715271, 1.0801843404769897, 1.195662021636963, 1.0246260166168213, 1.1473281383514404, 1.0913461446762085, 1.055138349533081, 1.010689616203308, 1.28134286403656, 1.037900447845459, 1.154272437095642, 1.090865135192871, 1.0888844728469849, 1.2392463684082031, 1.2674418687820435, 1.2182211875915527, 1.1025806665420532, 1.226377248764038, 1.3137755393981934, 1.1259185075759888, 1.2986342906951904, 1.2432324886322021, 1.2141081094741821, 1.4285714626312256, 1.157296895980835, 1.0595957040786743, 1.0392963886260986, 1.017874836921692, 1.1512823104858398, 1.2943166494369507, 1.154811143875122, 1.1002367734909058, 1.0267333984375, 1.2521860599517822, 1.0328826904296875, 1.0389478206634521, 1.182366967201233, 1.6293654441833496, 1.0454713106155396, 1.1885653734207153, 1.1668511629104614, 1.2022817134857178, 1.2735263109207153, 1.4113534688949585, 1.1066181659698486, 1.0344395637512207, 1.0961195230484009, 1.0503658056259155, 1.0885289907455444, 1.172247052192688, 1.022356390953064, 1.0304443836212158, 1.0986697673797607, 1.2361477613449097, 1.3390071392059326, 1.0502328872680664, 1.2008473873138428, 1.226789951324463, 1.0061582326889038, 1.0117206573486328, 1.0048964023590088, 1.0536619424819946, 1.149350643157959, 1.1316391229629517, 1.002043604850769, 1.0712149143218994, 1.0233714580535889, 1.1877307891845703, 1.1605427265167236, 1.0168818235397339, 1.0459033250808716, 1.187564730644226, 1.0542824268341064, 1.1358529329299927, 1.0753350257873535, 1.1120507717132568, 1.0052142143249512, 1.2183791399002075, 1.0116329193115234, 1.331969141960144, 1.0598857402801514, 1.0318121910095215, 1.49973726272583, 1.2279375791549683, 1.8973253965377808, 1.191149353981018, 1.1157149076461792, 1.1875, 1.0949113368988037, 1.036819338798523]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.785308599472046] ms
 --  Average per query NF    [1.3643503189086914] ms
 --  Average per query vegas [2.4209582805633545] ms
Mean [1.153]  Median [1.114]  95th [1.374]  99th [1.631]  max [1.897]
Mean [1.153]  Median [1.114]  95th [1.374]  99th [1.631]  max [1.897]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.855191 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=sample', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
Sample - START
Sample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[4.1723251e-07 1.4305115e-06 2.9802322e-07 5.9604645e-08 0.0000000e+00]
Distance score: 4.410743770222325e-07
SAUCE Drift detection: False
Detection latency: 0.0233s

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.021027 | Model-update-time: 0.000000


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=sample', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.16638469696045
tensor(0.9976)
result is  tensor(457506.9688)
Enter testHyper
ReportEsts: [1.0305002927780151, 1.0515648126602173, 1.1899441480636597, 1.0830711126327515, 1.2001498937606812, 1.093153476715088, 1.2272049188613892, 1.1029953956604004, 1.0918126106262207, 1.0410817861557007, 1.0296825170516968, 1.0779459476470947, 1.1917475461959839, 1.1409960985183716, 1.012403130531311, 1.024265170097351, 1.1386412382125854, 1.0315512418746948, 1.0243123769760132, 1.2463420629501343, 1.1660329103469849, 1.2221488952636719, 1.0233808755874634, 1.1238900423049927, 1.1729187965393066, 1.14540696144104, 1.009078025817871, 1.0748614072799683, 1.258436918258667, 1.4668902158737183, 1.118478775024414, 1.3185185194015503, 1.0904583930969238, 1.0656375885009766, 1.0016789436340332, 1.1556298732757568, 1.2419794797897339, 1.0348584651947021, 1.3212800025939941, 1.0871857404708862, 1.0815348625183105, 1.0650224685668945, 1.1697998046875, 1.147464394569397, 1.0030832290649414, 1.0038377046585083, 1.041872501373291, 1.0675899982452393, 1.2470118999481201, 1.3893020153045654, 1.0278184413909912, 1.0413447618484497, 1.022735834121704, 1.0756464004516602, 1.0367258787155151, 1.2040374279022217, 1.0808528661727905, 1.11665940284729, 1.2917195558547974, 1.1072834730148315, 1.4405286312103271, 1.074912190437317, 1.0222065448760986, 1.7728445529937744, 1.0220369100570679, 1.0413055419921875, 1.4134349822998047, 1.0632269382476807, 1.1428674459457397, 1.1404833793640137, 1.0024020671844482, 1.1384055614471436, 1.0104700326919556, 1.053871989250183, 1.1769676208496094, 1.2493795156478882, 1.0709882974624634, 1.0341880321502686, 1.2668256759643555, 1.1294244527816772, 1.2870129346847534, 1.1377856731414795, 1.1716885566711426, 1.0707918405532837, 1.3524218797683716, 1.3263157606124878, 1.2169417142868042, 1.495809555053711, 1.0054998397827148, 1.129106879234314, 1.1904109716415405, 1.0274662971496582, 1.257582664489746, 1.2085250616073608, 1.219565987586975, 1.0401560068130493, 1.0201088190078735, 1.1871531009674072, 1.5706874132156372, 1.1795822381973267, 1.0706322193145752, 1.1035606861114502, 1.213592290878296, 1.6555514335632324, 1.0748077630996704, 1.0245591402053833, 1.0946290493011475, 1.2774057388305664, 1.0708661079406738, 1.1354811191558838, 1.0286483764648438, 1.0909377336502075, 1.2165131568908691, 1.326763391494751, 1.1007074117660522, 1.1514545679092407, 1.0643755197525024, 1.1734890937805176, 1.1490685939788818, 1.045454502105713, 1.002320647239685, 1.07821524143219, 1.0040093660354614, 1.0056968927383423, 1.0836989879608154, 1.1939823627471924, 1.1450285911560059, 1.2662440538406372, 1.0386708974838257, 1.085011601448059, 1.1778407096862793, 1.0677258968353271, 1.154353380203247, 1.7014925479888916, 1.8201439380645752, 1.2360047101974487, 1.1443907022476196, 1.1008809804916382, 1.1182037591934204, 1.0048681497573853, 1.011043906211853, 1.1307069063186646, 1.0249027013778687, 1.0947089195251465, 1.0623846054077148, 1.153400182723999, 1.3858696222305298, 1.0321916341781616, 1.1188970804214478, 1.008751630783081, 1.204232931137085, 1.099215030670166, 1.0757306814193726, 1.0751898288726807, 1.0674161911010742, 1.3605149984359741, 1.1690044403076172, 1.2196969985961914, 1.0978556871414185, 1.1850656270980835, 1.0102005004882812, 1.0636507272720337, 1.0115437507629395, 1.0197864770889282, 1.135534405708313, 1.146360158920288, 1.0454747676849365, 1.176320195198059, 1.1152185201644897, 1.3178224563598633, 1.1158759593963623, 1.055305004119873, 1.7200000286102295, 1.0116279125213623, 1.0278637409210205, 1.0359525680541992, 1.0617609024047852, 1.1284661293029785, 1.0072418451309204, 1.0373839139938354, 1.5106383562088013, 1.1909961700439453, 1.151246428489685, 1.2750498056411743, 1.403968095779419, 1.2460620403289795, 1.2228057384490967, 1.068474531173706, 1.4587053060531616, 1.0069948434829712, 1.1077535152435303, 1.0716440677642822, 1.3795803785324097, 2.062152624130249, 1.037129521369934, 1.0340795516967773, 1.4085410833358765, 1.0779950618743896, 1.329470157623291, 1.1147117614746094]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7683582305908203] ms
 --  Average per query NF    [1.3630592823028564] ms
 --  Average per query vegas [2.405298948287964] ms
Mean [1.156]  Median [1.111]  95th [1.459]  99th [1.773]  max [2.062]
Mean [1.156]  Median [1.111]  95th [1.459]  99th [1.773]  max [2.062]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.240509 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=0 | total-time=26.173163