Input arguments = Namespace(data_update='sample', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 70, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.162447452545166
tensor(0.9980)
result is  tensor(381398.0312)
Enter testHyper
ReportEsts: [1.1838812828063965, 1.018155813217163, 1.3685977458953857, 1.3040640354156494, 1.2659320831298828, 1.1467833518981934, 1.254794716835022, 1.0264064073562622, 1.0620954036712646, 1.077821135520935, 1.0611541271209717, 1.121610164642334, 1.117703914642334, 1.00223708152771, 1.1439181566238403, 1.3555325269699097, 1.347102165222168, 1.1210213899612427, 1.1817187070846558, 1.0714285373687744, 1.2313307523727417, 1.0185396671295166, 1.183476209640503, 1.070788025856018, 1.0556236505508423, 1.2495479583740234, 1.0599662065505981, 1.2940704822540283, 1.0211670398712158, 1.1008036136627197, 1.1191911697387695, 1.2777248620986938, 1.0642751455307007, 1.0668939352035522, 1.102083683013916, 1.123422622680664, 1.3204829692840576, 1.3343242406845093, 1.0575069189071655, 1.0722155570983887, 1.03268301486969, 1.2048863172531128, 1.0352073907852173, 1.1166627407073975, 1.0826114416122437, 1.0255813598632812, 1.122498631477356, 1.2785204648971558, 1.0966906547546387, 1.1692047119140625, 1.2561308145523071, 1.4284745454788208, 1.0016758441925049, 1.285342812538147, 1.185025930404663, 1.0329160690307617, 1.2065420150756836, 1.03510582447052, 1.1699479818344116, 1.2663373947143555, 1.4137386083602905, 1.2275681495666504, 1.268438696861267, 1.0861302614212036, 1.3414634466171265, 1.2571429014205933, 1.1897532939910889, 1.116814374923706, 1.1868234872817993, 1.24210524559021, 1.1269265413284302, 1.0812097787857056, 1.062624216079712, 1.249900460243225, 1.1871109008789062, 1.1087431907653809, 1.8232251405715942, 1.0215585231781006, 1.0468515157699585, 1.2739202976226807, 1.178718090057373, 1.0487804412841797, 1.1351947784423828, 1.3230420351028442, 1.2031230926513672, 1.057902216911316, 1.0037829875946045, 1.156116008758545, 1.0826363563537598, 1.0875694751739502, 1.0284695625305176, 1.4353690147399902, 1.0270370244979858, 1.2832828760147095, 1.133720874786377, 1.1184719800949097, 1.079121470451355, 1.3371261358261108, 1.01694917678833, 1.1955809593200684, 1.153521180152893, 1.207861304283142, 1.043134093284607, 1.016837477684021, 1.0501046180725098, 1.0507402420043945, 1.1672072410583496, 1.2006981372833252, 1.05233895778656, 1.037753939628601, 1.2422689199447632, 1.0772058963775635, 1.1256293058395386, 1.1613012552261353, 1.0886751413345337, 1.0809524059295654, 1.0045732259750366, 1.0991873741149902, 1.271080493927002, 1.1425880193710327, 1.267818570137024, 1.1785566806793213, 1.0946855545043945, 1.1488624811172485, 1.2194766998291016, 1.1878869533538818, 1.0411561727523804, 1.1361676454544067, 1.2918059825897217, 1.1593186855316162, 1.082410216331482, 1.1437921524047852, 1.1239900588989258, 1.4285714626312256, 1.183273434638977, 1.0817949771881104, 1.0926399230957031, 1.0406503677368164, 1.0103901624679565, 1.2602107524871826, 1.1701925992965698, 1.1289803981781006, 1.1532431840896606, 1.2731152772903442, 1.0458983182907104, 1.0090749263763428, 1.1016967296600342, 1.4151177406311035, 1.1052803993225098, 1.056249976158142, 1.1755743026733398, 1.1557493209838867, 1.3806053400039673, 1.0819332599639893, 1.022401213645935, 1.0245294570922852, 1.0789321660995483, 1.001126766204834, 1.0381317138671875, 1.127245545387268, 1.052030086517334, 1.0336277484893799, 1.07470703125, 1.2696477174758911, 1.1442424058914185, 1.0732619762420654, 1.153079628944397, 1.2540711164474487, 1.0210996866226196, 1.0786274671554565, 1.0002753734588623, 1.0069313049316406, 1.1103895902633667, 1.1381597518920898, 1.1141008138656616, 1.0824593305587769, 1.0526853799819946, 1.2913228273391724, 1.0699645280838013, 1.1705924272537231, 1.0297282934188843, 1.0659602880477905, 1.027355670928955, 1.1664963960647583, 1.2086200714111328, 1.0909091234207153, 1.0013130903244019, 1.2040884494781494, 1.0542625188827515, 1.2678419351577759, 1.0383553504943848, 1.0215855836868286, 1.6238975524902344, 1.2122743129730225, 2.375992774963379, 1.168878197669983, 1.1323468685150146, 1.1875, 1.0966651439666748, 1.0362550020217896]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.6672842502593994] ms
 --  Average per query NF    [1.36482834815979] ms
 --  Average per query vegas [2.3024559020996094] ms
Mean [1.153]  Median [1.122]  95th [1.356]  99th [1.626]  max [2.376]
Mean [1.153]  Median [1.122]  95th [1.356]  99th [1.626]  max [2.376]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.777703 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=sample', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
Sample - START
Sample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[5.9008598e-06 2.8014183e-06 2.1457672e-06 8.3446503e-07 2.3841858e-07]
Distance score: 2.384185791015625e-06
SAUCE Drift detection: False
Detection latency: 0.0233s

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.019643 | Model-update-time: 0.000000


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=sample', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.252403497695923
tensor(0.9966)
result is  tensor(457019.5625)
Enter testHyper
ReportEsts: [1.122031807899475, 1.0095945596694946, 1.2017543315887451, 1.0134458541870117, 1.1060627698898315, 1.1883341073989868, 1.1373231410980225, 1.001952052116394, 1.1671642065048218, 1.1303317546844482, 1.0139062404632568, 1.160443902015686, 1.1833332777023315, 1.2105640172958374, 1.0631966590881348, 1.0879877805709839, 1.03125, 1.1739985942840576, 1.1308687925338745, 1.1961474418640137, 1.1192855834960938, 1.3404483795166016, 1.023956298828125, 1.2764393091201782, 1.0259554386138916, 1.1044292449951172, 1.1253198385238647, 1.0810426473617554, 1.2925204038619995, 1.5809954404830933, 1.122178554534912, 1.4436619281768799, 1.1661548614501953, 1.1732696294784546, 1.0477828979492188, 1.0439647436141968, 1.1252655982971191, 1.1235829591751099, 1.586486577987671, 1.0145130157470703, 1.004632592201233, 1.0400421619415283, 1.3682360649108887, 1.0254772901535034, 1.0588147640228271, 1.159529209136963, 1.006561279296875, 1.0544673204421997, 1.2173912525177002, 1.201690673828125, 1.0198462009429932, 1.0134598016738892, 1.0511503219604492, 1.1203123331069946, 1.133497714996338, 1.3258272409439087, 1.1776825189590454, 1.151920199394226, 1.2675069570541382, 1.1679884195327759, 1.5804020166397095, 1.0348715782165527, 1.1755121946334839, 1.6654765605926514, 1.0692988634109497, 1.104655385017395, 1.308434009552002, 1.0548195838928223, 1.1680530309677124, 1.03285813331604, 1.1215136051177979, 1.2505102157592773, 1.020402193069458, 1.1654256582260132, 1.0152902603149414, 1.1148508787155151, 1.070343017578125, 1.1073857545852661, 1.2441688776016235, 1.0851502418518066, 1.136717438697815, 1.0912410020828247, 1.1261582374572754, 1.096794605255127, 1.3245407342910767, 1.2541805505752563, 1.3040375709533691, 1.599071741104126, 1.0859113931655884, 1.0990756750106812, 1.1347352266311646, 1.1255213022232056, 1.4056284427642822, 1.1256276369094849, 1.1179977655410767, 1.0291621685028076, 1.2658051252365112, 1.264402151107788, 1.1854695081710815, 1.1111111640930176, 1.1757245063781738, 1.1581052541732788, 1.216417908668518, 1.1050364971160889, 1.0985052585601807, 1.0896291732788086, 1.0704374313354492, 1.0535863637924194, 1.1922005414962769, 1.2287062406539917, 1.1213033199310303, 1.016698956489563, 1.0969932079315186, 1.2186816930770874, 1.0236088037490845, 1.1786381006240845, 1.0148699283599854, 1.0840092897415161, 1.0018067359924316, 1.0887097120285034, 1.1111183166503906, 1.0561511516571045, 1.0399152040481567, 1.3253138065338135, 1.04671049118042, 1.0903750658035278, 1.143211007118225, 1.2720125913619995, 1.1710566282272339, 1.014760136604309, 1.0735117197036743, 1.1356391906738281, 1.0858845710754395, 1.9295426607131958, 1.7036328315734863, 1.2413746118545532, 1.0317102670669556, 1.0002466440200806, 1.1087859869003296, 1.038377046585083, 1.0464519262313843, 1.131555438041687, 1.0244766473770142, 1.0041944980621338, 1.0315214395523071, 1.1207717657089233, 1.4444444179534912, 1.0852346420288086, 1.152532935142517, 1.0098624229431152, 1.0657060146331787, 1.099829077720642, 1.182086706161499, 1.0522398948669434, 1.014451265335083, 1.2441412210464478, 1.1465989351272583, 1.2834645509719849, 1.0639445781707764, 1.2253432273864746, 1.0051623582839966, 1.0333001613616943, 1.0993776321411133, 1.0079103708267212, 1.1023447513580322, 1.5882352590560913, 1.0846681594848633, 1.3459529876708984, 1.0418336391448975, 1.1074384450912476, 1.1302459239959717, 1.018554925918579, 1.756077766418457, 1.0841341018676758, 1.0509885549545288, 1.0031949281692505, 1.0417466163635254, 1.0501471757888794, 1.0854934453964233, 1.157591462135315, 1.4583333730697632, 1.0617986917495728, 1.1049578189849854, 1.4657326936721802, 1.1017701625823975, 1.0346347093582153, 1.3169742822647095, 1.1349514722824097, 1.1977589130401611, 1.034597635269165, 1.2475123405456543, 1.0190271139144897, 1.0154625177383423, 2.0497238636016846, 1.0360255241394043, 1.1560091972351074, 1.3402962684631348, 1.1196929216384888, 1.3218390941619873, 1.1543197631835938]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.719831705093384] ms
 --  Average per query NF    [1.3585782051086426] ms
 --  Average per query vegas [2.361253499984741] ms
Mean [1.157]  Median [1.119]  95th [1.471]  99th [1.758]  max [2.050]
Mean [1.157]  Median [1.119]  95th [1.471]  99th [1.758]  max [2.050]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.275034 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=0 | total-time=26.123767