Input arguments = Namespace(data_update='valueskew', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 16, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.213246822357178
tensor(0.9966)
result is  tensor(380855.5625)
Enter testHyper
ReportEsts: [1.1491104364395142, 1.063508152961731, 1.4109628200531006, 1.0082802772521973, 1.303987741470337, 1.0653765201568604, 1.1105414628982544, 1.0391970872879028, 1.1201117038726807, 1.1870428323745728, 1.0956072807312012, 1.0531779527664185, 1.0974873304367065, 1.0714285373687744, 1.1547366380691528, 1.1942033767700195, 1.275167465209961, 1.2634204626083374, 1.1395208835601807, 1.1198979616165161, 1.2060385942459106, 1.0646207332611084, 1.1091433763504028, 1.0629615783691406, 1.1658906936645508, 1.123869776725769, 1.0695382356643677, 1.4789377450942993, 1.0497554540634155, 1.067032814025879, 1.0833629369735718, 1.360816240310669, 1.1504756212234497, 1.0706850290298462, 1.1697825193405151, 1.236079216003418, 1.4514988660812378, 1.0177037715911865, 1.1224504709243774, 1.0284518003463745, 1.0564806461334229, 1.1692066192626953, 1.06596839427948, 1.0508639812469482, 1.0380308628082275, 1.0986394882202148, 1.1427658796310425, 1.216800332069397, 1.0415349006652832, 1.0490694046020508, 1.1582914590835571, 1.2930346727371216, 1.0588243007659912, 1.0992218255996704, 1.0780513286590576, 1.0922577381134033, 1.2485980987548828, 1.0172749757766724, 1.2115495204925537, 1.4833110570907593, 1.4884910583496094, 1.1838372945785522, 1.2041418552398682, 1.1455166339874268, 1.1870503425598145, 1.2285714149475098, 1.0609136819839478, 1.0413068532943726, 1.0104905366897583, 1.263157844543457, 1.0201126337051392, 1.1358904838562012, 1.3568121194839478, 1.342049479484558, 1.1824140548706055, 1.2379499673843384, 1.822691559791565, 1.060150384902954, 1.0580239295959473, 1.3492083549499512, 1.145465612411499, 1.1683088541030884, 1.020783543586731, 1.2800755500793457, 1.2674036026000977, 1.1686056852340698, 1.0021848678588867, 1.1359899044036865, 1.087397813796997, 1.0624430179595947, 1.0135363340377808, 1.2030727863311768, 1.0194735527038574, 1.3323650360107422, 1.1818181276321411, 1.0793980360031128, 1.048933982849121, 1.1116695404052734, 1.0714285373687744, 1.2494148015975952, 1.2580645084381104, 1.0182161331176758, 1.0248626470565796, 1.012445092201233, 1.0525157451629639, 1.0512170791625977, 1.2049912214279175, 1.1954624652862549, 1.059935212135315, 1.076598882675171, 1.2347142696380615, 1.0882079601287842, 1.1796791553497314, 1.027259111404419, 1.1950851678848267, 1.101941704750061, 1.0596548318862915, 1.0364973545074463, 1.346627950668335, 1.0318480730056763, 1.1843360662460327, 1.16765558719635, 1.0079306364059448, 1.087070107460022, 1.2926356792449951, 1.2022286653518677, 1.107901692390442, 1.2844778299331665, 1.3330457210540771, 1.112892508506775, 1.2399039268493652, 1.1050770282745361, 1.2399005889892578, 1.3571428060531616, 1.1327883005142212, 1.0307167768478394, 1.0930618047714233, 1.102439045906067, 1.0206750631332397, 1.1562989950180054, 1.1218079328536987, 1.0752500295639038, 1.2310576438903809, 1.194288730621338, 1.1033928394317627, 1.0722240209579468, 1.1353180408477783, 1.4243438243865967, 1.1719716787338257, 1.0653408765792847, 1.2727786302566528, 1.1438276767730713, 1.345166563987732, 1.3591052293777466, 1.0759365558624268, 1.0601017475128174, 1.1717627048492432, 1.0016882419586182, 1.0867359638214111, 1.1867501735687256, 1.1373013257980347, 1.1149498224258423, 1.0154170989990234, 1.3031989336013794, 1.273954153060913, 1.1077193021774292, 1.1232339143753052, 1.2431869506835938, 1.106185793876648, 1.0407893657684326, 1.1018046140670776, 1.0798887014389038, 1.1298701763153076, 1.24193274974823, 1.0919618606567383, 1.1984456777572632, 1.0179786682128906, 1.3047103881835938, 1.2935541868209839, 1.0093410015106201, 1.0421820878982544, 1.1752029657363892, 1.0149574279785156, 1.1716036796569824, 1.1148134469985962, 1.1490485668182373, 1.044294834136963, 1.2419633865356445, 1.0612717866897583, 1.4163132905960083, 1.0794109106063843, 1.1317440271377563, 1.6197502613067627, 1.6026089191436768, 1.7546480894088745, 1.2242577075958252, 1.1435598134994507, 1.0704225301742554, 1.3716639280319214, 1.0625829696655273]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.738957643508911] ms
 --  Average per query NF    [1.3601791858673096] ms
 --  Average per query vegas [2.3787784576416016] ms
Mean [1.160]  Median [1.124]  95th [1.411]  99th [1.621]  max [1.823]
Mean [1.160]  Median [1.124]  95th [1.411]  99th [1.621]  max [1.823]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.877980 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=valueskew', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
ValueSample - START
ValueSample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[6.5565109e-07 8.9210272e-03 3.5762787e-07 1.1920929e-07 1.1920929e-07]
Distance score: 0.0017844557296484709
SAUCE Drift detection: True
Detection latency: 0.0235s

DRIFT-DETECTED after 2-th workload
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/incremental_train.py', '--dataset=bjaq', '--end2end', '--model=face', '--model_update=adapt', '--update_size=80000', '--epochs=0']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
update_size: 76433
AdaptTask - START
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
train data shape: 80000, transfer data shape:16000
Training done; evaluating likelihood on full data:
Saved to: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
AdaptTask - END

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.054657 | Model-update-time: 2.271969


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=valueskew', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.165883302688599
tensor(0.9932)
result is  tensor(455492.9688)
Enter testHyper
ReportEsts: [1.0114496946334839, 1.1411622762680054, 1.197479009628296, 1.0316325426101685, 1.0581601858139038, 1.2181520462036133, 1.2041751146316528, 1.0069475173950195, 1.1260950565338135, 1.5316416025161743, 1.2960948944091797, 1.2071460485458374, 1.1004366874694824, 1.0873414278030396, 70.35050201416016, 1.2420819997787476, 1.3754838705062866, 1.325915813446045, 1.0633333921432495, 1.5308339595794678, 1.0819681882858276, 4.289473533630371, 1.1264755725860596, 1.0669291019439697, 1.0643548965454102, 1.177572250366211, 1.029637336730957, 1.3659359216690063, 1.372660517692566, 1.4143426418304443, 1.3461538553237915, 1.3582090139389038, 1.0939137935638428, 1.2740854024887085, 1.0695216655731201, 1.0011005401611328, 1.4923030138015747, 1.9254696369171143, 1.2879829406738281, 1.0256142616271973, 1.2065675258636475, 1.1839081048965454, 1.1185320615768433, 2.54937481880188, 1.155988097190857, 1.0814094543457031, 1.207960844039917, 1.0702524185180664, 1.3571428060531616, 1.2133053541183472, 1.1544486284255981, 1.0808303356170654, 1.022546648979187, 1.0759681463241577, 1.0745811462402344, 1.5059250593185425, 1.1456758975982666, 1.0973467826843262, 1.055625081062317, 1.1089550256729126, 1.4125560522079468, 1.0460480451583862, 1.1175936460494995, 1.591918706893921, 1.0323652029037476, 1.4448484182357788, 1.3916956186294556, 1.0045489072799683, 1.1450213193893433, 1.1249154806137085, 1.099176049232483, 1.0875221490859985, 1.0101020336151123, 1.3498269319534302, 3.047268867492676, 1.0008591413497925, 37.6523323059082, 1.0593247413635254, 1.3323191404342651, 1.0693498849868774, 1.2401902675628662, 1.1442337036132812, 1.1082210540771484, 1.0529963970184326, 1.2970595359802246, 1.621276617050171, 1.02931809425354, 1.2589105367660522, 1.0807641744613647, 1.1221965551376343, 1.0832642316818237, 1.8390144109725952, 1.1162229776382446, 1.1597776412963867, 78.35713958740234, 1.2262492179870605, 1.0004189014434814, 1.2699499130249023, 2.0601794719696045, 1.0949724912643433, 1.1466528177261353, 2.872870445251465, 1.191176414489746, 1.0504975318908691, 1.1043360233306885, 1.0720720291137695, 1.0412086248397827, 1.1125729084014893, 1.0085959434509277, 1.325174331665039, 2.5603864192962646, 1.1775776147842407, 1.2249447107315063, 1.2551971673965454, 1.3983943462371826, 1.0418673753738403, 1.295276403427124, 1.219393253326416, 1.1040226221084595, 1.1696428060531616, 1.1280361413955688, 1.0996932983398438, 1.058150291442871, 1.4105262756347656, 1.1907771825790405, 1.0697795152664185, 1.4638397693634033, 1.2351096868515015, 1.4129599332809448, 1.1600059270858765, 1.279303789138794, 1.101975440979004, 1.02678644657135, 1.461254596710205, 1.202757477760315, 1.16087806224823, 1.0464856624603271, 1.0205578804016113, 1.4398947954177856, 1.1815367937088013, 1.2465543746948242, 1.2608908414840698, 1.2331207990646362, 1.053117036819458, 1.0116194486618042, 1.0494946241378784, 1.2267441749572754, 1.019689679145813, 1.1783857345581055, 1.0657929182052612, 1.0272248983383179, 1.043670892715454, 1.0935382843017578, 1.264724850654602, 1.3126178979873657, 2.123943567276001, 1.283197045326233, 1.0959999561309814, 1.037292242050171, 1.1003577709197998, 1.0484192371368408, 1.2565475702285767, 1.2228399515151978, 1.1437309980392456, 1.2946430444717407, 1.1066986322402954, 1.3092021942138672, 1.2949740886688232, 152.0, 1.29628324508667, 1.0047004222869873, 1.091109037399292, 1.1462174654006958, 1.1210992336273193, 3.5239017009735107, 1.2560948133468628, 1.7849091291427612, 1.061311960220337, 1.0179659128189087, 1.3377935886383057, 1.4375, 1.325060486793518, 1.0882129669189453, 1.3549747467041016, 1.2113038301467896, 1.0147956609725952, 1.3302286863327026, 1.046937346458435, 1.4746214151382446, 1.027010440826416, 1.1631253957748413, 1.4031705856323242, 1.1713299751281738, 1.339779019355774, 1.0587348937988281, 1.2466517686843872, 1.2399122714996338, 1.025390625, 1.105175256729126, 1.0730023384094238]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.727569580078125] ms
 --  Average per query NF    [1.360306739807129] ms
 --  Average per query vegas [2.367262840270996] ms
Mean [2.927]  Median [1.160]  95th [2.145]  99th [70.431]  max [152.000]
Mean [2.927]  Median [1.160]  95th [2.145]  99th [70.431]  max [152.000]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.385057 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=1 | total-time=28.614939