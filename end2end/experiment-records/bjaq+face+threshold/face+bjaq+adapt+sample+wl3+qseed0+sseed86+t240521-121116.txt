Input arguments = Namespace(data_update='sample', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 86, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.16351580619812
tensor(0.9974)
result is  tensor(381174.3125)
Enter testHyper
ReportEsts: [1.121863842010498, 1.0104488134384155, 1.4126290082931519, 1.0160033702850342, 1.2685765027999878, 1.0958514213562012, 1.2485992908477783, 1.1031644344329834, 1.0870481729507446, 1.0804835557937622, 1.0680447816848755, 1.1010593175888062, 1.0546129941940308, 1.0558035373687744, 1.0377421379089355, 1.304788589477539, 1.4549086093902588, 1.1811163425445557, 1.1316773891448975, 1.0663264989852905, 1.0075273513793945, 1.0168888568878174, 1.1469335556030273, 1.1291640996932983, 1.1163930892944336, 1.1030741930007935, 1.1033220291137695, 1.4229074716567993, 1.010594129562378, 1.0386687517166138, 1.1021639108657837, 1.0832024812698364, 1.0519509315490723, 1.0157253742218018, 1.2207214832305908, 1.1263240575790405, 1.2691411972045898, 1.0253006219863892, 1.1171090602874756, 1.0260505676269531, 1.0340831279754639, 1.2207305431365967, 1.193008303642273, 1.1076315641403198, 1.112402319908142, 1.0340136289596558, 1.0551785230636597, 1.2013076543807983, 1.0144314765930176, 1.0896785259246826, 1.1410890817642212, 1.3450367450714111, 1.05045747756958, 1.0871357917785645, 1.1034990549087524, 1.0159944295883179, 1.2813084125518799, 1.088642954826355, 1.1226894855499268, 1.4237505197525024, 1.2107402086257935, 1.170580506324768, 1.0864081382751465, 1.059897780418396, 1.2547528743743896, 1.0285714864730835, 1.1338155269622803, 1.0269495248794556, 1.0661464929580688, 1.2526315450668335, 1.013676643371582, 1.0271852016448975, 1.1640368700027466, 1.1030001640319824, 1.1028310060501099, 1.130204677581787, 1.834953784942627, 1.0226428508758545, 1.0584131479263306, 1.3732154369354248, 1.3968517780303955, 1.068971037864685, 1.1194677352905273, 1.248083233833313, 1.29535973072052, 1.1274232864379883, 1.0674446821212769, 1.084590196609497, 1.0415468215942383, 1.0190130472183228, 1.060683250427246, 1.2372492551803589, 1.00072181224823, 1.2551881074905396, 1.101694941520691, 1.1000807285308838, 1.1815745830535889, 1.2316384315490723, 1.0, 1.2085946798324585, 1.1219178438186646, 1.1777375936508179, 1.1441158056259155, 1.003673791885376, 1.0591003894805908, 1.0125062465667725, 1.190867304801941, 1.1832460165023804, 1.0291831493377686, 1.0016143321990967, 1.066078543663025, 1.123681664466858, 1.2167751789093018, 1.0427409410476685, 1.054132342338562, 1.15816330909729, 1.0081430673599243, 1.1825100183486938, 1.2324810028076172, 1.1189682483673096, 1.2393474578857422, 1.1495791673660278, 1.18563711643219, 1.2281581163406372, 1.3832364082336426, 1.1786009073257446, 1.1449307203292847, 1.222248911857605, 1.3636363744735718, 1.1399465799331665, 1.0340542793273926, 1.1251205205917358, 1.1886265277862549, 1.5357142686843872, 1.016158938407898, 1.0889997482299805, 1.036687970161438, 1.128780484199524, 1.073439121246338, 1.3842257261276245, 1.1486386060714722, 1.1125966310501099, 1.178932785987854, 1.3716474771499634, 1.05805242061615, 1.0755480527877808, 1.0064536333084106, 1.589724063873291, 1.0018843412399292, 1.109801173210144, 1.2714228630065918, 1.1786950826644897, 1.2895288467407227, 1.5003299713134766, 1.2324784994125366, 1.0334993600845337, 1.0918340682983398, 1.0315138101577759, 1.0376640558242798, 1.1361981630325317, 1.099314570426941, 1.0254418849945068, 1.0685402154922485, 1.3160111904144287, 1.2339869737625122, 1.0346847772598267, 1.1078569889068604, 1.3076502084732056, 1.0762344598770142, 1.0216002464294434, 1.0508265495300293, 1.1563810110092163, 1.1818181276321411, 1.1075071096420288, 1.182220697402954, 1.0102472305297852, 1.0305458307266235, 1.2259635925292969, 1.1213136911392212, 1.0285398960113525, 1.0993212461471558, 1.0402967929840088, 1.0149213075637817, 1.0480082035064697, 1.161535620689392, 1.1035940647125244, 1.0121989250183105, 1.3008689880371094, 1.0535492897033691, 1.3962160348892212, 1.0015422105789185, 1.0767741203308105, 1.5360603332519531, 1.4545191526412964, 2.0410659313201904, 1.295454502105713, 1.1458524465560913, 1.1176470518112183, 1.028468370437622, 1.1282868385314941]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7626469135284424] ms
 --  Average per query NF    [1.361384391784668] ms
 --  Average per query vegas [2.4012625217437744] ms
Mean [1.148]  Median [1.109]  95th [1.413]  99th [1.592]  max [2.041]
Mean [1.148]  Median [1.109]  95th [1.413]  99th [1.592]  max [2.041]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.836926 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=sample', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
Sample - START
Sample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[0.0000000e+00 1.1920929e-07 0.0000000e+00 0.0000000e+00 0.0000000e+00]
Distance score: 2.3841858265427618e-08
SAUCE Drift detection: False
Detection latency: 0.0236s

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.023272 | Model-update-time: 0.000000


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=sample', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.206338167190552
tensor(0.9949)
result is  tensor(456245.5000)
Enter testHyper
ReportEsts: [1.0598064661026, 1.021392583847046, 1.2071428298950195, 1.0350065231323242, 1.0910674333572388, 1.1965973377227783, 1.0729390382766724, 1.0679779052734375, 1.0512858629226685, 1.1240572929382324, 1.0166254043579102, 1.0248639583587646, 1.2599010467529297, 1.074131965637207, 1.0049893856048584, 1.0984700918197632, 1.4108936786651611, 1.1645082235336304, 1.0896683931350708, 1.1627604961395264, 1.0649198293685913, 1.5612986087799072, 1.0974082946777344, 1.0713587999343872, 1.052027940750122, 1.2313969135284424, 1.1368213891983032, 1.2055684328079224, 1.0053937435150146, 1.3283803462982178, 1.0253952741622925, 1.2978723049163818, 1.0912888050079346, 1.094338059425354, 1.0821151733398438, 1.1848465204238892, 1.1227829456329346, 1.0167067050933838, 1.0745776891708374, 1.1401920318603516, 1.0584455728530884, 1.012917160987854, 1.3620585203170776, 1.0030708312988281, 1.0192807912826538, 1.0844178199768066, 1.3828229904174805, 1.0816094875335693, 1.0440000295639038, 1.1827242374420166, 1.0293478965759277, 1.0864440202713013, 1.0565690994262695, 1.0670745372772217, 1.0570688247680664, 1.0952467918395996, 1.2927403450012207, 1.1180987358093262, 1.2577729225158691, 1.114233136177063, 1.6481481790542603, 1.048143982887268, 1.003330111503601, 1.433174729347229, 1.0330606698989868, 1.0417126417160034, 1.299054741859436, 1.0905667543411255, 1.172087550163269, 1.0876950025558472, 1.0864695310592651, 1.1990084648132324, 1.0220431089401245, 1.1199167966842651, 1.0375128984451294, 1.128001093864441, 1.0720072984695435, 1.1314926147460938, 1.2951260805130005, 1.125, 1.248157262802124, 1.0145738124847412, 1.0938838720321655, 1.1029736995697021, 1.3194671869277954, 1.3225806951522827, 1.372847557067871, 1.3621999025344849, 1.0781770944595337, 1.1400893926620483, 1.1430834531784058, 1.2907954454421997, 1.3331886529922485, 1.2203088998794556, 1.1938610076904297, 1.049526572227478, 1.1171115636825562, 1.2223464250564575, 1.3313411474227905, 1.131455421447754, 1.1188883781433105, 1.098252296447754, 1.201923131942749, 1.2688158750534058, 1.1297597885131836, 1.0137165784835815, 1.0145063400268555, 1.1313189268112183, 1.115384578704834, 1.0074065923690796, 1.1118792295455933, 1.0310266017913818, 1.0420172214508057, 1.267655849456787, 1.0157179832458496, 1.0482486486434937, 1.189346432685852, 1.185667634010315, 1.0091423988342285, 1.125, 1.0099366903305054, 1.0856993198394775, 1.0125043392181396, 1.4495091438293457, 1.045454502105713, 1.0554568767547607, 1.2119383811950684, 1.2817589044570923, 1.0967127084732056, 1.0128785371780396, 1.204862356185913, 1.1495459079742432, 1.0511717796325684, 1.6298227310180664, 1.8200409412384033, 1.1784067153930664, 1.0997300148010254, 1.2031463384628296, 1.1220909357070923, 1.0246089696884155, 1.0150506496429443, 1.1050440073013306, 1.0564022064208984, 1.0284823179244995, 1.039253830909729, 1.005873680114746, 1.5182926654815674, 1.0220056772232056, 1.0859349966049194, 1.0898855924606323, 1.1299817562103271, 1.0362411737442017, 1.1857253313064575, 1.0690853595733643, 1.0597140789031982, 1.1474655866622925, 1.0105162858963013, 1.265625, 1.2268321514129639, 1.1048858165740967, 1.0351881980895996, 1.1496063470840454, 1.1272504329681396, 1.1080217361450195, 1.0782450437545776, 1.0791962146759033, 1.1808218955993652, 1.1818302869796753, 1.1312017440795898, 1.1173607110977173, 1.0156713724136353, 1.0086946487426758, 1.3874679803848267, 1.009121060371399, 1.0844051837921143, 1.0825250148773193, 1.0116279125213623, 1.1613705158233643, 1.03127920627594, 1.0028058290481567, 1.5681818723678589, 1.138567328453064, 1.0243102312088013, 1.6829107999801636, 1.371132254600525, 1.2949402332305908, 1.360304832458496, 1.01791512966156, 1.3037663698196411, 1.1051708459854126, 1.2289332151412964, 1.040958285331726, 1.203908920288086, 1.947567343711853, 1.0334999561309814, 1.0697674751281738, 1.1567533016204834, 1.0271803140640259, 1.3091787099838257, 1.178138017654419]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.662102222442627] ms
 --  Average per query NF    [1.3569283485412598] ms
 --  Average per query vegas [2.305173873901367] ms
Mean [1.149]  Median [1.104]  95th [1.412]  99th [1.684]  max [1.948]
Mean [1.149]  Median [1.104]  95th [1.412]  99th [1.684]  max [1.948]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.233182 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=0 | total-time=26.140377