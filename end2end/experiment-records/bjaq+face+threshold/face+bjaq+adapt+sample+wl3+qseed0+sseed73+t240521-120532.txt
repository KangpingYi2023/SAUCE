Input arguments = Namespace(data_update='sample', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 73, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.158362627029419
tensor(0.9953)
result is  tensor(380356.0938)
Enter testHyper
ReportEsts: [1.1699252128601074, 1.016426682472229, 1.3825736045837402, 1.0335147380828857, 1.27351713180542, 1.1136422157287598, 1.21985924243927, 1.1288094520568848, 1.085740089416504, 1.0935300588607788, 1.02842378616333, 1.1211864948272705, 1.0727945566177368, 1.0200892686843872, 1.1209588050842285, 1.3460291624069214, 1.406868577003479, 1.1858669519424438, 1.2249757051467896, 1.086734652519226, 1.042336344718933, 1.0587936639785767, 1.09694504737854, 1.0341417789459229, 1.1014456748962402, 1.1220614910125732, 1.014567255973816, 1.531531572341919, 1.0372928380966187, 1.2244939804077148, 1.171692132949829, 1.2529886960983276, 1.0662990808486938, 1.0066289901733398, 1.0889474153518677, 1.0515199899673462, 1.5013262033462524, 1.025696873664856, 1.1011433601379395, 1.0205328464508057, 1.05032217502594, 1.0616836547851562, 1.0597864389419556, 1.0095003843307495, 1.0684555768966675, 1.0102040767669678, 1.0925756692886353, 1.199656367301941, 1.0784121751785278, 1.1133671998977661, 1.2005208730697632, 1.2750377655029297, 1.0909030437469482, 1.1988481283187866, 1.0875353813171387, 1.05322265625, 1.2813084125518799, 1.1574119329452515, 1.0310676097869873, 1.3933945894241333, 1.060288906097412, 1.1799452304840088, 1.3445196151733398, 1.1142184734344482, 1.4224138259887695, 1.0571428537368774, 1.0032000541687012, 1.0229915380477905, 1.1065804958343506, 1.3894736766815186, 1.149861216545105, 1.023102045059204, 1.1652065515518188, 1.1369277238845825, 1.021275520324707, 1.08895742893219, 1.805692434310913, 1.1594464778900146, 1.1009111404418945, 1.3195723295211792, 1.0685161352157593, 1.2099822759628296, 1.0579769611358643, 1.22983717918396, 1.2129722833633423, 1.069647192955017, 1.0347872972488403, 1.2424715757369995, 1.0266058444976807, 1.031262993812561, 1.0038819313049316, 1.1559584140777588, 1.0153789520263672, 1.2514779567718506, 1.0714285373687744, 1.1569994688034058, 1.1158889532089233, 1.2597990036010742, 1.01694917678833, 1.170770525932312, 1.1904069185256958, 1.0873849391937256, 1.130696415901184, 1.002936840057373, 1.0662133693695068, 1.0203462839126587, 1.2156776189804077, 1.191972017288208, 1.0644055604934692, 1.0237163305282593, 1.1126829385757446, 1.0811808109283447, 1.1967525482177734, 1.1591957807540894, 1.0678104162216187, 1.15816330909729, 1.065009593963623, 1.0426931381225586, 1.1480363607406616, 1.0023185014724731, 1.3078793287277222, 1.1141161918640137, 1.1211575269699097, 1.207319974899292, 1.222383737564087, 1.1869583129882812, 1.1165069341659546, 1.2032504081726074, 1.2832225561141968, 1.1158984899520874, 1.1610691547393799, 1.255002737045288, 1.140770673751831, 1.4285714626312256, 1.2048159837722778, 1.063271164894104, 1.0444166660308838, 1.1882927417755127, 1.0457007884979248, 1.4128508567810059, 1.0958733558654785, 1.1101433038711548, 1.1036958694458008, 1.0708943605422974, 1.0933946371078491, 1.0346007347106934, 1.041775107383728, 1.6484482288360596, 1.0327452421188354, 1.0602983236312866, 1.2058229446411133, 1.1394692659378052, 1.3017970323562622, 1.0259779691696167, 1.033577561378479, 1.1031807661056519, 1.0332177877426147, 1.023353934288025, 1.0015579462051392, 1.1555356979370117, 1.059452772140503, 1.001940131187439, 1.0116289854049683, 1.3086591958999634, 1.0216450691223145, 1.14883553981781, 1.2994972467422485, 1.2158560752868652, 1.139158844947815, 1.0110121965408325, 1.0072999000549316, 1.0145949125289917, 1.1103895902633667, 1.1313047409057617, 1.187670350074768, 1.0328049659729004, 1.0117994546890259, 1.1422652006149292, 1.0532423257827759, 1.0486195087432861, 1.1856354475021362, 1.05038321018219, 1.1017860174179077, 1.0194075107574463, 1.16841721534729, 1.124735713005066, 1.0027787685394287, 1.184245228767395, 1.093682885169983, 1.3557276725769043, 1.0298895835876465, 1.0470867156982422, 1.643062710762024, 1.2719696760177612, 1.4781149625778198, 1.3015446662902832, 1.1634430885314941, 1.1515151262283325, 1.0161404609680176, 1.135225772857666]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.768324851989746] ms
 --  Average per query NF    [1.3594365119934082] ms
 --  Average per query vegas [2.408888339996338] ms
Mean [1.140]  Median [1.108]  95th [1.394]  99th [1.643]  max [1.806]
Mean [1.140]  Median [1.108]  95th [1.394]  99th [1.643]  max [1.806]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.832302 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=sample', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
Sample - START
Sample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[5.9604645e-08 2.9802322e-07 5.9604645e-08 1.1920929e-07 4.1723251e-07]
Distance score: 1.9073486612342094e-07
SAUCE Drift detection: False
Detection latency: 0.0244s

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.026687 | Model-update-time: 0.000000


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=sample', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.164345502853394
tensor(0.9924)
result is  tensor(455108.3125)
Enter testHyper
ReportEsts: [1.17091703414917, 1.0567256212234497, 1.1786216497421265, 1.1058200597763062, 1.00495445728302, 1.1817189455032349, 1.0605926513671875, 1.0104904174804688, 1.04615318775177, 1.0161700248718262, 1.0421142578125, 1.1651642322540283, 1.1531322002410889, 1.0006998777389526, 1.1517665386199951, 1.072786569595337, 1.6794872283935547, 1.063255786895752, 1.1592615842819214, 1.3243517875671387, 1.0693823099136353, 1.2441357374191284, 1.0231083631515503, 1.0353591442108154, 1.0868312120437622, 1.0906968116760254, 1.0144764184951782, 1.1685289144515991, 1.1762133836746216, 1.4513776302337646, 1.2372138500213623, 1.2340425252914429, 1.034652829170227, 1.1146528720855713, 1.2629849910736084, 1.0268828868865967, 1.1162652969360352, 1.0763527154922485, 1.194043755531311, 1.0272624492645264, 1.1025474071502686, 1.032362461090088, 1.1761616468429565, 1.0696309804916382, 1.095674753189087, 1.0097407102584839, 1.2739533185958862, 1.0196917057037354, 1.1740890741348267, 1.05240797996521, 1.057997703552246, 1.0129846334457397, 1.065070629119873, 1.0896152257919312, 1.0811436176300049, 1.1890411376953125, 1.1078875064849854, 1.127739667892456, 1.222118616104126, 1.0916612148284912, 1.2902584075927734, 1.1058787107467651, 1.084028959274292, 1.5766648054122925, 1.0168882608413696, 1.0535351037979126, 1.359707236289978, 1.081423044204712, 1.1810771226882935, 1.0777124166488647, 1.3213272094726562, 1.091776967048645, 1.1179486513137817, 1.0054861307144165, 1.0039007663726807, 1.1351289749145508, 1.4235453605651855, 1.183254361152649, 1.4814950227737427, 1.0420252084732056, 1.3092589378356934, 1.2164239883422852, 1.3343799114227295, 1.19723379611969, 1.2564159631729126, 1.3003534078598022, 1.2759445905685425, 1.658906102180481, 1.1294326782226562, 1.1709928512573242, 1.187653660774231, 1.1553680896759033, 1.3735921382904053, 1.0784618854522705, 1.2176541090011597, 1.0970304012298584, 1.0654499530792236, 1.1744482517242432, 1.5886784791946411, 1.103774070739746, 1.057977557182312, 1.1463607549667358, 1.1496436595916748, 1.1350688934326172, 1.1160469055175781, 1.2084941864013672, 1.1656757593154907, 1.1106842756271362, 1.2419824600219727, 1.0370373725891113, 1.036253809928894, 1.1232237815856934, 1.1189614534378052, 1.2633384466171265, 1.171654224395752, 1.0478360652923584, 1.0605765581130981, 1.517241358757019, 1.1120448112487793, 1.1416666507720947, 1.0213713645935059, 1.0723382234573364, 1.2038873434066772, 1.6903352737426758, 1.0326226949691772, 1.0399171113967896, 1.248569130897522, 1.2372881174087524, 1.0705963373184204, 1.0545474290847778, 1.2373524904251099, 1.082671046257019, 1.0975569486618042, 1.4100974798202515, 1.6779025793075562, 1.0999518632888794, 1.0187031030654907, 1.0967947244644165, 1.0790125131607056, 1.0411901473999023, 1.0633288621902466, 1.114545464515686, 1.0845069885253906, 1.0281835794448853, 1.011575698852539, 1.0416899919509888, 1.4114285707473755, 1.0446040630340576, 1.2162907123565674, 1.0455764532089233, 1.1063083410263062, 1.0352866649627686, 1.1267210245132446, 1.0372902154922485, 1.0600926876068115, 1.0317797660827637, 1.0881823301315308, 1.28125, 1.0200018882751465, 1.1178264617919922, 1.0336154699325562, 1.0530973672866821, 1.17735755443573, 1.0176421403884888, 1.1670078039169312, 1.186401128768921, 1.0938297510147095, 1.2239534854888916, 1.054716944694519, 1.2732152938842773, 1.0186063051223755, 1.1303050518035889, 1.7844756841659546, 1.0207260847091675, 1.0416895151138306, 1.0024259090423584, 1.421042799949646, 1.0779584646224976, 1.0774208307266235, 1.1240681409835815, 1.7380952835083008, 1.1800167560577393, 1.050979495048523, 1.395580530166626, 1.4657279253005981, 1.3543689250946045, 1.3933372497558594, 1.0023939609527588, 1.4233793020248413, 1.0549489259719849, 1.1899018287658691, 1.0473976135253906, 1.2017654180526733, 1.5661994218826294, 1.0469131469726562, 1.1527974605560303, 1.4159966707229614, 1.077203392982483, 1.3083332777023315, 1.0988188982009888]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7674689292907715] ms
 --  Average per query NF    [1.358952522277832] ms
 --  Average per query vegas [2.4085164070129395] ms
Mean [1.162]  Median [1.111]  95th [1.483]  99th [1.691]  max [1.784]
Mean [1.162]  Median [1.111]  95th [1.483]  99th [1.691]  max [1.784]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.235979 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=0 | total-time=26.151673