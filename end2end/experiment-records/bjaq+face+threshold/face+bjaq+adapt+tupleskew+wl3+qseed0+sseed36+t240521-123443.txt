Input arguments = Namespace(data_update='tupleskew', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 36, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.202695608139038
tensor(0.9981)
result is  tensor(381450.2188)
Enter testHyper
ReportEsts: [1.193955421447754, 1.0040924549102783, 1.406015157699585, 1.2411034107208252, 1.2525044679641724, 1.090561032295227, 1.226159691810608, 1.1423653364181519, 1.0549546480178833, 1.1238998174667358, 1.2394487857818604, 1.2275424003601074, 1.0035252571105957, 1.0602678060531616, 1.1543595790863037, 1.25, 1.3288664817810059, 1.137054681777954, 1.173467755317688, 1.1071428060531616, 1.3326935768127441, 1.0697143077850342, 1.1315126419067383, 1.129550814628601, 1.1553540229797363, 1.0614827871322632, 1.0841779708862305, 1.5410305261611938, 1.0185257196426392, 1.085647463798523, 1.090457558631897, 1.2492711544036865, 1.2800586223602295, 1.0310630798339844, 1.1432218551635742, 1.0969878435134888, 1.3731069564819336, 1.0393381118774414, 1.079620599746704, 1.1477844715118408, 1.0219944715499878, 1.123971939086914, 1.0963631868362427, 1.1891077756881714, 1.0895837545394897, 1.0103092193603516, 1.0539345741271973, 1.2664611339569092, 1.0280919075012207, 1.0490694046020508, 1.1641414165496826, 1.2257126569747925, 1.0143715143203735, 1.3143901824951172, 1.2093544006347656, 1.0941121578216553, 1.3299065828323364, 1.107034683227539, 1.1747612953186035, 1.3434098958969116, 1.2733933925628662, 1.2888436317443848, 1.2708407640457153, 1.1582294702529907, 1.3636363744735718, 1.1714285612106323, 1.118644118309021, 1.002496600151062, 1.106643557548523, 1.24210524559021, 1.106999158859253, 1.011488676071167, 1.2365018129348755, 1.038015365600586, 1.286825180053711, 1.2070196866989136, 1.9383234977722168, 1.0031136274337769, 1.0312680006027222, 1.370123028755188, 1.1973406076431274, 1.2314649820327759, 1.070050835609436, 1.1354742050170898, 1.1863759756088257, 1.0296356678009033, 1.095518708229065, 1.126254677772522, 1.078763484954834, 1.095696210861206, 1.0346133708953857, 1.3647282123565674, 1.0213627815246582, 1.1519464254379272, 1.174698829650879, 1.0746279954910278, 1.2773351669311523, 1.1452282667160034, 1.034482717514038, 1.199794054031372, 1.2026431560516357, 1.1857258081436157, 1.0779900550842285, 1.0095168352127075, 1.025627613067627, 1.0217612981796265, 1.2282748222351074, 1.2094241380691528, 1.0324724912643433, 1.0315914154052734, 1.1549490690231323, 1.0994371175765991, 1.142394781112671, 1.017136812210083, 1.0255013704299927, 1.2611111402511597, 1.0213490724563599, 1.077518343925476, 1.2339953184127808, 1.101772665977478, 1.283953070640564, 1.1145302057266235, 1.0590118169784546, 1.2242921590805054, 1.288759708404541, 1.2271976470947266, 1.071622610092163, 1.2191007137298584, 1.2340255975723267, 1.136940598487854, 1.0920227766036987, 1.1314774751663208, 1.1615910530090332, 1.5, 1.1245211362838745, 1.014110803604126, 1.0446058511734009, 1.1521950960159302, 1.116544485092163, 1.226282000541687, 1.1587436199188232, 1.1320266723632812, 1.1992757320404053, 1.2928855419158936, 1.0079500675201416, 1.0992964506149292, 1.0197772979736328, 1.5624864101409912, 1.0340420007705688, 1.0893466472625732, 1.436955213546753, 1.1839507818222046, 1.2848200798034668, 1.0442042350769043, 1.153098464012146, 1.0514527559280396, 1.036137342453003, 1.0200918912887573, 1.010809302330017, 1.1184720993041992, 1.120637059211731, 1.0789836645126343, 1.0364725589752197, 1.2662161588668823, 1.221216082572937, 1.2042723894119263, 1.1108776330947876, 1.1792211532592773, 1.026576042175293, 1.0367156267166138, 1.0683106184005737, 1.054036259651184, 1.1558442115783691, 1.1641865968704224, 1.0507493019104004, 1.0226263999938965, 1.0083292722702026, 1.1481554508209229, 1.0944347381591797, 1.021776556968689, 1.0407443046569824, 1.1369538307189941, 1.0337109565734863, 1.0898876190185547, 1.096704125404358, 1.167019009590149, 1.0178120136260986, 1.1889476776123047, 1.041991949081421, 1.2382206916809082, 1.0561935901641846, 1.0456817150115967, 1.4620901346206665, 1.338204026222229, 1.7962952852249146, 1.1860464811325073, 1.1027928590774536, 1.1343283653259277, 1.0294910669326782, 1.0806772708892822]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.759312629699707] ms
 --  Average per query NF    [1.358480453491211] ms
 --  Average per query vegas [2.400832176208496] ms
Mean [1.151]  Median [1.125]  95th [1.365]  99th [1.565]  max [1.938]
Mean [1.151]  Median [1.125]  95th [1.365]  99th [1.565]  max [1.938]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.875275 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=tupleskew', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
TupleSkewSample - START
0.001
TupleSkewSample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[9.4413757e-05 1.9776821e-04 2.3066998e-05 6.5386295e-05 1.5026331e-04]
Distance score: 0.00010617971565807238
SAUCE Drift detection: True
Detection latency: 0.0230s

DRIFT-DETECTED after 2-th workload
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/incremental_train.py', '--dataset=bjaq', '--end2end', '--model=face', '--model_update=adapt', '--update_size=80000', '--epochs=0']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
update_size: 76433
AdaptTask - START
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
train data shape: 80000, transfer data shape:16000
Training done; evaluating likelihood on full data:
Saved to: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
AdaptTask - END

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.002258 | Model-update-time: 2.233747


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=tupleskew', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.153982639312744
tensor(0.9959)
result is  tensor(456700.8125)
Enter testHyper
ReportEsts: [1.078584909439087, 1.0080167055130005, 1.0056979656219482, 1.4906961917877197, 1.058796763420105, 1.1023398637771606, 1.2749673128128052, 1.1110292673110962, 1.1089332103729248, 4.025209903717041, 1.0595420598983765, 1.0605157613754272, 1.0145277976989746, 1.1085805892944336, 1.0631142854690552, 1.109070062637329, 1.0198287963867188, 1.0661981105804443, 1.0071332454681396, 1.1683160066604614, 1.1736772060394287, 1.466943621635437, 1.161744475364685, 1.0914881229400635, 1.0771734714508057, 1.3478058576583862, 1.0117380619049072, 1.3788645267486572, 1.2422629594802856, 1.4123947620391846, 1.229329228401184, 1.5254237651824951, 1.0596450567245483, 1.0241150856018066, 1.0895313024520874, 1.148607850074768, 1.1369386911392212, 1.3401890993118286, 1.1690235137939453, 1.0885419845581055, 1.0997023582458496, 1.07258939743042, 1.2063133716583252, 1.1444240808486938, 1.1108043193817139, 1.098257303237915, 1.2647837400436401, 1.1936347484588623, 1.4714285135269165, 1.1188743114471436, 1.0019919872283936, 1.0484739542007446, 1.012751579284668, 1.0878530740737915, 1.0514001846313477, 1.2153843641281128, 1.1373157501220703, 1.0065633058547974, 1.2396236658096313, 1.0682311058044434, 1.1120332479476929, 1.0906195640563965, 1.0095986127853394, 2.0555286407470703, 1.2046761512756348, 1.0303853750228882, 1.3095495700836182, 1.067819356918335, 1.1854205131530762, 1.2027456760406494, 1.09183669090271, 1.057055115699768, 1.0845451354980469, 1.1518889665603638, 1.0221214294433594, 1.1829862594604492, 1.0061304569244385, 1.0925027132034302, 1.4051965475082397, 1.1253498792648315, 1.1390267610549927, 1.094999074935913, 1.042357325553894, 1.125891089439392, 1.138006329536438, 1.6255319118499756, 1.2591314315795898, 1.643662929534912, 2.1818182468414307, 1.4224250316619873, 1.1058200597763062, 1.2035995721817017, 1.4217644929885864, 1.2336395978927612, 1.0653140544891357, 1.039169430732727, 1.067363977432251, 1.246850609779358, 1.0799435377120972, 1.0772080421447754, 1.0709182024002075, 1.0972222089767456, 1.0245097875595093, 1.0954006910324097, 1.039534091949463, 1.1550743579864502, 1.1414098739624023, 1.1565407514572144, 2.213296413421631, 1.0269168615341187, 1.1186771392822266, 1.0312711000442505, 1.2005659341812134, 1.1716681718826294, 1.1058379411697388, 1.0453811883926392, 1.2616236209869385, 1.3838661909103394, 1.185867190361023, 2.8318583965301514, 1.0524606704711914, 1.3071651458740234, 1.1184331178665161, 1.0229592323303223, 1.1979093551635742, 1.1777267456054688, 1.1691569089889526, 1.012012004852295, 1.0435807704925537, 1.059086561203003, 1.2723960876464844, 1.0657979249954224, 1.1677576303482056, 2.27726674079895, 1.5057573318481445, 1.0868992805480957, 1.008689045906067, 1.3592126369476318, 1.0522480010986328, 1.0007121562957764, 1.0563602447509766, 1.1425015926361084, 1.0937259197235107, 1.0226117372512817, 1.0468320846557617, 1.084909200668335, 1.2196531295776367, 1.0991268157958984, 1.0484752655029297, 1.102265477180481, 1.3902629613876343, 1.1833157539367676, 1.03325355052948, 1.0482336282730103, 1.040906310081482, 1.0709470510482788, 1.146008014678955, 2.641221284866333, 1.2368913888931274, 1.1977412700653076, 1.0380139350891113, 1.0287270545959473, 1.3148983716964722, 1.1389350891113281, 1.1070901155471802, 1.4491870403289795, 1.0605652332305908, 1.1145702600479126, 1.047508955001831, 1.185389518737793, 1.0230677127838135, 1.1354669332504272, 1.1557692289352417, 1.1317909955978394, 1.0931124687194824, 1.012416958808899, 1.2243781089782715, 1.1236430406570435, 1.0269839763641357, 1.0127736330032349, 1.605263113975525, 1.0955257415771484, 1.025718092918396, 1.5363566875457764, 1.4955196380615234, 2.1452763080596924, 2.357142925262451, 1.1127375364303589, 1.288910984992981, 1.0561273097991943, 1.140889286994934, 1.0395294427871704, 1.1523683071136475, 1.7969894409179688, 1.0402717590332031, 1.0215438604354858, 1.3738083839416504, 1.3569668531417847, 1.390804648399353, 1.0435086488723755]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7172555923461914] ms
 --  Average per query NF    [1.3537073135375977] ms
 --  Average per query vegas [2.3635482788085938] ms
Mean [1.216]  Median [1.112]  95th [1.651]  99th [2.643]  max [4.025]
Mean [1.216]  Median [1.112]  95th [1.651]  99th [2.643]  max [4.025]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.419311 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=1 | total-time=28.614848