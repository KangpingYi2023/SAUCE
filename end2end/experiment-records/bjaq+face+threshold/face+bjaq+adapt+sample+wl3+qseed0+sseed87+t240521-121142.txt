Input arguments = Namespace(data_update='sample', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 87, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.165185451507568
tensor(0.9945)
result is  tensor(380077.5938)
Enter testHyper
ReportEsts: [1.0833333730697632, 1.090482473373413, 1.4481465816497803, 1.1280269622802734, 1.2100768089294434, 1.1162989139556885, 1.2178415060043335, 1.0972580909729004, 1.1327683925628662, 1.0492522716522217, 1.149870753288269, 1.1720339059829712, 1.0417481660842896, 1.0580357313156128, 1.0496770143508911, 1.2187608480453491, 1.3771069049835205, 1.2066508531570435, 1.1398643255233765, 1.0357142686843872, 1.0220364332199097, 1.1020151376724243, 1.19423508644104, 1.0430247783660889, 1.2311525344848633, 1.0849909782409668, 1.1531531810760498, 1.6362714767456055, 1.0216026306152344, 1.1369138956069946, 1.112451195716858, 1.1656285524368286, 1.0902009010314941, 1.069128394126892, 1.1756712198257446, 1.1434450149536133, 1.0975186824798584, 1.1643215417861938, 1.0680315494537354, 1.1306586265563965, 1.0121725797653198, 1.2284711599349976, 1.1010868549346924, 1.0216201543807983, 1.1001478433609009, 1.0306122303009033, 1.1095253229141235, 1.198832392692566, 1.257887840270996, 1.0879864692687988, 1.1912144422531128, 1.450602412223816, 1.1605769395828247, 1.3930962085723877, 1.2231385707855225, 1.0091228485107422, 1.3252336978912354, 1.1318604946136475, 1.0222132205963135, 1.4932795763015747, 1.2046788930892944, 1.213183045387268, 1.3453056812286377, 1.1377513408660889, 1.3414634466171265, 1.3142857551574707, 1.0990359783172607, 1.0008233785629272, 1.0639667510986328, 1.399999976158142, 1.0096540451049805, 1.0116112232208252, 1.218584418296814, 1.3202989101409912, 1.0991381406784058, 1.148436427116394, 2.1292951107025146, 1.0108410120010376, 1.0386778116226196, 1.2993866205215454, 1.278447151184082, 1.0251978635787964, 1.0305482149124146, 1.1960971355438232, 1.2478621006011963, 1.0873792171478271, 1.1567342281341553, 1.0934678316116333, 1.0177116394042969, 1.1211543083190918, 1.1648274660110474, 1.2634174823760986, 1.0194735527038574, 1.2950588464736938, 1.1403508186340332, 1.07883882522583, 1.0904892683029175, 1.451370120048523, 1.0526316165924072, 1.1305121183395386, 1.1973683834075928, 1.0902966260910034, 1.0984035730361938, 1.0051244497299194, 1.0006279945373535, 1.0067206621170044, 1.1581064462661743, 1.191972017288208, 1.0505138635635376, 1.0681259632110596, 1.017059564590454, 1.0902326107025146, 1.116923213005066, 1.0172154903411865, 1.1808276176452637, 1.101941704750061, 1.0071171522140503, 1.019476294517517, 1.171602725982666, 1.077235221862793, 1.1854231357574463, 1.1443356275558472, 1.1708341836929321, 1.2000552415847778, 1.2543604373931885, 1.1765373945236206, 1.1461251974105835, 1.2245980501174927, 1.2918059825897217, 1.1142284870147705, 1.1236152648925781, 1.1973876953125, 1.1827222108840942, 1.4642857313156128, 1.102602481842041, 1.1585718393325806, 1.119469165802002, 1.2347967624664307, 1.0682597160339355, 1.2069400548934937, 1.1680521965026855, 1.092319369316101, 1.0410480499267578, 1.265643835067749, 1.0872372388839722, 1.0098798274993896, 1.0260920524597168, 1.3707988262176514, 1.0826677083969116, 1.1045454740524292, 1.147390604019165, 1.1569029092788696, 1.3422343730926514, 1.2017759084701538, 1.0901602506637573, 1.0255062580108643, 1.0196150541305542, 1.0295442342758179, 1.0660345554351807, 1.0399284362792969, 1.2159266471862793, 1.0067156553268433, 1.0059906244277954, 1.2074742317199707, 1.1741293668746948, 1.0243902206420898, 1.0682798624038696, 1.3302377462387085, 1.14945650100708, 1.0162981748580933, 1.1219589710235596, 1.1205567121505737, 1.1558442115783691, 1.151702642440796, 1.06641685962677, 1.0199564695358276, 1.0607385635375977, 1.250594139099121, 1.2028393745422363, 1.0121591091156006, 1.120124101638794, 1.081303596496582, 1.0557243824005127, 1.0939733982086182, 1.1763854026794434, 1.0676532983779907, 1.0153146982192993, 1.331727147102356, 1.1019489765167236, 1.2861485481262207, 1.0668442249298096, 1.0153205394744873, 1.6842726469039917, 1.1967213153839111, 1.6956312656402588, 1.2584415674209595, 1.142309308052063, 1.1515151262283325, 1.1089421510696411, 1.0589641332626343]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7667810916900635] ms
 --  Average per query NF    [1.3598370552062988] ms
 --  Average per query vegas [2.4069440364837646] ms
Mean [1.153]  Median [1.123]  95th [1.393]  99th [1.684]  max [2.129]
Mean [1.153]  Median [1.123]  95th [1.393]  99th [1.684]  max [2.129]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.859812 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=sample', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
Sample - START
Sample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[9.5367432e-07 5.3644180e-07 1.7881393e-07 5.9604645e-08 4.1723251e-07]
Distance score: 4.2915343101412873e-07
SAUCE Drift detection: False
Detection latency: 0.0245s

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.023150 | Model-update-time: 0.000000


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=sample', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.162379264831543
tensor(0.9945)
result is  tensor(456073.3125)
Enter testHyper
ReportEsts: [1.0705220699310303, 1.0367227792739868, 1.1295546293258667, 1.0384656190872192, 1.0654205083847046, 1.4197534322738647, 1.1205400228500366, 1.16408109664917, 1.123888611793518, 1.116188645362854, 1.0631448030471802, 1.4268825054168701, 1.0357142686843872, 1.1547898054122925, 1.0469059944152832, 1.0115128755569458, 1.1730880737304688, 1.1540052890777588, 1.011171579360962, 1.244361400604248, 1.138813853263855, 1.5776253938674927, 1.031864047050476, 1.3095343112945557, 1.1266295909881592, 1.2119933366775513, 1.041062593460083, 1.1547785997390747, 1.2636698484420776, 1.2731428146362305, 1.1085686683654785, 1.2676056623458862, 1.0508697032928467, 1.0272927284240723, 1.2799726724624634, 1.0752571821212769, 1.105325698852539, 1.2023704051971436, 1.342737078666687, 1.0102102756500244, 1.0700997114181519, 1.0405827760696411, 1.1387959718704224, 1.0036664009094238, 1.066514253616333, 1.0562232732772827, 1.0796200037002563, 1.0487778186798096, 1.173553705215454, 1.1359950304031372, 1.118812918663025, 1.026181697845459, 1.0130478143692017, 1.002650499343872, 1.1059725284576416, 1.4203294515609741, 1.1241228580474854, 1.1690045595169067, 1.2990307807922363, 1.1730962991714478, 1.5501222610473633, 1.056020975112915, 1.1567944288253784, 1.7034050226211548, 1.036562204360962, 1.0018861293792725, 1.386992335319519, 1.0048125982284546, 1.191841959953308, 1.1638246774673462, 1.04001784324646, 1.1448688507080078, 1.0789318084716797, 1.1385482549667358, 1.0759639739990234, 1.145096778869629, 1.1314030885696411, 1.098080039024353, 1.3958301544189453, 1.0900059938430786, 1.1817119121551514, 1.0892530679702759, 1.1655908823013306, 1.2552059888839722, 1.343137264251709, 1.3732393980026245, 1.250918984413147, 1.4929765462875366, 1.0712405443191528, 1.0206210613250732, 1.078402042388916, 1.415627360343933, 1.3087999820709229, 1.1170459985733032, 1.0659037828445435, 1.092873215675354, 1.037821650505066, 1.2016191482543945, 1.175366997718811, 1.0424656867980957, 1.2247962951660156, 1.1031628847122192, 1.191176414489746, 1.2793633937835693, 1.026755452156067, 1.1952191591262817, 1.0131970643997192, 1.0493996143341064, 1.2114285230636597, 1.152426838874817, 1.1262660026550293, 1.0804489850997925, 1.1099892854690552, 1.4098849296569824, 1.1479897499084473, 1.0314613580703735, 1.0460669994354248, 1.2052642107009888, 1.1706916093826294, 1.1065573692321777, 1.0654133558273315, 1.0880372524261475, 1.0188406705856323, 1.4125465154647827, 1.067263126373291, 1.028753399848938, 1.201500415802002, 1.3284789323806763, 1.0361871719360352, 1.0293114185333252, 1.1486493349075317, 1.069281816482544, 1.066034197807312, 1.4409091472625732, 1.4657872915267944, 1.1825014352798462, 1.003297209739685, 1.0695806741714478, 1.088165521621704, 1.0404223203659058, 1.0243251323699951, 1.2956129312515259, 1.0152229070663452, 1.0993156433105469, 1.0207879543304443, 1.137641429901123, 1.454545497894287, 1.0437109470367432, 1.3090850114822388, 1.1639455556869507, 1.1101222038269043, 1.1809771060943604, 1.1118732690811157, 1.0780506134033203, 1.1277282238006592, 1.0976415872573853, 1.211179256439209, 1.2661290168762207, 1.0400516986846924, 1.1213221549987793, 1.0880597829818726, 1.1103928089141846, 1.1315512657165527, 1.1391736268997192, 1.2007054090499878, 1.0313456058502197, 1.0625560283660889, 1.0512354373931885, 1.2320185899734497, 1.1876838207244873, 1.0057642459869385, 1.1841470003128052, 1.437791109085083, 1.0652631521224976, 1.1376582384109497, 1.0213449001312256, 1.214985728263855, 1.0806429386138916, 1.09022057056427, 1.0946849584579468, 1.5813953876495361, 1.1822199821472168, 1.0686148405075073, 1.4110989570617676, 1.4338985681533813, 1.463355541229248, 1.054973840713501, 1.128830075263977, 1.413928747177124, 1.042703628540039, 1.0913517475128174, 1.1028944253921509, 1.122645378112793, 2.001955032348633, 1.0822077989578247, 1.0613198280334473, 1.2654410600662231, 1.005720853805542, 1.2964824438095093, 1.0815600156784058]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.77183198928833] ms
 --  Average per query NF    [1.3582408428192139] ms
 --  Average per query vegas [2.413591146469116] ms
Mean [1.160]  Median [1.120]  95th [1.438]  99th [1.583]  max [2.002]
Mean [1.160]  Median [1.120]  95th [1.438]  99th [1.583]  max [2.002]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.225960 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=0 | total-time=26.166005