Input arguments = Namespace(data_update='valueskew', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 7, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.16522479057312
tensor(0.9937)
result is  tensor(379761.2188)
Enter testHyper
ReportEsts: [1.1413744688034058, 1.0006916522979736, 1.0052073001861572, 1.112865924835205, 1.2212008237838745, 1.1068682670593262, 1.2867034673690796, 1.107591986656189, 1.0795692205429077, 1.1535396575927734, 1.052540898323059, 1.1584745645523071, 1.0081135034561157, 1.0066964626312256, 1.0214177370071411, 1.3385769128799438, 1.3624074459075928, 1.209144949913025, 1.1621081829071045, 1.0714285373687744, 1.1697111129760742, 1.0259047746658325, 1.149381160736084, 1.107470989227295, 1.1249693632125854, 1.1365280151367188, 1.0807995796203613, 1.3508992195129395, 1.0763154029846191, 1.0171905755996704, 1.0024831295013428, 1.1202301979064941, 1.1239174604415894, 1.020321249961853, 1.0937654972076416, 1.0848973989486694, 1.3290928602218628, 1.2198110818862915, 1.096962571144104, 1.1931736469268799, 1.0298957824707031, 1.137639045715332, 1.1174120903015137, 1.0945343971252441, 1.0638073682785034, 1.0634920597076416, 1.1950873136520386, 1.3559914827346802, 1.1208287477493286, 1.165820598602295, 1.2163587808609009, 1.3771241903305054, 1.0359973907470703, 1.2708868980407715, 1.148032546043396, 1.03751802444458, 1.4429906606674194, 1.183010458946228, 1.054586410522461, 1.4491304159164429, 1.4493542909622192, 1.2059811353683472, 1.4237347841262817, 1.1969398260116577, 1.3807531595230103, 1.2857142686843872, 1.1546961069107056, 1.0136526823043823, 1.111177921295166, 1.1684210300445557, 1.072405457496643, 1.14094078540802, 1.103856086730957, 1.1424744129180908, 1.07558012008667, 1.1521862745285034, 1.844828486442566, 1.1255841255187988, 1.0829921960830688, 1.433758020401001, 1.0806457996368408, 1.0495880842208862, 1.0076842308044434, 1.1979833841323853, 1.3004320859909058, 1.1200175285339355, 1.165839433670044, 1.070718765258789, 1.0037569999694824, 1.1396467685699463, 1.0525317192077637, 1.2920407056808472, 1.013893961906433, 1.3323650360107422, 1.0955055952072144, 1.06667160987854, 1.0902376174926758, 1.3117070198059082, 1.0, 1.1057953834533691, 1.1219178438186646, 1.099273920059204, 1.0416994094848633, 1.014641284942627, 1.1014643907546997, 1.033400535583496, 1.258839726448059, 1.1745200157165527, 1.0892415046691895, 1.0497945547103882, 1.2856426239013672, 1.0772058963775635, 1.1066439151763916, 1.0359735488891602, 1.018776535987854, 1.0758293867111206, 1.0929988622665405, 1.0154551267623901, 1.2834935188293457, 1.0614886283874512, 1.1977369785308838, 1.1187387704849243, 1.1656330823898315, 1.077256441116333, 1.4060077667236328, 1.2112051248550415, 1.0096222162246704, 1.1302567720413208, 1.4058234691619873, 1.135270595550537, 1.0289549827575684, 1.1774457693099976, 1.2883778810501099, 1.4642857313156128, 1.2261857986450195, 1.1551588773727417, 1.0166049003601074, 1.0842276811599731, 1.0400506258010864, 1.3193103075027466, 1.1908009052276611, 1.107457160949707, 1.1120885610580444, 1.2797597646713257, 1.0462881326675415, 1.0336097478866577, 1.0216162204742432, 1.323221206665039, 1.0241661071777344, 1.0017045736312866, 1.2875672578811646, 1.1821560859680176, 1.3249058723449707, 1.0788776874542236, 1.0729933977127075, 1.042959213256836, 1.2310798168182373, 1.0458638668060303, 1.0629611015319824, 1.1867501735687256, 1.0967422723770142, 1.0654714107513428, 1.0488818883895874, 1.3779411315917969, 1.3543758392333984, 1.0629630088806152, 1.0273152589797974, 1.207553505897522, 1.111713171005249, 1.0180726051330566, 1.044285774230957, 1.0711928606033325, 1.1558442115783691, 1.133589744567871, 1.0226402282714844, 1.0594890117645264, 1.0162962675094604, 1.2653552293777466, 1.1524900197982788, 1.0219758749008179, 1.0316312313079834, 1.047448754310608, 1.026472568511963, 1.0551583766937256, 1.060123085975647, 1.0665961503982544, 1.1103484630584717, 1.2952414751052856, 1.0402284860610962, 1.3526935577392578, 1.0819323062896729, 1.1059792041778564, 1.4483633041381836, 1.0959529876708984, 1.708236813545227, 1.219635009765625, 1.1912463903427124, 1.0270270109176636, 1.0281727313995361, 1.078884482383728]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7775814533233643] ms
 --  Average per query NF    [1.363823413848877] ms
 --  Average per query vegas [2.4137580394744873] ms
Mean [1.147]  Median [1.108]  95th [1.406]  99th [1.467]  max [1.845]
Mean [1.147]  Median [1.108]  95th [1.406]  99th [1.467]  max [1.845]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.849352 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=valueskew', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
ValueSample - START
ValueSample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[5.9604645e-08 7.7486038e-07 3.5762787e-07 5.9604645e-07 8.6831450e-03]
Distance score: 0.0017369866836816072
SAUCE Drift detection: True
Detection latency: 0.0233s

DRIFT-DETECTED after 2-th workload
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/incremental_train.py', '--dataset=bjaq', '--end2end', '--model=face', '--model_update=adapt', '--update_size=80000', '--epochs=0']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
update_size: 76433
AdaptTask - START
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
train data shape: 80000, transfer data shape:16000
Training done; evaluating likelihood on full data:
Saved to: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
AdaptTask - END

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.046201 | Model-update-time: 2.226892


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=valueskew', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.168450832366943
tensor(0.9991)
result is  tensor(458181.0938)
Enter testHyper
ReportEsts: [1.285901665687561, 1.2185765504837036, 1.1872398853302002, 1.6602140665054321, 1.0555747747421265, 3.106898784637451, 1.1686497926712036, 1.0795003175735474, 1.4093494415283203, 1.0827375650405884, 1.0176401138305664, 1.702988862991333, 1.0477327108383179, 1.2110273838043213, 1.0631695985794067, 1.3502471446990967, 1.4215312004089355, 1.0263566970825195, 1.089675784111023, 1.9708701372146606, 1.0687572956085205, 2.4085874557495117, 2.679887294769287, 1.0304803848266602, 1.1555992364883423, 1.4144558906555176, 1.2032099962234497, 1.4550000429153442, 19.299663543701172, 1.6571699380874634, 1.3939393758773804, 1.5254237651824951, 1.4108432531356812, 88.44000244140625, 1.0649102926254272, 1.1279569864273071, 1.0504059791564941, 1.1578947305679321, 1.27565598487854, 1.0006935596466064, 1.0084211826324463, 1.3307790756225586, 59.24561309814453, 1.1027039289474487, 1.224037528038025, 1.102707862854004, 1.1585359573364258, 1.0524674654006958, 1.3857142925262451, 1.1551343202590942, 1.1391608715057373, 1.2982020378112793, 1.2178969383239746, 1.0980819463729858, 1.2884665727615356, 1.322698950767517, 1.0298230648040771, 1.0951247215270996, 1.2599667310714722, 1.051937222480774, 1.2552692890167236, 1.012542963027954, 1.161117434501648, 1.2458245754241943, 1.0812406539916992, 1.042791485786438, 1.409568190574646, 2.1868600845336914, 1.1632310152053833, 1.0496327877044678, 1.1304607391357422, 1.1039317846298218, 1.3577325344085693, 1.1493926048278809, 1.0259361267089844, 1.2378497123718262, 1.2916666269302368, 1.0883057117462158, 1.5066996812820435, 1.1199074983596802, 1.1603163480758667, 1.1155309677124023, 1.2772494554519653, 1.0643088817596436, 1.157375454902649, 1.6042553186416626, 1.248520851135254, 1.5796133279800415, 1.0940057039260864, 1.697500467300415, 1.0620554685592651, 1.1423218250274658, 1.071623682975769, 1.5407134294509888, 1.16079843044281, 1.2368098497390747, 1.1865828037261963, 1.2570213079452515, 1.0126168727874756, 2.21366548538208, 1.4734292030334473, 1.1324831247329712, 1.2068965435028076, 1.4487133026123047, 1.0273144245147705, 1.142323613166809, 1.0882070064544678, 1.0201479196548462, 1.1742857694625854, 1.107048749923706, 1.0339245796203613, 1.096683144569397, 1.2723993062973022, 1.1844056844711304, 1.0913009643554688, 1.0717512369155884, 1.305864930152893, 1.1464534997940063, 3.8886711597442627, 1.2035398483276367, 1.1251602172851562, 1.1318907737731934, 1.0353689193725586, 1.8491779565811157, 1.0611368417739868, 1.4977620840072632, 1.21729576587677, 1.2682539224624634, 1.2324715852737427, 1.1183655261993408, 1.0944887399673462, 1.314718246459961, 1.0739425420761108, 1.297350287437439, 1.5613878965377808, 1.2143093347549438, 1.2047022581100464, 1.1492977142333984, 1.0220736265182495, 1.066778540611267, 1.073922872543335, 1.1062333583831787, 1.0563292503356934, 1.6331813335418701, 1.1238887310028076, 1.0369950532913208, 1.1722222566604614, 1.0592111349105835, 1.0603523254394531, 1.4948455095291138, 1.130186915397644, 1.1674984693527222, 1.2359895706176758, 1.0303497314453125, 1.0705184936523438, 1.0514990091323853, 1.1252832412719727, 1.203007459640503, 11.004459381103516, 1.2155439853668213, 1.009751796722412, 1.4570605754852295, 1.6730973720550537, 1.0860203504562378, 1.0791840553283691, 31.49114990234375, 1.2798877954483032, 1.1542736291885376, 1.0324888229370117, 1.2131023406982422, 1.0635244846343994, 1.0106955766677856, 1.177661657333374, 1.7867025136947632, 1.0376137495040894, 1.3264578580856323, 1.097754716873169, 1.3882901668548584, 1.0256036520004272, 1.3623393774032593, 1.763157844543457, 1.2150918245315552, 1.076812505722046, 1.3777538537979126, 1.1341768503189087, 1.0627632141113281, 1.94346284866333, 1.1170872449874878, 1.1812849044799805, 1.0005325078964233, 1.1843427419662476, 1.1368188858032227, 1.0524251461029053, 1.735685110092163, 1.0180541276931763, 4.204415798187256, 1.2692346572875977, 1.223138451576233, 1.0528700351715088, 1.1818501949310303]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7304770946502686] ms
 --  Average per query NF    [1.354820728302002] ms
 --  Average per query vegas [2.3756563663482666] ms
Mean [2.292]  Median [1.162]  95th [2.223]  99th [31.769]  max [88.440]
Mean [2.292]  Median [1.162]  95th [2.223]  99th [31.769]  max [88.440]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.376517 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=1 | total-time=28.578690