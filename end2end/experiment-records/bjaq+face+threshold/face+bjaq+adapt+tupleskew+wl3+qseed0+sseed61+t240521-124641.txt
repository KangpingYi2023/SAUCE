Input arguments = Namespace(data_update='tupleskew', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 61, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.161999702453613
tensor(0.9924)
result is  tensor(379270.2188)
Enter testHyper
ReportEsts: [1.1513864994049072, 1.074401617050171, 1.406882643699646, 1.028005838394165, 1.18478262424469, 1.106494426727295, 1.2668888568878174, 1.1505707502365112, 1.1108033657073975, 1.0266886949539185, 1.0559861660003662, 1.2173728942871094, 1.1407793760299683, 1.0089285373687744, 1.0237842798233032, 1.200982928276062, 1.2150042057037354, 1.1261283159255981, 1.0712465047836304, 1.1122448444366455, 1.1570650339126587, 1.0680862665176392, 1.1811403036117554, 1.047676920890808, 1.1328922510147095, 1.1446654796600342, 1.1632882356643677, 1.3622944355010986, 1.0021532773971558, 1.0251245498657227, 1.131606936454773, 1.1604923009872437, 1.0459896326065063, 1.0040830373764038, 1.0617278814315796, 1.2156239748001099, 1.4016975164413452, 1.0181992053985596, 1.0853922367095947, 1.0209071636199951, 1.0042847394943237, 1.1164731979370117, 1.0083210468292236, 1.1114238500595093, 1.1005704402923584, 1.0419501066207886, 1.1417624950408936, 1.1578773260116577, 1.0857781171798706, 1.1861251592636108, 1.2228116989135742, 1.2346909046173096, 1.0249601602554321, 1.0555111169815063, 1.0671535730361938, 1.0157757997512817, 1.4065420627593994, 1.153558373451233, 1.2515782117843628, 1.4045511484146118, 1.344038724899292, 1.1758217811584473, 1.4256250858306885, 1.0438122749328613, 1.1458333730697632, 1.1428571939468384, 1.203454852104187, 1.08188796043396, 1.189214825630188, 1.4210525751113892, 1.0138661861419678, 1.005266785621643, 1.2332788705825806, 1.0548641681671143, 1.1552714109420776, 1.0045589208602905, 1.5431981086730957, 1.0273308753967285, 1.0591504573822021, 1.1204736232757568, 1.0863158702850342, 1.1707316637039185, 1.105936050415039, 1.2265276908874512, 1.1746554374694824, 1.1354011297225952, 1.1660137176513672, 1.031273603439331, 1.0607982873916626, 1.0158387422561646, 1.0817877054214478, 1.4501055479049683, 1.025604009628296, 1.293233036994934, 1.0833333730697632, 1.1002814769744873, 1.2430174350738525, 1.2372609376907349, 1.034482717514038, 1.1013950109481812, 1.3492586612701416, 1.118161916732788, 1.1104329824447632, 1.0226939916610718, 1.1201882362365723, 1.0656089782714844, 1.255753993988037, 1.2129144668579102, 1.0623985528945923, 1.0041618347167969, 1.193171501159668, 1.070319652557373, 1.0400958061218262, 1.1110680103302002, 1.1736408472061157, 1.1073170900344849, 1.0445626974105835, 1.1501353979110718, 1.3039122819900513, 1.1639858484268188, 1.2229167222976685, 1.1410928964614868, 1.2217110395431519, 1.1436582803726196, 1.2897286415100098, 1.1864423751831055, 1.0898462533950806, 1.0578131675720215, 1.3493449687957764, 1.0838342905044556, 1.104507327079773, 1.1854627132415771, 1.1494717597961426, 1.5, 1.0606143474578857, 1.1829876899719238, 1.0756772756576538, 1.1593495607376099, 1.1141855716705322, 1.3102740049362183, 1.1588928699493408, 1.1587326526641846, 1.024283766746521, 1.2926987409591675, 1.0691742897033691, 1.0307657718658447, 1.1788626909255981, 1.2396506071090698, 1.1856130361557007, 1.0819602012634277, 1.2689636945724487, 1.2201000452041626, 1.3356833457946777, 1.0184853076934814, 1.1227115392684937, 1.097154974937439, 1.0034735202789307, 1.0106921195983887, 1.0692626237869263, 1.166696548461914, 1.1026427745819092, 1.0145878791809082, 1.194520354270935, 1.310489535331726, 1.0465631484985352, 1.1617295742034912, 1.1782981157302856, 1.3105214834213257, 1.105011224746704, 1.1014448404312134, 1.1025547981262207, 1.1406556367874146, 1.1818181276321411, 1.1945605278015137, 1.0820844173431396, 1.0089061260223389, 1.0796890258789062, 1.146790862083435, 1.1272860765457153, 1.1959030628204346, 1.0110794305801392, 1.0212321281433105, 1.0078290700912476, 1.134831428527832, 1.1970300674438477, 1.1025370359420776, 1.1360684633255005, 1.227536678314209, 1.0977057218551636, 1.4125306606292725, 1.0246599912643433, 1.01914381980896, 1.5221333503723145, 1.1735787391662598, 1.6239885091781616, 1.1809872388839722, 1.103334665298462, 1.1875, 1.106298565864563, 1.1181607246398926]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7432122230529785] ms
 --  Average per query NF    [1.3605868816375732] ms
 --  Average per query vegas [2.3826253414154053] ms
Mean [1.147]  Median [1.127]  95th [1.405]  99th [1.522]  max [1.624]
Mean [1.147]  Median [1.127]  95th [1.405]  99th [1.522]  max [1.624]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.845885 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=tupleskew', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
TupleSkewSample - START
0.001
TupleSkewSample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[1.0132790e-06 1.4173985e-04 6.6637993e-05 1.7344952e-05 1.5258789e-05]
Distance score: 4.839897155761719e-05
SAUCE Drift detection: True
Detection latency: 0.0227s

DRIFT-DETECTED after 2-th workload
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/incremental_train.py', '--dataset=bjaq', '--end2end', '--model=face', '--model_update=adapt', '--update_size=80000', '--epochs=0']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
update_size: 76433
AdaptTask - START
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
train data shape: 80000, transfer data shape:16000
Training done; evaluating likelihood on full data:
Saved to: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
AdaptTask - END

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.003015 | Model-update-time: 2.212622


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=tupleskew', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.167617082595825
tensor(1.0006)
result is  tensor(458860.1250)
Enter testHyper
ReportEsts: [1.1458861827850342, 1.0133086442947388, 1.0113314390182495, 1.1869285106658936, 1.009236216545105, 1.1080502271652222, 1.1866354942321777, 1.0061894655227661, 1.0626671314239502, 1.1040387153625488, 1.0372328758239746, 1.0486397743225098, 1.0145277976989746, 1.2570123672485352, 1.1618188619613647, 1.085034728050232, 1.1369304656982422, 1.16715407371521, 1.032502293586731, 1.3537399768829346, 1.0380817651748657, 2.8345322608947754, 1.0975661277770996, 1.033321499824524, 1.2768646478652954, 1.156213641166687, 1.0797597169876099, 1.2182921171188354, 1.3159252405166626, 1.469992756843567, 1.2016322612762451, 1.6525423526763916, 1.0667387247085571, 1.0151950120925903, 1.062469482421875, 1.0490710735321045, 1.092403769493103, 1.0566600561141968, 1.4758894443511963, 1.0587471723556519, 1.1638025045394897, 1.1762452125549316, 1.1407407522201538, 1.039762020111084, 1.0288984775543213, 1.111186146736145, 1.2661241292953491, 1.074512004852295, 1.2857142686843872, 1.1184605360031128, 1.0022149085998535, 1.0445635318756104, 1.0258318185806274, 1.1871172189712524, 1.0199922323226929, 1.4697657823562622, 1.2226173877716064, 1.1214604377746582, 1.22084641456604, 1.1342689990997314, 1.2154195308685303, 1.1470768451690674, 1.1881232261657715, 1.5157784223556519, 1.1316921710968018, 1.1318989992141724, 1.291007161140442, 1.179648756980896, 1.1591123342514038, 1.131702184677124, 1.1084736585617065, 1.1376632452011108, 1.1156435012817383, 1.0585575103759766, 1.1877917051315308, 1.1739507913589478, 1.2064917087554932, 1.1545352935791016, 1.4101754426956177, 1.0915061235427856, 1.2680997848510742, 1.0940139293670654, 1.0578882694244385, 1.1175906658172607, 1.4351415634155273, 1.1026315689086914, 1.3399728536605835, 1.3622666597366333, 1.3179882764816284, 1.2658476829528809, 1.1058984994888306, 1.233817458152771, 1.3393667936325073, 1.2704486846923828, 1.014960527420044, 1.0513757467269897, 1.0512264966964722, 1.2604502439498901, 1.0902618169784546, 1.922910213470459, 1.120495080947876, 1.1421654224395752, 1.0149253606796265, 1.102285385131836, 1.1355973482131958, 1.1239641904830933, 1.1037808656692505, 1.1388037204742432, 1.137535810470581, 1.022666096687317, 1.0766115188598633, 1.0122675895690918, 1.1133438348770142, 1.2764424085617065, 1.1997288465499878, 1.1251254081726074, 1.0235235691070557, 1.08710515499115, 1.0369527339935303, 1.0707964897155762, 1.0037710666656494, 1.065020203590393, 1.0591670274734497, 1.563894510269165, 1.0575588941574097, 1.0509587526321411, 1.164269208908081, 2.066560983657837, 1.1307373046875, 1.6125245094299316, 1.1054887771606445, 1.0843924283981323, 1.119231104850769, 1.7610208988189697, 2.256465435028076, 1.131515383720398, 1.0494741201400757, 1.0028184652328491, 1.0662850141525269, 1.002380132675171, 1.0511932373046875, 1.3018072843551636, 1.096072793006897, 1.026743769645691, 1.0168260335922241, 1.0208758115768433, 1.2634730339050293, 1.0310171842575073, 1.0719457864761353, 1.064711570739746, 2.484802484512329, 1.1130220890045166, 1.170377254486084, 1.1246322393417358, 1.0378637313842773, 1.1772003173828125, 1.1740260124206543, 1.0378787517547607, 1.2543953657150269, 1.2320992946624756, 1.0253716707229614, 1.1690647602081299, 1.0056700706481934, 1.130418300628662, 1.1867799758911133, 1.4580063819885254, 1.1781799793243408, 1.0281388759613037, 1.1243295669555664, 1.0801911354064941, 1.0194015502929688, 1.121996521949768, 2.3899316787719727, 1.0864667892456055, 1.1762144565582275, 1.0492140054702759, 1.1511290073394775, 1.0723037719726562, 1.0118695497512817, 1.0565193891525269, 3.2266666889190674, 1.1403887271881104, 1.1706960201263428, 1.4724985361099243, 1.3154124021530151, 4.20858907699585, 1.3097038269042969, 1.0651599168777466, 1.4241974353790283, 1.2044702768325806, 1.1290452480316162, 1.0718368291854858, 1.1529803276062012, 2.0802838802337646, 1.0105390548706055, 1.0095266103744507, 1.178350806236267, 1.3282767534255981, 1.4991334676742554, 1.00356125831604]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.768496513366699] ms
 --  Average per query NF    [1.3760042190551758] ms
 --  Average per query vegas [2.3924922943115234] ms
Mean [1.217]  Median [1.125]  95th [1.658]  99th [2.838]  max [4.209]
Mean [1.217]  Median [1.125]  95th [1.658]  99th [2.838]  max [4.209]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.386560 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=1 | total-time=28.516466