Input arguments = Namespace(data_update='sample', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 1, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.155481100082397
tensor(0.9964)
result is  tensor(380787.7188)
Enter testHyper
ReportEsts: [1.1381818056106567, 1.0072903633117676, 1.3868564367294312, 1.1958307027816772, 1.195780634880066, 1.1452797651290894, 1.2357990741729736, 1.1368670463562012, 1.0776351690292358, 1.088761806488037, 1.1937984228134155, 1.1752119064331055, 1.028361201286316, 1.0580357313156128, 1.0202528238296509, 1.3644778728485107, 1.1577690839767456, 1.0957244634628296, 1.193655252456665, 1.0127551555633545, 1.0637558698654175, 1.0486018657684326, 1.1253656148910522, 1.1160709857940674, 1.1698930263519287, 1.1627486944198608, 1.1399211883544922, 1.3385826349258423, 1.0407811403274536, 1.0823924541473389, 1.099680781364441, 1.055343508720398, 1.095975637435913, 1.000900149345398, 1.0912535190582275, 1.1140501499176025, 1.3331351280212402, 1.0122367143630981, 1.021762728691101, 1.0965200662612915, 1.0284351110458374, 1.035921573638916, 1.0441755056381226, 1.0946674346923828, 1.0929642915725708, 1.1077097654342651, 1.1358691453933716, 1.3765772581100464, 1.0516642332077026, 1.1979695558547974, 1.2068063020706177, 1.3038365840911865, 1.0082873106002808, 1.1791890859603882, 1.1324810981750488, 1.0560964345932007, 1.3476635217666626, 1.0192439556121826, 1.1651290655136108, 1.4098985195159912, 1.3777801990509033, 1.2144145965576172, 1.471405029296875, 1.2196913957595825, 1.1578947305679321, 1.1714285612106323, 1.2210321426391602, 1.0211460590362549, 1.1740573644638062, 1.4315789937973022, 1.1299999952316284, 1.0032850503921509, 1.2656223773956299, 1.4214110374450684, 1.1388351917266846, 1.0972015857696533, 1.9774038791656494, 1.0461857318878174, 1.095548391342163, 1.38466215133667, 1.2441623210906982, 1.0097863674163818, 1.0814518928527832, 1.1447031497955322, 1.262585163116455, 1.0381852388381958, 1.0490421056747437, 1.2447919845581055, 1.043857455253601, 1.0772037506103516, 1.0018055438995361, 1.279678225517273, 1.0083636045455933, 1.308295726776123, 1.0103627443313599, 1.0188237428665161, 1.0631102323532104, 1.2211397886276245, 1.034482717514038, 1.271041989326477, 1.115803837776184, 1.106515645980835, 1.0801922082901, 1.0036603212356567, 1.0066336393356323, 1.038069486618042, 1.1380057334899902, 1.2076789140701294, 1.0768479108810425, 1.0621179342269897, 1.130200743675232, 1.0932835340499878, 1.2483558654785156, 1.073638677597046, 1.1489509344100952, 1.0913461446762085, 1.028597116470337, 1.052110195159912, 1.178992509841919, 1.0234748125076294, 1.0907094478607178, 1.102249264717102, 1.1493631601333618, 1.194043755531311, 1.258720874786377, 1.1962443590164185, 1.1682363748550415, 1.1865838766098022, 1.2939698696136475, 1.1309285163879395, 1.0191079378128052, 1.0651721954345703, 1.1050342321395874, 1.4285714626312256, 1.1498209238052368, 1.1241796016693115, 1.0001039505004883, 1.0630894899368286, 1.0006166696548462, 1.1272834539413452, 1.1349992752075195, 1.075939416885376, 1.1562680006027222, 1.2223435640335083, 1.0013248920440674, 1.0819164514541626, 1.0553762912750244, 1.5530211925506592, 1.0892220735549927, 1.0051136016845703, 1.2332167625427246, 1.1630560159683228, 1.28549063205719, 1.2428643703460693, 1.046784520149231, 1.0524578094482422, 1.1942099332809448, 1.0154755115509033, 1.1005223989486694, 1.275977373123169, 1.0591450929641724, 1.1390142440795898, 1.0319795608520508, 1.2800546884536743, 1.2705248594284058, 1.1370429992675781, 1.2057584524154663, 1.2538515329360962, 1.072898030281067, 1.07853102684021, 1.120051383972168, 1.0566632747650146, 1.1948051452636719, 1.1164242029190063, 1.002043604850769, 1.079605221748352, 1.0420253276824951, 1.318678855895996, 1.2520500421524048, 1.2066841125488281, 1.01702082157135, 1.078875184059143, 1.0060229301452637, 1.2155261039733887, 1.040565013885498, 1.1479915380477905, 1.0105220079421997, 1.241105318069458, 1.1564687490463257, 1.3362458944320679, 1.11933434009552, 1.0533092021942139, 1.4121721982955933, 1.0912045240402222, 1.6058135032653809, 1.0924464464187622, 1.1469361782073975, 1.1515151262283325, 1.0229017734527588, 1.2239707708358765]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.811063766479492] ms
 --  Average per query NF    [1.373523473739624] ms
 --  Average per query vegas [2.437540292739868] ms
Mean [1.147]  Median [1.120]  95th [1.385]  99th [1.554]  max [1.977]
Mean [1.147]  Median [1.120]  95th [1.385]  99th [1.554]  max [1.977]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.829406 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=sample', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
Sample - START
Sample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[1.9073486e-06 1.7881393e-07 2.3841858e-07 1.2516975e-06 1.6689301e-06]
Distance score: 1.0490417707842425e-06
SAUCE Drift detection: False
Detection latency: 0.0234s

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.042521 | Model-update-time: 0.000000


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=sample', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.1511812210083
tensor(0.9933)
result is  tensor(455520.4062)
Enter testHyper
ReportEsts: [1.2790236473083496, 1.0795632600784302, 1.1940085887908936, 1.33423912525177, 1.0476750135421753, 1.0419636964797974, 1.145837426185608, 1.0845838785171509, 1.0137373208999634, 1.226141095161438, 1.0972346067428589, 1.0013182163238525, 1.0408997535705566, 1.094942569732666, 1.0227680206298828, 1.0652967691421509, 1.523865818977356, 1.0390491485595703, 1.063513994216919, 1.2535864114761353, 1.0448949337005615, 1.257429599761963, 1.0187808275222778, 1.0059154033660889, 1.311597466468811, 1.2990963459014893, 1.0968234539031982, 1.1795709133148193, 1.631346583366394, 1.0511431694030762, 1.29348886013031, 1.2518517971038818, 1.0365180969238281, 1.005004644393921, 1.1158366203308105, 1.1322957277297974, 1.1464409828186035, 1.3498364686965942, 1.336146593093872, 1.0160773992538452, 1.0410871505737305, 1.0494505167007446, 1.0719292163848877, 1.0905492305755615, 1.0120913982391357, 1.0298806428909302, 1.5269831418991089, 1.1121408939361572, 1.2591092586517334, 1.0369527339935303, 1.0527335405349731, 1.0222692489624023, 1.038054347038269, 1.1342133283615112, 1.0776389837265015, 1.0947990417480469, 1.0553947687149048, 1.0839204788208008, 1.2614773511886597, 1.111429214477539, 1.4441964626312256, 1.081078052520752, 1.0256410837173462, 1.460760474205017, 1.0172618627548218, 1.0337196588516235, 1.2895201444625854, 1.028403401374817, 1.171444296836853, 1.0526602268218994, 1.1888670921325684, 1.2358444929122925, 1.1644057035446167, 1.139892578125, 1.099261999130249, 1.1122881174087524, 1.2307637929916382, 1.2212224006652832, 1.2241795063018799, 1.091953992843628, 1.1860430240631104, 1.163772463798523, 1.675719141960144, 1.1425015926361084, 1.3127036094665527, 1.360714316368103, 1.2940373420715332, 1.6024690866470337, 1.063962697982788, 1.028157353401184, 1.1860913038253784, 1.2359564304351807, 1.148003101348877, 1.1040583848953247, 1.3494666814804077, 1.017972707748413, 1.0346579551696777, 1.1806600093841553, 1.3876025676727295, 1.1253410577774048, 1.1918244361877441, 1.0897798538208008, 1.1703163385391235, 1.1247037649154663, 1.0794070959091187, 1.2414624691009521, 1.1636505126953125, 1.0938540697097778, 1.1694444417953491, 1.1108278036117554, 1.1216464042663574, 1.0459131002426147, 1.1318012475967407, 1.4674543142318726, 1.0717264413833618, 1.2001339197158813, 1.1007790565490723, 1.2405775785446167, 1.0967663526535034, 1.0887097120285034, 1.1326063871383667, 1.0715404748916626, 1.1585928201675415, 1.5897564888000488, 1.0179754495620728, 1.0124655961990356, 1.1143747568130493, 1.315619945526123, 1.107814073562622, 1.1023833751678467, 1.0524595975875854, 1.0940054655075073, 1.0148308277130127, 1.4910629987716675, 1.433901071548462, 1.1329017877578735, 1.0054848194122314, 1.1470177173614502, 1.0943337678909302, 1.0566753149032593, 1.065666913986206, 1.1363056898117065, 1.1016923189163208, 1.0622364282608032, 1.0984703302383423, 1.0853997468948364, 1.4057142734527588, 1.022177815437317, 1.0962183475494385, 1.0927329063415527, 1.1354740858078003, 1.055952787399292, 1.1223357915878296, 1.097434163093567, 1.0180819034576416, 1.033947467803955, 1.1161781549453735, 1.3305785655975342, 1.0574712753295898, 1.081425428390503, 1.0752345323562622, 1.0181639194488525, 1.1596535444259644, 1.0186833143234253, 1.1102696657180786, 1.177947759628296, 1.0784189701080322, 1.2053329944610596, 1.1872217655181885, 1.2933986186981201, 1.0456000566482544, 1.1631698608398438, 1.493524193763733, 1.1261094808578491, 1.1931394338607788, 1.0071003437042236, 1.130391240119934, 1.2391146421432495, 1.2137787342071533, 1.1045935153961182, 1.5111111402511597, 1.0502662658691406, 1.1487544775009155, 1.4199962615966797, 1.3242939710617065, 1.0936250686645508, 1.2642611265182495, 1.0138869285583496, 1.3927799463272095, 1.0326087474822998, 1.1404204368591309, 1.0535203218460083, 1.2870018482208252, 1.7759371995925903, 1.007177472114563, 1.0512096881866455, 1.2781625986099243, 1.0601171255111694, 1.2739059925079346, 1.1828640699386597]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7256991863250732] ms
 --  Average per query NF    [1.3567006587982178] ms
 --  Average per query vegas [2.3689985275268555] ms
Mean [1.160]  Median [1.112]  95th [1.469]  99th [1.632]  max [1.776]
Mean [1.160]  Median [1.112]  95th [1.469]  99th [1.632]  max [1.776]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.189399 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=0 | total-time=26.106604