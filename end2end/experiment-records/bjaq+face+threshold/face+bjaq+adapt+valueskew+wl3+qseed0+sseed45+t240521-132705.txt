Input arguments = Namespace(data_update='valueskew', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 45, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.166358470916748
tensor(0.9950)
result is  tensor(380248.8125)
Enter testHyper
ReportEsts: [1.1915080547332764, 1.015932559967041, 1.467748761177063, 1.044851541519165, 1.2268397808074951, 1.0904701948165894, 1.3467981815338135, 1.0381792783737183, 1.0463902950286865, 1.1264657974243164, 1.1197243928909302, 1.2072033882141113, 1.0213745832443237, 1.0290178060531616, 1.1158925294876099, 1.2796134948730469, 1.1575398445129395, 1.1756532192230225, 1.1318467855453491, 1.1301020383834839, 1.079737663269043, 1.1194030046463013, 1.1370065212249756, 1.0974715948104858, 1.0998121500015259, 1.0473484992980957, 1.1143018007278442, 1.5023255348205566, 1.0362073183059692, 1.0023449659347534, 1.1504079103469849, 1.250781536102295, 1.0606454610824585, 1.0428346395492554, 1.1461868286132812, 1.0959758758544922, 1.368401288986206, 1.2612299919128418, 1.0320154428482056, 1.0404984951019287, 1.086473822593689, 1.1802128553390503, 1.1511497497558594, 1.001915693283081, 1.103105902671814, 1.2358276844024658, 1.0586146116256714, 1.2559813261032104, 1.0382593870162964, 1.1353638172149658, 1.2228116989135742, 1.3450367450714111, 1.0734944343566895, 1.1813023090362549, 1.0916588306427002, 1.0164580345153809, 1.2878504991531372, 1.012799620628357, 1.2584123611450195, 1.3963133096694946, 1.3416608572006226, 1.1930193901062012, 1.2870385646820068, 1.10120689868927, 1.2741312980651855, 1.485714316368103, 1.1504586935043335, 1.0967954397201538, 1.097195029258728, 1.4631578922271729, 1.0249396562576294, 1.0391684770584106, 1.2628462314605713, 1.0656527280807495, 1.0430818796157837, 1.1365355253219604, 1.695648193359375, 1.0921986103057861, 1.007684588432312, 1.3239461183547974, 1.2640111446380615, 1.076078176498413, 1.018017292022705, 1.1867543458938599, 1.1869608163833618, 1.0748651027679443, 1.033628225326538, 1.0296090841293335, 1.0909223556518555, 1.0849158763885498, 1.05106520652771, 1.3844815492630005, 1.0003606081008911, 1.241597056388855, 1.1538461446762085, 1.0454561710357666, 1.1909600496292114, 1.2216356992721558, 1.0526316165924072, 1.1599100828170776, 1.1886792182922363, 1.1834673881530762, 1.0265066623687744, 1.0131771564483643, 1.0738493204116821, 1.0085831880569458, 1.0048370361328125, 1.1849912405014038, 1.097730040550232, 1.0439903736114502, 1.2813979387283325, 1.0912476778030396, 1.1113709211349487, 1.0768060684204102, 1.1526602506637573, 1.164102554321289, 1.0796815156936646, 1.0389975309371948, 1.3377134799957275, 1.0640970468521118, 1.2460440397262573, 1.1299848556518555, 1.1605654954910278, 1.167172908782959, 1.3187984228134155, 1.2653734683990479, 1.1347941160202026, 1.041469931602478, 1.338821530342102, 1.100534439086914, 1.1474121809005737, 1.1776835918426514, 1.1609694957733154, 1.4642857313156128, 1.1061071157455444, 1.1491204500198364, 1.0046132802963257, 1.1840649843215942, 1.0340656042099, 1.3882437944412231, 1.1423665285110474, 1.0731109380722046, 1.1735434532165527, 1.2673463821411133, 1.052790880203247, 1.0015512704849243, 1.1019048690795898, 1.6333907842636108, 1.0733275413513184, 1.1012784242630005, 1.079278826713562, 1.203179121017456, 1.3349593877792358, 1.2516517639160156, 1.2197041511535645, 1.1189483404159546, 1.1544028520584106, 1.0059088468551636, 1.0276415348052979, 1.1694419384002686, 1.0992374420166016, 1.0681266784667969, 1.0290091037750244, 1.2560322284698486, 1.2949244976043701, 1.123887538909912, 1.2991807460784912, 1.2262648344039917, 1.0973645448684692, 1.062373399734497, 1.0175837278366089, 1.1983156204223633, 1.0779221057891846, 1.0554534196853638, 1.0177111625671387, 1.1106220483779907, 1.0494645833969116, 1.1742393970489502, 1.0581640005111694, 1.0389294624328613, 1.3203086853027344, 1.0263676643371582, 1.0420385599136353, 1.2042900323867798, 1.1970300674438477, 1.1479915380477905, 1.0638035535812378, 1.2700600624084473, 1.073899269104004, 1.2579158544540405, 1.1326524019241333, 1.0132719278335571, 1.5348211526870728, 1.280701756477356, 1.9157805442810059, 1.166064977645874, 1.1151312589645386, 1.1014492511749268, 1.1757155656814575, 1.0180610418319702]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.767244815826416] ms
 --  Average per query NF    [1.3626468181610107] ms
 --  Average per query vegas [2.4045979976654053] ms
Mean [1.155]  Median [1.122]  95th [1.389]  99th [1.634]  max [1.916]
Mean [1.155]  Median [1.122]  95th [1.389]  99th [1.634]  max [1.916]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.829678 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=valueskew', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
ValueSample - START
ValueSample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[3.5762787e-07 2.3841858e-07 1.1920929e-07 2.3609459e-02 1.1920929e-07]
Distance score: 0.0047220587730407715
SAUCE Drift detection: True
Detection latency: 0.0232s

DRIFT-DETECTED after 2-th workload
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/incremental_train.py', '--dataset=bjaq', '--end2end', '--model=face', '--model_update=adapt', '--update_size=80000', '--epochs=0']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
update_size: 76433
AdaptTask - START
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
train data shape: 80000, transfer data shape:16000
Training done; evaluating likelihood on full data:
Saved to: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
AdaptTask - END

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.039040 | Model-update-time: 2.221965


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=valueskew', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.167891025543213
tensor(0.9945)
result is  tensor(456058.2812)
Enter testHyper
ReportEsts: [1.1556943655014038, 1.0494071245193481, 1.01875901222229, 1.1932991743087769, 1.2119967937469482, 1.3397644758224487, 1.0755189657211304, 1.0394916534423828, 1.1208041906356812, 2.0340816974639893, 1.0767440795898438, 1.045211911201477, 1.0072115659713745, 1.064115285873413, 1.0501827001571655, 1.0431681871414185, 1.5642666816711426, 1.3136428594589233, 1.2659341096878052, 1.273860216140747, 1.0095765590667725, 2.0046730041503906, 1.3579732179641724, 5.206989288330078, 1.008013129234314, 1.1825785636901855, 1.1037371158599854, 1.138043999671936, 1.1286728382110596, 1.4143426418304443, 1.2319347858428955, 1.4322034120559692, 1.005806803703308, 1.245282769203186, 1.062406063079834, 1.0969362258911133, 1.0246460437774658, 1.038703203201294, 1.6830127239227295, 1.1468325853347778, 1.1703293323516846, 1.0032051801681519, 164.07106018066406, 1.1367396116256714, 1.0063507556915283, 1.0073026418685913, 1.002002477645874, 1.0025744438171387, 1.3666666746139526, 2.720301628112793, 1.0663790702819824, 1.0217642784118652, 1.0566576719284058, 1.0559269189834595, 1.0138962268829346, 1.1980935335159302, 1.1204521656036377, 1.1245759725570679, 1.076432228088379, 1.1315401792526245, 1.2792363166809082, 1.0377167463302612, 1.0446194410324097, 2.0384316444396973, 1.1460267305374146, 1.0341103076934814, 1.192799687385559, 1.111071228981018, 1.102124810218811, 1.1182763576507568, 1.0279477834701538, 1.040677785873413, 1.0737725496292114, 1.1805920600891113, 2.0707638263702393, 1.3060864210128784, 1.0333620309829712, 1.443441390991211, 1.2005916833877563, 1.1886043548583984, 1.5138784646987915, 1.2113604545593262, 1.1670558452606201, 1.0530762672424316, 1.1121119260787964, 1.3859648704528809, 1.052700161933899, 1.3036211729049683, 1.0552932024002075, 1.1309770345687866, 1.1419087648391724, 1.4027998447418213, 1.1295690536499023, 1.0634592771530151, 167.15789794921875, 1.0185436010360718, 1.0456781387329102, 1.131524682044983, 1.2359579801559448, 1.082521677017212, 1.145599365234375, 1.117235541343689, 1.0251256227493286, 1.3324223756790161, 5.331116676330566, 1.142727255821228, 1.39285409450531, 1.0939080715179443, 1.03438401222229, 1.085668683052063, 1.2192033529281616, 1.102583885192871, 1.1384919881820679, 1.0961683988571167, 1.1198136806488037, 1.7063308954238892, 1.0804203748703003, 1.202561378479004, 1.1228080987930298, 1.1061947345733643, 1.0047804117202759, 1.2170000076293945, 1.0417464971542358, 1.3210773468017578, 1.0549558401107788, 1.4354019165039062, 1.0081554651260376, 1.0836012363433838, 1.0850212574005127, 1.1083836555480957, 1.3001899719238281, 1.024491786956787, 1.076801061630249, 1.5901803970336914, 1.3693444728851318, 1.1298863887786865, 1.1224253177642822, 1.309997797012329, 1.1273223161697388, 1.0241047143936157, 1.0208333730697632, 1.0981749296188354, 1.0083346366882324, 1.0661123991012573, 1.0130949020385742, 1.9014016389846802, 1.2196531295776367, 1.088969111442566, 1.1733049154281616, 1.091313362121582, 62.918540954589844, 1.219751238822937, 1.3495503664016724, 1.0644279718399048, 1.0722134113311768, 1.1005572080612183, 1.210459589958191, 1.0620155334472656, 1.1646679639816284, 1.0028705596923828, 1.1214501857757568, 1.1440552473068237, 1.0200294256210327, 1.1480190753936768, 1.0159425735473633, 1.187298059463501, 1.0729379653930664, 1.1178615093231201, 1.049180269241333, 1.102813720703125, 1.0302239656448364, 1.0368019342422485, 1.715402603149414, 1.0061806440353394, 1.5760118961334229, 1.1645288467407227, 1.1551101207733154, 1.147910475730896, 1.232357144355774, 1.1655330657958984, 1.9473683834075928, 1.308514952659607, 1.0188703536987305, 1.5026137828826904, 1.3318132162094116, 1.0614944696426392, 1.24610435962677, 1.0694410800933838, 1.2923128604888916, 1.0882394313812256, 1.0014861822128296, 1.0089833736419678, 1.1830294132232666, 2.0175867080688477, 1.031100869178772, 1.023123025894165, 1.145292043685913, 1.0847166776657104, 1.105175256729126, 1.0193147659301758]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.641788959503174] ms
 --  Average per query NF    [1.36246919631958] ms
 --  Average per query vegas [2.2793197631835938] ms
Mean [3.182]  Median [1.121]  95th [2.005]  99th [63.930]  max [167.158]
Mean [3.182]  Median [1.121]  95th [2.005]  99th [63.930]  max [167.158]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.338916 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=1 | total-time=28.475051