Input arguments = Namespace(data_update='valueskew', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 24, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.165392875671387
tensor(0.9955)
result is  tensor(380436.5312)
Enter testHyper
ReportEsts: [1.0885499715805054, 1.0379666090011597, 1.3909273147583008, 1.2815330028533936, 1.2332463264465332, 1.1143999099731445, 1.1388529539108276, 1.0642635822296143, 1.0491279363632202, 1.0259848833084106, 1.2067183256149292, 1.0588983297348022, 1.0946632623672485, 1.0379464626312256, 1.0105425119400024, 1.2417457103729248, 1.4504142999649048, 1.167933464050293, 1.1476479768753052, 1.0484694242477417, 1.0233936309814453, 1.0614638328552246, 1.1673169136047363, 1.1202328205108643, 1.0065773725509644, 1.0614827871322632, 1.048423409461975, 1.327579140663147, 1.0648627281188965, 1.1146373748779297, 1.1280596256256104, 1.2336938381195068, 1.3211970329284668, 1.0502790212631226, 1.144457221031189, 1.1022523641586304, 1.1934328079223633, 1.0325340032577515, 1.1212776899337769, 1.1031839847564697, 1.0238581895828247, 1.0939767360687256, 1.0892834663391113, 1.1369010210037231, 1.065920114517212, 1.0850340127944946, 1.0822426080703735, 1.3626073598861694, 1.1694804430007935, 1.2233502864837646, 1.1730279922485352, 1.402329444885254, 1.0431464910507202, 1.12678062915802, 1.1661757230758667, 1.0313172340393066, 1.3317756652832031, 1.1562834978103638, 1.1721680164337158, 1.539491891860962, 1.3560552597045898, 1.1330106258392334, 1.2573480606079102, 1.1417946815490723, 1.235954999923706, 1.0285714864730835, 1.2318271398544312, 1.0104248523712158, 1.1461905241012573, 1.1684210300445557, 1.1393216848373413, 1.1375058889389038, 1.2200109958648682, 1.028403878211975, 1.048993706703186, 1.0003697872161865, 2.0739855766296387, 1.0302976369857788, 1.1075712442398071, 1.463431715965271, 1.2705925703048706, 1.249717354774475, 1.053005337715149, 1.0187751054763794, 1.228757381439209, 1.006839632987976, 1.033348560333252, 1.4273896217346191, 1.016404628753662, 1.0441993474960327, 1.0596963167190552, 1.3091648817062378, 1.0058034658432007, 1.303647518157959, 1.1890244483947754, 1.1849981546401978, 1.1355867385864258, 1.3591145277023315, 1.0909091234207153, 1.1685235500335693, 1.1767241954803467, 1.1703839302062988, 1.0277951955795288, 1.003673791885376, 1.0816946029663086, 1.02878737449646, 1.1352275609970093, 1.2111692428588867, 1.071798324584961, 1.0018454790115356, 1.1020320653915405, 1.0871984958648682, 1.2403526306152344, 1.1186144351959229, 1.1782774925231934, 1.0132158994674683, 1.0395253896713257, 1.0447568893432617, 1.2372853755950928, 1.0394145250320435, 1.2849751710891724, 1.0811370611190796, 1.1650997400283813, 1.1071860790252686, 1.2592054605484009, 1.1700371503829956, 1.1145652532577515, 1.0662987232208252, 1.2213438749313354, 1.0895123481750488, 1.201277732849121, 1.1136542558670044, 1.2756370306015015, 1.5357142686843872, 1.0687578916549683, 1.1098484992980957, 1.0845015048980713, 1.1879675388336182, 1.0739189386367798, 1.013068437576294, 1.1630245447158813, 1.0769752264022827, 1.0247310400009155, 1.4023816585540771, 1.2454307079315186, 1.0137393474578857, 1.0297627449035645, 1.5995416641235352, 1.0278563499450684, 1.1401278972625732, 1.1333974599838257, 1.1938213109970093, 1.3637874126434326, 1.2911282777786255, 1.2350305318832397, 1.0450830459594727, 1.0748413801193237, 1.023072600364685, 1.024370789527893, 1.127245545387268, 1.2525500059127808, 1.0414133071899414, 1.1346136331558228, 1.3404864072799683, 1.221216082572937, 1.063141942024231, 1.1605150699615479, 1.1822383403778076, 1.0292898416519165, 1.1277694702148438, 1.0402348041534424, 1.188976764678955, 1.1233766078948975, 1.1344256401062012, 1.046702265739441, 1.0556377172470093, 1.0111758708953857, 1.2974002361297607, 1.231890320777893, 1.0166597366333008, 1.0350987911224365, 1.0449199676513672, 1.0337109565734863, 1.0909091234207153, 1.096341848373413, 1.0835095643997192, 1.0735043287277222, 1.2167288064956665, 1.0256415605545044, 1.356959581375122, 1.040096402168274, 1.2148569822311401, 1.6768507957458496, 1.3464314937591553, 1.8951709270477295, 1.208229422569275, 1.154481053352356, 1.1176470518112183, 1.001397967338562, 1.0691567659378052]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7382137775421143] ms
 --  Average per query NF    [1.3576138019561768] ms
 --  Average per query vegas [2.3805999755859375] ms
Mean [1.154]  Median [1.121]  95th [1.402]  99th [1.679]  max [2.074]
Mean [1.154]  Median [1.121]  95th [1.402]  99th [1.679]  max [2.074]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.824024 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=valueskew', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
ValueSample - START
ValueSample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[2.9802322e-07 3.5762787e-07 2.9802322e-07 1.0473847e-02 3.5762787e-07]
Distance score: 0.0020950317848473787
SAUCE Drift detection: True
Detection latency: 0.0233s

DRIFT-DETECTED after 2-th workload
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/incremental_train.py', '--dataset=bjaq', '--end2end', '--model=face', '--model_update=adapt', '--update_size=80000', '--epochs=0']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
update_size: 76433
AdaptTask - START
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
train data shape: 80000, transfer data shape:16000
Training done; evaluating likelihood on full data:
Saved to: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
AdaptTask - END

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.054665 | Model-update-time: 2.233783


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=valueskew', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.217367172241211
tensor(0.9980)
result is  tensor(457662.3750)
Enter testHyper
ReportEsts: [1.0329904556274414, 1.170167088508606, 1.0056657791137695, 1.1624237298965454, 1.150269865989685, 1.2762391567230225, 1.0863901376724243, 1.0180134773254395, 1.2813754081726074, 1.400144100189209, 1.0190542936325073, 1.276561975479126, 1.0167064666748047, 1.1413891315460205, 1.2384276390075684, 1.0152974128723145, 1.3671101331710815, 1.0097037553787231, 1.2166742086410522, 1.2593390941619873, 1.091529130935669, 1.5507372617721558, 1.8521093130111694, 2.2935547828674316, 1.081527829170227, 1.174415946006775, 1.0524505376815796, 1.09268057346344, 1.2768577337265015, 1.2079343795776367, 1.4726107120513916, 1.610169529914856, 1.088370680809021, 1.1558955907821655, 1.2068138122558594, 1.2227040529251099, 1.0283108949661255, 1.0539393424987793, 1.1675392389297485, 1.017482876777649, 1.3221336603164673, 1.063829779624939, 70.25438690185547, 1.1621651649475098, 1.0893442630767822, 1.0553815364837646, 1.0898189544677734, 1.1171537637710571, 1.4714285135269165, 1.4992159605026245, 1.0200257301330566, 1.0216317176818848, 1.0475422143936157, 1.219374656677246, 1.1104636192321777, 1.254311442375183, 1.0505845546722412, 1.211700201034546, 1.0075657367706299, 1.1233696937561035, 1.1331924200057983, 1.100923776626587, 1.1095505952835083, 2.0106594562530518, 1.0967950820922852, 1.0636780261993408, 1.0753597021102905, 1.0306297540664673, 1.1270332336425781, 1.0840156078338623, 1.0605154037475586, 1.0060853958129883, 1.181093454360962, 1.162682056427002, 1.5437285900115967, 1.4046119451522827, 1.1484006643295288, 2.2148478031158447, 1.1063296794891357, 1.1602026224136353, 3.278158664703369, 1.1387827396392822, 1.0174037218093872, 1.2710860967636108, 1.1110584735870361, 1.2832168340682983, 1.1027580499649048, 1.274336338043213, 1.1845847368240356, 1.1848208904266357, 1.027385950088501, 1.6741701364517212, 1.1225568056106567, 1.0150212049484253, 51.0, 1.036616325378418, 1.0183409452438354, 1.284812331199646, 1.071054220199585, 1.0031625032424927, 1.1525778770446777, 1.1008822917938232, 1.0220588445663452, 1.1725687980651855, 2.1982815265655518, 1.7615842819213867, 1.0519160032272339, 1.029100775718689, 1.017192006111145, 1.117516040802002, 1.4004608392715454, 1.0692715644836426, 1.0040162801742554, 1.014929175376892, 1.0074013471603394, 2.987755060195923, 1.0491507053375244, 1.1213302612304688, 1.081302285194397, 1.0796459913253784, 1.1397713422775269, 1.0275774002075195, 1.0356723070144653, 1.1882065534591675, 1.12409508228302, 1.3652420043945312, 1.1167455911636353, 1.0766773223876953, 1.193450689315796, 1.0213626623153687, 1.1542540788650513, 1.074051022529602, 1.154962182044983, 1.304241418838501, 1.4844844341278076, 1.0357240438461304, 1.1616839170455933, 2.2148149013519287, 1.0868873596191406, 1.0341919660568237, 1.051762580871582, 1.1996219158172607, 1.0021971464157104, 1.0287914276123047, 1.0425645112991333, 2.850257396697998, 1.2267441749572754, 1.0146032571792603, 1.2741516828536987, 1.080709457397461, 30.27777862548828, 1.2857142686843872, 1.38741934299469, 1.011222004890442, 1.0129953622817993, 1.0781015157699585, 1.0239639282226562, 1.1138211488723755, 1.7863883972167969, 1.0367772579193115, 1.0396062135696411, 1.012562870979309, 1.1452758312225342, 1.1794854402542114, 1.0987993478775024, 1.0089143514633179, 1.00578773021698, 1.1162738800048828, 1.0446357727050781, 1.0655419826507568, 1.0232428312301636, 1.147788643836975, 1.3772609233856201, 1.0359948873519897, 1.5281782150268555, 1.0610041618347168, 1.1694915294647217, 1.0240478515625, 1.1408344507217407, 1.0864700078964233, 1.7894736528396606, 1.293179988861084, 1.0066174268722534, 1.2893315553665161, 1.4664690494537354, 1.0079952478408813, 1.454545497894287, 1.0785496234893799, 1.4692593812942505, 1.0492026805877686, 1.0173389911651611, 1.036592960357666, 1.1402980089187622, 1.6876293420791626, 1.0713940858840942, 1.0784971714019775, 1.1987262964248657, 1.0501328706741333, 1.0474683046340942, 1.1675366163253784]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7211239337921143] ms
 --  Average per query NF    [1.3554167747497559] ms
 --  Average per query vegas [2.3657071590423584] ms
Mean [1.954]  Median [1.117]  95th [2.020]  99th [30.485]  max [70.254]
Mean [1.954]  Median [1.117]  95th [2.020]  99th [30.485]  max [70.254]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.421353 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=1 | total-time=28.558663