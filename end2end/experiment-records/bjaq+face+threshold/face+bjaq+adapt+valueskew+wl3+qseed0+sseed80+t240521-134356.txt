Input arguments = Namespace(data_update='valueskew', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 80, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.165101766586304
tensor(0.9971)
result is  tensor(381061.1562)
Enter testHyper
ReportEsts: [1.0738980770111084, 1.0045697689056396, 1.1960173845291138, 1.3065909147262573, 1.2655552625656128, 1.067894697189331, 1.156722903251648, 1.1248688697814941, 1.1003048419952393, 1.0765981674194336, 1.048234224319458, 1.077754259109497, 1.0767515897750854, 1.0200892686843872, 1.0186537504196167, 1.301481008529663, 1.2570558786392212, 1.1268408298492432, 1.2225993871688843, 1.0204081535339355, 1.1634851694107056, 1.0652698278427124, 1.180105209350586, 1.0288013219833374, 1.1279915571212769, 1.1338155269622803, 1.0805180072784424, 1.5581283569335938, 1.0515166521072388, 1.1077204942703247, 1.1216742992401123, 1.130529761314392, 1.060124158859253, 1.0039392709732056, 1.0609455108642578, 1.1747536659240723, 1.1486384868621826, 1.1794160604476929, 1.052248239517212, 1.0459727048873901, 1.0461583137512207, 1.043420433998108, 1.0211193561553955, 1.0096312761306763, 1.0916966199874878, 1.0589568614959717, 1.2188138961791992, 1.2994602918624878, 1.0414953231811523, 1.2351945638656616, 1.1974025964736938, 1.3606716394424438, 1.006413459777832, 1.192702054977417, 1.1169886589050293, 1.0044043064117432, 1.4242991209030151, 1.0408531427383423, 1.1825332641601562, 1.3609637022018433, 1.4881370067596436, 1.1737709045410156, 1.4435780048370361, 1.1090810298919678, 1.2132352590560913, 1.2571429014205933, 1.2127659320831299, 1.0518277883529663, 1.042348861694336, 1.378947377204895, 1.100000023841858, 1.0152446031570435, 1.2029690742492676, 1.0605484247207642, 1.1329071521759033, 1.351765513420105, 1.6788874864578247, 1.0406503677368164, 1.091540813446045, 1.342389464378357, 1.033237338066101, 1.0983686447143555, 1.0109591484069824, 1.215997338294983, 1.2201950550079346, 1.023419976234436, 1.043923258781433, 1.0045397281646729, 1.0571225881576538, 1.1258810758590698, 1.0301342010498047, 1.6108505725860596, 1.0191106796264648, 1.326904535293579, 1.1963189840316772, 1.0204826593399048, 1.0120774507522583, 1.3745145797729492, 1.034482717514038, 1.2546577453613281, 1.1666666269302368, 1.2305567264556885, 1.0922969579696655, 1.0133531093597412, 1.030334711074829, 1.0741703510284424, 1.0765395164489746, 1.2146596908569336, 1.0673127174377441, 1.0345402956008911, 1.1420503854751587, 1.1512770652770996, 1.1624140739440918, 1.0063447952270508, 1.1627448797225952, 1.0133928060531616, 1.0757346153259277, 1.0076099634170532, 1.301214337348938, 1.0294643640518188, 1.193089485168457, 1.1286739110946655, 1.0781489610671997, 1.1635618209838867, 1.2621123790740967, 1.1748864650726318, 1.2038036584854126, 1.245697259902954, 1.2918059825897217, 1.122578501701355, 1.1808804273605347, 1.1361887454986572, 1.1314481496810913, 1.4642857313156128, 1.1716128587722778, 1.0619585514068604, 1.0376338958740234, 1.0946341753005981, 1.0215269327163696, 1.4297459125518799, 1.1084175109863281, 1.100637674331665, 1.128618597984314, 1.3173388242721558, 1.054626703262329, 1.0546435117721558, 1.1445820331573486, 1.45401930809021, 1.078980803489685, 1.0764914751052856, 1.155096411705017, 1.180233359336853, 1.3087141513824463, 1.1299982070922852, 1.1611862182617188, 1.0071635246276855, 1.114123821258545, 1.0137872695922852, 1.0176697969436646, 1.1585198640823364, 1.19395112991333, 1.2260195016860962, 1.0635186433792114, 1.2696477174758911, 1.243741750717163, 1.0142972469329834, 1.0550440549850464, 1.1663545370101929, 1.0383042097091675, 1.029028296470642, 1.035650372505188, 1.0346667766571045, 1.1753246784210205, 1.147801399230957, 1.037806510925293, 1.3636739253997803, 1.0733722448349, 1.3311105966567993, 1.1055457592010498, 1.1000545024871826, 1.0179088115692139, 1.0080312490463257, 1.0319361686706543, 1.1859040260314941, 1.067004680633545, 1.1183931827545166, 1.0288302898406982, 1.3103574514389038, 1.0797590017318726, 1.3792990446090698, 1.033398985862732, 1.0550918579101562, 1.5257952213287354, 1.3902842998504639, 1.98858642578125, 1.2181018590927124, 1.135389804840088, 1.085714340209961, 1.2233744859695435, 1.033466100692749]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.697272539138794] ms
 --  Average per query NF    [1.3612127304077148] ms
 --  Average per query vegas [2.336059808731079] ms
Mean [1.151]  Median [1.118]  95th [1.425]  99th [1.612]  max [1.989]
Mean [1.151]  Median [1.118]  95th [1.425]  99th [1.612]  max [1.989]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.847366 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=valueskew', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
ValueSample - START
ValueSample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[2.9802322e-07 4.7683716e-07 2.9802322e-07 6.5565109e-07 8.9296699e-03]
Distance score: 0.0017862797249108553
SAUCE Drift detection: True
Detection latency: 0.0233s

DRIFT-DETECTED after 2-th workload
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/incremental_train.py', '--dataset=bjaq', '--end2end', '--model=face', '--model_update=adapt', '--update_size=80000', '--epochs=0']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
update_size: 76433
AdaptTask - START
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
train data shape: 80000, transfer data shape:16000
Training done; evaluating likelihood on full data:
Saved to: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
AdaptTask - END

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.051499 | Model-update-time: 2.208043


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=valueskew', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.198400020599365
tensor(0.9940)
result is  tensor(455866.1250)
Enter testHyper
ReportEsts: [1.1837735176086426, 1.0489168167114258, 1.3226299285888672, 1.4855296611785889, 1.0335427522659302, 2.6083645820617676, 1.2031582593917847, 1.023890733718872, 1.5214875936508179, 1.1105214357376099, 1.0388476848602295, 1.6708314418792725, 1.0501253604888916, 1.1775637865066528, 1.0344171524047852, 1.2838799953460693, 1.4498335123062134, 1.1179966926574707, 1.0261263847351074, 1.8941359519958496, 1.15822172164917, 1.930685043334961, 1.4437401294708252, 1.0381520986557007, 1.212166428565979, 1.3580580949783325, 1.1485134363174438, 1.4713455438613892, 5.279069900512695, 1.5637823343276978, 1.454545497894287, 1.5508474111557007, 1.1647887229919434, 99.45454406738281, 1.1143800020217896, 1.0780911445617676, 1.0959715843200684, 1.0244200229644775, 1.2741901874542236, 1.1057523488998413, 1.0055779218673706, 1.2733078002929688, 69.12857055664062, 1.1326794624328613, 1.2186368703842163, 1.1084399223327637, 1.3840564489364624, 1.0868239402770996, 1.3523809909820557, 1.199934959411621, 1.1463170051574707, 1.205565094947815, 1.0329561233520508, 1.22826087474823, 1.0251458883285522, 1.1934713125228882, 1.172255516052246, 1.2131662368774414, 1.2183877229690552, 1.0349079370498657, 1.377892017364502, 1.019088864326477, 1.0397058725357056, 1.515631079673767, 1.1026161909103394, 1.0864003896713257, 1.242208480834961, 2.149587631225586, 1.1506909132003784, 1.0932849645614624, 1.2625395059585571, 1.1464232206344604, 1.0377390384674072, 1.044820785522461, 1.0293681621551514, 1.2197203636169434, 1.5354430675506592, 1.079153060913086, 1.2759649753570557, 1.1261911392211914, 1.2841328382492065, 1.0947163105010986, 1.4649384021759033, 1.150436282157898, 1.1249101161956787, 1.5404255390167236, 1.3123537302017212, 1.4579439163208008, 1.0081307888031006, 1.548741102218628, 1.1147499084472656, 1.1089067459106445, 1.0732635259628296, 1.5478090047836304, 1.164488673210144, 1.1961429119110107, 1.0727179050445557, 1.2215642929077148, 1.414138913154602, 2.4522969722747803, 1.4387452602386475, 1.1442012786865234, 1.102449893951416, 1.2857863903045654, 1.0810904502868652, 1.0726375579833984, 1.0286909341812134, 1.1927465200424194, 1.1764706373214722, 1.0813477039337158, 1.1343449354171753, 1.0798100233078003, 1.1246252059936523, 1.286553144454956, 1.0630220174789429, 1.0543005466461182, 1.3366508483886719, 1.334546446800232, 6.425145149230957, 1.0796459913253784, 1.0214064121246338, 1.0262346267700195, 1.2414096593856812, 1.4748618602752686, 1.016347050666809, 1.3048646450042725, 1.1356297731399536, 1.258164882659912, 1.1889703273773193, 1.145542025566101, 1.2030081748962402, 1.2933814525604248, 1.0861414670944214, 1.187780737876892, 1.7856431007385254, 1.565102458000183, 1.0525422096252441, 1.1479600667953491, 1.109165072441101, 1.0271745920181274, 1.056789755821228, 1.2343173027038574, 1.006406307220459, 1.7712675333023071, 1.0314600467681885, 1.02120041847229, 1.2411764860153198, 1.0827635526657104, 1.0302757024765015, 1.3285642862319946, 1.0748809576034546, 1.0575720071792603, 1.247435212135315, 1.0775679349899292, 1.0186339616775513, 1.1899142265319824, 1.0546952486038208, 1.291338562965393, 3.949840545654297, 1.0930145978927612, 1.0670750141143799, 1.1856540441513062, 1.5460461378097534, 1.0125266313552856, 1.1152209043502808, 6.236786365509033, 1.1381595134735107, 1.1140153408050537, 1.0529299974441528, 1.2674189805984497, 1.1201404333114624, 1.043002963066101, 1.1980066299438477, 1.555295467376709, 1.1612902879714966, 1.2632222175598145, 1.1401804685592651, 1.4123457670211792, 1.081527829170227, 1.4106335639953613, 1.8421052694320679, 1.0925397872924805, 1.0483940839767456, 1.5964041948318481, 1.0438231229782104, 1.1979444026947021, 1.6936230659484863, 1.0475026369094849, 1.0864874124526978, 1.014007806777954, 1.1329545974731445, 1.077675700187683, 1.0794471502304077, 1.3629064559936523, 1.0480436086654663, 8.146998405456543, 1.347745656967163, 1.103938102722168, 1.1201353073120117, 1.2101577520370483]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.649822473526001] ms
 --  Average per query NF    [1.3615763187408447] ms
 --  Average per query vegas [2.2882461547851562] ms
Mean [2.178]  Median [1.154]  95th [1.942]  99th [8.757]  max [99.455]
Mean [2.178]  Median [1.154]  95th [1.942]  99th [8.757]  max [99.455]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.370411 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=1 | total-time=28.511032