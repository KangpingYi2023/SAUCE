Input arguments = Namespace(data_update='tupleskew', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 17, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.164860963821411
tensor(0.9962)
result is  tensor(380719.3750)
Enter testHyper
ReportEsts: [1.1553094387054443, 1.0419188737869263, 1.2538875341415405, 1.112865924835205, 1.2300347089767456, 1.1271507740020752, 1.2436734437942505, 1.0708056688308716, 1.07602858543396, 1.1544897556304932, 1.115417718887329, 1.1194915771484375, 1.0096211433410645, 1.0446428060531616, 1.154948353767395, 1.1736830472946167, 1.1110213994979858, 1.1933491230010986, 1.0855461359024048, 1.0816326141357422, 1.0095616579055786, 1.0195555686950684, 1.152085542678833, 1.1233817338943481, 1.1269296407699585, 1.0877034664154053, 1.0295608043670654, 1.4622000455856323, 1.0279958248138428, 1.038449764251709, 1.1245121955871582, 1.0934730768203735, 1.0828067064285278, 1.0363961458206177, 1.131650447845459, 1.0673854351043701, 1.4860565662384033, 1.0104373693466187, 1.0547598600387573, 1.039721131324768, 1.0738143920898438, 1.1296565532684326, 1.0921183824539185, 1.0902338027954102, 1.1204310655593872, 1.0600906610488892, 1.0027964115142822, 1.212995171546936, 1.1457773447036743, 1.0930626392364502, 1.1760203838348389, 1.385728359222412, 1.061346173286438, 1.19486403465271, 1.1131597757339478, 1.000927209854126, 1.4813084602355957, 1.1204191446304321, 1.1411586999893188, 1.533118724822998, 1.3243372440338135, 1.1357594728469849, 1.4603317975997925, 1.0869964361190796, 1.2741312980651855, 1.0285714864730835, 1.2222222089767456, 1.0474284887313843, 1.014487862586975, 1.2736842632293701, 1.1295253038406372, 1.209873914718628, 1.3219331502914429, 1.2035820484161377, 1.123373031616211, 1.2489997148513794, 1.7097688913345337, 1.0202387571334839, 1.0218112468719482, 1.2436126470565796, 1.2987918853759766, 1.2038443088531494, 1.0874700546264648, 1.2315287590026855, 1.2282872200012207, 1.1741533279418945, 1.1849547624588013, 1.1091550588607788, 1.0784512758255005, 1.2012604475021362, 1.0512022972106934, 1.3784202337265015, 1.0140641927719116, 1.1828927993774414, 1.133720874786377, 1.102611780166626, 1.0179427862167358, 1.3703197240829468, 1.0526316165924072, 1.1983896493911743, 1.0719895362854004, 1.1364340782165527, 1.093082070350647, 1.018642783164978, 1.0265220403671265, 1.0234471559524536, 1.1672297716140747, 1.1483420133590698, 1.0892415046691895, 1.0075984001159668, 1.2340203523635864, 1.0606335401535034, 1.1337052583694458, 1.0485488176345825, 1.410455584526062, 1.0809524059295654, 1.010643720626831, 1.0457887649536133, 1.2112065553665161, 1.1073757410049438, 1.2477294206619263, 1.1163239479064941, 1.0158504247665405, 1.272765874862671, 1.2403100728988647, 1.212546467781067, 1.1157779693603516, 1.1391266584396362, 1.2928869724273682, 1.096860408782959, 1.1161128282546997, 1.2958868741989136, 1.1215040683746338, 1.4642857313156128, 1.1143854856491089, 1.181937575340271, 1.0194801092147827, 1.1180487871170044, 1.1286472082138062, 1.2341935634613037, 1.1495842933654785, 1.2312803268432617, 1.2045584917068481, 1.3013449907302856, 1.0810409784317017, 1.0004432201385498, 1.010964274406433, 1.4316484928131104, 1.071115493774414, 1.005570650100708, 1.003280520439148, 1.1481860876083374, 1.315002679824829, 1.3526734113693237, 1.1226825714111328, 1.0093138217926025, 1.1727067232131958, 1.0413618087768555, 1.0971990823745728, 1.1380482912063599, 1.188604712486267, 1.0835354328155518, 1.070390224456787, 1.2594085931777954, 1.1456310749053955, 1.1272987127304077, 1.1737016439437866, 1.3514482975006104, 1.13092839717865, 1.070214033126831, 1.0157605409622192, 1.0990855693817139, 1.1168831586837769, 1.0890040397644043, 1.012413740158081, 1.157319188117981, 1.0024354457855225, 1.2942097187042236, 1.0397382974624634, 1.0034382343292236, 1.185605764389038, 1.0151376724243164, 1.0052777528762817, 1.0909091234207153, 1.1245925426483154, 1.1236786842346191, 1.0046989917755127, 1.2855098247528076, 1.0740277767181396, 1.2484508752822876, 1.0059483051300049, 1.0030311346054077, 1.5629792213439941, 1.5809792280197144, 1.610053300857544, 1.2391303777694702, 1.0410970449447632, 1.1515151262283325, 1.017088532447815, 1.1698870658874512]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.762381076812744] ms
 --  Average per query NF    [1.3656795024871826] ms
 --  Average per query vegas [2.3967015743255615] ms
Mean [1.150]  Median [1.122]  95th [1.433]  99th [1.581]  max [1.710]
Mean [1.150]  Median [1.122]  95th [1.433]  99th [1.581]  max [1.710]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.817412 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=tupleskew', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
TupleSkewSample - START
0.001
TupleSkewSample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[3.2210350e-04 3.6758184e-04 1.9311905e-05 1.4650822e-04 1.4841557e-05]
Distance score: 0.0001740693987812847
SAUCE Drift detection: True
Detection latency: 0.0244s

DRIFT-DETECTED after 2-th workload
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/incremental_train.py', '--dataset=bjaq', '--end2end', '--model=face', '--model_update=adapt', '--update_size=80000', '--epochs=0']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
update_size: 76433
AdaptTask - START
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
train data shape: 80000, transfer data shape:16000
Training done; evaluating likelihood on full data:
Saved to: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
AdaptTask - END

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.008702 | Model-update-time: 2.243428


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=tupleskew', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.16987133026123
tensor(0.9937)
result is  tensor(455706.6250)
Enter testHyper
ReportEsts: [1.0140000581741333, 1.0847744941711426, 1.234100103378296, 1.8997721672058105, 1.0735535621643066, 1.4950882196426392, 1.140154480934143, 1.0646365880966187, 1.052334189414978, 1.384615421295166, 1.0965754985809326, 1.031632900238037, 1.5833333730697632, 1.1192352771759033, 1.469275712966919, 1.037655234336853, 1.1849321126937866, 1.1240230798721313, 1.0438605546951294, 1.2801412343978882, 1.058401346206665, 1.1419318914413452, 1.1361817121505737, 1.078773856163025, 1.1909136772155762, 1.2386151552200317, 1.0745596885681152, 1.1267154216766357, 1.1254125833511353, 1.4665604829788208, 1.1907957792282104, 1.4661016464233398, 1.0721601247787476, 1.0172746181488037, 1.0441385507583618, 1.000596523284912, 1.1628338098526, 2.127659559249878, 1.1868122816085815, 1.0345304012298584, 1.052427887916565, 1.219667911529541, 1.5189075469970703, 1.05846107006073, 1.0800535678863525, 1.06053626537323, 2.043731689453125, 1.1106764078140259, 1.4190475940704346, 1.0096582174301147, 1.033540964126587, 1.0597232580184937, 1.05557382106781, 1.0029820203781128, 1.1436576843261719, 1.1940791606903076, 1.0371330976486206, 1.002632737159729, 1.3211321830749512, 1.0298563241958618, 1.1601731777191162, 1.023010492324829, 1.093973994255066, 1.62546706199646, 1.0851788520812988, 1.1409231424331665, 1.3704807758331299, 1.0332589149475098, 1.1592310667037964, 1.0881409645080566, 1.210577368736267, 1.196997880935669, 1.2694278955459595, 1.055381417274475, 1.1061604022979736, 1.0422568321228027, 3.41717791557312, 1.0387029647827148, 1.308449625968933, 1.2146698236465454, 1.008920431137085, 1.7064363956451416, 1.1786779165267944, 1.114406943321228, 1.4733812808990479, 1.5957447290420532, 1.1934007406234741, 1.3797752857208252, 1.2336759567260742, 1.3212573528289795, 1.1194361448287964, 1.1422603130340576, 1.2194786071777344, 1.1034621000289917, 1.1685959100723267, 1.06647789478302, 1.0689740180969238, 1.2009282112121582, 1.4682179689407349, 1.3264340162277222, 1.0650365352630615, 1.124344825744629, 1.0808823108673096, 1.2737586498260498, 1.018129825592041, 1.2788877487182617, 1.0474317073822021, 1.125867247581482, 1.0028653144836426, 1.125726580619812, 1.0400419235229492, 1.0154902935028076, 1.1418416500091553, 1.1330939531326294, 1.1681195497512817, 1.067892074584961, 1.2224324941635132, 1.0132644176483154, 1.0628244876861572, 1.0796459913253784, 1.0733367204666138, 1.1991199254989624, 1.0340157747268677, 1.0224723815917969, 1.0022838115692139, 1.0315788984298706, 1.003876805305481, 1.3882725238800049, 1.0749304294586182, 1.1405720710754395, 1.8181818723678589, 1.156410574913025, 1.0127989053726196, 1.879347801208496, 1.61421799659729, 1.2424126863479614, 1.0950695276260376, 1.074252963066101, 1.0652729272842407, 1.0009799003601074, 1.051628589630127, 1.183076024055481, 1.0067206621170044, 1.0140771865844727, 1.0089459419250488, 1.0637530088424683, 3.6647398471832275, 1.039857029914856, 1.0648587942123413, 1.119827151298523, 1.0464364290237427, 1.2710280418395996, 1.1578750610351562, 1.0073349475860596, 1.0593936443328857, 1.0499454736709595, 1.0266635417938232, 1.078740119934082, 1.4309284687042236, 1.033530592918396, 2.2448275089263916, 1.382140874862671, 1.1132686138153076, 1.1479815244674683, 1.088158369064331, 1.1505556106567383, 1.0466965436935425, 1.3530024290084839, 1.0040606260299683, 1.1125234365463257, 1.0200200080871582, 1.0022960901260376, 1.9442675113677979, 1.2808728218078613, 1.0855180025100708, 1.0833333730697632, 1.131839394569397, 1.160169243812561, 1.1378852128982544, 1.202908992767334, 1.8421052694320679, 1.2891656160354614, 1.1972510814666748, 1.4077577590942383, 1.3318272829055786, 1.128132700920105, 1.328727126121521, 1.0284758806228638, 1.4706389904022217, 1.1640044450759888, 1.2063597440719604, 1.0286346673965454, 1.2699593305587769, 2.1268692016601562, 1.0030938386917114, 1.0088552236557007, 1.2053316831588745, 1.0851771831512451, 1.074018120765686, 1.0584524869918823]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.725355863571167] ms
 --  Average per query NF    [1.3610148429870605] ms
 --  Average per query vegas [2.3643410205841064] ms
Mean [1.214]  Median [1.122]  95th [1.819]  99th [2.257]  max [3.665]
Mean [1.214]  Median [1.122]  95th [1.819]  99th [2.257]  max [3.665]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.377590 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=1 | total-time=28.501074