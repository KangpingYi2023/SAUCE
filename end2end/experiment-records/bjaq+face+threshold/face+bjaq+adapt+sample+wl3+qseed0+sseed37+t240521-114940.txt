Input arguments = Namespace(data_update='sample', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 37, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.16319990158081
tensor(0.9967)
result is  tensor(380914.4375)
Enter testHyper
ReportEsts: [1.125899314880371, 1.015339732170105, 1.5276644229888916, 1.1339229345321655, 1.2364747524261475, 1.0917423963546753, 1.0254133939743042, 1.1587743759155273, 1.0485183000564575, 1.1287541389465332, 1.1714040040969849, 1.1523305177688599, 1.1866296529769897, 1.0066964626312256, 1.1625449657440186, 1.1437474489212036, 1.2575291395187378, 1.2502375841140747, 1.1815341711044312, 1.1607142686843872, 1.1580132246017456, 1.0114285945892334, 1.1711241006851196, 1.0550429821014404, 1.141386866569519, 1.1717902421951294, 1.056869387626648, 1.362869143486023, 1.077711820602417, 1.0723222494125366, 1.1291238069534302, 1.0909693241119385, 1.1819214820861816, 1.0308153629302979, 1.169535517692566, 1.2775614261627197, 1.3786596059799194, 1.2020742893218994, 1.0895642042160034, 1.1541317701339722, 1.000292181968689, 1.0399129390716553, 1.0119233131408691, 1.0279719829559326, 1.0382421016693115, 1.0714285373687744, 1.0949172973632812, 1.3218477964401245, 1.0163885354995728, 1.3045685291290283, 1.2036553621292114, 1.1985210180282593, 1.0455445051193237, 1.2567524909973145, 1.034165859222412, 1.0558003187179565, 1.3607476949691772, 1.2088744640350342, 1.181809902191162, 1.3772727251052856, 1.1988502740859985, 1.086478352546692, 1.2367349863052368, 1.2413345575332642, 1.1578947305679321, 1.2000000476837158, 1.1107174158096313, 1.0038244724273682, 1.2014515399932861, 1.2526315450668335, 1.1415929794311523, 1.0947225093841553, 1.1836845874786377, 1.1896741390228271, 1.1565965414047241, 1.05608332157135, 1.8376610279083252, 1.0712679624557495, 1.0310651063919067, 1.398241639137268, 1.412782907485962, 1.1645938158035278, 1.1876869201660156, 1.2248497009277344, 1.224227786064148, 1.1528569459915161, 1.0217171907424927, 1.1576796770095825, 1.0219478607177734, 1.054661512374878, 1.0913904905319214, 1.392133355140686, 1.0396682024002075, 1.335598111152649, 1.1271675825119019, 1.0449814796447754, 1.14882230758667, 1.2830638885498047, 1.034482717514038, 1.2496957778930664, 1.2390317916870117, 1.1509172916412354, 1.0323649644851685, 1.0117130279541016, 1.0231164693832397, 1.0481826066970825, 1.092966914176941, 1.1675392389297485, 1.0704723596572876, 1.0442414283752441, 1.0558364391326904, 1.076216697692871, 1.1342377662658691, 1.024004340171814, 1.237046480178833, 1.1947368383407593, 1.0549956560134888, 1.1386560201644897, 1.360898733139038, 1.0683475732803345, 1.2963260412216187, 1.0808610916137695, 1.0958858728408813, 1.0899590253829956, 1.3129844665527344, 1.1933553218841553, 1.1162638664245605, 1.001382827758789, 1.381932020187378, 1.1002004146575928, 1.0587304830551147, 1.0541762113571167, 1.194530725479126, 1.4285714626312256, 1.13461434841156, 1.0333421230316162, 1.0444507598876953, 1.1830893754959106, 1.1333997249603271, 1.03629469871521, 1.136343240737915, 1.1270848512649536, 1.097411870956421, 1.1835492849349976, 1.0474470853805542, 1.002944827079773, 1.1460046768188477, 1.6238890886306763, 1.1219532489776611, 1.1370028257369995, 1.3334410190582275, 1.159851312637329, 1.306631326675415, 1.208608627319336, 1.2269909381866455, 1.0115838050842285, 1.000787377357483, 1.0557118654251099, 1.0126440525054932, 1.167830467224121, 1.238847255706787, 1.0535355806350708, 1.0307462215423584, 1.3482013940811157, 1.0465631484985352, 1.0099167823791504, 1.1591393947601318, 1.1389949321746826, 1.0331553220748901, 1.0092062950134277, 1.0304272174835205, 1.0091160535812378, 1.1363636255264282, 1.2296717166900635, 1.0381470918655396, 1.0185989141464233, 1.0855199098587036, 1.2138813734054565, 1.3390860557556152, 1.0062936544418335, 1.0090073347091675, 1.0837993621826172, 1.0055570602416992, 1.079673171043396, 1.148134708404541, 1.1226215362548828, 1.0170202255249023, 1.2791029214859009, 1.0210630893707275, 1.292631983757019, 1.0256232023239136, 1.0066264867782593, 1.3522862195968628, 1.083691954612732, 1.7898063659667969, 1.2600780725479126, 1.1320966482162476, 1.0555555820465088, 1.0282394886016846, 1.0718791484832764]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.744598627090454] ms
 --  Average per query NF    [1.3626420497894287] ms
 --  Average per query vegas [2.3819565773010254] ms
Mean [1.148]  Median [1.133]  95th [1.377]  99th [1.626]  max [1.838]
Mean [1.148]  Median [1.133]  95th [1.377]  99th [1.626]  max [1.838]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.856893 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=sample', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
Sample - START
Sample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[3.5762787e-07 5.9604645e-07 3.5762787e-07 1.4305115e-06 1.7881393e-07]
Distance score: 5.841255301675119e-07
SAUCE Drift detection: False
Detection latency: 0.0233s

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.028306 | Model-update-time: 0.000000


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=sample', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.168099641799927
tensor(0.9948)
result is  tensor(456199.7188)
Enter testHyper
ReportEsts: [1.3259714841842651, 1.038764238357544, 1.0585241317749023, 1.0829018354415894, 1.0303380489349365, 1.313694715499878, 1.0928674936294556, 1.0611019134521484, 1.0732976198196411, 1.1483983993530273, 1.01374351978302, 1.1985480785369873, 1.2412935495376587, 1.1280319690704346, 1.085025429725647, 1.1129019260406494, 1.5302367210388184, 1.2144922018051147, 1.1213871240615845, 1.282019019126892, 1.1434601545333862, 1.1155332326889038, 1.1746145486831665, 1.1581765413284302, 1.2921725511550903, 1.1417399644851685, 1.1259346008300781, 1.0647141933441162, 1.1894179582595825, 1.2933824062347412, 1.162372350692749, 1.3138686418533325, 1.1677688360214233, 1.135793685913086, 1.0003782510757446, 1.2611955404281616, 1.099471926689148, 1.2326996326446533, 1.248853087425232, 1.0993843078613281, 1.0690940618515015, 1.0728100538253784, 1.2325854301452637, 1.0783777236938477, 1.102622389793396, 1.0976006984710693, 1.046413779258728, 1.0488499402999878, 1.1411290168762207, 1.2314976453781128, 1.0550211668014526, 1.0164809226989746, 1.172724962234497, 1.0371187925338745, 1.0044810771942139, 1.4308807849884033, 1.1991004943847656, 1.112969994544983, 1.1984974145889282, 1.0662418603897095, 1.591478705406189, 1.0489165782928467, 1.1076265573501587, 1.2996551990509033, 1.0126843452453613, 1.046907901763916, 1.2773956060409546, 1.1183645725250244, 1.1819736957550049, 1.088562250137329, 1.268120288848877, 1.1492581367492676, 1.0997065305709839, 1.1848183870315552, 1.2409590482711792, 1.5713123083114624, 1.1156723499298096, 1.3023890256881714, 1.2383432388305664, 1.1240144968032837, 1.2321428060531616, 1.1390575170516968, 1.0006195306777954, 1.095167636871338, 1.308050274848938, 1.4029303789138794, 1.1641618013381958, 1.6774073839187622, 1.0418988466262817, 1.16925847530365, 1.1725915670394897, 1.2359857559204102, 1.3301403522491455, 1.1757912635803223, 1.2519505023956299, 1.0252841711044312, 1.1902809143066406, 1.1927531957626343, 1.0625091791152954, 1.0213903188705444, 1.0929349660873413, 1.1093577146530151, 1.1451612710952759, 1.013999104499817, 1.0085313320159912, 1.2620152235031128, 1.2171438932418823, 1.1688228845596313, 1.128947377204895, 1.0764273405075073, 1.0590293407440186, 1.0266211032867432, 1.1866543292999268, 1.316145658493042, 1.063617467880249, 1.0593899488449097, 1.1287503242492676, 1.2027902603149414, 1.0758960247039795, 1.1355931758880615, 1.0546430349349976, 1.290091872215271, 1.0045592784881592, 1.7052239179611206, 1.0797443389892578, 1.1750144958496094, 1.2392103672027588, 1.2877813577651978, 1.0449033975601196, 1.149806261062622, 1.2217923402786255, 1.1130597591400146, 1.17111074924469, 1.8031854629516602, 1.874458909034729, 1.006880283355713, 1.023935079574585, 1.021295428276062, 1.1217310428619385, 1.0092332363128662, 1.0559881925582886, 1.1556284427642822, 1.033815622329712, 1.0698318481445312, 1.0192818641662598, 1.0102405548095703, 1.4078211784362793, 1.0779777765274048, 1.2059623003005981, 1.0682978630065918, 1.2330690622329712, 1.048040509223938, 1.058152198791504, 1.0874077081680298, 1.0779088735580444, 1.4534056186676025, 1.114039659500122, 1.2439024448394775, 1.2026779651641846, 1.2425262928009033, 1.0408433675765991, 1.011534571647644, 1.1921147108078003, 1.0809541940689087, 1.116911768913269, 1.028696060180664, 1.092875361442566, 1.1884503364562988, 1.0428379774093628, 1.1814117431640625, 1.111458420753479, 1.15842604637146, 1.4393837451934814, 1.101237416267395, 1.170674443244934, 1.0372594594955444, 1.1174933910369873, 1.0433743000030518, 1.025222897529602, 1.1481289863586426, 1.5909091234207153, 1.0895397663116455, 1.1011193990707397, 1.4324324131011963, 1.4799022674560547, 1.1378744840621948, 1.3467848300933838, 1.041215419769287, 1.3421940803527832, 1.0506004095077515, 1.132490634918213, 1.0464240312576294, 1.2939157485961914, 1.4700394868850708, 1.0244150161743164, 1.0464211702346802, 1.3559471368789673, 1.0578818321228027, 1.218181848526001, 1.145928978919983]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.733646869659424] ms
 --  Average per query NF    [1.354755163192749] ms
 --  Average per query vegas [2.378891706466675] ms
Mean [1.167]  Median [1.129]  95th [1.454]  99th [1.706]  max [1.874]
Mean [1.167]  Median [1.129]  95th [1.454]  99th [1.706]  max [1.874]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.200626 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=0 | total-time=26.209432