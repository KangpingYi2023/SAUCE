Input arguments = Namespace(data_update='valueskew', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 51, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.160147190093994
tensor(0.9913)
result is  tensor(378849.5938)
Enter testHyper
ReportEsts: [1.107813835144043, 1.020031213760376, 1.2869689464569092, 1.1973047256469727, 1.2510299682617188, 1.1360443830490112, 1.174142599105835, 1.178470253944397, 1.0850871801376343, 1.2085832357406616, 1.0577088594436646, 1.1514830589294434, 1.0415775775909424, 1.0446428060531616, 1.1715856790542603, 1.2388840913772583, 1.2089611291885376, 1.2285035848617554, 1.1493921279907227, 1.0969387292861938, 1.0336657762527466, 1.0397412776947021, 1.139652967453003, 1.0835312604904175, 1.1618067026138306, 1.0298372507095337, 1.0670045614242554, 1.2607338428497314, 1.0116864442825317, 1.2403621673583984, 1.1724015474319458, 1.1989338397979736, 1.0089834928512573, 1.0140129327774048, 1.1305385828018188, 1.0495471954345703, 1.4488294124603271, 1.0912604331970215, 1.1095192432403564, 1.038083791732788, 1.0193567276000977, 1.0510401725769043, 1.1323394775390625, 1.0868324041366577, 1.0676103830337524, 1.0589568614959717, 1.0065016746520996, 1.396958827972412, 1.0459884405136108, 1.1184433698654175, 1.2734806537628174, 1.348479986190796, 1.0750113725662231, 1.2551571130752563, 1.0751649141311646, 1.0041899681091309, 1.2850466966629028, 1.0766619443893433, 1.028568148612976, 1.3721696138381958, 1.3029624223709106, 1.1426297426223755, 1.3644527196884155, 1.1326518058776855, 1.3095238208770752, 1.2571429014205933, 1.2000000476837158, 1.0985904932022095, 1.0461130142211914, 1.2000000476837158, 1.105390191078186, 1.1677528619766235, 1.1422982215881348, 1.1554492712020874, 1.2794249057769775, 1.1731714010238647, 1.9520949125289917, 1.0526219606399536, 1.1013765335083008, 1.3560969829559326, 1.013645887374878, 1.0403811931610107, 1.004373550415039, 1.2475863695144653, 1.2404688596725464, 1.1068336963653564, 1.262764573097229, 1.1409331560134888, 1.1531864404678345, 1.0238580703735352, 1.0308703184127808, 1.2566938400268555, 1.0299314260482788, 1.2797024250030518, 1.1963189840316772, 1.0808546543121338, 1.191623568534851, 1.3821556568145752, 1.01694917678833, 1.1025184392929077, 1.148667573928833, 1.1150637865066528, 1.0248546600341797, 1.0204977989196777, 1.05585777759552, 1.0299357175827026, 1.0481672286987305, 1.1867364645004272, 1.0751276016235352, 1.0513192415237427, 1.3136522769927979, 1.0821791887283325, 1.1079845428466797, 1.03574538230896, 1.1651791334152222, 1.1947368383407593, 1.0629770755767822, 1.0290210247039795, 1.3933902978897095, 1.0660290718078613, 1.2360260486602783, 1.0529184341430664, 1.0348069667816162, 1.1683199405670166, 1.261143445968628, 1.1641559600830078, 1.1261531114578247, 1.1204146146774292, 1.328460931777954, 1.0965263843536377, 1.1469433307647705, 1.114106297492981, 1.264449954032898, 1.3928571939468384, 1.1793982982635498, 1.0181769132614136, 1.0370677709579468, 1.1180487871170044, 1.0386518239974976, 1.2001254558563232, 1.1071232557296753, 1.2027473449707031, 1.0871871709823608, 1.2575523853302002, 1.1140228509902954, 1.1153441667556763, 1.0602338314056396, 1.444779872894287, 1.0440784692764282, 1.0580966472625732, 1.1527174711227417, 1.1960004568099976, 1.3157051801681519, 1.0633577108383179, 1.1689800024032593, 1.0288355350494385, 1.0248072147369385, 1.0461452007293701, 1.0419766902923584, 1.2562220096588135, 1.2496984004974365, 1.0106711387634277, 1.0308781862258911, 1.2748299837112427, 1.1799999475479126, 1.0617117881774902, 1.051470398902893, 1.2024848461151123, 1.0567498207092285, 1.056118369102478, 1.06313157081604, 1.0872265100479126, 1.1298701763153076, 1.0887254476547241, 1.1389645338058472, 1.0350056886672974, 1.0167983770370483, 1.3634008169174194, 1.1955136060714722, 1.0591293573379517, 1.1101807355880737, 1.0592774152755737, 1.0175002813339233, 1.121552586555481, 1.1332850456237793, 1.1236786842346191, 1.1032533645629883, 1.2562936544418335, 1.0081743001937866, 1.3760840892791748, 1.0162241458892822, 1.0203551054000854, 1.6124293804168701, 1.3529411554336548, 2.0600273609161377, 1.326488733291626, 1.0753231048583984, 1.1515151262283325, 1.2314574718475342, 1.055511236190796]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.760308027267456] ms
 --  Average per query NF    [1.3589513301849365] ms
 --  Average per query vegas [2.4013566970825195] ms
Mean [1.151]  Median [1.117]  95th [1.372]  99th [1.616]  max [2.060]
Mean [1.151]  Median [1.117]  95th [1.372]  99th [1.616]  max [2.060]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.842041 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=valueskew', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
ValueSample - START
ValueSample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[3.5762787e-07 8.8331699e-03 1.4305115e-06 2.3245811e-06 2.3841858e-07]
Distance score: 0.0017675042618066072
SAUCE Drift detection: True
Detection latency: 0.0233s

DRIFT-DETECTED after 2-th workload
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/incremental_train.py', '--dataset=bjaq', '--end2end', '--model=face', '--model_update=adapt', '--update_size=80000', '--epochs=0']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
update_size: 76433
AdaptTask - START
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
train data shape: 80000, transfer data shape:16000
Training done; evaluating likelihood on full data:
Saved to: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
AdaptTask - END

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.050751 | Model-update-time: 2.241035


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=valueskew', '--model_update=adapt']
/home/kangping/code_copy/SAUCE/./FACE/FACE_utils/dataUtils.py:321: RuntimeWarning: invalid value encountered in cast
  oracle_cards = oracle_cards.astype(np.int32)
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.171468019485474
tensor(0.9920)
result is  tensor(454925.8438)
Enter testHyper
ReportEsts: [1.0321340560913086, 1.157874345779419, 1.179063320159912, 1.244956135749817, 1.0213085412979126, 1.8391705751419067, 1.2122126817703247, 1.040827989578247, 1.0382513999938965, 1.7105201482772827, 1.525333285331726, 1.028395414352417, 1.3540540933609009, 1.0952935218811035, 20.504638671875, 1.0773954391479492, 1.0210679769515991, 1.0056716203689575, 1.1820924282073975, 1.4193580150604248, 1.2575631141662598, 1.99933922290802, 1.0422585010528564, 3.923307180404663, 1.0881214141845703, 1.0768827199935913, 1.1303000450134277, 1.3333333730697632, 2.6016860008239746, 1.3185241222381592, 1.103196382522583, 1.2463767528533936, 1.4280216693878174, 1.6373804807662964, 1.1539324522018433, 1.0141162872314453, 1.2441635131835938, 1.1981594562530518, 1.2845991849899292, 1.0817961692810059, 1.2265398502349854, 1.158365249633789, 1.3903779983520508, 1.2441822290420532, 1.2810934782028198, 1.05112624168396, 1.0218290090560913, 1.2545539140701294, 1.2714285850524902, 1.2324445247650146, 1.127011775970459, 1.0265297889709473, 1.0110645294189453, 1.0997674465179443, 1.004945993423462, 1.0264145135879517, 1.051601529121399, 1.11179780960083, 1.0557719469070435, 1.4757492542266846, 1.365384578704834, 1.0935853719711304, 36.52450180053711, 1.3131120204925537, 1.0606664419174194, 1.957137107849121, 1.2864060401916504, 1.026358962059021, 1.1422346830368042, 1.33255934715271, 1.0047975778579712, 1.120147943496704, 1.265541911125183, 1.0945852994918823, 1.6690119504928589, 1.064976453781128, 101.66666412353516, 2.6410155296325684, 1.231508731842041, 1.0940029621124268, 1.1891891956329346, 1.0023014545440674, 1.0524981021881104, 1.0987629890441895, 1.2704675197601318, 1.655319094657898, 1.6462644338607788, 1.3187742233276367, 1.0896692276000977, 1.3156617879867554, 1.0265560150146484, 1.165606141090393, 1.582838773727417, 1.0178885459899902, 37.394256591796875, 1.1453694105148315, 1.0451688766479492, 1.2442814111709595, 1.0474289655685425, 1.0321760177612305, 1.182044506072998, 1.3272154331207275, 1.2386934757232666, 1.028100609779358, 1.0800418853759766, 1.055207371711731, 1.0042967796325684, 1.0576252937316895, 1.0286532640457153, 1.13983952999115, 1.2011765241622925, 1.4662911891937256, 1.2541296482086182, 1.3797801733016968, 1.356246829032898, 1.2178399562835693, 1.0298784971237183, 1.248958945274353, 1.0351439714431763, 1.0227272510528564, 1.0503425598144531, 1.0688607692718506, 1.1149976253509521, 2.3529412746429443, 1.0665675401687622, 1.2431631088256836, 1.018865704536438, 1.31220281124115, 1.4414381980895996, 1.128063678741455, 1.005929708480835, 1.0496137142181396, 1.1428300142288208, 1.5358526706695557, 1.2546530961990356, 1.1736773252487183, 1.039259672164917, 1.1394907236099243, 1.2854145765304565, 1.4156591892242432, 1.2319914102554321, 1.0420196056365967, 1.2496248483657837, 1.1566489934921265, 1.0449731349945068, 1.0443305969238281, 1.2267441749572754, 1.1307419538497925, 1.1828926801681519, 1.0348013639450073, 1.0825470685958862, 1.034005045890808, 1.1088484525680542, 1.1783218383789062, 1.189577579498291, 1.7944902181625366, 1.000140905380249, 1.13223135471344, 1.1993205547332764, 1.058930516242981, 1.920285940170288, 1.3630952835083008, 1.2033336162567139, 1.125259518623352, 1.254341959953308, 1.3813196420669556, 1.2345143556594849, 1.2540944814682007, 26.95833396911621, 1.2275638580322266, 1.0863046646118164, 1.205915093421936, 1.358703851699829, 1.0314358472824097, 1.3100017309188843, 1.280143141746521, 1.2996736764907837, 1.0355892181396484, 1.089971661567688, 1.3167035579681396, 1.5581395626068115, 1.0691540241241455, 1.2000797986984253, 1.2686007022857666, 1.3371306657791138, 1.0281609296798706, 1.6621167659759521, 1.1431788206100464, 1.2611271142959595, 1.0762048959732056, 1.104084849357605, 2.7675554752349854, 1.127974271774292, 1.5953947305679321, 1.0984697341918945, 1.0050209760665894, 1.3977205753326416, 2.6103005409240723, 1.6471631526947021, 1.3069089651107788]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7529611587524414] ms
 --  Average per query NF    [1.3655805587768555] ms
 --  Average per query vegas [2.387380599975586] ms
Mean [2.344]  Median [1.182]  95th [2.365]  99th [36.533]  max [101.667]
Mean [2.344]  Median [1.182]  95th [2.365]  99th [36.533]  max [101.667]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.379536 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=1 | total-time=28.538342