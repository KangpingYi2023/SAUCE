Input arguments = Namespace(data_update='valueskew', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 82, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.191237688064575
tensor(0.9899)
result is  tensor(378310.8125)
Enter testHyper
ReportEsts: [1.191857099533081, 1.0708940029144287, 1.2666631937026978, 1.1495051383972168, 1.2357558012008667, 1.1134529113769531, 1.1416584253311157, 1.1639279127120972, 1.0680674314498901, 1.0635281801223755, 1.0008612871170044, 1.1048728227615356, 1.1046276092529297, 1.0290178060531616, 1.1989262104034424, 1.4812953472137451, 1.2754595279693604, 1.2125890254974365, 1.1622867584228516, 1.0208333730697632, 1.083975911140442, 1.0378228425979614, 1.1102865934371948, 1.0767568349838257, 1.0969533920288086, 1.1455695629119873, 1.0951576232910156, 1.3964548110961914, 1.0251450538635254, 1.017699122428894, 1.1089038848876953, 1.028749942779541, 1.0202983617782593, 1.043904185295105, 1.1722121238708496, 1.1674686670303345, 1.3787248134613037, 1.0638790130615234, 1.0006660223007202, 1.1549700498580933, 1.0235223770141602, 1.2941460609436035, 1.2423245906829834, 1.0287162065505981, 1.1242340803146362, 1.0328798294067383, 1.220477819442749, 1.3390871286392212, 1.0947532653808594, 1.1015228033065796, 1.1582914590835571, 1.3829996585845947, 1.071144938468933, 1.113143801689148, 1.0706291198730469, 1.020398736000061, 1.1869158744812012, 1.2047706842422485, 1.0007268190383911, 1.3455793857574463, 1.32293701171875, 1.1825370788574219, 1.4766663312911987, 1.1274281740188599, 1.2087912559509277, 1.0571428537368774, 1.1785714626312256, 1.035433053970337, 1.003415822982788, 1.2842105627059937, 1.0603379011154175, 1.0048012733459473, 1.1600840091705322, 1.1992361545562744, 1.0902804136276245, 1.0202388763427734, 1.7707799673080444, 1.0515481233596802, 1.0538288354873657, 1.1495451927185059, 1.282074213027954, 1.0230979919433594, 1.0161857604980469, 1.1212040185928345, 1.3169697523117065, 1.0819177627563477, 1.1110011339187622, 1.1470869779586792, 1.1186662912368774, 1.0510821342468262, 1.0155737400054932, 1.4198609590530396, 1.025964617729187, 1.3211714029312134, 1.174698829650879, 1.0082305669784546, 1.2203346490859985, 1.3675167560577393, 1.01694917678833, 1.0747121572494507, 1.1683309078216553, 1.077978253364563, 1.0950013399124146, 1.0036603212356567, 1.0953974723815918, 1.050693392753601, 1.2155554294586182, 1.1884816884994507, 1.103027582168579, 1.0046050548553467, 1.1083259582519531, 1.0912476778030396, 1.173030972480774, 1.0283023118972778, 1.1612379550933838, 1.065727710723877, 1.0645734071731567, 1.0038845539093018, 1.0887454748153687, 1.1457760334014893, 1.2429258823394775, 1.1251552104949951, 1.1328932046890259, 1.1548526287078857, 1.2136627435684204, 1.1944903135299683, 1.0412970781326294, 1.2109023332595825, 1.2581433057785034, 1.1272544860839844, 1.1266045570373535, 1.0046722888946533, 1.1059664487838745, 1.5, 1.0684260129928589, 1.1428196430206299, 1.0819777250289917, 1.2448780536651611, 1.068576455116272, 1.2568987607955933, 1.1440589427947998, 1.1212278604507446, 1.165981411933899, 1.2890681028366089, 1.0712417364120483, 1.0055584907531738, 1.1639429330825806, 1.4189940690994263, 1.0853713750839233, 1.1376420259475708, 1.0817999839782715, 1.1624150276184082, 1.3128998279571533, 1.1950933933258057, 1.2851535081863403, 1.0402542352676392, 1.1314836740493774, 1.0261677503585815, 1.053580403327942, 1.0725157260894775, 1.1204578876495361, 1.048343539237976, 1.0117170810699463, 1.246010661125183, 1.140096664428711, 1.0328807830810547, 1.1962686777114868, 1.3179978132247925, 1.0836892127990723, 1.0092469453811646, 1.215425968170166, 1.0352061986923218, 1.1168831586837769, 1.1046648025512695, 1.0875340700149536, 1.1591761112213135, 1.0626822710037231, 1.2154104709625244, 1.1984963417053223, 1.2019398212432861, 1.0312459468841553, 1.0401326417922974, 1.0389610528945923, 1.0439224243164062, 1.206809163093567, 1.082452416419983, 1.0166327953338623, 1.2718584537506104, 1.0103602409362793, 1.4164713621139526, 1.0894631147384644, 1.0334399938583374, 1.6449568271636963, 1.58346426486969, 1.741255283355713, 1.3486430644989014, 1.0798249244689941, 1.085714340209961, 1.0042885541915894, 1.1632802486419678]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7458062171936035] ms
 --  Average per query NF    [1.3624536991119385] ms
 --  Average per query vegas [2.383352518081665] ms
Mean [1.147]  Median [1.113]  95th [1.397]  99th [1.646]  max [1.771]
Mean [1.147]  Median [1.113]  95th [1.397]  99th [1.646]  max [1.771]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.878231 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=valueskew', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
ValueSample - START
ValueSample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[2.9802322e-07 6.5565109e-07 1.5389502e-02 1.2516975e-06 2.3841858e-07]
Distance score: 0.0030783892143517733
SAUCE Drift detection: True
Detection latency: 0.0237s

DRIFT-DETECTED after 2-th workload
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/incremental_train.py', '--dataset=bjaq', '--end2end', '--model=face', '--model_update=adapt', '--update_size=80000', '--epochs=0']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
update_size: 76433
AdaptTask - START
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
train data shape: 80000, transfer data shape:16000
Training done; evaluating likelihood on full data:
Saved to: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
AdaptTask - END

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.054415 | Model-update-time: 2.240556


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=valueskew', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.16430926322937
tensor(0.9983)
result is  tensor(457827.0625)
Enter testHyper
ReportEsts: [1.5467723608016968, 1.1746550798416138, 1.0553064346313477, 1.0037919282913208, 1.321171522140503, 1.2901700735092163, 1.0739574432373047, 1.2091012001037598, 1.0765948295593262, 1.194690227508545, 1.2476520538330078, 1.8450865745544434, 1.2123457193374634, 1.270569920539856, 1.3847748041152954, 1.1028897762298584, 1.2860440015792847, 1.453832745552063, 1.008387804031372, 1.076603889465332, 1.0920774936676025, 1.1722124814987183, 6.884112358093262, 1.2000000476837158, 1.0486505031585693, 1.4788846969604492, 1.02396821975708, 1.3445756435394287, 1.5523693561553955, 1.1282578706741333, 1.0807543992996216, 1.4067796468734741, 1.150080680847168, 11.782896995544434, 1.1325461864471436, 1.0247465372085571, 1.1887919902801514, 1.1742292642593384, 1.0374387502670288, 1.2937837839126587, 1.0126688480377197, 1.1915708780288696, 1.3838635683059692, 1.0775409936904907, 1.0171946287155151, 1.0385082960128784, 1.168752908706665, 1.21037757396698, 1.2833333015441895, 1.8648052215576172, 1.150610089302063, 1.1300057172775269, 1.2542475461959839, 1.3558313846588135, 1.1587717533111572, 1.8978198766708374, 1.070773720741272, 1.0653502941131592, 1.2668249607086182, 1.1521681547164917, 1.3994778394699097, 1.3766275644302368, 1.0057530403137207, 1.3717894554138184, 1.0754204988479614, 14.667187690734863, 1.1558996438980103, 1.0032010078430176, 1.4183558225631714, 1.1137175559997559, 1.178597092628479, 1.1881612539291382, 1.1073542833328247, 1.1183613538742065, 1.0284664630889893, 1.2190260887145996, 212.0, 1.1653786897659302, 1.131022334098816, 1.0942786931991577, 1.1490368843078613, 1.1810959577560425, 1.1024911403656006, 1.0557631254196167, 1.3774280548095703, 1.4528985023498535, 1.2599544525146484, 1.370903491973877, 1.5533168315887451, 1.0012502670288086, 1.0392062664031982, 1.0642094612121582, 1.2908955812454224, 1.048315167427063, 1.2666698694229126, 1.0595743656158447, 2.146320343017578, 1.2711358070373535, 1.1765449047088623, 1.0829081535339355, 1.0343362092971802, 1.0173503160476685, 1.0392156839370728, 1.3877151012420654, 1.1764613389968872, 1.1850653886795044, 1.1766201257705688, 1.0765247344970703, 1.5149863958358765, 1.0523672103881836, 1.1388888359069824, 1.118187427520752, 1.0212562084197998, 1.1727169752120972, 1.0898027420043945, 1.0540450811386108, 1.0764201879501343, 1.1964919567108154, 1.0409828424453735, 1.1504424810409546, 1.1604968309402466, 1.299688458442688, 1.9051202535629272, 10.166666984558105, 1.0695425271987915, 1.1297880411148071, 1.0087611675262451, 1.027438998222351, 1.0571519136428833, 1.1240962743759155, 1.1300048828125, 1.2855440378189087, 1.0356119871139526, 1.6320987939834595, 1.2185702323913574, 1.2914738655090332, 1.1352380514144897, 1.1414645910263062, 1.0960028171539307, 1.1591306924819946, 1.2700138092041016, 1.0426325798034668, 1.0566415786743164, 1.2545465230941772, 1.1989920139312744, 1.1508979797363281, 1.5575757026672363, 1.049607276916504, 1.0214184522628784, 1.1136265993118286, 6.062129974365234, 1.0409654378890991, 1.2026559114456177, 1.0070408582687378, 1.0456410646438599, 1.285137414932251, 1.0493375062942505, 1.2824426889419556, 1.006739854812622, 1.0885790586471558, 1.047215223312378, 1.0737419128417969, 3.380432605743408, 1.103327989578247, 1.3266725540161133, 1.038079023361206, 1.2250828742980957, 1.3025124073028564, 31.961538314819336, 1.0957303047180176, 1.3781479597091675, 1.1175251007080078, 1.184692144393921, 1.2882095575332642, 1.2826300859451294, 1.1259974241256714, 1.0126582384109497, 1.2669522762298584, 1.3838346004486084, 1.1581125259399414, 1.736842155456543, 1.3781275749206543, 1.6912840604782104, 1.388636827468872, 1.3740284442901611, 1.1433449983596802, 1.0131148099899292, 1.082906723022461, 1.1928737163543701, 1.0878523588180542, 1.3643548488616943, 1.1560078859329224, 1.0461828708648682, 1.4818856716156006, 1.2187187671661377, 1.1534525156021118, 1.5991467237472534, 1.0093222856521606, 1.3614457845687866, 1.0051809549331665]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7480127811431885] ms
 --  Average per query NF    [1.370319128036499] ms
 --  Average per query vegas [2.3776936531066895] ms
Mean [2.642]  Median [1.160]  95th [1.898]  99th [14.840]  max [212.000]
Mean [2.642]  Median [1.160]  95th [1.898]  99th [14.840]  max [212.000]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.371789 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=1 | total-time=28.570331