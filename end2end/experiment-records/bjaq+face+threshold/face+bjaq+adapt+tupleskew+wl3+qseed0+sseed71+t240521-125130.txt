Input arguments = Namespace(data_update='tupleskew', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 71, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.169065475463867
tensor(0.9952)
result is  tensor(380321.9375)
Enter testHyper
ReportEsts: [1.1087193489074707, 1.0925573110580444, 1.5384210348129272, 1.0471677780151367, 1.2588095664978027, 1.1176320314407349, 1.2669163942337036, 1.1151700019836426, 1.1585874557495117, 1.039823293685913, 1.1429802179336548, 1.120339035987854, 1.0727945566177368, 1.0223214626312256, 1.0018078088760376, 1.2648084163665771, 1.3403226137161255, 1.1741092205047607, 1.0661121606826782, 1.1428571939468384, 1.1372219324111938, 1.1476246118545532, 1.1652964353561401, 1.0661104917526245, 1.1678509712219238, 1.0913200378417969, 1.0292792320251465, 1.3750531673431396, 1.008892297744751, 1.2097446918487549, 1.1269954442977905, 1.287583589553833, 1.081925630569458, 1.0012072324752808, 1.1096194982528687, 1.2167831659317017, 1.3761862516403198, 1.1114743947982788, 1.0448570251464844, 1.0385628938674927, 1.0201668739318848, 1.1522737741470337, 1.025292992591858, 1.016615867614746, 1.0988801717758179, 1.1326531171798706, 1.1203007698059082, 1.2953617572784424, 1.073501467704773, 1.1269035339355469, 1.2099738121032715, 1.3807339668273926, 1.0019557476043701, 1.1430635452270508, 1.0146677494049072, 1.0220327377319336, 1.3252336978912354, 1.121332049369812, 1.2141252756118774, 1.398657202720642, 1.446840524673462, 1.1508122682571411, 1.3762871026992798, 1.0981957912445068, 1.1538461446762085, 1.1428571939468384, 1.092334508895874, 1.0096946954727173, 1.279057502746582, 1.2000000476837158, 1.0427852869033813, 1.03024423122406, 1.207999587059021, 1.0144320726394653, 1.120732069015503, 1.040779709815979, 1.8702201843261719, 1.1005016565322876, 1.0924954414367676, 1.2653254270553589, 1.3286328315734863, 1.1185592412948608, 1.0009719133377075, 1.135988712310791, 1.1595232486724854, 1.0157008171081543, 1.0790396928787231, 1.033694863319397, 1.047633409500122, 1.1373248100280762, 1.1009411811828613, 1.4932318925857544, 1.0158672332763672, 1.2874853610992432, 1.133720874786377, 1.0088181495666504, 1.1849342584609985, 1.2453533411026, 1.034482717514038, 1.1119744777679443, 1.1067568063735962, 1.0260244607925415, 1.022943377494812, 1.003673791885376, 1.0087580680847168, 1.0765085220336914, 1.0925718545913696, 1.1640489101409912, 1.1297738552093506, 1.0114113092422485, 1.1971491575241089, 1.0973782539367676, 1.0661073923110962, 1.0451689958572388, 1.0934276580810547, 1.1884816884994507, 1.0597988367080688, 1.047336459159851, 1.303356647491455, 1.1708447933197021, 1.217612624168396, 1.0876225233078003, 1.0238956212997437, 1.1357775926589966, 1.262596845626831, 1.2496904134750366, 1.2048410177230835, 1.042772889137268, 1.264320731163025, 1.1018704175949097, 1.0154153108596802, 1.216968297958374, 1.146053433418274, 1.4642857313156128, 1.021959662437439, 1.1987398862838745, 1.0162720680236816, 1.1014634370803833, 1.0285239219665527, 1.047645092010498, 1.2225595712661743, 1.0871692895889282, 1.1544359922409058, 1.1938108205795288, 1.2052760124206543, 1.0237064361572266, 1.0739738941192627, 1.446401834487915, 1.0746794939041138, 1.0637073516845703, 1.0472968816757202, 1.189334750175476, 1.3790593147277832, 1.0242321491241455, 1.2470214366912842, 1.0113499164581299, 1.0121026039123535, 1.0070343017578125, 1.078879475593567, 1.211578607559204, 1.1558921337127686, 1.082565426826477, 1.0439621210098267, 1.229658842086792, 1.3074792623519897, 1.1378626823425293, 1.2029894590377808, 1.1770893335342407, 1.0687482357025146, 1.0805330276489258, 1.069909691810608, 1.0547765493392944, 1.1298701763153076, 1.0944658517837524, 1.037806510925293, 1.0516399145126343, 1.050536036491394, 1.289884090423584, 1.1225148439407349, 1.051344633102417, 1.0535049438476562, 1.093602180480957, 1.0192452669143677, 1.1389172077178955, 1.127852201461792, 1.1099365949630737, 1.037008285522461, 1.2768300771713257, 1.0279266834259033, 1.4398502111434937, 1.0504505634307861, 1.0633331537246704, 1.4425069093704224, 1.6201350688934326, 1.5744786262512207, 1.202979564666748, 1.0994163751602173, 1.1692308187484741, 1.0084589719772339, 1.1143425703048706]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.6849045753479004] ms
 --  Average per query NF    [1.3621962070465088] ms
 --  Average per query vegas [2.3227083683013916] ms
Mean [1.144]  Median [1.112]  95th [1.401]  99th [1.575]  max [1.870]
Mean [1.144]  Median [1.112]  95th [1.401]  99th [1.575]  max [1.870]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.797151 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=tupleskew', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
TupleSkewSample - START
0.001
TupleSkewSample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[2.7835369e-05 2.1100044e-04 2.5147200e-04 3.5524368e-05 7.3850155e-05]
Distance score: 0.00011993646330665797
SAUCE Drift detection: True
Detection latency: 0.0235s

DRIFT-DETECTED after 2-th workload
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/incremental_train.py', '--dataset=bjaq', '--end2end', '--model=face', '--model_update=adapt', '--update_size=80000', '--epochs=0']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
update_size: 76433
AdaptTask - START
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
train data shape: 80000, transfer data shape:16000
Training done; evaluating likelihood on full data:
Saved to: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
AdaptTask - END

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.002802 | Model-update-time: 2.226600


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=tupleskew', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.163761615753174
tensor(0.9940)
result is  tensor(455855.8438)
Enter testHyper
ReportEsts: [1.0532147884368896, 1.0255447626113892, 1.4488189220428467, 1.2512922286987305, 1.074923038482666, 1.0329464673995972, 1.1103217601776123, 1.1269410848617554, 3.0963854789733887, 1.1073943376541138, 1.0830730199813843, 1.232932448387146, 1.0554156303405762, 1.1426583528518677, 1.0968296527862549, 1.1053990125656128, 1.131095051765442, 1.1688798666000366, 1.0391356945037842, 1.3622509241104126, 1.1704447269439697, 1.0323278903961182, 1.3573797941207886, 1.0120643377304077, 1.23672354221344, 1.1474422216415405, 1.0383710861206055, 1.304170846939087, 1.5399880409240723, 1.361344575881958, 1.054031252861023, 1.73714280128479, 1.0157496929168701, 1.0219939947128296, 1.2088121175765991, 1.244232416152954, 1.091686725616455, 1.1072626113891602, 1.298856496810913, 1.0227910280227661, 1.0053859949111938, 1.0198123455047607, 1.0568745136260986, 1.091522455215454, 1.0505417585372925, 1.1170310974121094, 1.055403709411621, 1.1289809942245483, 1.3238095045089722, 1.1230841875076294, 1.0370228290557861, 1.0903880596160889, 1.0253053903579712, 1.0101882219314575, 1.0442379713058472, 1.1604598760604858, 1.0898116827011108, 1.1443047523498535, 1.2998021841049194, 1.15481436252594, 1.5431034564971924, 1.0711469650268555, 1.1164968013763428, 1.3660187721252441, 1.0027998685836792, 1.0358365774154663, 1.4378457069396973, 1.0339370965957642, 1.2136791944503784, 1.111106276512146, 1.13584566116333, 1.3217573165893555, 1.1060839891433716, 1.081607460975647, 1.0035767555236816, 1.1834181547164917, 1.0404638051986694, 1.0466489791870117, 1.3305563926696777, 1.2734410762786865, 1.117995023727417, 1.1248153448104858, 1.3078542947769165, 1.2343324422836304, 1.2356501817703247, 1.5021276473999023, 1.3593337535858154, 1.3392692804336548, 1.098952293395996, 1.195366621017456, 1.1087414026260376, 1.1422030925750732, 1.3488316535949707, 1.0830793380737305, 1.1624186038970947, 1.0532764196395874, 1.1137363910675049, 1.1876649856567383, 1.0068340301513672, 1.0063148736953735, 1.0725045204162598, 1.1426666975021362, 1.5101523399353027, 1.0509291887283325, 1.029326319694519, 1.0126471519470215, 1.1708754301071167, 1.0412708520889282, 1.0114613771438599, 1.0584224462509155, 1.1515051126480103, 1.0677708387374878, 1.224679708480835, 1.1988537311553955, 1.1184158325195312, 1.1933107376098633, 1.1544393301010132, 1.1221537590026855, 1.1383798122406006, 1.2035398483276367, 1.0664812326431274, 1.4224299192428589, 1.072723150253296, 1.3443924188613892, 1.114540696144104, 1.1016801595687866, 1.1605995893478394, 1.030580997467041, 1.0205414295196533, 1.2884291410446167, 1.217747449874878, 1.1968134641647339, 1.1720705032348633, 2.013422727584839, 1.9179331064224243, 1.0310066938400269, 1.182681679725647, 1.0814636945724487, 1.033198356628418, 1.0186665058135986, 1.0300986766815186, 1.1050424575805664, 1.0475831031799316, 1.1124491691589355, 1.0552712678909302, 1.1484975814819336, 2.2369942665100098, 1.0998551845550537, 1.2003988027572632, 1.0906593799591064, 1.1903728246688843, 1.0910179615020752, 1.068254828453064, 1.1214985847473145, 1.0361669063568115, 1.3236180543899536, 1.0933088064193726, 1.0703125, 1.0422961711883545, 1.0440363883972168, 1.043504238128662, 1.090476155281067, 1.3353326320648193, 1.1769311428070068, 1.0593290328979492, 1.059931993484497, 1.1534664630889893, 1.0504484176635742, 1.2505261898040771, 1.262870192527771, 1.0306832790374756, 1.143354892730713, 1.4133148193359375, 1.0006918907165527, 1.0360870361328125, 1.1589407920837402, 1.076134443283081, 1.0283491611480713, 1.0295599699020386, 1.18792724609375, 1.6578947305679321, 1.1350644826889038, 1.1264604330062866, 2.0015931129455566, 1.3838220834732056, 1.0965126752853394, 1.0944570302963257, 1.0296741724014282, 1.4162492752075195, 1.0214686393737793, 1.1322652101516724, 1.1383949518203735, 1.1361852884292603, 2.0582761764526367, 1.1377341747283936, 1.065485954284668, 1.1275819540023804, 3.0495049953460693, 1.36089026927948, 1.1662930250167847]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7308382987976074] ms
 --  Average per query NF    [1.3538122177124023] ms
 --  Average per query vegas [2.377026081085205] ms
Mean [1.191]  Median [1.118]  95th [1.540]  99th [2.245]  max [3.096]
Mean [1.191]  Median [1.118]  95th [1.540]  99th [2.245]  max [3.096]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.368102 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=1 | total-time=28.441983