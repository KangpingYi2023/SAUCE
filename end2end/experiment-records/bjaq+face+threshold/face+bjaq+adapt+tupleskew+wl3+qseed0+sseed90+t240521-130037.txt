Input arguments = Namespace(data_update='tupleskew', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 90, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.205329418182373
tensor(0.9970)
result is  tensor(381031.5000)
Enter testHyper
ReportEsts: [1.2117332220077515, 1.056492805480957, 1.4036083221435547, 1.0387450456619263, 1.2433459758758545, 1.096860647201538, 1.3953100442886353, 1.000430703163147, 1.0583577156066895, 1.1278666257858276, 1.0431267023086548, 1.0677965879440308, 1.0856901407241821, 1.0691964626312256, 1.002462387084961, 1.2170404195785522, 1.3144787549972534, 1.2010688781738281, 1.1906485557556152, 1.1734694242477417, 1.0675143003463745, 1.0969494581222534, 1.1548027992248535, 1.0589654445648193, 1.2380952835083008, 1.055153727531433, 1.033502221107483, 1.4393939971923828, 1.0630332231521606, 1.022276520729065, 1.1794962882995605, 1.1173611879348755, 1.1902440786361694, 1.0505119562149048, 1.1724179983139038, 1.0566802024841309, 1.3008590936660767, 1.09363853931427, 1.147045373916626, 1.0791616439819336, 1.0166521072387695, 1.1132075786590576, 1.0235216617584229, 1.0325279235839844, 1.0684555768966675, 1.0680272579193115, 1.1267428398132324, 1.2729262113571167, 1.067728877067566, 1.145516037940979, 1.245945930480957, 1.3026275634765625, 1.0629940032958984, 1.2870159149169922, 1.0931904315948486, 1.011358380317688, 1.4056074619293213, 1.1043025255203247, 1.0625336170196533, 1.478704571723938, 1.107100248336792, 1.1406928300857544, 1.2332311868667603, 1.24767005443573, 1.25, 1.2571429014205933, 1.164345383644104, 1.016343116760254, 1.1443127393722534, 1.3368420600891113, 1.046296238899231, 1.185508370399475, 1.2631756067276, 1.0448288917541504, 1.1753345727920532, 1.3250612020492554, 1.978869915008545, 1.0564693212509155, 1.0489418506622314, 1.3728190660476685, 1.2693368196487427, 1.092553734779358, 1.0891621112823486, 1.2960244417190552, 1.2868787050247192, 1.1091387271881104, 1.2131128311157227, 1.2200251817703247, 1.0179117918014526, 1.011360764503479, 1.0000462532043457, 1.253774642944336, 1.0036062002182007, 1.3249880075454712, 1.167664647102356, 1.0011800527572632, 1.1392160654067993, 1.2323951721191406, 1.01694917678833, 1.1294822692871094, 1.2133333683013916, 1.116519570350647, 1.1415859460830688, 1.016837477684021, 1.0861924886703491, 1.027895212173462, 1.101952314376831, 1.165794014930725, 1.034632921218872, 1.0382500886917114, 1.3265436887741089, 1.0742437839508057, 1.0964922904968262, 1.0609259605407715, 1.059000849723816, 1.140703558921814, 1.0226885080337524, 1.091706395149231, 1.3047466278076172, 1.3391778469085693, 1.3102678060531616, 1.1226024627685547, 1.0114022493362427, 1.094462275505066, 1.3265503644943237, 1.197069764137268, 1.1761871576309204, 1.1607269048690796, 1.3399826288223267, 1.1145625114440918, 1.0802414417266846, 1.2383164167404175, 1.1532007455825806, 1.3928571939468384, 1.1003303527832031, 1.138619065284729, 1.0732423067092896, 1.1521950960159302, 1.0952236652374268, 1.3605974912643433, 1.148738145828247, 1.1335560083389282, 1.028757095336914, 1.25288724899292, 1.1927013397216797, 1.1753430366516113, 1.0613515377044678, 1.451080083847046, 1.1532095670700073, 1.0085227489471436, 1.158121109008789, 1.1567747592926025, 1.3570247888565063, 1.0912986993789673, 1.157266616821289, 1.0179259777069092, 1.2506424188613892, 1.0016882419586182, 1.1211931705474854, 1.1188899278640747, 1.0800167322158813, 1.025146484375, 1.0236270427703857, 1.2560322284698486, 1.2259740829467773, 1.107913613319397, 1.2628282308578491, 1.401428461074829, 1.0405393838882446, 1.0224649906158447, 1.0881043672561646, 1.0288742780685425, 1.1168831586837769, 1.131026029586792, 1.0514304637908936, 1.1310133934020996, 1.0199222564697266, 1.258204698562622, 1.2108724117279053, 1.0312063694000244, 1.0285099744796753, 1.090345025062561, 1.0152896642684937, 1.0755873918533325, 1.1419775485992432, 1.0993657112121582, 1.0441956520080566, 1.2462712526321411, 1.0110214948654175, 1.311937928199768, 1.0620979070663452, 1.0179387331008911, 1.6803061962127686, 1.4273165464401245, 1.8695831298828125, 1.1695835590362549, 1.091413140296936, 1.085714340209961, 1.0235625505447388, 1.0308765172958374]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.777003288269043] ms
 --  Average per query NF    [1.3743889331817627] ms
 --  Average per query vegas [2.4026143550872803] ms
Mean [1.155]  Median [1.118]  95th [1.396]  99th [1.682]  max [1.979]
Mean [1.155]  Median [1.118]  95th [1.396]  99th [1.682]  max [1.979]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.878032 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=tupleskew', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
TupleSkewSample - START
0.001
TupleSkewSample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[8.7320805e-05 5.9008598e-06 4.2140484e-05 8.7738037e-05 8.0764294e-05]
Distance score: 6.077289435779676e-05
SAUCE Drift detection: True
Detection latency: 0.0227s

DRIFT-DETECTED after 2-th workload
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/incremental_train.py', '--dataset=bjaq', '--end2end', '--model=face', '--model_update=adapt', '--update_size=80000', '--epochs=0']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
update_size: 76433
AdaptTask - START
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
train data shape: 80000, transfer data shape:16000
Training done; evaluating likelihood on full data:
Saved to: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
AdaptTask - END

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 1.998695 | Model-update-time: 2.217401


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=tupleskew', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.171496152877808
tensor(0.9950)
result is  tensor(456287.4375)
Enter testHyper
ReportEsts: [1.1082549095153809, 1.0523064136505127, 1.016997218132019, 1.1339211463928223, 1.0564664602279663, 1.2347946166992188, 1.2717562913894653, 1.0197778940200806, 1.072128176689148, 1.0381155014038086, 1.0566710233688354, 1.0550758838653564, 1.4808611869812012, 1.072729468345642, 1.3580336570739746, 1.0132081508636475, 1.032050371170044, 1.08477783203125, 1.0072306394577026, 1.4935131072998047, 1.1070524454116821, 1.0166149139404297, 1.1923528909683228, 1.1275335550308228, 1.2352750301361084, 1.1968685388565063, 1.0683562755584717, 1.1498993635177612, 1.0094845294952393, 1.2678260803222656, 1.1065274477005005, 1.6542552709579468, 1.1167947053909302, 1.118457317352295, 1.0426806211471558, 1.172356128692627, 1.0348788499832153, 1.097946286201477, 1.265242338180542, 1.0226353406906128, 1.0689964294433594, 1.007216453552246, 1.1976103782653809, 1.1528433561325073, 1.0219510793685913, 1.0482620000839233, 1.1622815132141113, 1.1024142503738403, 1.3875432014465332, 1.0173449516296387, 1.053739070892334, 1.0600672960281372, 1.0054104328155518, 1.2132436037063599, 1.1090295314788818, 1.0646986961364746, 1.2418006658554077, 1.1159621477127075, 1.3603957891464233, 1.1341207027435303, 1.5258798599243164, 1.0273972749710083, 1.1407099962234497, 1.0342861413955688, 1.0238946676254272, 1.0269118547439575, 1.4196596145629883, 1.0344126224517822, 1.205193042755127, 1.0822926759719849, 1.0357297658920288, 1.0379576683044434, 1.0560916662216187, 1.051103115081787, 1.1234830617904663, 1.0706429481506348, 1.6549450159072876, 1.0896166563034058, 1.2782492637634277, 1.121925711631775, 1.0263367891311646, 1.0206807851791382, 1.2001147270202637, 1.1489663124084473, 1.2197352647781372, 1.6468085050582886, 1.1203646659851074, 1.3401929140090942, 4.494845390319824, 1.0138797760009766, 1.1953463554382324, 1.2168078422546387, 1.4504214525222778, 1.156137228012085, 1.193312644958496, 1.0275639295578003, 1.0663976669311523, 1.1749919652938843, 1.5565403699874878, 1.0674704313278198, 1.2276219129562378, 1.0917987823486328, 1.0355329513549805, 1.2191137075424194, 1.6008771657943726, 1.1665865182876587, 1.0424919128417969, 1.0895851850509644, 1.0057636499404907, 1.141337513923645, 5.409090995788574, 1.1208730936050415, 1.2466245889663696, 1.1932090520858765, 1.1601170301437378, 1.0310789346694946, 1.100822925567627, 1.9560351371765137, 1.0932029485702515, 1.1238938570022583, 1.0669784545898438, 1.157309651374817, 1.1742215156555176, 1.2336668968200684, 1.024084448814392, 1.0119339227676392, 1.2453787326812744, 1.0766773223876953, 1.176313877105713, 1.0494377613067627, 1.2273797988891602, 1.139232873916626, 1.187650442123413, 1.2413145303726196, 1.3253105878829956, 1.0346938371658325, 1.0621795654296875, 1.1836156845092773, 1.037373661994934, 1.0127676725387573, 1.0593788623809814, 1.1606624126434326, 1.0618962049484253, 1.024454951286316, 1.0056517124176025, 1.1146363019943237, 1.2196531295776367, 1.0326498746871948, 1.1230800151824951, 1.1075451374053955, 1.1878738403320312, 1.1025373935699463, 1.0986987352371216, 1.0407098531723022, 1.0054000616073608, 1.1215436458587646, 1.0935051441192627, 1.0873016119003296, 1.6917073726654053, 1.3090908527374268, 1.0295994281768799, 1.1973475217819214, 1.8808664083480835, 1.0762659311294556, 1.145806908607483, 1.097736120223999, 1.1797727346420288, 1.1873959302902222, 1.161117434501648, 1.34502375125885, 1.0788207054138184, 1.1683475971221924, 2.2411067485809326, 1.0214428901672363, 1.0428186655044556, 1.0186238288879395, 1.3018356561660767, 1.0005567073822021, 1.1262410879135132, 1.0149644613265991, 1.8421052694320679, 1.1481740474700928, 1.0512490272521973, 1.6142462491989136, 1.222219467163086, 1.3398876190185547, 1.0296562910079956, 1.404466986656189, 1.391821026802063, 1.0178699493408203, 1.1572779417037964, 1.0994304418563843, 1.3141149282455444, 2.2699902057647705, 1.0353777408599854, 1.1381988525390625, 1.105940341949463, 1.288973331451416, 1.6571879386901855, 1.0413849353790283]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7324905395507812] ms
 --  Average per query NF    [1.3601112365722656] ms
 --  Average per query vegas [2.3723793029785156] ms
Mean [1.212]  Median [1.118]  95th [1.654]  99th [2.292]  max [5.409]
Mean [1.212]  Median [1.118]  95th [1.654]  99th [2.292]  max [5.409]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.374281 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=1 | total-time=28.517862