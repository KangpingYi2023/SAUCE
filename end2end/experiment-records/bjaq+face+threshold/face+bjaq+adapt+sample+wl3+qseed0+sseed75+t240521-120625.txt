Input arguments = Namespace(data_update='sample', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 75, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.153197526931763
tensor(0.9971)
result is  tensor(381072.5312)
Enter testHyper
ReportEsts: [1.1423357725143433, 1.0737841129302979, 1.2606239318847656, 1.1450831890106201, 1.2411679029464722, 1.1800414323806763, 1.2006337642669678, 1.2046245336532593, 1.1016483306884766, 1.1965543031692505, 1.0111972093582153, 1.1597458124160767, 1.0098047256469727, 1.0513392686843872, 1.1037737131118774, 1.21432363986969, 1.0676778554916382, 1.228622317314148, 1.1445218324661255, 1.045918345451355, 1.22579026222229, 1.1545227766036987, 1.1486457586288452, 1.1258125305175781, 1.0465571880340576, 1.198010802268982, 1.117117166519165, 1.3050504922866821, 1.004105806350708, 1.195504069328308, 1.1805604696273804, 1.1152105331420898, 1.0108352899551392, 1.0007624626159668, 1.2573710680007935, 1.1360923051834106, 1.1091282367706299, 1.089608907699585, 1.063165545463562, 1.1173652410507202, 1.0062323808670044, 1.123367190361023, 1.037113904953003, 1.0821800231933594, 1.0916966199874878, 1.0328798294067383, 1.0870952606201172, 1.312406063079834, 1.2275620698928833, 1.0761420726776123, 1.2036553621292114, 1.4136196374893188, 1.0663249492645264, 1.2845079898834229, 1.161581039428711, 1.0208234786987305, 1.2355140447616577, 1.117885947227478, 1.2242910861968994, 1.3412474393844604, 1.4001343250274658, 1.2133197784423828, 1.2196433544158936, 1.0534685850143433, 1.2547528743743896, 1.3142857551574707, 1.1863765716552734, 1.0189447402954102, 1.1572915315628052, 1.4526315927505493, 1.189058780670166, 1.0056980848312378, 1.2235647439956665, 1.145809531211853, 1.2686434984207153, 1.097646713256836, 1.9486336708068848, 1.017989993095398, 1.0802675485610962, 1.254104495048523, 1.158681869506836, 1.030043601989746, 1.078125, 1.078143835067749, 1.233636498451233, 1.0355724096298218, 1.0197597742080688, 1.02547287940979, 1.0351197719573975, 1.1119495630264282, 1.0495707988739014, 1.3765370845794678, 1.013893961906433, 1.3129770755767822, 1.0209424495697021, 1.1634989976882935, 1.115372896194458, 1.3282705545425415, 1.01694917678833, 1.136597752571106, 1.2917981147766113, 1.0191679000854492, 1.025298833847046, 1.0014641284942627, 1.118933081626892, 1.0137771368026733, 1.15247642993927, 1.1972076892852783, 1.0697160959243774, 1.0062557458877563, 1.2780628204345703, 1.089219331741333, 1.1106551885604858, 1.074602723121643, 1.1035122871398926, 1.1464647054672241, 1.0017342567443848, 1.0346990823745728, 1.3464932441711426, 1.0182582139968872, 1.120423436164856, 1.1062508821487427, 1.0442088842391968, 1.2808377742767334, 1.2902132272720337, 1.2262691259384155, 1.1166690587997437, 1.2368037700653076, 1.307106614112854, 1.138610601425171, 1.292890191078186, 1.183448314666748, 1.1876941919326782, 1.4285714626312256, 1.139666199684143, 1.1373063325881958, 1.0612071752548218, 1.1317073106765747, 1.1134397983551025, 1.226282000541687, 1.1332570314407349, 1.1036536693572998, 1.1816167831420898, 1.3032399415969849, 1.0198001861572266, 1.1138285398483276, 1.0256410837173462, 1.3140511512756348, 1.0271189212799072, 1.0742897987365723, 1.1673187017440796, 1.1613895893096924, 1.3073248863220215, 1.165172815322876, 1.1244221925735474, 1.1236929893493652, 1.021756649017334, 1.0216656923294067, 1.0248957872390747, 1.1683080196380615, 1.0224709510803223, 1.102264642715454, 1.0054620504379272, 1.24105966091156, 1.2620320320129395, 1.152610421180725, 1.0849529504776, 1.2695205211639404, 1.2039425373077393, 1.0853372812271118, 1.0362094640731812, 1.0450161695480347, 1.1363636255264282, 1.0599119663238525, 1.0103235244750977, 1.0925002098083496, 1.0276968479156494, 1.2962383031845093, 1.17781400680542, 1.1374210119247437, 1.1132677793502808, 1.0374079942703247, 1.0445449352264404, 1.09601628780365, 1.058312177658081, 1.1712473630905151, 1.017909049987793, 1.1449967622756958, 1.0202784538269043, 1.3723645210266113, 1.005728006362915, 1.0793185234069824, 1.5044807195663452, 1.3035714626312256, 1.4373130798339844, 1.1955583095550537, 1.0934139490127563, 1.0410958528518677, 1.004117727279663, 1.0026965141296387]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7418007850646973] ms
 --  Average per query NF    [1.3608598709106445] ms
 --  Average per query vegas [2.3809409141540527] ms
Mean [1.145]  Median [1.122]  95th [1.342]  99th [1.453]  max [1.949]
Mean [1.145]  Median [1.122]  95th [1.342]  99th [1.453]  max [1.949]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.824963 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=sample', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
Sample - START
Sample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[7.1525574e-07 1.7881393e-07 1.7881393e-07 7.7486038e-07 4.1723251e-07]
Distance score: 4.5299529460862686e-07
SAUCE Drift detection: False
Detection latency: 0.0233s

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.022631 | Model-update-time: 0.000000


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=sample', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.170910120010376
tensor(1.0006)
result is  tensor(458872.3125)
Enter testHyper
ReportEsts: [1.0427290201187134, 1.0199670791625977, 1.2496285438537598, 1.1722688674926758, 1.1131374835968018, 1.4513016939163208, 1.3015366792678833, 1.013312578201294, 1.0008881092071533, 1.3125, 1.1335347890853882, 1.171157956123352, 1.1655011177062988, 1.1323457956314087, 1.2494127750396729, 1.0703176259994507, 1.392927885055542, 1.0927984714508057, 1.0381947755813599, 1.2581510543823242, 1.0679192543029785, 1.4643714427947998, 1.1380891799926758, 1.0411059856414795, 1.0760146379470825, 1.223050832748413, 1.025770902633667, 1.0474178791046143, 1.2218666076660156, 1.6001830101013184, 1.1279528141021729, 1.136986255645752, 1.1115484237670898, 1.0762287378311157, 1.026326298713684, 1.1089892387390137, 1.0849241018295288, 1.1815658807754517, 1.2998778820037842, 1.0002200603485107, 1.0752147436141968, 1.0213220119476318, 1.048872470855713, 1.124023675918579, 1.0091367959976196, 1.1060371398925781, 1.1258821487426758, 1.1055959463119507, 1.0229008197784424, 1.043313980102539, 1.0726029872894287, 1.0206319093704224, 1.1327428817749023, 1.0242823362350464, 1.0238585472106934, 1.4425019025802612, 1.2243716716766357, 1.0908094644546509, 1.2107218503952026, 1.1189543008804321, 1.5257009267807007, 1.0402002334594727, 1.13945734500885, 1.2702796459197998, 1.006584882736206, 1.1453957557678223, 1.2807282209396362, 1.0194023847579956, 1.1787885427474976, 1.1213332414627075, 1.121316909790039, 1.332444190979004, 1.0200319290161133, 1.1526634693145752, 1.026285171508789, 1.100577712059021, 1.0850327014923096, 1.1804877519607544, 1.2853692770004272, 1.0609979629516602, 1.2862920761108398, 1.1200408935546875, 1.103853702545166, 1.1782578229904175, 1.3414863348007202, 1.3508771657943726, 1.1147435903549194, 1.630364179611206, 1.004258155822754, 1.0757906436920166, 1.2002736330032349, 1.1690311431884766, 1.2179087400436401, 1.1114259958267212, 1.0851569175720215, 1.0978715419769287, 1.1147665977478027, 1.2556283473968506, 1.3773632049560547, 1.0023434162139893, 1.1457411050796509, 1.1301426887512207, 1.2539267539978027, 1.003682255744934, 1.2394702434539795, 1.078162431716919, 1.0037752389907837, 1.074091911315918, 1.1713483333587646, 1.1363043785095215, 1.0148792266845703, 1.1114555597305298, 1.345050573348999, 1.2801882028579712, 1.0665289163589478, 1.0173382759094238, 1.0554695129394531, 1.1104881763458252, 1.04887855052948, 1.100000023841858, 1.076600193977356, 1.0541102886199951, 1.0320113897323608, 1.7262259721755981, 1.0227272510528564, 1.1446993350982666, 1.2743631601333618, 1.302931547164917, 1.1546159982681274, 1.171920657157898, 1.2217276096343994, 1.0459710359573364, 1.0936567783355713, 1.760917067527771, 2.2824132442474365, 1.1552709341049194, 1.0406051874160767, 1.0323996543884277, 1.0539395809173584, 1.0078160762786865, 1.1258257627487183, 1.1429328918457031, 1.0153100490570068, 1.0175200700759888, 1.0510696172714233, 1.1653892993927002, 1.465517282485962, 1.0319552421569824, 1.1854418516159058, 1.0426859855651855, 1.074280023574829, 1.105513334274292, 1.1095061302185059, 1.0454953908920288, 1.0034953355789185, 1.2545454502105713, 1.3013614416122437, 1.2635658979415894, 1.0104482173919678, 1.1945399045944214, 1.16489577293396, 1.057522177696228, 1.0486418008804321, 1.2229647636413574, 1.1921926736831665, 1.0010521411895752, 1.0148643255233765, 1.0, 1.045971155166626, 1.3477681875228882, 1.01798415184021, 1.03177011013031, 1.41865074634552, 1.0505635738372803, 1.080064058303833, 1.0114542245864868, 1.179794430732727, 1.001092791557312, 1.0430325269699097, 1.1699414253234863, 1.3829786777496338, 1.113112211227417, 1.0348397493362427, 1.6045738458633423, 1.2078744173049927, 1.0234448909759521, 1.2982099056243896, 1.1073664426803589, 1.4765273332595825, 1.0398731231689453, 1.1710833311080933, 1.0382999181747437, 1.298621416091919, 1.6021251678466797, 1.0937763452529907, 1.0084619522094727, 1.2598272562026978, 1.0799256563186646, 1.321608066558838, 1.133316159248352]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.730623722076416] ms
 --  Average per query NF    [1.3599514961242676] ms
 --  Average per query vegas [2.3706722259521484] ms
Mean [1.157]  Median [1.112]  95th [1.464]  99th [1.727]  max [2.282]
Mean [1.157]  Median [1.112]  95th [1.464]  99th [1.727]  max [2.282]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.201983 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=0 | total-time=26.141030