Input arguments = Namespace(data_update='sample', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 27, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.163748264312744
tensor(0.9934)
result is  tensor(379650.5000)
Enter testHyper
ReportEsts: [1.1513864994049072, 1.0588642358779907, 1.333095908164978, 1.0720151662826538, 1.2917046546936035, 1.1109980344772339, 1.1576437950134277, 1.149266004562378, 1.1413662433624268, 1.0410343408584595, 1.1963824033737183, 1.0991525650024414, 1.062100887298584, 1.0267857313156128, 1.1393946409225464, 1.3577073812484741, 1.4500006437301636, 1.1861045360565186, 1.1806119680404663, 1.0943877696990967, 1.1127523183822632, 1.0743520259857178, 1.2125169038772583, 1.1217060089111328, 1.151351809501648, 1.141048789024353, 1.1148648262023926, 1.4172883033752441, 1.0303784608840942, 1.0161240100860596, 1.0461156368255615, 1.0118192434310913, 1.0768340826034546, 1.020577311515808, 1.227268934249878, 1.0784786939620972, 1.2510569095611572, 1.0631523132324219, 1.1293692588806152, 1.1151175498962402, 1.0351543426513672, 1.0543057918548584, 1.0790818929672241, 1.0673234462738037, 1.0086625814437866, 1.019274353981018, 1.0981957912445068, 1.2087950706481934, 1.118575096130371, 1.1201353073120117, 1.1760203838348389, 1.2875038385391235, 1.048636794090271, 1.2929061651229858, 1.0743991136550903, 1.0702364444732666, 1.2831776142120361, 1.1469820737838745, 1.0414267778396606, 1.3374799489974976, 1.3644839525222778, 1.1833168268203735, 1.4272674322128296, 1.106870412826538, 1.25, 1.1714285612106323, 1.2092574834823608, 1.0127187967300415, 1.0052787065505981, 1.263157844543457, 1.0579243898391724, 1.0999760627746582, 1.1750181913375854, 1.227687954902649, 1.160753607749939, 1.1989954710006714, 1.9233580827713013, 1.048612356185913, 1.0297794342041016, 1.367258906364441, 1.2022366523742676, 1.1734776496887207, 1.1383447647094727, 1.20062255859375, 1.1776717901229858, 1.1152368783950806, 1.0994951725006104, 1.0627747774124146, 1.0488550662994385, 1.029106855392456, 1.0928878784179688, 1.2455084323883057, 1.0014445781707764, 1.3107882738113403, 1.0955055952072144, 1.1479889154434204, 1.145756721496582, 1.4957489967346191, 1.034482717514038, 1.2103735208511353, 1.2026431560516357, 1.260941743850708, 1.0311436653137207, 1.010354995727539, 1.0844142436981201, 1.017555832862854, 1.0383445024490356, 1.216404914855957, 1.0051860809326172, 1.0462539196014404, 1.153631329536438, 1.1119544506072998, 1.290083408355713, 1.0293463468551636, 1.1594992876052856, 1.0913461446762085, 1.0332581996917725, 1.010705590248108, 1.2094213962554932, 1.0662223100662231, 1.251356601715088, 1.1392300128936768, 1.044742226600647, 1.2523950338363647, 1.3454457521438599, 1.205633521080017, 1.0592975616455078, 1.2006776332855225, 1.2581433057785034, 1.1202404499053955, 1.0735595226287842, 1.1800066232681274, 1.3014295101165771, 1.4642857313156128, 1.2385427951812744, 1.016546607017517, 1.0397454500198364, 1.130081295967102, 1.15785813331604, 1.2184712886810303, 1.1334561109542847, 1.1174120903015137, 1.096453309059143, 1.300021767616272, 1.0055283308029175, 1.009270429611206, 1.0261614322662354, 1.5450938940048218, 1.0033704042434692, 1.1008522510528564, 1.0731866359710693, 1.1544673442840576, 1.2875065803527832, 1.0538185834884644, 1.183822751045227, 1.0203830003738403, 1.0613101720809937, 1.029249906539917, 1.0545554161071777, 1.2368844747543335, 1.0023250579833984, 1.0537253618240356, 1.0069597959518433, 1.2427055835723877, 1.2356021404266357, 1.0095938444137573, 1.1110037565231323, 1.2932466268539429, 1.0152902603149414, 1.0207470655441284, 1.100541353225708, 1.1428309679031372, 1.2207791805267334, 1.1155325174331665, 1.107629418373108, 1.0510987043380737, 1.0038872957229614, 1.0639588832855225, 1.1280951499938965, 1.167514681816101, 1.11388099193573, 1.1428200006484985, 1.0157501697540283, 1.2390193939208984, 1.1245925426483154, 1.130021095275879, 1.0169233083724976, 1.280470371246338, 1.0101948976516724, 1.3057969808578491, 1.0393179655075073, 1.098301887512207, 1.4234414100646973, 1.2345588207244873, 2.128187894821167, 1.251937985420227, 1.0698624849319458, 1.013157844543457, 1.0300695896148682, 1.0749003887176514]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.757215738296509] ms
 --  Average per query NF    [1.3616609573364258] ms
 --  Average per query vegas [2.395554780960083] ms
Mean [1.148]  Median [1.116]  95th [1.365]  99th [1.549]  max [2.128]
Mean [1.148]  Median [1.116]  95th [1.365]  99th [1.549]  max [2.128]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.846653 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=sample', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
Sample - START
Sample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[2.9802322e-07 6.5565109e-07 4.7683716e-07 3.5762787e-07 1.1920929e-07]
Distance score: 3.814697322468419e-07
SAUCE Drift detection: False
Detection latency: 0.0234s

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.025455 | Model-update-time: 0.000000


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=sample', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.168691635131836
tensor(0.9983)
result is  tensor(457802.4375)
Enter testHyper
ReportEsts: [1.054541826248169, 1.0112186670303345, 1.1948424577713013, 1.0842735767364502, 1.010471224784851, 1.228256344795227, 1.123680830001831, 1.061068058013916, 1.0282459259033203, 1.1166666746139526, 1.00680410861969, 1.2280036211013794, 1.1876484155654907, 1.0021684169769287, 1.1394520998001099, 1.0838276147842407, 1.2894333600997925, 1.1056243181228638, 1.206904411315918, 1.2224929332733154, 1.1657639741897583, 1.374812364578247, 1.073351502418518, 1.0295406579971313, 1.1015331745147705, 1.2404873371124268, 1.0191316604614258, 1.1769157648086548, 1.1092745065689087, 1.4052718877792358, 1.1687345504760742, 1.2086330652236938, 1.1232479810714722, 1.0133823156356812, 1.056758999824524, 1.2059271335601807, 1.0266350507736206, 1.2878504991531372, 1.1699141263961792, 1.1020801067352295, 1.0284827947616577, 1.0150375366210938, 1.1799728870391846, 1.020885944366455, 1.026258111000061, 1.110794186592102, 1.1712907552719116, 1.1570712327957153, 1.0714285373687744, 1.218963384628296, 1.0083352327346802, 1.063309669494629, 1.0399668216705322, 1.0556548833847046, 1.196211576461792, 1.395100474357605, 1.221516489982605, 1.0603080987930298, 1.237221360206604, 1.1828335523605347, 1.3016194105148315, 1.0579979419708252, 1.0296021699905396, 1.2445541620254517, 1.0435856580734253, 1.1439985036849976, 1.1720596551895142, 1.0369694232940674, 1.1139777898788452, 1.1148769855499268, 1.1577372550964355, 1.114994764328003, 1.191145420074463, 1.106859803199768, 1.0308829545974731, 1.1578353643417358, 1.1583236455917358, 1.2123486995697021, 1.2988176345825195, 1.1141773462295532, 1.1812865734100342, 1.0614076852798462, 1.103033185005188, 1.143734335899353, 1.3207058906555176, 1.4028269052505493, 1.1880621910095215, 1.4511958360671997, 1.0204799175262451, 1.1163651943206787, 1.0869346857070923, 1.143188238143921, 1.4613597393035889, 1.055274486541748, 1.241370439529419, 1.081723690032959, 1.0080955028533936, 1.2357816696166992, 1.1534010171890259, 1.200668215751648, 1.1646702289581299, 1.132934331893921, 1.1392111778259277, 1.0308058261871338, 1.088849425315857, 1.252619743347168, 1.301845908164978, 1.1792701482772827, 1.2470588684082031, 1.0014578104019165, 1.0623103380203247, 1.1454565525054932, 1.1084492206573486, 1.1230355501174927, 1.0525000095367432, 1.0240963697433472, 1.1055705547332764, 1.171295166015625, 1.070846438407898, 1.2589285373687744, 1.0106374025344849, 1.1226415634155273, 1.142992615699768, 1.2854626178741455, 1.0580137968063354, 1.0927917957305908, 1.2139689922332764, 1.2515337467193604, 1.0504868030548096, 1.095749855041504, 1.2427483797073364, 1.0326124429702759, 1.048055648803711, 1.509039044380188, 1.9234973192214966, 1.1560919284820557, 1.171379566192627, 1.1015546321868896, 1.1276377439498901, 1.021662950515747, 1.1331602334976196, 1.1506943702697754, 1.0003128051757812, 1.0079478025436401, 1.0473750829696655, 1.0364394187927246, 1.4682080745697021, 1.036818265914917, 1.258428692817688, 1.0987656116485596, 1.1082032918930054, 1.0760802030563354, 1.1766408681869507, 1.0345842838287354, 1.0353091955184937, 1.0823616981506348, 1.232561469078064, 1.3495935201644897, 1.117996096611023, 1.155138373374939, 1.056021809577942, 1.1789230108261108, 1.0747873783111572, 1.0275506973266602, 1.2248162031173706, 1.116275429725647, 1.0419505834579468, 1.2244046926498413, 1.113386631011963, 1.2715411186218262, 1.0809251070022583, 1.1512718200683594, 1.2860519886016846, 1.0443568229675293, 1.0840336084365845, 1.042671799659729, 1.05576491355896, 1.0432251691818237, 1.0577776432037354, 1.0031617879867554, 1.6595745086669922, 1.0452176332473755, 1.0182386636734009, 1.559862732887268, 1.3467661142349243, 1.400237798690796, 1.0808429718017578, 1.052014946937561, 1.3138089179992676, 1.0230488777160645, 1.1181752681732178, 1.0274014472961426, 1.1428656578063965, 1.7693638801574707, 1.063331127166748, 1.075905203819275, 1.1658556461334229, 1.0012257099151611, 1.3406040668487549, 1.2108159065246582]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.801363706588745] ms
 --  Average per query NF    [1.3825011253356934] ms
 --  Average per query vegas [2.4188625812530518] ms
Mean [1.149]  Median [1.117]  95th [1.400]  99th [1.661]  max [1.923]
Mean [1.149]  Median [1.117]  95th [1.400]  99th [1.661]  max [1.923]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.213636 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=0 | total-time=26.134528