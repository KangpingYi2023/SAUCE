Input arguments = Namespace(data_update='sample', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 28, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.165806293487549
tensor(0.9948)
result is  tensor(380179.4375)
Enter testHyper
ReportEsts: [1.1353236436843872, 1.05911123752594, 1.0409181118011475, 1.1985681056976318, 1.2307469844818115, 1.1145895719528198, 1.264465093612671, 1.1392135620117188, 1.036473274230957, 1.1289608478546143, 1.0120586156845093, 1.0597457885742188, 1.0631961822509766, 1.0379464626312256, 1.0439984798431396, 1.3043416738510132, 1.236842393875122, 1.153206706047058, 1.2064125537872314, 1.0, 1.1053954362869263, 1.0902671813964844, 1.1016567945480347, 1.0081688165664673, 1.2128562927246094, 1.043399691581726, 1.0370802879333496, 1.4728682041168213, 1.005863070487976, 1.0959210395812988, 1.1518268585205078, 1.2674168348312378, 1.0193461179733276, 1.0472192764282227, 1.0751111507415771, 1.0269650220870972, 1.4740328788757324, 1.0439622402191162, 1.0610918998718262, 1.0743695497512817, 1.0858622789382935, 1.1505805253982544, 1.0642660856246948, 1.0266635417938232, 1.0931755304336548, 1.0045558214187622, 1.034198522567749, 1.200068712234497, 1.0385578870773315, 1.0930626392364502, 1.1354680061340332, 1.2650855779647827, 1.1609060764312744, 1.1156558990478516, 1.1459119319915771, 1.021325945854187, 1.277570128440857, 1.1784799098968506, 1.1258772611618042, 1.4027777910232544, 1.1026127338409424, 1.2163352966308594, 1.4128069877624512, 1.14298415184021, 1.2790697813034058, 1.1714285612106323, 1.2115942239761353, 1.0297956466674805, 1.0442899465560913, 1.3368420600891113, 1.0120675563812256, 1.017181158065796, 1.2245838642120361, 1.2023460865020752, 1.058857798576355, 1.159263014793396, 1.9421517848968506, 1.0603448152542114, 1.019622802734375, 1.2030118703842163, 1.0860258340835571, 1.064448356628418, 1.030240774154663, 1.18866765499115, 1.1547961235046387, 1.1261247396469116, 1.0520329475402832, 1.0385876893997192, 1.0178720951080322, 1.1169251203536987, 1.0015250444412231, 1.2713888883590698, 1.0032455921173096, 1.2441229820251465, 1.1890244483947754, 1.1885273456573486, 1.126054286956787, 1.348151445388794, 1.01694917678833, 1.162437915802002, 1.175035834312439, 1.1637768745422363, 1.1649655103683472, 1.014641284942627, 1.0301254987716675, 1.0092973709106445, 1.2560149431228638, 1.169284462928772, 1.0923354625701904, 1.068651556968689, 1.3666847944259644, 1.0821791887283325, 1.255731225013733, 1.0997505187988281, 1.141068696975708, 1.0509259700775146, 1.0381414890289307, 1.0527538061141968, 1.3165658712387085, 1.0526010990142822, 1.2591654062271118, 1.066096305847168, 1.090151309967041, 1.2187479734420776, 1.2616279125213623, 1.1490920782089233, 1.1319546699523926, 1.1098400354385376, 1.2520259618759155, 1.0958583354949951, 1.1715022325515747, 1.093839406967163, 1.2482908964157104, 1.4285714626312256, 1.017274260520935, 1.0390070676803589, 1.0433523654937744, 1.0904065370559692, 1.0450100898742676, 1.2349903583526611, 1.094628930091858, 1.1302900314331055, 1.159974455833435, 1.356368899345398, 1.1108125448226929, 1.0289191007614136, 1.1817424297332764, 1.524560809135437, 1.0510015487670898, 1.0681108236312866, 1.117606520652771, 1.20805025100708, 1.3473742008209229, 1.2777132987976074, 1.075909972190857, 1.1010830402374268, 1.314732313156128, 1.0523353815078735, 1.0048496723175049, 1.169143557548523, 1.0695570707321167, 1.0177592039108276, 1.0498634576797485, 1.2730978727340698, 1.232375979423523, 1.0164198875427246, 1.0022549629211426, 1.3445978164672852, 1.0508832931518555, 1.0244030952453613, 1.006862998008728, 1.0842318534851074, 1.1428571939468384, 1.106838345527649, 1.0197547674179077, 1.0813933610916138, 1.0160349607467651, 1.1577999591827393, 1.0422192811965942, 1.1132090091705322, 1.1394438743591309, 1.028909683227539, 1.0266187191009521, 1.0602655410766602, 1.159362554550171, 1.1131078004837036, 1.0209916830062866, 1.2475694417953491, 1.0347177982330322, 1.432618498802185, 1.0286402702331543, 1.0921887159347534, 1.5278372764587402, 1.127602458000183, 1.6491575241088867, 1.2234848737716675, 1.078240990638733, 1.1343283653259277, 1.047109603881836, 1.097576379776001]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7466835975646973] ms
 --  Average per query NF    [1.356954574584961] ms
 --  Average per query vegas [2.3897290229797363] ms
Mean [1.140]  Median [1.104]  95th [1.368]  99th [1.529]  max [1.942]
Mean [1.140]  Median [1.104]  95th [1.368]  99th [1.529]  max [1.942]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.823069 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=sample', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
Sample - START
Sample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[1.1920929e-07 2.9802322e-07 0.0000000e+00 0.0000000e+00 5.9604645e-08]
Distance score: 9.536743306171047e-08
SAUCE Drift detection: False
Detection latency: 0.0235s

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.028908 | Model-update-time: 0.000000


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=sample', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.17603588104248
tensor(0.9957)
result is  tensor(456641.9688)
Enter testHyper
ReportEsts: [1.0306941270828247, 1.105741024017334, 1.3246153593063354, 1.2834529876708984, 1.0679489374160767, 1.0210537910461426, 1.3553680181503296, 1.053725242614746, 1.0248756408691406, 1.1298731565475464, 1.101407766342163, 1.070643663406372, 1.2320988178253174, 1.1088594198226929, 1.0021051168441772, 1.038515567779541, 1.3058357238769531, 1.0433565378189087, 1.081882119178772, 1.2691712379455566, 1.0402076244354248, 1.800639033317566, 1.1009330749511719, 1.0793437957763672, 1.207500696182251, 1.104905605316162, 1.1291550397872925, 1.1773815155029297, 1.0723732709884644, 1.4635761976242065, 1.3520580530166626, 1.1458333730697632, 1.0742533206939697, 1.1556947231292725, 1.1518429517745972, 1.101324200630188, 1.0472114086151123, 1.1725226640701294, 1.1481167078018188, 1.04427170753479, 1.1247833967208862, 1.07626211643219, 1.0290859937667847, 1.0896588563919067, 1.1055256128311157, 1.123136281967163, 1.2643418312072754, 1.1122701168060303, 1.1619433164596558, 1.1897838115692139, 1.0663561820983887, 1.0199737548828125, 1.089322566986084, 1.041556477546692, 1.0807654857635498, 1.2793608903884888, 1.01547372341156, 1.2013531923294067, 1.2446092367172241, 1.1204057931900024, 1.5425790548324585, 1.0608274936676025, 1.0182926654815674, 1.5383517742156982, 1.0184762477874756, 1.0178945064544678, 1.4294601678848267, 1.096415400505066, 1.1483113765716553, 1.0662460327148438, 1.0849977731704712, 1.2084311246871948, 1.095200777053833, 1.0512416362762451, 1.1044658422470093, 1.157536506652832, 1.014902114868164, 1.1006922721862793, 1.2068792581558228, 1.0558120012283325, 1.2133039236068726, 1.1887308359146118, 1.1216554641723633, 1.2334064245224, 1.3134223222732544, 1.3795620203018188, 1.17156183719635, 1.379742980003357, 1.0996354818344116, 1.151111125946045, 1.1374444961547852, 1.1280828714370728, 1.2855420112609863, 1.1718417406082153, 1.2874679565429688, 1.0897352695465088, 1.1124383211135864, 1.3562952280044556, 1.2385553121566772, 1.7778379917144775, 1.1766020059585571, 1.0875751972198486, 1.1435185670852661, 1.2822556495666504, 1.0556694269180298, 1.132371425628662, 1.1101869344711304, 1.2782763242721558, 1.1971428394317627, 1.0407259464263916, 1.0416368246078491, 1.0197993516921997, 1.2235376834869385, 1.3943043947219849, 1.1345348358154297, 1.0489078760147095, 1.0609709024429321, 1.1356056928634644, 1.0686537027359009, 1.174311876296997, 1.0209749937057495, 1.0592173337936401, 1.0752778053283691, 1.023400902748108, 1.123955488204956, 1.074255108833313, 1.1033713817596436, 1.3197389841079712, 1.3166807889938354, 1.1509391069412231, 1.1993589401245117, 1.1652411222457886, 1.0058048963546753, 1.7339149713516235, 1.6810344457626343, 1.1733646392822266, 1.107694387435913, 1.0837581157684326, 1.0984019041061401, 1.0344407558441162, 1.095292568206787, 1.2231676578521729, 1.007816195487976, 1.0176756381988525, 1.003627061843872, 1.2167900800704956, 1.402234673500061, 1.0242177248001099, 1.1038236618041992, 1.1223456859588623, 1.1816226243972778, 1.0629304647445679, 1.221613883972168, 1.1188380718231201, 1.0517947673797607, 1.104003667831421, 1.038103461265564, 1.370078682899475, 1.168010950088501, 1.1292952299118042, 1.092860460281372, 1.0608007907867432, 1.1934453248977661, 1.1126518249511719, 1.1770403385162354, 1.018315076828003, 1.1710864305496216, 1.271978735923767, 1.0370705127716064, 1.398003339767456, 1.1094657182693481, 1.0383094549179077, 1.3249694108963013, 1.1381086111068726, 1.0190491676330566, 1.0817559957504272, 1.1971629858016968, 1.083016276359558, 1.1174439191818237, 1.0509904623031616, 1.5813953876495361, 1.1026201248168945, 1.0702030658721924, 1.4304476976394653, 1.3053175210952759, 1.258372187614441, 1.384313702583313, 1.1007369756698608, 1.5326194763183594, 1.0623195171356201, 1.1355921030044556, 1.0293530225753784, 1.2083046436309814, 2.0484604835510254, 1.0416089296340942, 1.3333333730697632, 1.590078353881836, 1.053505539894104, 1.2141757011413574, 1.0537930727005005]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.667604923248291] ms
 --  Average per query NF    [1.3573813438415527] ms
 --  Average per query vegas [2.3102235794067383] ms
Mean [1.169]  Median [1.120]  95th [1.467]  99th [1.778]  max [2.048]
Mean [1.169]  Median [1.120]  95th [1.467]  99th [1.778]  max [2.048]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.153481 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=0 | total-time=26.079617