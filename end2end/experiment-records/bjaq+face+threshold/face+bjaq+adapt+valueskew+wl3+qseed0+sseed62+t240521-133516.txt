Input arguments = Namespace(data_update='valueskew', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 62, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.193544149398804
tensor(0.9944)
result is  tensor(380035.3750)
Enter testHyper
ReportEsts: [1.1753321886062622, 1.0071650743484497, 1.4110174179077148, 1.0486418008804321, 1.2364747524261475, 1.1114692687988281, 1.2091197967529297, 1.078533411026001, 1.085740089416504, 1.138589859008789, 1.058570146560669, 1.1088982820510864, 1.0309432744979858, 1.0513392686843872, 1.2107549905776978, 1.3199018239974976, 1.2931501865386963, 1.1507126092910767, 1.2766711711883545, 1.0663264989852905, 1.0441299676895142, 1.0718660354614258, 1.105273962020874, 1.0713220834732056, 1.2517356872558594, 1.1555153131484985, 1.079673409461975, 1.436193823814392, 1.0003618001937866, 1.0588953495025635, 1.1943951845169067, 1.2580381631851196, 1.0949844121932983, 1.016329050064087, 1.1231263875961304, 1.2418267726898193, 1.391294002532959, 1.2066984176635742, 1.0803970098495483, 1.160239577293396, 1.015928030014038, 1.1552975177764893, 1.091365098953247, 1.1463366746902466, 1.0933868885040283, 1.1077097654342651, 1.077189564704895, 1.246118187904358, 1.1346670389175415, 1.094754695892334, 1.1820513010025024, 1.2727272510528564, 1.1011184453964233, 1.22559654712677, 1.0685673952102661, 1.0778859853744507, 1.2719626426696777, 1.0796502828598022, 1.109506368637085, 1.439740777015686, 1.2302625179290771, 1.2353143692016602, 1.4156010150909424, 1.1694920063018799, 1.2406015396118164, 1.2857142686843872, 1.1146667003631592, 1.0608587265014648, 1.0809599161148071, 1.3157894611358643, 1.0450522899627686, 1.0056657791137695, 1.2235101461410522, 1.0109001398086548, 1.0662442445755005, 1.0077624320983887, 2.035017967224121, 1.0347235202789307, 1.011258840560913, 1.2578125, 1.208787441253662, 1.1831691265106201, 1.0299134254455566, 1.2243711948394775, 1.2771515846252441, 1.1169289350509644, 1.010692834854126, 1.1745271682739258, 1.0909680128097534, 1.1504271030426025, 1.0487060546875, 1.248905062675476, 1.0050486326217651, 1.2746641635894775, 1.05978262424469, 1.0016878843307495, 1.1451200246810913, 1.1323397159576416, 1.01694917678833, 1.152888298034668, 1.2465753555297852, 1.1374045610427856, 1.0377737283706665, 1.016837477684021, 1.2027196884155273, 1.0292606353759766, 1.1620914936065674, 1.1780104637145996, 1.0677361488342285, 1.0399904251098633, 1.15046226978302, 1.0953271389007568, 1.1977735757827759, 1.102125883102417, 1.1419960260391235, 1.1522842645645142, 1.0204135179519653, 1.1893460750579834, 1.3223613500595093, 1.1152006387710571, 1.2424476146697998, 1.1359872817993164, 1.2641195058822632, 1.0637891292572021, 1.297965168952942, 1.1860296726226807, 1.0338778495788574, 1.0966428518295288, 1.2885738611221313, 1.127922534942627, 1.2472891807556152, 1.1198818683624268, 1.214418888092041, 1.3928571939468384, 1.0686103105545044, 1.0084723234176636, 1.0928012132644653, 1.1401625871658325, 1.0254833698272705, 1.268567681312561, 1.136691689491272, 1.1430355310440063, 1.0130994319915771, 1.257464051246643, 1.0752015113830566, 1.0802570581436157, 1.022830605506897, 1.5069125890731812, 1.248740315437317, 1.0827414989471436, 1.1409683227539062, 1.1576720476150513, 1.3291958570480347, 1.2740212678909302, 1.0962259769439697, 1.028948426246643, 1.044632077217102, 1.0174634456634521, 1.0400315523147583, 1.1585795879364014, 1.064715027809143, 1.035184621810913, 1.0768214464187622, 1.3347578048706055, 1.1387213468551636, 1.040026307106018, 1.3400713205337524, 1.3812922239303589, 1.1048660278320312, 1.0403262376785278, 1.0320197343826294, 1.009753704071045, 1.149350643157959, 1.1601181030273438, 1.0657356977462769, 1.0880987644195557, 1.024295449256897, 1.2497841119766235, 1.1686320304870605, 1.0129457712173462, 1.0096923112869263, 1.0187419652938843, 1.0464216470718384, 1.1450459957122803, 1.1202462911605835, 1.1437631845474243, 1.0155020952224731, 1.2664786577224731, 1.032421588897705, 1.2535676956176758, 1.026877760887146, 1.138337254524231, 1.5435370206832886, 1.3192771673202515, 1.680088996887207, 1.229695439338684, 1.078741192817688, 1.0555555820465088, 1.086599588394165, 1.154249668121338]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7578535079956055] ms
 --  Average per query NF    [1.359250545501709] ms
 --  Average per query vegas [2.3986029624938965] ms
Mean [1.151]  Median [1.126]  95th [1.382]  99th [1.545]  max [2.035]
Mean [1.151]  Median [1.126]  95th [1.382]  99th [1.545]  max [2.035]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.863390 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=valueskew', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
ValueSample - START
ValueSample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[1.1371195e-02 4.7683716e-07 8.3446503e-07 1.8477440e-06 2.3841858e-07]
Distance score: 0.0022749186027795076
SAUCE Drift detection: True
Detection latency: 0.0234s

DRIFT-DETECTED after 2-th workload
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/incremental_train.py', '--dataset=bjaq', '--end2end', '--model=face', '--model_update=adapt', '--update_size=80000', '--epochs=0']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
update_size: 76433
AdaptTask - START
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
train data shape: 80000, transfer data shape:16000
Training done; evaluating likelihood on full data:
Saved to: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
AdaptTask - END

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.055688 | Model-update-time: 2.249417


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=valueskew', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.167203903198242
tensor(0.9962)
result is  tensor(456850.9062)
Enter testHyper
ReportEsts: [1.0701520442962646, 1.0383027791976929, 1.0861538648605347, 1.220969796180725, 1.3530470132827759, 1.325631022453308, 1.1220998764038086, 1.0697356462478638, 1.8404908180236816, 1.0746300220489502, 1.0179325342178345, 1.0524609088897705, 1.0501192808151245, 1.0909091234207153, 15.177462577819824, 1.2455867528915405, 1.4976234436035156, 1.14072847366333, 1.043525218963623, 1.1925663948059082, 1.203602910041809, 1.3180136680603027, 1.07158362865448, 1.1023125648498535, 1.1191582679748535, 1.5036094188690186, 1.1280887126922607, 1.107344627380371, 1.3559410572052002, 1.2039636373519897, 1.0077745914459229, 1.1538461446762085, 1.079736590385437, 1.0634722709655762, 1.1079645156860352, 1.067604422569275, 1.0368582010269165, 1.98778235912323, 1.429355263710022, 1.338788390159607, 1.1069540977478027, 1.046236515045166, 13.289790153503418, 1.0073689222335815, 1.0041922330856323, 1.1625114679336548, 1.0811715126037598, 1.1892739534378052, 1.0415093898773193, 1.054482340812683, 1.0540459156036377, 1.0897032022476196, 1.1475775241851807, 1.095985770225525, 1.2812265157699585, 1.4451813697814941, 1.2618956565856934, 1.0831280946731567, 1.025672197341919, 1.1448346376419067, 1.465596318244934, 1.440004587173462, 2.804654598236084, 1.3503304719924927, 1.215592384338379, 1.1124593019485474, 1.3810980319976807, 1.0144981145858765, 1.1691774129867554, 1.4107521772384644, 1.0550745725631714, 1.0883028507232666, 1.0130438804626465, 1.1933393478393555, 1.0929828882217407, 1.2136645317077637, 28.359025955200195, 1.114174723625183, 1.0460554361343384, 3.331862688064575, 1.3527194261550903, 1.095439076423645, 1.3920979499816895, 1.0565201044082642, 2.136099100112915, 1.1609907150268555, 1.2192878723144531, 1.4224110841751099, 1.5918196439743042, 3.3728814125061035, 1.1820944547653198, 1.0460505485534668, 1.3967726230621338, 1.135844111442566, 1.0543930530548096, 1.0809266567230225, 3.2529091835021973, 1.0033432245254517, 1.212085247039795, 1.0178204774856567, 1.2750167846679688, 1.072894811630249, 1.0392156839370728, 1.1316710710525513, 1.1370232105255127, 6.838983058929443, 1.008243203163147, 1.099772572517395, 1.1216216087341309, 1.1701765060424805, 1.104644775390625, 1.1144787073135376, 1.3162761926651, 1.3532053232192993, 1.0827759504318237, 1.0841169357299805, 1.0773133039474487, 1.4010180234909058, 1.6610753536224365, 1.168067216873169, 1.0089081525802612, 1.1178311109542847, 1.363678216934204, 2.6624398231506348, 1.127146601676941, 1.2337193489074707, 1.1199378967285156, 1.040123462677002, 1.0179965496063232, 1.2085883617401123, 1.071401834487915, 1.0948580503463745, 1.1077325344085693, 1.3326612710952759, 1.3560371398925781, 1.413003921508789, 1.1207501888275146, 1.0448768138885498, 1.3033686876296997, 1.195061206817627, 1.0233993530273438, 1.098863124847412, 1.2286196947097778, 1.1096512079238892, 1.2507820129394531, 1.084692120552063, 1.3425414562225342, 1.2410578727722168, 1.2251873016357422, 1.2518428564071655, 1.0398130416870117, 1.269883155822754, 1.2270846366882324, 1.0788648128509521, 1.0321321487426758, 1.0119717121124268, 1.2125816345214844, 1.0378787517547607, 1.1598684787750244, 1.07443106174469, 7.9873738288879395, 1.2684524059295654, 1.4727239608764648, 1.0991753339767456, 1.2398998737335205, 1.2525964975357056, 1.02105712890625, 1.1942867040634155, 81.12000274658203, 1.0919922590255737, 1.0631704330444336, 1.1625311374664307, 1.566888451576233, 1.0542970895767212, 1.077093482017517, 1.1015076637268066, 1.002200722694397, 1.1314438581466675, 1.1542328596115112, 1.1112098693847656, 1.54347825050354, 1.0899850130081177, 1.0147684812545776, 1.298848271369934, 1.1443524360656738, 1.2211209535598755, 2.1974523067474365, 1.308825969696045, 1.48856782913208, 1.0569466352462769, 1.06242036819458, 1.0500074625015259, 1.1643686294555664, 1.7974348068237305, 1.0255156755447388, 1.0002371072769165, 1.570793867111206, 1.0150645971298218, 1.34024178981781, 1.179324746131897]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.737821578979492] ms
 --  Average per query NF    [1.3589918613433838] ms
 --  Average per query vegas [2.3788297176361084] ms
Mean [1.969]  Median [1.136]  95th [2.670]  99th [15.309]  max [81.120]
Mean [1.969]  Median [1.136]  95th [2.670]  99th [15.309]  max [81.120]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.365082 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=1 | total-time=28.602899