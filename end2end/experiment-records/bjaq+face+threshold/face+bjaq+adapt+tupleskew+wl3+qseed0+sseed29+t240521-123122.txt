Input arguments = Namespace(data_update='tupleskew', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 29, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.164818525314331
tensor(0.9954)
result is  tensor(380405.1250)
Enter testHyper
ReportEsts: [1.1184717416763306, 1.1055998802185059, 1.577087640762329, 1.08970308303833, 1.2368344068527222, 1.19511079788208, 1.2318730354309082, 1.1874827146530151, 1.0699673891067505, 1.0606931447982788, 1.105943202972412, 1.087499976158142, 1.1951186656951904, 1.0513392686843872, 1.1101740598678589, 1.4784197807312012, 1.32403564453125, 1.171140193939209, 1.2042993307113647, 1.0357142686843872, 1.095068335533142, 1.0934462547302246, 1.1183555126190186, 1.0350072383880615, 1.1082251071929932, 1.184448480606079, 1.0526463985443115, 1.3194444179534912, 1.0226774215698242, 1.103041410446167, 1.111032247543335, 1.0758329629898071, 1.081519365310669, 1.0875117778778076, 1.0738757848739624, 1.0929162502288818, 1.2753046751022339, 1.2286959886550903, 1.1236687898635864, 1.2671856880187988, 1.0320602655410767, 1.1455007791519165, 1.0244483947753906, 1.0032161474227905, 1.0676103830337524, 1.0510203838348389, 1.110386610031128, 1.2614272832870483, 1.104123830795288, 1.0761420726776123, 1.2595628499984741, 1.4308998584747314, 1.0091791152954102, 1.233239769935608, 1.0589655637741089, 1.0739452838897705, 1.1700934171676636, 1.131588339805603, 1.305639386177063, 1.3951444625854492, 1.623483657836914, 1.2214406728744507, 1.1599985361099243, 1.0845328569412231, 1.2643678188323975, 1.1714285612106323, 1.0546678304672241, 1.0233250856399536, 1.107217788696289, 1.3052631616592407, 1.0799305438995361, 1.1160788536071777, 1.193672776222229, 1.1142617464065552, 1.2879011631011963, 1.2480393648147583, 1.709612488746643, 1.0743815898895264, 1.1315736770629883, 1.3416322469711304, 1.257238507270813, 1.1489259004592896, 1.0347638130187988, 1.1650787591934204, 1.3137362003326416, 1.0827507972717285, 1.0053763389587402, 1.230617880821228, 1.004523754119873, 1.0173314809799194, 1.0020333528518677, 1.2873083353042603, 1.0331594944000244, 1.3815261125564575, 1.1470588445663452, 1.0521596670150757, 1.1643520593643188, 1.3882787227630615, 1.034482717514038, 1.1185282468795776, 1.1617021560668945, 1.0516806840896606, 1.0665619373321533, 1.003673791885376, 1.152510404586792, 1.0990310907363892, 1.1342476606369019, 1.179755687713623, 1.048513412475586, 1.0485272407531738, 1.0631506443023682, 1.1467710733413696, 1.073215365409851, 1.052337408065796, 1.063173770904541, 1.213903784751892, 1.064282774925232, 1.0548174381256104, 1.220698356628418, 1.0929334163665771, 1.154891848564148, 1.1194287538528442, 1.1274254322052002, 1.1055505275726318, 1.4437984228134155, 1.176640510559082, 1.1770873069763184, 1.2002100944519043, 1.3423110246658325, 1.1295925378799438, 1.0087333917617798, 1.231973648071289, 1.1979490518569946, 1.5, 1.0506123304367065, 1.0654546022415161, 1.0468250513076782, 1.1333333253860474, 1.0943737030029297, 1.1019585132598877, 1.1187714338302612, 1.1450285911560059, 1.244584083557129, 1.3376177549362183, 1.0545446872711182, 1.1465531587600708, 1.0909059047698975, 1.5804736614227295, 1.1079840660095215, 1.0540482997894287, 1.244057059288025, 1.1551083326339722, 1.2990506887435913, 1.2343610525131226, 1.2254713773727417, 1.0303764343261719, 1.2073215246200562, 1.0160382986068726, 1.0278791189193726, 1.084333062171936, 1.1001049280166626, 1.1035704612731934, 1.0273103713989258, 1.323446273803711, 1.2722371816635132, 1.000633955001831, 1.2536805868148804, 1.2342956066131592, 1.0325132608413696, 1.0308314561843872, 1.2693731784820557, 1.121625542640686, 1.1883116960525513, 1.0940200090408325, 1.0681198835372925, 1.148172378540039, 1.0568512678146362, 1.2576580047607422, 1.1761226654052734, 1.0948870182037354, 1.083008885383606, 1.121329426765442, 1.0017499923706055, 1.067415714263916, 1.2241941690444946, 1.1543340682983398, 1.047556757926941, 1.326319694519043, 1.004743218421936, 1.303450345993042, 1.0864555835723877, 1.0312000513076782, 1.5104525089263916, 1.5604089498519897, 2.167167901992798, 1.208229422569275, 1.0980408191680908, 1.0555555820465088, 1.1201006174087524, 1.0017627477645874]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.764655590057373] ms
 --  Average per query NF    [1.3605213165283203] ms
 --  Average per query vegas [2.4041342735290527] ms
Mean [1.161]  Median [1.118]  95th [1.432]  99th [1.624]  max [2.167]
Mean [1.161]  Median [1.118]  95th [1.432]  99th [1.624]  max [2.167]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.836046 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=tupleskew', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
TupleSkewSample - START
0.001
TupleSkewSample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[5.9068203e-05 2.3841858e-05 3.5339594e-04 3.6478043e-05 3.3140182e-05]
Distance score: 0.0001011848435155116
SAUCE Drift detection: True
Detection latency: 0.0228s

DRIFT-DETECTED after 2-th workload
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/incremental_train.py', '--dataset=bjaq', '--end2end', '--model=face', '--model_update=adapt', '--update_size=80000', '--epochs=0']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
update_size: 76433
AdaptTask - START
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
train data shape: 80000, transfer data shape:16000
Training done; evaluating likelihood on full data:
Saved to: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
AdaptTask - END

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 1.999039 | Model-update-time: 2.245333


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=tupleskew', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.162011861801147
tensor(0.9946)
result is  tensor(456142.2500)
Enter testHyper
ReportEsts: [1.0766489505767822, 1.0760838985443115, 1.04283607006073, 1.0535622835159302, 1.0243234634399414, 1.2977460622787476, 1.1287968158721924, 1.1194764375686646, 1.0304595232009888, 1.0163689851760864, 1.1329058408737183, 1.1245052814483643, 1.0661578178405762, 1.2695417404174805, 1.1954501867294312, 1.0479811429977417, 1.3240506649017334, 1.0537819862365723, 1.0216748714447021, 1.2852096557617188, 1.0079182386398315, 1.0266108512878418, 1.5751256942749023, 1.0122289657592773, 1.068022608757019, 1.1777228116989136, 1.0211683511734009, 1.1806004047393799, 1.4360476732254028, 2.186119794845581, 1.2985469102859497, 1.51694917678833, 1.113667607307434, 1.0084712505340576, 1.091479778289795, 1.0636261701583862, 1.1996898651123047, 1.173076868057251, 1.0796657800674438, 1.1125725507736206, 1.0094223022460938, 1.173690915107727, 1.1552517414093018, 1.151152491569519, 1.024224877357483, 1.203141689300537, 1.0185739994049072, 1.0334866046905518, 1.2619047164916992, 1.1130952835083008, 1.0203062295913696, 1.006007194519043, 1.101467251777649, 1.0693572759628296, 1.0845149755477905, 1.1089913845062256, 1.1403371095657349, 1.0199403762817383, 1.2653201818466187, 1.1359151601791382, 1.3333333730697632, 1.0532758235931396, 1.0140618085861206, 1.5744537115097046, 1.0034648180007935, 1.084747076034546, 1.3893153667449951, 1.0721861124038696, 1.1535160541534424, 1.1708145141601562, 1.0561081171035767, 1.2927731275558472, 1.2044358253479004, 1.152363657951355, 1.0761489868164062, 1.0863902568817139, 1.067637324333191, 1.2605003118515015, 1.0602498054504395, 1.1125373840332031, 1.0431256294250488, 1.0071321725845337, 1.001451015472412, 1.2033179998397827, 1.2895480394363403, 1.6936169862747192, 1.4293756484985352, 1.35602605342865, 2.2298507690429688, 1.2727272510528564, 1.369515061378479, 1.0633106231689453, 1.471329927444458, 1.1958904266357422, 1.0152127742767334, 1.0367271900177002, 1.0287171602249146, 1.1855955123901367, 1.1924805641174316, 1.2480577230453491, 1.0382317304611206, 1.1570736169815063, 1.0355329513549805, 1.1304422616958618, 1.056026577949524, 1.2180376052856445, 1.0043772459030151, 1.1660484075546265, 1.0028735399246216, 1.163455605506897, 1.036927580833435, 1.0527740716934204, 1.3062386512756348, 1.3767673969268799, 1.143823266029358, 1.0200059413909912, 1.0999871492385864, 1.160721778869629, 1.1735643148422241, 1.0, 1.0323172807693481, 1.4866043329238892, 1.0522633790969849, 1.2049918174743652, 1.0610766410827637, 1.0185984373092651, 1.1720062494277954, 1.0369230508804321, 1.0124154090881348, 1.0127754211425781, 1.1098594665527344, 1.1422054767608643, 1.1478358507156372, 1.8550186157226562, 1.4785642623901367, 1.0246691703796387, 1.0500651597976685, 1.1137696504592896, 1.1295579671859741, 1.0794986486434937, 1.0097092390060425, 1.0693421363830566, 1.0640580654144287, 1.0273605585098267, 1.075967788696289, 1.022131085395813, 2.4035086631774902, 1.0726158618927002, 1.2669869661331177, 1.0482211112976074, 1.105384349822998, 1.2287975549697876, 1.0892266035079956, 1.1203125715255737, 1.05521559715271, 1.4520089626312256, 1.1345348358154297, 1.0959999561309814, 1.3739148378372192, 1.0870859622955322, 1.0, 1.2583333253860474, 1.1780741214752197, 1.0497384071350098, 1.0416511297225952, 1.4203338623046875, 1.1157543659210205, 1.0674313306808472, 1.016268253326416, 1.3510730266571045, 1.0878982543945312, 1.105207920074463, 1.374449372291565, 1.2234102487564087, 1.0347009897232056, 1.0981345176696777, 1.1305502653121948, 1.2169215679168701, 1.1014635562896729, 1.177101969718933, 1.8157894611358643, 1.0052140951156616, 1.0776625871658325, 1.5029388666152954, 1.3424993753433228, 1.2050167322158813, 1.4387755393981934, 1.0456186532974243, 1.429351806640625, 1.085477590560913, 1.1983449459075928, 1.0482620000839233, 1.1438840627670288, 1.5976970195770264, 1.0879958868026733, 1.484581470489502, 1.145346760749817, 1.0244346857070923, 1.4193037748336792, 1.1627857685089111]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.6490297317504883] ms
 --  Average per query NF    [1.3562572002410889] ms
 --  Average per query vegas [2.2927725315093994] ms
Mean [1.175]  Median [1.113]  95th [1.504]  99th [2.187]  max [2.404]
Mean [1.175]  Median [1.113]  95th [1.504]  99th [2.187]  max [2.404]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.321123 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=1 | total-time=28.441262