Input arguments = Namespace(data_update='valueskew', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 64, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.169061660766602
tensor(0.9955)
result is  tensor(380456.0625)
Enter testHyper
ReportEsts: [1.1904622316360474, 1.0858632326126099, 1.1633931398391724, 1.0117919445037842, 1.2617987394332886, 1.1051876544952393, 1.281840205192566, 1.0302739143371582, 1.0457838773727417, 1.2122176885604858, 1.0051679611206055, 1.1343220472335815, 1.0345155000686646, 1.0267857313156128, 1.0939509868621826, 1.2987068891525269, 1.3323038816452026, 1.2369358539581299, 1.1434835195541382, 1.1147959232330322, 1.0570844411849976, 1.1279003620147705, 1.1192851066589355, 1.0270848274230957, 1.0588908195495605, 1.0235081911087036, 1.1199324131011963, 1.3862661123275757, 1.0264215469360352, 1.0460786819458008, 1.1372827291488647, 1.2103952169418335, 1.0109179019927979, 1.0867069959640503, 1.1619173288345337, 1.0188958644866943, 1.5974242687225342, 1.103018879890442, 1.08359956741333, 1.0100399255752563, 1.004303216934204, 1.082002878189087, 1.1396479606628418, 1.0246696472167969, 1.0887386798858643, 1.0510203838348389, 1.1140186786651611, 1.1776015758514404, 1.1077415943145752, 1.067681908607483, 1.1912144422531128, 1.3541131019592285, 1.0955106019973755, 1.2886934280395508, 1.0700401067733765, 1.012285590171814, 1.2626168727874756, 1.186416745185852, 1.3617576360702515, 1.3423278331756592, 1.2444554567337036, 1.1863155364990234, 1.3210301399230957, 1.1184017658233643, 1.226765751838684, 1.2285714149475098, 1.1611111164093018, 1.0006006956100464, 1.0590652227401733, 1.357894778251648, 1.0516074895858765, 1.0816861391067505, 1.198346495628357, 1.2578201293945312, 1.1510778665542603, 1.0562207698822021, 2.1312382221221924, 1.0299304723739624, 1.0395859479904175, 1.4189831018447876, 1.1935341358184814, 1.1224358081817627, 1.0008971691131592, 1.227188229560852, 1.2215880155563354, 1.026130199432373, 1.0737501382827759, 1.0830265283584595, 1.0050281286239624, 1.1193299293518066, 1.038190245628357, 1.5693665742874146, 1.0126217603683472, 1.186974287033081, 1.174698829650879, 1.170215368270874, 1.1331686973571777, 1.3149175643920898, 1.01694917678833, 1.1719876527786255, 1.0499999523162842, 1.1450568437576294, 1.0279159545898438, 1.0239880084991455, 1.035304307937622, 1.0048350095748901, 1.1589279174804688, 1.1989529132843018, 1.0774224996566772, 1.0407381057739258, 1.266655683517456, 1.130183219909668, 1.060842514038086, 1.0266168117523193, 1.0943549871444702, 1.164102554321289, 1.0761799812316895, 1.0871920585632324, 1.2593764066696167, 1.0232816934585571, 1.2477294206619263, 1.140333890914917, 1.0776822566986084, 1.215646743774414, 1.3594961166381836, 1.2115145921707153, 1.2129169702529907, 1.1753969192504883, 1.3250428438186646, 1.1459585428237915, 1.1099584102630615, 1.1416373252868652, 1.2190802097320557, 1.5357142686843872, 1.0451171398162842, 1.0042005777359009, 1.0566864013671875, 1.1047154664993286, 1.1381125450134277, 1.2069400548934937, 1.1209616661071777, 1.0057601928710938, 1.1398231983184814, 1.2441787719726562, 1.0783605575561523, 1.004302740097046, 1.1696679592132568, 1.4085328578948975, 1.0035229921340942, 1.087357997894287, 1.1329437494277954, 1.1762593984603882, 1.2669752836227417, 1.0751439332962036, 1.2234742641448975, 1.0083091259002686, 1.1135469675064087, 1.0270118713378906, 1.0386958122253418, 1.194330096244812, 1.0342400074005127, 1.016042947769165, 1.085543155670166, 1.3443328142166138, 1.0776255130767822, 1.0347427129745483, 1.2144439220428467, 1.2602498531341553, 1.2196711301803589, 1.05453360080719, 1.0451757907867432, 1.0844738483428955, 1.1623376607894897, 1.1625146865844727, 1.0439373254776, 1.0174940824508667, 1.0301263332366943, 1.2881619930267334, 1.121137261390686, 1.034641146659851, 1.0374670028686523, 1.0159574747085571, 1.014644980430603, 1.0970377922058105, 1.083665370941162, 1.0909091234207153, 1.0673472881317139, 1.292911171913147, 1.0038725137710571, 1.2556759119033813, 1.0358121395111084, 1.0582292079925537, 1.6506651639938354, 1.4723764657974243, 1.8846954107284546, 1.1426886320114136, 1.0600666999816895, 1.1343283653259277, 1.0242743492126465, 1.095484733581543]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.8078224658966064] ms
 --  Average per query NF    [1.3672173023223877] ms
 --  Average per query vegas [2.4406051635742188] ms
Mean [1.147]  Median [1.114]  95th [1.363]  99th [1.653]  max [2.131]
Mean [1.147]  Median [1.114]  95th [1.363]  99th [1.653]  max [2.131]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.846899 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=valueskew', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
ValueSample - START
ValueSample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[3.5762787e-07 7.6002181e-02 2.9802322e-07 7.1525574e-07 7.1525574e-07]
Distance score: 0.01520085334777832
SAUCE Drift detection: True
Detection latency: 0.0231s

DRIFT-DETECTED after 2-th workload
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/incremental_train.py', '--dataset=bjaq', '--end2end', '--model=face', '--model_update=adapt', '--update_size=80000', '--epochs=0']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
update_size: 76433
AdaptTask - START
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
train data shape: 80000, transfer data shape:16000
Training done; evaluating likelihood on full data:
Saved to: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
AdaptTask - END

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.044860 | Model-update-time: 2.217574


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=valueskew', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.203686952590942
tensor(0.9936)
result is  tensor(455677.9375)
Enter testHyper
ReportEsts: [1.1833006143569946, 1.1899325847625732, 1.1165562868118286, 1.009093999862671, 1.0491610765457153, 1.3156743049621582, 1.1509886980056763, 1.00428307056427, 1.0206888914108276, 1.0177550315856934, 1.354341745376587, 1.0335242748260498, 1.1900237798690796, 1.049602746963501, 1879.238037109375, 1.2743704319000244, 1.488869071006775, 1.2895307540893555, 1.0457819700241089, 1.3967455625534058, 1.0304287672042847, 3.632413625717163, 1.1082338094711304, 1.203593373298645, 1.090654730796814, 1.1331429481506348, 1.1909488439559937, 1.3130972385406494, 1.4012994766235352, 1.5511810779571533, 1.2738927602767944, 1.2244898080825806, 1.085294246673584, 1.0580323934555054, 1.179734468460083, 1.2136889696121216, 1.2963604927062988, 1.113992691040039, 1.2367699146270752, 1.0568888187408447, 1.250266432762146, 1.07662832736969, 1.1108486652374268, 1.2868002653121948, 1.2287975549697876, 1.0314983129501343, 1.0708060264587402, 1.310980200767517, 1.2380952835083008, 1.1363470554351807, 1.1437723636627197, 1.3462756872177124, 1.0701775550842285, 1.0670757293701172, 1.0626698732376099, 1.4120914936065674, 1.1215909719467163, 1.1020863056182861, 1.0357483625411987, 1.0215483903884888, 1.4142539501190186, 1.0676077604293823, 1.1510573625564575, 1.036319613456726, 1.2306503057479858, 2.5405843257904053, 1.3561456203460693, 1.0131850242614746, 1.1678754091262817, 1.3287228345870972, 1.1954299211502075, 1.1064833402633667, 1.231489658355713, 1.1296672821044922, 1.7262020111083984, 1.1096105575561523, 2878.60009765625, 1.1460801362991333, 1.3343085050582886, 1.1471707820892334, 1.0522336959838867, 1.038414478302002, 1.0313631296157837, 1.163418173789978, 1.366245150566101, 1.6595745086669922, 1.1938612461090088, 1.255533218383789, 1.1987696886062622, 1.0532433986663818, 1.034301519393921, 1.3760467767715454, 1.1746257543563843, 1.145437479019165, 476.3333435058594, 1.0918763875961304, 1.0017772912979126, 1.008154034614563, 9.73127269744873, 1.1397061347961426, 1.1285805702209473, 1.3399558067321777, 1.1746411323547363, 1.201872706413269, 1.068986415863037, 1.0159871578216553, 1.0743249654769897, 1.0174410343170166, 1.0429799556732178, 1.1531788110733032, 2.8548600673675537, 1.1401973962783813, 1.1570000648498535, 1.2683379650115967, 1.3482187986373901, 1.0426844358444214, 1.2743399143218994, 1.3108296394348145, 1.132432222366333, 1.0296295881271362, 1.2624974250793457, 1.3532710075378418, 1.1349513530731201, 1.4418853521347046, 1.1357381343841553, 1.119683861732483, 1.5034373998641968, 1.2838915586471558, 1.108855962753296, 1.0474885702133179, 1.2304327487945557, 1.3274428844451904, 1.0538469552993774, 2.079155683517456, 1.0185439586639404, 1.1208866834640503, 1.1595208644866943, 1.0982447862625122, 1.3139190673828125, 1.1716457605361938, 1.1077911853790283, 1.084875226020813, 1.17873215675354, 1.0225605964660645, 1.0235413312911987, 1.1841343641281128, 1.318750023841858, 1.0795375108718872, 1.0924006700515747, 1.0974308252334595, 1.0731828212738037, 1.0467817783355713, 1.3992836475372314, 1.2907733917236328, 1.1294418573379517, 1.631229281425476, 1.1216521263122559, 1.030075192451477, 1.0441882610321045, 1.1317261457443237, 1.9529497623443604, 1.2178571224212646, 1.0781701803207397, 1.0737850666046143, 1.2780436277389526, 1.0437183380126953, 1.2110629081726074, 53.159732818603516, 875.0, 1.0682071447372437, 1.0213229656219482, 1.133476972579956, 3.5144879817962646, 1.1581350564956665, 4.029229640960693, 1.1089696884155273, 6.839354038238525, 1.3051997423171997, 1.0256654024124146, 1.425520658493042, 1.6585365533828735, 1.4788135290145874, 1.135017991065979, 1.6560723781585693, 1.5380975008010864, 1.0442477464675903, 1.4119776487350464, 1.1183820962905884, 1.2879270315170288, 1.0078959465026855, 1.129375696182251, 1.063051700592041, 1.2375152111053467, 1.6067203283309937, 1.0489376783370972, 43.30088424682617, 1.2196873426437378, 1.1240026950836182, 1.0592000484466553, 1.0667879581451416]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.724789619445801] ms
 --  Average per query NF    [1.3551068305969238] ms
 --  Average per query vegas [2.369682788848877] ms
Mean [32.308]  Median [1.151]  95th [3.520]  99th [885.042]  max [2878.600]
Mean [32.308]  Median [1.151]  95th [3.520]  99th [885.042]  max [2878.600]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.444138 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=1 | total-time=28.578279