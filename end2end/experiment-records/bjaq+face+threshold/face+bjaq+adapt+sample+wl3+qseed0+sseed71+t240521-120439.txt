Input arguments = Namespace(data_update='sample', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 71, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.15438985824585
tensor(0.9981)
result is  tensor(381443.6250)
Enter testHyper
ReportEsts: [1.168916940689087, 1.0660771131515503, 1.6052221059799194, 1.0257019996643066, 1.2606761455535889, 1.1168698072433472, 1.3232059478759766, 1.150119662284851, 1.078601360321045, 1.0298395156860352, 1.0930233001708984, 1.0597457885742188, 1.0875060558319092, 1.03125, 1.1199020147323608, 1.2922428846359253, 1.221797227859497, 1.1476247310638428, 1.1993340253829956, 1.170918345451355, 1.077601432800293, 1.0182857513427734, 1.1324642896652222, 1.0936412811279297, 1.1211304664611816, 1.330922245979309, 1.1154279708862305, 1.4086350202560425, 1.0612674951553345, 1.0728307962417603, 1.0752040147781372, 1.2457256317138672, 1.1479010581970215, 1.0234309434890747, 1.0649811029434204, 1.2366560697555542, 1.3291231393814087, 1.1590038537979126, 1.002995252609253, 1.2023952007293701, 1.0851105451583862, 1.0951862335205078, 1.06203293800354, 1.0057079792022705, 1.0904289484024048, 1.0544217824935913, 1.1339781284332275, 1.3079805374145508, 1.0788193941116333, 1.1641285419464111, 1.1850899457931519, 1.303030252456665, 1.0417755842208862, 1.4267677068710327, 1.2047597169876099, 1.0011603832244873, 1.3887850046157837, 1.2295606136322021, 1.246082067489624, 1.5067812204360962, 1.133423924446106, 1.1658905744552612, 1.3777587413787842, 1.212687373161316, 1.2547528743743896, 1.1142857074737549, 1.1399999856948853, 1.038489818572998, 1.0171555280685425, 1.1473684310913086, 1.0949316024780273, 1.1389187574386597, 1.1907378435134888, 1.0301381349563599, 1.1516075134277344, 1.0390474796295166, 1.7534136772155762, 1.0453888177871704, 1.1224915981292725, 1.4650297164916992, 1.1362388134002686, 1.118074655532837, 1.059736967086792, 1.2143479585647583, 1.309983730316162, 1.151340365409851, 1.1741513013839722, 1.001715064048767, 1.0749181509017944, 1.0352433919906616, 1.0016200542449951, 1.4565342664718628, 1.010936975479126, 1.321488618850708, 1.1890244483947754, 1.053301453590393, 1.2316585779190063, 1.270546555519104, 1.01694917678833, 1.149611473083496, 1.2390317916870117, 1.0572985410690308, 1.074219822883606, 1.0219619274139404, 1.006066918373108, 1.1125777959823608, 1.1798735857009888, 1.1710296869277954, 1.024786353111267, 1.0704954862594604, 1.041731357574463, 1.0732600688934326, 1.0801868438720703, 1.031164288520813, 1.160078763961792, 1.140703558921814, 1.0065182447433472, 1.0247646570205688, 1.196454644203186, 1.1137516498565674, 1.229670524597168, 1.114254117012024, 1.1790357828140259, 1.039743423461914, 1.2655038833618164, 1.1983078718185425, 1.128963589668274, 1.0714366436004639, 1.3227739334106445, 1.1175684928894043, 1.1253150701522827, 1.140158772468567, 1.2265381813049316, 1.4285714626312256, 1.157210350036621, 1.1517459154129028, 1.0095454454421997, 1.2868292331695557, 1.2076740264892578, 1.3994147777557373, 1.0947781801223755, 1.0068196058273315, 1.2523165941238403, 1.3070464134216309, 1.0786784887313843, 1.087052822113037, 1.0652649402618408, 1.6779536008834839, 1.0300273895263672, 1.062926173210144, 1.126079797744751, 1.1763876676559448, 1.2935924530029297, 1.2345197200775146, 1.0733637809753418, 1.1657081842422485, 1.062044382095337, 1.0096590518951416, 1.009055733680725, 1.2247687578201294, 1.0260766744613647, 1.000410556793213, 1.0197339057922363, 1.2137305736541748, 1.14702308177948, 1.1204968690872192, 1.257199764251709, 1.238778829574585, 1.0316376686096191, 1.0033146142959595, 1.204850196838379, 1.0006097555160522, 1.1103895902633667, 1.1610099077224731, 1.1372616291046143, 1.1480003595352173, 1.0223547220230103, 1.1271417140960693, 1.1056314706802368, 1.0054357051849365, 1.096077799797058, 1.0609829425811768, 1.0075167417526245, 1.1695607900619507, 1.1847156286239624, 1.1733615398406982, 1.0428496599197388, 1.254101276397705, 1.0476089715957642, 1.3762333393096924, 1.012131690979004, 1.0735992193222046, 1.3990195989608765, 1.0573047399520874, 1.925669550895691, 1.2792079448699951, 1.0874947309494019, 1.0704225301742554, 1.091047763824463, 1.0559097528457642]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7736618518829346] ms
 --  Average per query NF    [1.370474100112915] ms
 --  Average per query vegas [2.4031877517700195] ms
Mean [1.153]  Median [1.124]  95th [1.400]  99th [1.679]  max [1.926]
Mean [1.153]  Median [1.124]  95th [1.400]  99th [1.679]  max [1.926]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.841369 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=sample', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
Sample - START
Sample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[3.5762787e-06 4.0531158e-06 1.0132790e-06 3.4570694e-06 1.0728836e-06]
Distance score: 2.6345253445470007e-06
SAUCE Drift detection: False
Detection latency: 0.0234s

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.028505 | Model-update-time: 0.000000


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=sample', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.163047552108765
tensor(0.9913)
result is  tensor(454615.7812)
Enter testHyper
ReportEsts: [1.0533547401428223, 1.0246858596801758, 1.170698881149292, 1.067217230796814, 1.015919804573059, 1.2960121631622314, 1.2749377489089966, 1.1570383310317993, 1.0374503135681152, 1.0469841957092285, 1.0767515897750854, 1.2603943347930908, 1.2412060499191284, 1.0473029613494873, 1.151070237159729, 1.0221400260925293, 1.1023328304290771, 1.0789391994476318, 1.0554217100143433, 1.183095097541809, 1.2049643993377686, 1.5130559206008911, 1.030903697013855, 1.078863263130188, 1.0810468196868896, 1.1935046911239624, 1.2123126983642578, 1.1591336727142334, 1.3394625186920166, 1.3262518644332886, 1.1937984228134155, 1.241134762763977, 1.0380768775939941, 1.094305157661438, 1.0420234203338623, 1.1285680532455444, 1.1154567003250122, 1.0299487113952637, 1.09889817237854, 1.014093041419983, 1.0573068857192993, 1.073752760887146, 1.4009783267974854, 1.0279569625854492, 1.043890118598938, 1.1468563079833984, 1.175804615020752, 1.0559252500534058, 1.195918321609497, 1.2235026359558105, 1.0043984651565552, 1.0061548948287964, 1.1157772541046143, 1.0115643739700317, 1.089859962463379, 1.5682228803634644, 1.2138978242874146, 1.2317962646484375, 1.2505476474761963, 1.1018085479736328, 1.4838709831237793, 1.0264407396316528, 1.1054084300994873, 1.2984721660614014, 1.0825368165969849, 1.0269523859024048, 1.3515805006027222, 1.1466730833053589, 1.1382967233657837, 1.0511102676391602, 1.1077682971954346, 1.1826300621032715, 1.0811853408813477, 1.0527069568634033, 1.052778959274292, 1.047943115234375, 1.034885287284851, 1.2398663759231567, 1.3206647634506226, 1.0696004629135132, 1.164921522140503, 1.0167677402496338, 1.0316236019134521, 1.1134693622589111, 1.238439679145813, 1.2831541299819946, 1.273821473121643, 1.4721044301986694, 1.115638256072998, 1.0825275182724, 1.005753755569458, 1.0692707300186157, 1.3098604679107666, 1.1208679676055908, 1.2677286863327026, 1.0943814516067505, 1.0346684455871582, 1.2951807975769043, 1.001562476158142, 1.01432466506958, 1.0271137952804565, 1.1415891647338867, 1.2519084215164185, 1.1403822898864746, 1.2396726608276367, 1.2226557731628418, 1.0372503995895386, 1.044838547706604, 1.1123287677764893, 1.1527783870697021, 1.1004819869995117, 1.0679948329925537, 1.138202428817749, 1.17099130153656, 1.0311203002929688, 1.0227605104446411, 1.0243360996246338, 1.0813112258911133, 1.076546311378479, 1.1607142686843872, 1.0246405601501465, 1.1788703203201294, 1.1197924613952637, 1.6184509992599487, 1.0335142612457275, 1.1549100875854492, 1.2573026418685913, 1.2866241931915283, 1.0666842460632324, 1.0479404926300049, 1.0122783184051514, 1.0679596662521362, 1.1377454996109009, 1.625, 1.2675343751907349, 1.0566999912261963, 1.0792498588562012, 1.2147188186645508, 1.0503077507019043, 1.0606797933578491, 1.0238611698150635, 1.1854981184005737, 1.0266729593276978, 1.0906751155853271, 1.0510437488555908, 1.0111058950424194, 1.5617283582687378, 1.0068360567092896, 1.2059158086776733, 1.02965247631073, 1.0087409019470215, 1.00252366065979, 1.248450517654419, 1.1750425100326538, 1.0118274688720703, 1.0416977405548096, 1.1636513471603394, 1.350000023841858, 1.328525424003601, 1.1878812313079834, 1.06365966796875, 1.0497666597366333, 1.2153120040893555, 1.1067224740982056, 1.1073386669158936, 1.1855145692825317, 1.0691783428192139, 1.234052062034607, 1.1238183975219727, 1.322766661643982, 1.1699392795562744, 1.0265666246414185, 1.4647217988967896, 1.0356999635696411, 1.009034276008606, 1.056433081626892, 1.1291605234146118, 1.0209169387817383, 1.133449912071228, 1.1255937814712524, 1.4199999570846558, 1.0649546384811401, 1.0110262632369995, 1.3299826383590698, 1.3256404399871826, 1.1642374992370605, 1.037158489227295, 1.1515718698501587, 1.2924480438232422, 1.009609580039978, 1.2760963439941406, 1.2019420862197876, 1.2446043491363525, 1.5319702625274658, 1.0, 1.0743350982666016, 1.2322142124176025, 1.0341105461120605, 1.3780487775802612, 1.2145403623580933]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.779435157775879] ms
 --  Average per query NF    [1.3689148426055908] ms
 --  Average per query vegas [2.410520315170288] ms
Mean [1.147]  Median [1.110]  95th [1.402]  99th [1.569]  max [1.625]
Mean [1.147]  Median [1.110]  95th [1.402]  99th [1.569]  max [1.625]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.223949 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=0 | total-time=26.154099