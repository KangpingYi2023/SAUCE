Input arguments = Namespace(data_update='sample', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 92, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.17214584350586
tensor(0.9946)
result is  tensor(380110.7812)
Enter testHyper
ReportEsts: [1.1615757942199707, 1.0445371866226196, 1.3827046155929565, 1.0245954990386963, 1.2632986307144165, 1.0992532968521118, 1.1341673135757446, 1.2552127838134766, 1.0709198713302612, 1.0162972211837769, 1.0663220882415771, 1.144915223121643, 1.0800033807754517, 1.0446428060531616, 1.065019130706787, 1.111503005027771, 1.4656696319580078, 1.1852731704711914, 1.1507912874221802, 1.040816307067871, 1.0544569492340088, 1.0584677457809448, 1.1469335556030273, 1.0891847610473633, 1.1450624465942383, 1.0768535137176514, 1.0807995796203613, 1.5178571939468384, 1.0027443170547485, 1.1208422183990479, 1.095423936843872, 1.0681533813476562, 1.071638822555542, 1.0904979705810547, 1.133050560951233, 1.019863247871399, 1.283983826637268, 1.1452635526657104, 1.0869628190994263, 1.1687425374984741, 1.0119777917861938, 1.206579566001892, 1.1591979265213013, 1.032918930053711, 1.072681188583374, 1.0147392749786377, 1.1365911960601807, 1.237504482269287, 1.106160044670105, 1.0456852912902832, 1.1553884744644165, 1.1998860836029053, 1.0218294858932495, 1.118179202079773, 1.272737979888916, 1.0489104986190796, 1.3112149238586426, 1.16646409034729, 1.065101146697998, 1.4669893980026245, 1.3272167444229126, 1.1822773218154907, 1.2771389484405518, 1.0582270622253418, 1.2741312980651855, 1.1428571939468384, 1.223414659500122, 1.1607133150100708, 1.0879980325698853, 1.24210524559021, 1.0466612577438354, 1.035338044166565, 1.193395972251892, 1.3445571660995483, 1.0946913957595825, 1.1902037858963013, 1.9031782150268555, 1.019936442375183, 1.0034886598587036, 1.2428150177001953, 1.2833552360534668, 1.1024067401885986, 1.0496331453323364, 1.2424542903900146, 1.194616675376892, 1.167482852935791, 1.075408697128296, 1.1148045063018799, 1.0652387142181396, 1.0105315446853638, 1.0169658660888672, 1.209136724472046, 1.011305570602417, 1.2288457155227661, 1.2580645084381104, 1.0371067523956299, 1.0075374841690063, 1.3187217712402344, 1.0526316165924072, 1.1749836206436157, 1.1567796468734741, 1.069859504699707, 1.0577510595321655, 1.0007320642471313, 1.0390167236328125, 1.0392526388168335, 1.0315337181091309, 1.1954624652862549, 1.0032193660736084, 1.0032340288162231, 1.303038477897644, 1.0943044424057007, 1.1726890802383423, 1.033210277557373, 1.0310652256011963, 1.164102554321289, 1.022152304649353, 1.0562362670898438, 1.213806390762329, 1.1841762065887451, 1.1913284063339233, 1.1219815015792847, 1.1083550453186035, 1.1699131727218628, 1.2189922332763672, 1.1747833490371704, 1.1760073900222778, 1.135554313659668, 1.287500023841858, 1.108216404914856, 1.0967117547988892, 1.130901575088501, 1.2361714839935303, 1.5, 1.1329748630523682, 1.0446311235427856, 1.0056109428405762, 1.1843901872634888, 1.1338752508163452, 1.326629638671875, 1.1578973531723022, 1.069350004196167, 1.1593780517578125, 1.3584275245666504, 1.2019939422607422, 1.0373215675354004, 1.0574581623077393, 1.5656996965408325, 1.1206423044204712, 1.0544744729995728, 1.1813639402389526, 1.151390790939331, 1.3473742008209229, 1.2272192239761353, 1.100270390510559, 1.0535300970077515, 1.0041075944900513, 1.0119589567184448, 1.089901328086853, 1.2090718746185303, 1.073386311531067, 1.0099989175796509, 1.0244030952453613, 1.2264398336410522, 1.1484185457229614, 1.0756388902664185, 1.0018408298492432, 1.4163947105407715, 1.1798146963119507, 1.0350189208984375, 1.00992751121521, 1.0534000396728516, 1.149350643157959, 1.0862175226211548, 1.0728882551193237, 1.1406997442245483, 1.0131195783615112, 1.3347936868667603, 1.3286159038543701, 1.0261430740356445, 1.039475679397583, 1.1129827499389648, 1.0692640542984009, 1.0653728246688843, 1.1191596984863281, 1.1469345092773438, 1.0292712450027466, 1.199265718460083, 1.058115839958191, 1.3390653133392334, 1.0821901559829712, 1.0909342765808105, 1.480290412902832, 1.3887510299682617, 1.7545509338378906, 1.1653637886047363, 1.1203835010528564, 1.1176470518112183, 1.0293024778366089, 1.177157998085022]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.780360221862793] ms
 --  Average per query NF    [1.368485689163208] ms
 --  Average per query vegas [2.411874532699585] ms
Mean [1.146]  Median [1.119]  95th [1.383]  99th [1.568]  max [1.903]
Mean [1.146]  Median [1.119]  95th [1.383]  99th [1.568]  max [1.903]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.858236 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=sample', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
Sample - START
Sample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[1.1920929e-07 2.3841858e-07 4.7683716e-07 1.0132790e-06 1.1920929e-07]
Distance score: 3.9339064983323624e-07
SAUCE Drift detection: False
Detection latency: 0.0235s

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.024840 | Model-update-time: 0.000000


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=sample', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.218444347381592
tensor(0.9988)
result is  tensor(458042.6562)
Enter testHyper
ReportEsts: [1.0217747688293457, 1.0124790668487549, 1.2290748357772827, 1.2056385278701782, 1.0253182649612427, 1.3281034231185913, 1.2194318771362305, 1.0052541494369507, 1.0545027256011963, 1.0525317192077637, 1.0418781042099, 1.0887885093688965, 1.3289474248886108, 1.2018338441848755, 1.0314843654632568, 1.0090633630752563, 1.4657783508300781, 1.1220459938049316, 1.0629950761795044, 1.3677308559417725, 1.192762851715088, 2.674931049346924, 1.068460464477539, 1.130370020866394, 1.0414464473724365, 1.17635977268219, 1.114457607269287, 1.1277492046356201, 1.2490774393081665, 1.4862778186798096, 1.1260300874710083, 1.3133333921432495, 1.0334504842758179, 1.0804238319396973, 1.0827903747558594, 1.1495634317398071, 1.0487991571426392, 1.1000471115112305, 1.2609328031539917, 1.0451890230178833, 1.0178989171981812, 1.0148462057113647, 1.4472922086715698, 1.1334919929504395, 1.041711688041687, 1.1571506261825562, 1.1862202882766724, 1.1586893796920776, 1.0155038833618164, 1.0236037969589233, 1.056101679801941, 1.0088523626327515, 1.0110962390899658, 1.0070794820785522, 1.1801955699920654, 1.072536587715149, 1.3611496686935425, 1.0451908111572266, 1.2539900541305542, 1.1067980527877808, 1.2230769395828247, 1.1156340837478638, 1.0904219150543213, 1.7423733472824097, 1.0559989213943481, 1.1002286672592163, 1.2962490320205688, 1.07014799118042, 1.17292320728302, 1.058205246925354, 1.0206928253173828, 1.1895166635513306, 1.205560564994812, 1.0789496898651123, 1.0513179302215576, 1.1461368799209595, 1.292808175086975, 1.0707261562347412, 1.2542085647583008, 1.0272496938705444, 1.1797752380371094, 1.0495225191116333, 1.0447262525558472, 1.1960893869400024, 1.3482099771499634, 1.3873239755630493, 1.3269866704940796, 1.5513663291931152, 1.061172366142273, 1.0135022401809692, 1.0779448747634888, 1.1539459228515625, 1.4505317211151123, 1.1442029476165771, 1.0889415740966797, 1.0117290019989014, 1.0012812614440918, 1.112521767616272, 1.00320565700531, 1.2239341735839844, 1.1606806516647339, 1.1514354944229126, 1.2670156955718994, 1.2855780124664307, 1.0978144407272339, 1.015294075012207, 1.0438851118087769, 1.0642614364624023, 1.1263736486434937, 1.0787211656570435, 1.1924679279327393, 1.0925425291061401, 1.0593218803405762, 1.2779557704925537, 1.1703828573226929, 1.0392621755599976, 1.0594538450241089, 1.0904871225357056, 1.1050175428390503, 1.2566372156143188, 1.0638459920883179, 1.1101914644241333, 1.1008667945861816, 1.8985507488250732, 1.0065420866012573, 1.052242398262024, 1.0565590858459473, 1.313628911972046, 1.133847713470459, 1.0763473510742188, 1.1371263265609741, 1.1201915740966797, 1.0541924238204956, 2.0948617458343506, 1.723973274230957, 1.0910465717315674, 1.1095975637435913, 1.088037371635437, 1.0568368434906006, 1.01085364818573, 1.092734932899475, 1.1635713577270508, 1.0333281755447388, 1.0453826189041138, 1.0196806192398071, 1.1685365438461304, 1.429411768913269, 1.044697880744934, 1.064591884613037, 1.141564130783081, 1.0800862312316895, 1.0934386253356934, 1.1398371458053589, 1.1153697967529297, 1.0391968488693237, 1.0877633094787598, 1.0724984407424927, 1.251968502998352, 1.2689388990402222, 1.1959829330444336, 1.0792852640151978, 1.0195980072021484, 1.150529384613037, 1.0382473468780518, 1.2324532270431519, 1.0003714561462402, 1.009147047996521, 1.151155948638916, 1.0332536697387695, 1.2784204483032227, 1.0339477062225342, 1.276859998703003, 1.5926740169525146, 1.0624022483825684, 1.1510416269302368, 1.0370768308639526, 1.2485207319259644, 1.057314157485962, 1.0354489088058472, 1.1107414960861206, 1.8333333730697632, 1.1060172319412231, 1.1013644933700562, 1.6054009199142456, 1.2671350240707397, 1.3248200416564941, 1.1641221046447754, 1.1360646486282349, 1.4707566499710083, 1.011580467224121, 1.1223748922348022, 1.0329205989837646, 1.283400058746338, 1.983559012413025, 1.0093708038330078, 1.0246243476867676, 1.4236140251159668, 1.1092309951782227, 1.3200000524520874, 1.0920859575271606]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7524819374084473] ms
 --  Average per query NF    [1.357799768447876] ms
 --  Average per query vegas [2.3946821689605713] ms
Mean [1.169]  Median [1.106]  95th [1.490]  99th [1.985]  max [2.675]
Mean [1.169]  Median [1.106]  95th [1.490]  99th [1.985]  max [2.675]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.305614 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=0 | total-time=26.255110