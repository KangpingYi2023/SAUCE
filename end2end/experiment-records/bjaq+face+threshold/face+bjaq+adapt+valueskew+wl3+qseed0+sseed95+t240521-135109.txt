Input arguments = Namespace(data_update='valueskew', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 95, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.16483998298645
tensor(0.9926)
result is  tensor(379358.2812)
Enter testHyper
ReportEsts: [1.1609129905700684, 1.0026997327804565, 1.3451861143112183, 1.1853021383285522, 1.2233093976974487, 1.0779989957809448, 1.2504918575286865, 1.1152814626693726, 1.0847610235214233, 1.0749280452728271, 1.107665777206421, 1.145339012145996, 1.0266876220703125, 1.03125, 1.0741119384765625, 1.2964591979980469, 1.1682504415512085, 1.1116389036178589, 1.1316773891448975, 1.1147959232330322, 1.1385014057159424, 1.0371394157409668, 1.1680763959884644, 1.0733108520507812, 1.1333006620407104, 1.1320072412490845, 1.113175630569458, 1.3565728664398193, 1.1146759986877441, 1.025531530380249, 1.1269954442977905, 1.2191566228866577, 1.0729901790618896, 1.0280834436416626, 1.226733684539795, 1.0456159114837646, 1.4329465627670288, 1.116065502166748, 1.0254260301589966, 1.008143663406372, 1.0125222206115723, 1.1179245710372925, 1.1537678241729736, 1.2007193565368652, 1.068244218826294, 1.072562336921692, 1.0826520919799805, 1.523123860359192, 1.1066938638687134, 1.1556683778762817, 1.1912144422531128, 1.3348115682601929, 1.0443326234817505, 1.2105907201766968, 1.0110780000686646, 1.0432889461517334, 1.318691611289978, 1.256852388381958, 1.2392116785049438, 1.297897219657898, 1.3164650201797485, 1.2217179536819458, 1.3131675720214844, 1.1013147830963135, 1.2087912559509277, 1.1714285612106323, 1.1136767864227295, 1.0597591400146484, 1.085959553718567, 1.2842105627059937, 1.1552695035934448, 1.127267599105835, 1.2953319549560547, 1.0073492527008057, 1.0649398565292358, 1.0193418264389038, 1.92851984500885, 1.0211036205291748, 1.1386806964874268, 1.3881151676177979, 1.2118488550186157, 1.117105484008789, 1.0326330661773682, 1.1297430992126465, 1.2232948541641235, 1.0423856973648071, 1.04022216796875, 1.0098865032196045, 1.020912766456604, 1.0418773889541626, 1.0107431411743164, 1.4431818723678589, 1.023079752922058, 1.37703275680542, 1.0955055952072144, 1.095231294631958, 1.230361819267273, 1.1942360401153564, 1.01694917678833, 1.1200262308120728, 1.1234568357467651, 1.0136210918426514, 1.050206184387207, 1.009608268737793, 1.0, 1.007586121559143, 1.222512125968933, 1.2076789140701294, 1.0574371814727783, 1.0525933504104614, 1.334931492805481, 1.0994371175765991, 1.303257942199707, 1.006072998046875, 1.0829952955245972, 1.1761658191680908, 1.0083403587341309, 1.032374620437622, 1.2180689573287964, 1.0014491081237793, 1.0826627016067505, 1.0754104852676392, 1.1270921230316162, 1.2867430448532104, 1.286821722984314, 1.2259595394134521, 1.1327048540115356, 1.1294283866882324, 1.3160135746002197, 1.0838342905044556, 1.0960084199905396, 1.2464871406555176, 1.2510876655578613, 1.4285714626312256, 1.050291657447815, 1.0913625955581665, 1.042184829711914, 1.0790244340896606, 1.0878949165344238, 1.2200255393981934, 1.2124545574188232, 1.0506051778793335, 1.1470869779586792, 1.2795767784118652, 1.095560908317566, 1.0978190898895264, 1.0700877904891968, 1.4000166654586792, 1.0428495407104492, 1.0954545736312866, 1.2435418367385864, 1.1520317792892456, 1.336408019065857, 1.0395432710647583, 1.2104136943817139, 1.0725016593933105, 1.1634236574172974, 1.0196961164474487, 1.103331446647644, 1.1058191061019897, 1.04798424243927, 1.1337909698486328, 1.034358263015747, 1.3086591958999634, 1.2861034870147705, 1.0100784301757812, 1.0901638269424438, 1.2117418050765991, 1.1583163738250732, 1.0170469284057617, 1.0545951128005981, 1.0535907745361328, 1.1688311100006104, 1.1615114212036133, 1.0548365116119385, 1.1373748779296875, 1.0162962675094604, 1.2495143413543701, 1.0492254495620728, 1.028433918952942, 1.0292631387710571, 1.0343348979949951, 1.006395936012268, 1.227783441543579, 1.120970606803894, 1.1553910970687866, 1.0266371965408325, 1.2028791904449463, 1.0117645263671875, 1.4318912029266357, 1.045562744140625, 1.0083551406860352, 1.563835620880127, 1.3952908515930176, 1.8378347158432007, 1.1831501722335815, 1.1291788816452026, 1.1176470518112183, 1.07886803150177, 1.1382137537002563]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.804504871368408] ms
 --  Average per query NF    [1.3611090183258057] ms
 --  Average per query vegas [2.4433958530426025] ms
Mean [1.148]  Median [1.116]  95th [1.388]  99th [1.567]  max [1.929]
Mean [1.148]  Median [1.116]  95th [1.388]  99th [1.567]  max [1.929]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.858042 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=valueskew', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
ValueSample - START
ValueSample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[5.9604645e-08 9.2519522e-03 0.0000000e+00 2.4437904e-06 7.7486038e-07]
Distance score: 0.0018510461086407304
SAUCE Drift detection: True
Detection latency: 0.0233s

DRIFT-DETECTED after 2-th workload
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/incremental_train.py', '--dataset=bjaq', '--end2end', '--model=face', '--model_update=adapt', '--update_size=80000', '--epochs=0']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
update_size: 76433
AdaptTask - START
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
train data shape: 80000, transfer data shape:16000
Training done; evaluating likelihood on full data:
Saved to: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
AdaptTask - END

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.052512 | Model-update-time: 2.232368


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=valueskew', '--model_update=adapt']
/home/kangping/code_copy/SAUCE/./FACE/FACE_utils/dataUtils.py:321: RuntimeWarning: invalid value encountered in cast
  oracle_cards = oracle_cards.astype(np.int32)
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.157427310943604
tensor(0.9933)
result is  tensor(455514.3750)
Enter testHyper
ReportEsts: [1.1467667818069458, 1.229189395904541, 1.0329114198684692, 1.015163779258728, 1.0580430030822754, 1.58169424533844, 1.329982042312622, 1.1495386362075806, 1.0855581760406494, 2.2656712532043457, 1.1654309034347534, 1.007286548614502, 1.2469733953475952, 1.043751835823059, 56.96120834350586, 1.1537933349609375, 1.157687783241272, 1.2437859773635864, 1.01763916015625, 1.1728359460830688, 1.1954445838928223, 2.681227922439575, 1.1730834245681763, 1.262912392616272, 1.2259641885757446, 1.1822081804275513, 1.0167094469070435, 1.639569878578186, 1.490041971206665, 1.3212192058563232, 1.4090908765792847, 1.0810810327529907, 1.0301557779312134, 1.0708333253860474, 1.2211742401123047, 1.2821356058120728, 1.1458864212036133, 8.074872970581055, 1.1713930368423462, 1.0340110063552856, 1.2775027751922607, 1.2681992053985596, 1.161530613899231, 3.6106276512145996, 1.473099708557129, 1.4842427968978882, 1.249977469444275, 1.2417606115341187, 1.2333333492279053, 1.1235954761505127, 1.1625308990478516, 1.072921633720398, 1.0394381284713745, 1.0871988534927368, 1.0608786344528198, 1.1632835865020752, 1.3084861040115356, 1.309059977531433, 1.5090343952178955, 1.015351414680481, 1.3736730813980103, 1.0202325582504272, 1.536056637763977, 2.0994083881378174, 1.011378526687622, 2.204167604446411, 1.3937641382217407, 1.1527881622314453, 1.1766921281814575, 1.1214035749435425, 1.1760647296905518, 1.1037694215774536, 1.0770246982574463, 1.4122693538665771, 3.9040300846099854, 1.0648051500320435, 1880.0, 1.064261794090271, 1.308786153793335, 1.0150713920593262, 1.1523476839065552, 1.1950318813323975, 1.1908719539642334, 1.0433813333511353, 1.3183196783065796, 1.6297872066497803, 1.0139832496643066, 1.2046332359313965, 1.1312512159347534, 1.1695247888565063, 3.043887138366699, 1.094119906425476, 1.4715667963027954, 1.157678484916687, 49.08189010620117, 1.2972025871276855, 1.0583723783493042, 1.4028854370117188, 1.512584924697876, 1.0108788013458252, 1.1641818284988403, 1.3176285028457642, 1.0669642686843872, 1.057442307472229, 1.0461721420288086, 1.2104915380477905, 1.1269904375076294, 1.1031473875045776, 1.0200573205947876, 1.1348063945770264, 12.064934730529785, 1.1503868103027344, 1.2640846967697144, 1.169601321220398, 1.270446538925171, 1.0190311670303345, 1.0208159685134888, 1.2520133256912231, 1.077223300933838, 1.0924370288848877, 1.0599266290664673, 1.011861801147461, 1.0108635425567627, 1.5492957830429077, 1.071773886680603, 1.0894194841384888, 1.0312774181365967, 1.3425774574279785, 1.22764253616333, 1.1734397411346436, 1.1788561344146729, 1.0904545783996582, 1.0344288349151611, 1.5213178396224976, 1.4204981327056885, 1.0206773281097412, 1.0667589902877808, 1.074889063835144, 1.2800469398498535, 1.1626968383789062, 1.2321442365646362, 1.3493551015853882, 1.301950454711914, 1.0479906797409058, 1.0012048482894897, 1.0403211116790771, 1.1722222566604614, 1.050875186920166, 1.0092202425003052, 1.0171363353729248, 1.0412827730178833, 1.0826557874679565, 1.0731569528579712, 1.2065701484680176, 1.2216030359268188, 4.206291198730469, 1.0005642175674438, 1.1138211488723755, 1.3110671043395996, 1.166699767112732, 2.020934820175171, 1.2929874658584595, 1.2296624183654785, 1.009151816368103, 1.1866878271102905, 1.0176405906677246, 1.1829049587249756, 1.367424488067627, 175.38461303710938, 1.1962032318115234, 1.061431646347046, 1.0785892009735107, 1.1609787940979004, 1.0569164752960205, 2.102325677871704, 1.232511281967163, 1.5480949878692627, 1.040958285331726, 1.0907509326934814, 1.3909614086151123, 1.56521737575531, 1.3290960788726807, 1.0229750871658325, 1.4274927377700806, 1.3502615690231323, 1.3297113180160522, 1.196319818496704, 1.130110263824463, 1.4933255910873413, 1.0199713706970215, 1.1842252016067505, 1.1779859066009521, 1.2170660495758057, 1.6634002923965454, 1.0050075054168701, 1.0522085428237915, 1.6429194211959839, 1.596970558166504, 1.1513043642044067, 1.156042456626892]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7216615676879883] ms
 --  Average per query NF    [1.3558876514434814] ms
 --  Average per query vegas [2.365773916244507] ms
Mean [12.145]  Median [1.173]  95th [2.699]  99th [58.145]  max [1880.000]
Mean [12.145]  Median [1.173]  95th [2.699]  99th [58.145]  max [1880.000]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.382289 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=1 | total-time=28.578794