Input arguments = Namespace(data_update='valueskew', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 98, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.216249942779541
tensor(0.9952)
result is  tensor(380315.1250)
Enter testHyper
ReportEsts: [1.1265226602554321, 1.0160561800003052, 1.3661125898361206, 1.0006316900253296, 1.2547225952148438, 1.085771083831787, 1.222782850265503, 1.076866626739502, 1.1281650066375732, 1.2543014287948608, 1.0551248788833618, 1.14322030544281, 1.0281671285629272, 1.00223708152771, 1.0881277322769165, 1.1973639726638794, 1.3791049718856812, 1.084679365158081, 1.19497549533844, 1.165816307067871, 1.094131588935852, 1.0476254224777222, 1.1413434743881226, 1.015634536743164, 1.0996488332748413, 1.0922242403030396, 1.0534909963607788, 1.5432393550872803, 1.07600998878479, 1.0634727478027344, 1.1252217292785645, 1.201878547668457, 1.0594426393508911, 1.0230096578598022, 1.2096441984176636, 1.057815670967102, 1.3332875967025757, 1.216309905052185, 1.0539460182189941, 1.2142515182495117, 1.0399259328842163, 1.1354620456695557, 1.0371874570846558, 1.3375948667526245, 1.0876822471618652, 1.0255813598632812, 1.0568937063217163, 1.286056399345398, 1.0834650993347168, 1.1979695558547974, 1.1974025964736938, 1.3205891847610474, 1.0101401805877686, 1.2559542655944824, 1.108211636543274, 1.020398736000061, 1.2345794439315796, 1.0172466039657593, 1.0833492279052734, 1.4323163032531738, 1.3279914855957031, 1.1751800775527954, 1.2731009721755981, 1.153388500213623, 1.217712163925171, 1.1428571939468384, 1.0502512454986572, 1.0465408563613892, 1.0912386178970337, 1.3473684787750244, 1.19710373878479, 1.0385433435440063, 1.1201207637786865, 1.1551401615142822, 1.2077326774597168, 1.4498034715652466, 1.8553624153137207, 1.0414339303970337, 1.0047717094421387, 1.2319591045379639, 1.2132948637008667, 1.1124212741851807, 1.0380257368087769, 1.2110627889633179, 1.2236056327819824, 1.1620627641677856, 1.013439416885376, 1.0511107444763184, 1.0057889223098755, 1.0432871580123901, 1.0063773393630981, 1.3493750095367432, 1.0347014665603638, 1.2880879640579224, 1.107954502105713, 1.0707801580429077, 1.1381522417068481, 1.1971348524093628, 1.0526316165924072, 1.1300439834594727, 1.1801152229309082, 1.0676383972167969, 1.104161262512207, 1.0014662742614746, 1.161401629447937, 1.0760993957519531, 1.1274992227554321, 1.2094241380691528, 1.0359601974487305, 1.0497945547103882, 1.1372841596603394, 1.1558185815811157, 1.2301907539367676, 1.0397812128067017, 1.0567984580993652, 1.213903784751892, 1.1461747884750366, 1.102283000946045, 1.2021831274032593, 1.0472986698150635, 1.1462808847427368, 1.0966607332229614, 1.1047543287277222, 1.2193002700805664, 1.3585271835327148, 1.230808973312378, 1.082406759262085, 1.2677183151245117, 1.2469733953475952, 1.1289244890213013, 1.1033351421356201, 1.104637622833252, 1.2100683450698853, 1.4642857313156128, 1.1423776149749756, 1.0015777349472046, 1.0524297952651978, 1.1791869401931763, 1.0551235675811768, 1.2046599388122559, 1.1940364837646484, 1.1118186712265015, 1.0691447257995605, 1.4276598691940308, 1.087878704071045, 1.035770297050476, 1.0540578365325928, 1.5912847518920898, 1.1744705438613892, 1.019105076789856, 1.21243417263031, 1.153698205947876, 1.2534351348876953, 1.2391974925994873, 1.1157207489013672, 1.0367047786712646, 1.0544157028198242, 1.008159875869751, 1.01072359085083, 1.1195464134216309, 1.1205285787582397, 1.0354245901107788, 1.0071359872817993, 1.3328591585159302, 1.300275444984436, 1.0939016342163086, 1.3244316577911377, 1.3049103021621704, 1.0542786121368408, 1.043784737586975, 1.0685487985610962, 1.1505635976791382, 1.1558442115783691, 1.0626986026763916, 1.0579018592834473, 1.0269591808319092, 1.067055344581604, 1.2417417764663696, 1.2254005670547485, 1.0260030031204224, 1.056496500968933, 1.139115810394287, 1.0422768592834473, 1.0520939826965332, 1.0373053550720215, 1.1257928609848022, 1.0808666944503784, 1.2584939002990723, 1.0140340328216553, 1.21052885055542, 1.0209146738052368, 1.0529779195785522, 1.4135711193084717, 1.2041597366333008, 1.6768019199371338, 1.1817072629928589, 1.117965817451477, 1.1014492511749268, 1.010090947151184, 1.0770584344863892]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.739657402038574] ms
 --  Average per query NF    [1.360626220703125] ms
 --  Average per query vegas [2.379031181335449] ms
Mean [1.147]  Median [1.117]  95th [1.367]  99th [1.592]  max [1.855]
Mean [1.147]  Median [1.117]  95th [1.367]  99th [1.592]  max [1.855]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.898740 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=valueskew', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
ValueSample - START
ValueSample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[5.9604645e-08 4.1723251e-07 1.7881393e-07 6.5565109e-07 1.2422502e-02]
Distance score: 0.0024847625754773617
SAUCE Drift detection: True
Detection latency: 0.0233s

DRIFT-DETECTED after 2-th workload
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/incremental_train.py', '--dataset=bjaq', '--end2end', '--model=face', '--model_update=adapt', '--update_size=80000', '--epochs=0']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
update_size: 76433
AdaptTask - START
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
train data shape: 80000, transfer data shape:16000
Training done; evaluating likelihood on full data:
Saved to: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
AdaptTask - END

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.058270 | Model-update-time: 2.270933


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=valueskew', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.16450023651123
tensor(0.9925)
result is  tensor(455157.3125)
Enter testHyper
ReportEsts: [1.0001893043518066, 1.0712287425994873, 1.2069464921951294, 3.1553030014038086, 1.0219532251358032, 3.1306564807891846, 1.297948956489563, 1.1900393962860107, 1.1524226665496826, 1.0763211250305176, 1.0472384691238403, 1.3783916234970093, 2.5142858028411865, 1.2224873304367065, 1.0009673833847046, 1.232444167137146, 3.092381000518799, 1.2152398824691772, 1.1630977392196655, 1.003394365310669, 1.0688997507095337, 8.105478286743164, 56.186439514160156, 1.0753055810928345, 1.1186985969543457, 1.2511279582977295, 1.320875644683838, 1.3760539293289185, 2.3973941802978516, 1.1817562580108643, 1.2680652141571045, 1.6779661178588867, 1.2405325174331665, 92.32231140136719, 1.030637502670288, 1.0422847270965576, 1.1147831678390503, 1.030482530593872, 1.280946135520935, 1.1265672445297241, 1.074021577835083, 1.1954022645950317, 781.0, 1.0958865880966187, 1.1239320039749146, 1.1152081489562988, 1.2239255905151367, 1.201728343963623, 1.3333333730697632, 1.0932282209396362, 1.064983606338501, 1.3139126300811768, 1.0506913661956787, 1.1608206033706665, 1.0901339054107666, 1.3485527038574219, 1.1589226722717285, 1.1548229455947876, 1.257988691329956, 1.1952756643295288, 1.1028807163238525, 1.082294225692749, 1.1089431047439575, 1.6894210577011108, 1.0424742698669434, 1.0364985466003418, 1.301676630973816, 1.127396821975708, 1.0933650732040405, 1.043465495109558, 1.0226726531982422, 1.1555979251861572, 1.25462806224823, 1.0951529741287231, 1.1177295446395874, 1.0288344621658325, 1.0735448598861694, 1.014285683631897, 1.2346481084823608, 1.153839111328125, 1.0597602128982544, 1.0309439897537231, 1.4229521751403809, 1.0345209836959839, 1.5058878660202026, 1.612765908241272, 1.4899946451187134, 1.4854304790496826, 1.292062759399414, 3.6915202140808105, 1.156374216079712, 1.2006633281707764, 2.322943925857544, 1.0212256908416748, 1.2336838245391846, 1.104250431060791, 1.0104122161865234, 1.1921669244766235, 1.5061700344085693, 1.3976632356643677, 1.5062004327774048, 1.1214830875396729, 1.1913875341415405, 1.5836701393127441, 1.0274862051010132, 1.0990875959396362, 1.0507103204727173, 1.1798853874206543, 1.1606647968292236, 1.2672135829925537, 1.0731923580169678, 1.1667882204055786, 1.2855995893478394, 1.4032243490219116, 1.2584043741226196, 1.0449997186660767, 1.3832679986953735, 1.3061180114746094, 1.7751933336257935, 1.0884956121444702, 1.0612242221832275, 1.0489327907562256, 1.005702257156372, 3.428974151611328, 1.0090625286102295, 1.353804349899292, 1.223891258239746, 1.192250370979309, 1.396098017692566, 1.161443829536438, 1.286331295967102, 1.3185921907424927, 1.0914279222488403, 1.2413145303726196, 1.8280773162841797, 1.374173879623413, 1.1482821702957153, 1.0047671794891357, 1.1144107580184937, 1.037146806716919, 1.0395939350128174, 1.274117350578308, 1.0533270835876465, 1.6684043407440186, 1.0914032459259033, 1.0866310596466064, 1.14673912525177, 1.1839591264724731, 1.0663710832595825, 1.338696002960205, 1.0524146556854248, 1.0858396291732788, 1.32138192653656, 1.2477562427520752, 1.0474196672439575, 1.0965462923049927, 1.0168498754501343, 1.307692289352417, 2.115692615509033, 1.1612902879714966, 1.0500848293304443, 1.208687424659729, 2.2954366207122803, 1.0707018375396729, 1.0011521577835083, 2.012861728668213, 1.141983151435852, 1.0794178247451782, 1.0497604608535767, 1.3344314098358154, 1.1559640169143677, 1.0449130535125732, 1.2003995180130005, 1.4811800718307495, 1.129815936088562, 1.2701516151428223, 1.1041733026504517, 1.4837175607681274, 1.0140687227249146, 1.316260576248169, 1.9736841917037964, 1.1160202026367188, 1.1761797666549683, 1.690742015838623, 1.9588309526443481, 1.0775315761566162, 20.220918655395508, 1.103480577468872, 2.4838969707489014, 1.0174137353897095, 1.064329743385315, 1.0376794338226318, 1.0830583572387695, 1.6715903282165527, 1.1112769842147827, 1.6232802867889404, 1.2494724988937378, 1.1339609622955322, 2.0576272010803223, 1.0799823999404907]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.743997812271118] ms
 --  Average per query NF    [1.365966796875] ms
 --  Average per query vegas [2.378031015396118] ms
Mean [6.056]  Median [1.161]  95th [2.543]  99th [56.548]  max [781.000]
Mean [6.056]  Median [1.161]  95th [2.543]  99th [56.548]  max [781.000]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.413682 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=1 | total-time=28.716818