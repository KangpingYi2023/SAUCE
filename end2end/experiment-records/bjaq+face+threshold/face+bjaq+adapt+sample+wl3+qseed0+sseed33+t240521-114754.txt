Input arguments = Namespace(data_update='sample', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 33, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.157996892929077
tensor(0.9922)
result is  tensor(379188.6875)
Enter testHyper
ReportEsts: [1.1184717416763306, 1.1265963315963745, 1.4089198112487793, 1.1240260601043701, 1.2375545501708984, 1.1108096837997437, 1.2384698390960693, 1.1435840129852295, 1.0926430225372314, 1.173714518547058, 1.067183494567871, 1.1144068241119385, 1.1356621980667114, 1.015625, 1.1304540634155273, 1.3960344791412354, 1.370600938796997, 1.1345605850219727, 1.223192572593689, 1.1607142686843872, 1.0197287797927856, 1.065629243850708, 1.1012063026428223, 1.1148923635482788, 1.1236624717712402, 1.163652777671814, 1.2052364349365234, 1.3856713771820068, 1.0425468683242798, 1.0403825044631958, 1.1429585218429565, 1.12718665599823, 1.0986741781234741, 1.0054748058319092, 1.1736122369766235, 1.1065715551376343, 1.217814564704895, 1.0659267902374268, 1.0476256608963013, 1.0950819253921509, 1.0310240983963013, 1.096879482269287, 1.1427478790283203, 1.1710063219070435, 1.1098668575286865, 1.0589568614959717, 1.1137584447860718, 1.3398579359054565, 1.0857385396957397, 1.1184433698654175, 1.232620358467102, 1.281240463256836, 1.013424277305603, 1.0577694177627563, 1.1204053163528442, 1.0084151029586792, 1.2037383317947388, 1.0450007915496826, 1.0549784898757935, 1.4522875547409058, 1.3534151315689087, 1.141539454460144, 1.528228521347046, 1.0476289987564087, 1.2643678188323975, 1.1142857074737549, 1.0951964855194092, 1.0174427032470703, 1.2298508882522583, 1.24210524559021, 1.0605802536010742, 1.008273959159851, 1.3255300521850586, 1.141077995300293, 1.10234534740448, 1.028904676437378, 1.9839129447937012, 1.0522401332855225, 1.011258840560913, 1.2483001947402954, 1.283287763595581, 1.1062833070755005, 1.0112266540527344, 1.2422080039978027, 1.2353770732879639, 1.1157439947128296, 1.1644293069839478, 1.1957628726959229, 1.0425667762756348, 1.0074633359909058, 1.0129858255386353, 1.3816968202590942, 1.0393552780151367, 1.413819670677185, 1.0, 1.0384796857833862, 1.2759835720062256, 1.0940829515457153, 1.01694917678833, 1.1468963623046875, 1.1567796468734741, 1.197148084640503, 1.0672599077224731, 1.0156134366989136, 1.2781380414962769, 1.0553319454193115, 1.093837022781372, 1.2303664684295654, 1.0167574882507324, 1.0186506509780884, 1.2602578401565552, 1.084181308746338, 1.2844011783599854, 1.0991261005401611, 1.056102991104126, 1.1237623691558838, 1.0404269695281982, 1.0202502012252808, 1.2548671960830688, 1.080374836921692, 1.086854100227356, 1.0486408472061157, 1.1012202501296997, 1.1354163885116577, 1.3439922332763672, 1.233904242515564, 1.143568754196167, 1.1269792318344116, 1.2674323320388794, 1.1122244596481323, 1.206259846687317, 1.1955775022506714, 1.1805468797683716, 1.5, 1.11562979221344, 1.0026322603225708, 1.042832374572754, 1.1157723665237427, 1.0241395235061646, 1.0360690355300903, 1.142067790031433, 1.1013197898864746, 1.1104483604431152, 1.2626084089279175, 1.0033961534500122, 1.0356595516204834, 1.0840359926223755, 1.4685097932815552, 1.0210970640182495, 1.157812476158142, 1.0298129320144653, 1.2040764093399048, 1.377516746520996, 1.2305604219436646, 1.1903603076934814, 1.0449683666229248, 1.0866942405700684, 1.0295442342758179, 1.0717308521270752, 1.145926594734192, 1.0249030590057373, 1.1064432859420776, 1.094617247581482, 1.2713704109191895, 1.3020689487457275, 1.1559867858886719, 1.1421257257461548, 1.0261479616165161, 1.1623244285583496, 1.1244736909866333, 1.1169606447219849, 1.0897645950317383, 1.1168831586837769, 1.148470163345337, 1.067779302597046, 1.016952633857727, 1.0357322692871094, 1.201535940170288, 1.2531803846359253, 1.1768280267715454, 1.1692357063293457, 1.0246860980987549, 1.044846534729004, 1.1930540800094604, 1.105034351348877, 1.1310782432556152, 1.0111603736877441, 1.1703583002090454, 1.0051250457763672, 1.466635823249817, 1.023132562637329, 1.0729249715805054, 1.547722339630127, 1.152895450592041, 1.6267378330230713, 1.1860464811325073, 1.1700708866119385, 1.1515151262283325, 1.1286665201187134, 1.0176295042037964]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.748960494995117] ms
 --  Average per query NF    [1.3585925102233887] ms
 --  Average per query vegas [2.3903679847717285] ms
Mean [1.149]  Median [1.118]  95th [1.397]  99th [1.549]  max [1.984]
Mean [1.149]  Median [1.118]  95th [1.397]  99th [1.549]  max [1.984]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.835324 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=sample', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
Sample - START
Sample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[1.4901161e-06 1.6093254e-06 2.4437904e-06 1.6689301e-06 1.1920929e-07]
Distance score: 1.466274284211977e-06
SAUCE Drift detection: False
Detection latency: 0.0234s

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.020886 | Model-update-time: 0.000000


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=sample', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.163811206817627
tensor(0.9938)
result is  tensor(455759.2500)
Enter testHyper
ReportEsts: [1.1088740825653076, 1.0621546506881714, 1.1701245307922363, 1.2377849817276, 1.0432870388031006, 1.1785520315170288, 1.2465416193008423, 1.0381418466567993, 1.164385199546814, 1.108458161354065, 1.1124571561813354, 1.1354403495788574, 1.204938292503357, 1.1601587533950806, 1.0441632270812988, 1.0319937467575073, 1.5145984888076782, 1.0573219060897827, 1.0065617561340332, 1.3055795431137085, 1.1349138021469116, 1.367045283317566, 1.0082036256790161, 1.0346981287002563, 1.3904142379760742, 1.248474359512329, 1.089925765991211, 1.0966386795043945, 1.3775558471679688, 1.436170220375061, 1.1786588430404663, 1.3943661451339722, 1.0395711660385132, 1.1164355278015137, 1.010223150253296, 1.0820798873901367, 1.013907790184021, 1.135504126548767, 1.3442445993423462, 1.0234167575836182, 1.0020976066589355, 1.0638527870178223, 1.3847167491912842, 1.0897406339645386, 1.0736455917358398, 1.1210832595825195, 1.2779793739318848, 1.1164824962615967, 1.0352941751480103, 1.021963357925415, 1.0501430034637451, 1.0433619022369385, 1.042181372642517, 1.0845770835876465, 1.105857491493225, 1.4528642892837524, 1.1188273429870605, 1.1861910820007324, 1.2239989042282104, 1.1232211589813232, 1.465753436088562, 1.02206552028656, 1.0591164827346802, 1.8305226564407349, 1.0610512495040894, 1.1098538637161255, 1.2979958057403564, 1.1757171154022217, 1.104099154472351, 1.0608681440353394, 1.2078584432601929, 1.133337378501892, 1.1090087890625, 1.0657304525375366, 1.1096386909484863, 1.0715594291687012, 1.440840482711792, 1.0297565460205078, 1.1452157497406006, 1.0975524187088013, 1.0498143434524536, 1.1872745752334595, 1.03636634349823, 1.0034072399139404, 1.2930361032485962, 1.298969030380249, 1.146691083908081, 1.4187736511230469, 1.1780718564987183, 1.0328476428985596, 1.1520811319351196, 1.1447993516921997, 1.2918106317520142, 1.007328748703003, 1.2311227321624756, 1.0693012475967407, 1.0430384874343872, 1.2237974405288696, 1.1305227279663086, 1.0788567066192627, 1.209473967552185, 1.1658148765563965, 1.1798560619354248, 1.2222332954406738, 1.1087397336959839, 1.0760035514831543, 1.211152195930481, 1.1240582466125488, 1.174386978149414, 1.047971487045288, 1.0941436290740967, 1.0542134046554565, 1.0397976636886597, 1.2190297842025757, 1.0561330318450928, 1.0097484588623047, 1.0743682384490967, 1.27738618850708, 1.0190235376358032, 1.1127820014953613, 1.013427734375, 1.195083737373352, 1.0661441087722778, 1.1351863145828247, 1.0325151681900024, 1.1685056686401367, 1.2153184413909912, 1.3135048151016235, 1.1236637830734253, 1.08695650100708, 1.0800609588623047, 1.0403016805648804, 1.1876707077026367, 1.567460298538208, 1.6377880573272705, 1.0500651597976685, 1.1244926452636719, 1.2360749244689941, 1.0861496925354004, 1.0171372890472412, 1.1354235410690308, 1.1299090385437012, 1.01247239112854, 1.0244141817092896, 1.04209303855896, 1.1686477661132812, 1.3478261232376099, 1.120208740234375, 1.0822833776474, 1.0277009010314941, 1.0557351112365723, 1.0075709819793701, 1.1115738153457642, 1.0208501815795898, 1.0245332717895508, 1.0098413228988647, 1.265601634979248, 1.2230769395828247, 1.1700280904769897, 1.1004694700241089, 1.0025100708007812, 1.1386083364486694, 1.5000383853912354, 1.2155699729919434, 1.190548300743103, 1.0666251182556152, 1.01264226436615, 1.283949851989746, 1.2248061895370483, 1.2604937553405762, 1.1930115222930908, 1.1301807165145874, 1.6633126735687256, 1.052474856376648, 1.0127846002578735, 1.0143951177597046, 1.138274073600769, 1.0737617015838623, 1.1194965839385986, 1.081915020942688, 1.7173912525177002, 1.2273880243301392, 1.0912278890609741, 1.6983006000518799, 1.2492624521255493, 1.415114164352417, 1.3394652605056763, 1.1674494743347168, 1.3699103593826294, 1.0376863479614258, 1.1412962675094604, 1.0742709636688232, 1.3279824256896973, 1.601258397102356, 1.040942668914795, 1.2055652141571045, 1.2523330450057983, 1.1034226417541504, 1.2996742725372314, 1.0079233646392822]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7786853313446045] ms
 --  Average per query NF    [1.3608002662658691] ms
 --  Average per query vegas [2.4178850650787354] ms
Mean [1.162]  Median [1.120]  95th [1.454]  99th [1.698]  max [1.831]
Mean [1.162]  Median [1.120]  95th [1.454]  99th [1.698]  max [1.831]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.210289 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=0 | total-time=26.125295