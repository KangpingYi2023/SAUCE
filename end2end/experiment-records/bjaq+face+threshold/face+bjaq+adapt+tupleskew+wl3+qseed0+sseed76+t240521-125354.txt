Input arguments = Namespace(data_update='tupleskew', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 76, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.212643384933472
tensor(0.9949)
result is  tensor(380236.9062)
Enter testHyper
ReportEsts: [1.2102915048599243, 1.0321863889694214, 1.3145806789398193, 1.086333990097046, 1.2469933032989502, 1.0757862329483032, 1.2225258350372314, 1.0153363943099976, 1.0976277589797974, 1.1381486654281616, 1.13178288936615, 1.16927969455719, 1.0557513236999512, 1.0401785373687744, 1.0884954929351807, 1.540159821510315, 1.3252813816070557, 1.1495249271392822, 1.2820817232131958, 1.1173468828201294, 1.15297532081604, 1.0355556011199951, 1.1406183242797852, 1.079258918762207, 1.1649922132492065, 1.0036298036575317, 1.105011224746704, 1.4622000455856323, 1.0221030712127686, 1.0585901737213135, 1.1046470403671265, 1.1868118047714233, 1.102611780166626, 1.0571516752243042, 1.187448501586914, 1.1727941036224365, 1.410719871520996, 1.22714364528656, 1.1229366064071655, 1.1399999856948853, 1.0978673696517944, 1.0940977334976196, 1.1571063995361328, 1.0647040605545044, 1.0401437282562256, 1.0158730745315552, 1.1528046131134033, 1.4099353551864624, 1.0594061613082886, 1.306260585784912, 1.1943005323410034, 1.3293375968933105, 1.064718246459961, 1.238259196281433, 1.2090009450912476, 1.103042721748352, 1.1841121912002563, 1.2123408317565918, 1.2406339645385742, 1.3648648262023926, 1.4372020959854126, 1.1656382083892822, 1.2794216871261597, 1.0707467794418335, 1.3524590730667114, 1.3142857551574707, 1.0745501518249512, 1.0103394985198975, 1.025720238685608, 1.4210525751113892, 1.0323920249938965, 1.1262834072113037, 1.2106640338897705, 1.3397331237792969, 1.1244454383850098, 1.1343116760253906, 2.1091041564941406, 1.0086489915847778, 1.0913101434707642, 1.3837101459503174, 1.2673591375350952, 1.0060123205184937, 1.0289697647094727, 1.072654128074646, 1.2094688415527344, 1.067193627357483, 1.056976556777954, 1.1563178300857544, 1.0358597040176392, 1.047184705734253, 1.0108599662780762, 1.3516680002212524, 1.0076308250427246, 1.2797024250030518, 1.0773481130599976, 1.083964228630066, 1.1851201057434082, 1.1134387254714966, 1.01694917678833, 1.122554063796997, 1.1886792182922363, 1.1870509386062622, 1.0874989032745361, 1.012445092201233, 1.0854603052139282, 1.0050320625305176, 1.1359741687774658, 1.1815009117126465, 1.0502406358718872, 1.0734058618545532, 1.0606234073638916, 1.0530098676681519, 1.1261123418807983, 1.0224614143371582, 1.0472934246063232, 1.1884816884994507, 1.0419979095458984, 1.0955759286880493, 1.1829304695129395, 1.1715210676193237, 1.2586745023727417, 1.142265796661377, 1.1982396841049194, 1.0967563390731812, 1.2291666269302368, 1.1859265565872192, 1.1916788816452026, 1.156170129776001, 1.3137755393981934, 1.100534439086914, 1.2268917560577393, 1.2210766077041626, 1.2364822626113892, 1.4285714626312256, 1.0267024040222168, 1.1491204500198364, 1.0524916648864746, 1.1170731782913208, 1.1258461475372314, 1.1736196279525757, 1.1687490940093994, 1.0822227001190186, 1.0040851831436157, 1.2428829669952393, 1.00356924533844, 1.0697863101959229, 1.077963948249817, 1.7487906217575073, 1.0872557163238525, 1.0264204740524292, 1.3184982538223267, 1.159723162651062, 1.3320714235305786, 1.0123624801635742, 1.2681598663330078, 1.114200472831726, 1.1306445598602295, 1.025685429573059, 1.0769792795181274, 1.083497405052185, 1.2503968477249146, 1.0847903490066528, 1.1198132038116455, 1.323446273803711, 1.0238611698150635, 1.1804075241088867, 1.1595746278762817, 1.3084863424301147, 1.232969880104065, 1.0050023794174194, 1.2247862815856934, 1.0084465742111206, 1.2142857313156128, 1.1237808465957642, 1.0205074548721313, 1.0077025890350342, 1.000485897064209, 1.3008989095687866, 1.1600703001022339, 1.3457223176956177, 1.0099295377731323, 1.074608564376831, 1.0095778703689575, 1.1532175540924072, 1.1267656087875366, 1.1553910970687866, 1.0007649660110474, 1.2777382135391235, 1.062859296798706, 1.2776687145233154, 1.0394353866577148, 1.0748896598815918, 1.4428715705871582, 1.3262243270874023, 1.616043210029602, 1.2463022470474243, 1.025427222251892, 1.1014492511749268, 1.0926491022109985, 1.151162028312683]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7586045265197754] ms
 --  Average per query NF    [1.3644909858703613] ms
 --  Average per query vegas [2.394113540649414] ms
Mean [1.159]  Median [1.127]  95th [1.410]  99th [1.617]  max [2.109]
Mean [1.159]  Median [1.127]  95th [1.410]  99th [1.617]  max [2.109]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.884073 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=tupleskew', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
TupleSkewSample - START
0.001
TupleSkewSample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[1.0075569e-03 6.1225891e-04 9.0599060e-05 1.1742115e-05 8.6665154e-05]
Distance score: 0.00036176442517898977
SAUCE Drift detection: True
Detection latency: 0.0228s

DRIFT-DETECTED after 2-th workload
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/incremental_train.py', '--dataset=bjaq', '--end2end', '--model=face', '--model_update=adapt', '--update_size=80000', '--epochs=0']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
update_size: 76433
AdaptTask - START
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
train data shape: 80000, transfer data shape:16000
Training done; evaluating likelihood on full data:
Saved to: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
AdaptTask - END

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 1.995965 | Model-update-time: 2.221379


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=tupleskew', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.162963151931763
tensor(0.9975)
result is  tensor(457434.0938)
Enter testHyper
ReportEsts: [1.0789345502853394, 1.0725234746932983, 1.0, 1.692307710647583, 1.0098410844802856, 1.1499006748199463, 1.2363150119781494, 1.065647006034851, 1.091814398765564, 1.0623501539230347, 1.0347295999526978, 1.1475950479507446, 1.5, 1.0045439004898071, 1.0597286224365234, 1.1235392093658447, 1.814628005027771, 1.0494804382324219, 1.03957998752594, 1.2833976745605469, 1.1877398490905762, 1.0439598560333252, 1.0800954103469849, 1.1605054140090942, 1.0372323989868164, 1.1767327785491943, 1.0500903129577637, 1.0334004163742065, 1.172890543937683, 1.4346811771392822, 1.0101590156555176, 1.48305082321167, 1.1932356357574463, 1.5444902181625366, 1.0702120065689087, 1.0017865896224976, 1.2191271781921387, 1.0426408052444458, 1.5916258096694946, 1.0746276378631592, 1.0563193559646606, 1.0334378480911255, 1.2231777906417847, 1.0115758180618286, 1.0820796489715576, 1.044779896736145, 1.3431121110916138, 1.1342641115188599, 1.5927419662475586, 1.083175778388977, 1.0378044843673706, 1.004028558731079, 1.041635274887085, 1.0030591487884521, 1.0313761234283447, 1.2165932655334473, 1.0824576616287231, 1.1327557563781738, 1.36241614818573, 1.0840517282485962, 1.6572668552398682, 1.0377095937728882, 1.107922911643982, 1.605659008026123, 1.0372575521469116, 1.0998029708862305, 1.229303002357483, 1.1402647495269775, 1.2386620044708252, 1.1474249362945557, 1.0586202144622803, 1.128778338432312, 1.12818443775177, 1.1635411977767944, 1.0004243850708008, 1.0925177335739136, 1.7006109952926636, 1.0105042457580566, 1.3648852109909058, 1.283582091331482, 1.2321120500564575, 1.1815168857574463, 1.027152419090271, 1.1756852865219116, 1.3717739582061768, 1.6170213222503662, 1.1013281345367432, 1.5340871810913086, 1.1598031520843506, 1.216908574104309, 1.0917978286743164, 1.4343345165252686, 1.3120704889297485, 1.243496298789978, 1.1364871263504028, 1.002668023109436, 1.0321056842803955, 1.243812084197998, 1.0799380540847778, 1.4460033178329468, 1.0512268543243408, 1.0404446125030518, 2.086294412612915, 1.2492027282714844, 1.0650427341461182, 1.1480698585510254, 1.0073432922363281, 1.247227430343628, 1.5718390941619873, 1.045396327972412, 1.0037678480148315, 1.0150545835494995, 1.2678486108779907, 1.1847971677780151, 1.1242603063583374, 1.278087854385376, 1.3097485303878784, 1.3310317993164062, 1.0189743041992188, 1.265486717224121, 1.0854254961013794, 1.5258567333221436, 1.012533187866211, 1.3402808904647827, 1.1701842546463013, 1.1134898662567139, 1.118120551109314, 1.325301170349121, 1.0806918144226074, 1.0683581829071045, 1.2866188287734985, 1.1513198614120483, 1.0154486894607544, 2.0813703536987305, 1.526735782623291, 1.1291950941085815, 1.0630699396133423, 1.0932592153549194, 1.0561338663101196, 1.0565500259399414, 1.0949292182922363, 1.1896144151687622, 1.0107457637786865, 1.105067253112793, 1.0658330917358398, 1.045250415802002, 1.2411764860153198, 1.0581611394882202, 1.2040531635284424, 1.0961734056472778, 1.0768201351165771, 1.0349371433258057, 1.0560203790664673, 1.0848124027252197, 1.0022952556610107, 1.096116542816162, 1.1689571142196655, 1.1048387289047241, 1.4030544757843018, 1.145526647567749, 1.130554437637329, 1.0663881301879883, 1.4972723722457886, 1.1038446426391602, 1.143349528312683, 1.1829936504364014, 1.0609968900680542, 1.2308474779129028, 1.17900550365448, 1.2151926755905151, 1.2188810110092163, 1.1569403409957886, 1.1233644485473633, 1.035176396369934, 1.1227054595947266, 1.0247814655303955, 1.2630666494369507, 1.0986145734786987, 1.0685333013534546, 1.053551435470581, 1.9210525751113892, 1.054803490638733, 1.0457918643951416, 1.7254984378814697, 1.179711103439331, 1.50943922996521, 1.3121967315673828, 1.0802878141403198, 1.4991164207458496, 1.0500670671463013, 1.1474312543869019, 1.0295175313949585, 1.2917466163635254, 1.7322899103164673, 1.070638656616211, 1.0132628679275513, 1.2159943580627441, 1.2520756721496582, 1.1182432174682617, 1.0723369121551514]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7195706367492676] ms
 --  Average per query NF    [1.3536620140075684] ms
 --  Average per query vegas [2.365908622741699] ms
Mean [1.189]  Median [1.123]  95th [1.606]  99th [1.923]  max [2.086]
Mean [1.189]  Median [1.123]  95th [1.606]  99th [1.923]  max [2.086]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.383662 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=1 | total-time=28.537806