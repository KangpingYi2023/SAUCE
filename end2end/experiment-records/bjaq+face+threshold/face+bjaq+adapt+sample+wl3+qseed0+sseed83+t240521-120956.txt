Input arguments = Namespace(data_update='sample', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 83, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.147916078567505
tensor(0.9979)
result is  tensor(381374.0938)
Enter testHyper
ReportEsts: [1.2679963111877441, 1.0266778469085693, 1.3210057020187378, 1.01263427734375, 1.2448023557662964, 1.1127909421920776, 1.2067617177963257, 1.0586246252059937, 1.0769919157028198, 1.1259310245513916, 1.052540898323059, 1.075635552406311, 1.0006204843521118, 1.0535714626312256, 1.073793649673462, 1.445266842842102, 1.2709534168243408, 1.2226841449737549, 1.1727399826049805, 1.1301020383834839, 1.0403372049331665, 1.0054903030395508, 1.1107444763183594, 1.0159587860107422, 1.076125144958496, 1.1618444919586182, 1.0320945978164673, 1.500232219696045, 1.0502691268920898, 1.0464856624603271, 1.1738204956054688, 1.348401665687561, 1.054314136505127, 1.035654902458191, 1.1214791536331177, 1.1078169345855713, 1.2871873378753662, 1.1046704053878784, 1.023695468902588, 1.0167664289474487, 1.0340831279754639, 1.1082487106323242, 1.212867259979248, 1.1257721185684204, 1.0640186071395874, 1.0566893815994263, 1.181075096130371, 1.31810462474823, 1.0050666332244873, 1.1184433698654175, 1.2068063020706177, 1.3981419801712036, 1.0351741313934326, 1.1844863891601562, 1.0310981273651123, 1.0268892049789429, 1.294392466545105, 1.2110424041748047, 1.306353211402893, 1.424967885017395, 1.349983811378479, 1.1764642000198364, 1.3958486318588257, 1.1000219583511353, 1.2132352590560913, 1.2285714149475098, 1.1297297477722168, 1.008293867111206, 1.0493110418319702, 1.3052631616592407, 1.0247321128845215, 1.0951614379882812, 1.2934799194335938, 1.0412383079528809, 1.1595436334609985, 1.1294182538986206, 1.7540721893310547, 1.0376951694488525, 1.000980257987976, 1.287207841873169, 1.2660441398620605, 1.045549988746643, 1.0436139106750488, 1.1855758428573608, 1.2186511754989624, 1.007859706878662, 1.042479157447815, 1.0353593826293945, 1.079232096672058, 1.090471863746643, 1.0915006399154663, 1.5000495910644531, 1.0025243759155273, 1.2923221588134766, 1.1607142686843872, 1.0572879314422607, 1.114145040512085, 1.2483505010604858, 1.0, 1.211309790611267, 1.2115384340286255, 1.2089438438415527, 1.1226555109024048, 1.0161054134368896, 1.094665288925171, 1.004266381263733, 1.1273730993270874, 1.1727749109268188, 1.0826220512390137, 1.0016143321990967, 1.2258707284927368, 1.0752294063568115, 1.0911210775375366, 1.0584914684295654, 1.107337474822998, 1.207446813583374, 1.0136573314666748, 1.0340512990951538, 1.3207521438598633, 1.0126551389694214, 1.2636008262634277, 1.1690354347229004, 1.073348045349121, 1.1770927906036377, 1.2582364082336426, 1.1618860960006714, 1.1087003946304321, 1.0011242628097534, 1.4770554304122925, 1.08016037940979, 1.0783072710037231, 1.2316484451293945, 1.1830329895019531, 1.4642857313156128, 1.1727219820022583, 1.031241774559021, 1.0839273929595947, 1.1834145784378052, 1.2515724897384644, 1.4383459091186523, 1.152969241142273, 1.0692743062973022, 1.1087868213653564, 1.3598723411560059, 1.0372930765151978, 1.076545238494873, 1.1023212671279907, 1.3113418817520142, 1.058703064918518, 1.0568181276321411, 1.1978622674942017, 1.1690808534622192, 1.3192287683486938, 1.1109449863433838, 1.2012304067611694, 1.0942373275756836, 1.0978868007659912, 1.026870846748352, 1.0131334066390991, 1.1390630006790161, 1.159511685371399, 1.0154460668563843, 1.0256365537643433, 1.2594085931777954, 1.126491665840149, 1.1118154525756836, 1.136858582496643, 1.1878265142440796, 1.0281352996826172, 1.004557728767395, 1.0294148921966553, 1.1469638347625732, 1.1623376607894897, 1.227944016456604, 1.0504087209701538, 1.0602282285690308, 1.0478614568710327, 1.239880084991455, 1.0561825037002563, 1.0076067447662354, 1.0067692995071411, 1.0113186836242676, 1.0022104978561401, 1.080694556236267, 1.1220571994781494, 1.1331924200057983, 1.094207525253296, 1.2868911027908325, 1.0755524635314941, 1.2896769046783447, 1.039670467376709, 1.1592520475387573, 1.593968152999878, 1.577513337135315, 1.674146056175232, 1.2336091995239258, 1.0558983087539673, 1.1176470518112183, 1.0023695230484009, 1.062715768814087]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.75940203666687] ms
 --  Average per query NF    [1.3595056533813477] ms
 --  Average per query vegas [2.3998963832855225] ms
Mean [1.148]  Median [1.111]  95th [1.426]  99th [1.595]  max [1.754]
Mean [1.148]  Median [1.111]  95th [1.426]  99th [1.595]  max [1.754]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.815144 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=sample', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
Sample - START
Sample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[7.7486038e-07 5.3644180e-07 1.4901161e-06 5.9604645e-08 2.3841858e-07]
Distance score: 6.19888282926695e-07
SAUCE Drift detection: False
Detection latency: 0.0234s

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.022856 | Model-update-time: 0.000000


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=sample', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.161518573760986
tensor(0.9933)
result is  tensor(455550.2500)
Enter testHyper
ReportEsts: [1.0296968221664429, 1.094472885131836, 1.300775170326233, 1.263653039932251, 1.1193420886993408, 1.4131604433059692, 1.220440149307251, 1.0419323444366455, 1.1499323844909668, 1.128889560699463, 1.0776528120040894, 1.243246078491211, 1.1666666269302368, 1.1520410776138306, 1.3003637790679932, 1.0077217817306519, 1.172451138496399, 1.0406973361968994, 1.0534915924072266, 1.2492022514343262, 1.1286206245422363, 1.4238766431808472, 1.0611129999160767, 1.265521764755249, 1.060969591140747, 1.1768507957458496, 1.1086838245391846, 1.1707546710968018, 1.167304515838623, 1.6403756141662598, 1.07073175907135, 1.3478261232376099, 1.0204081535339355, 1.1977193355560303, 1.1515488624572754, 1.158180832862854, 1.0494880676269531, 1.2255913019180298, 1.1407175064086914, 1.0995185375213623, 1.0113970041275024, 1.079128384590149, 1.100127935409546, 1.0401943922042847, 1.0454206466674805, 1.1200729608535767, 1.3234626054763794, 1.0347349643707275, 1.1284046173095703, 1.0200241804122925, 1.0045255422592163, 1.0757181644439697, 1.046754240989685, 1.0976406335830688, 1.1119880676269531, 1.4243229627609253, 1.3367948532104492, 1.1275675296783447, 1.2051756381988525, 1.059931755065918, 1.3766233921051025, 1.0968025922775269, 1.272449254989624, 1.334044098854065, 1.0243957042694092, 1.015100121498108, 1.3287923336029053, 1.0433547496795654, 1.1671472787857056, 1.0956711769104004, 1.1008070707321167, 1.1257874965667725, 1.1804147958755493, 1.036513090133667, 1.1580257415771484, 1.066103458404541, 1.107125163078308, 1.1501774787902832, 1.3087058067321777, 1.0336848497390747, 1.0503023862838745, 1.1313706636428833, 1.0331506729125977, 1.0473947525024414, 1.3188337087631226, 1.3414634466171265, 1.1554176807403564, 1.5639972686767578, 1.1012725830078125, 1.162610650062561, 1.1517572402954102, 1.119362235069275, 1.4567275047302246, 1.04542875289917, 1.1066232919692993, 1.0192972421646118, 1.1007413864135742, 1.2381112575531006, 1.1045809984207153, 1.064713954925537, 1.1712772846221924, 1.1333649158477783, 1.162291169166565, 1.1670074462890625, 1.121696949005127, 1.0280308723449707, 1.0391197204589844, 1.0026943683624268, 1.2022792100906372, 1.0663204193115234, 1.2097737789154053, 1.0971500873565674, 1.1678533554077148, 1.3871382474899292, 1.0730785131454468, 1.010773777961731, 1.1777328252792358, 1.2765089273452759, 1.0350253582000732, 1.0, 1.132347822189331, 1.1031914949417114, 1.046065092086792, 1.3710317611694336, 1.0663349628448486, 1.0031434297561646, 1.2401208877563477, 1.3606009483337402, 1.067671298980713, 1.169235110282898, 1.6321228742599487, 1.1119369268417358, 1.0043785572052002, 1.9949558973312378, 1.7305034399032593, 1.2425498962402344, 1.097544550895691, 1.0883569717407227, 1.070794701576233, 1.0362318754196167, 1.0024042129516602, 1.2043763399124146, 1.032218098640442, 1.1782954931259155, 1.005126714706421, 1.0728543996810913, 1.4444444179534912, 1.1754347085952759, 1.13068425655365, 1.053175926208496, 1.059247374534607, 1.103459119796753, 1.212317705154419, 1.0243473052978516, 1.0238533020019531, 1.0652759075164795, 1.0576039552688599, 1.3548387289047241, 1.0653361082077026, 1.2200335264205933, 1.0725781917572021, 1.170098066329956, 1.2376340627670288, 1.0624271631240845, 1.226616621017456, 1.0469639301300049, 1.1182749271392822, 1.1144441366195679, 1.0043115615844727, 1.1325175762176514, 1.0316537618637085, 1.088834524154663, 1.4902777671813965, 1.018314242362976, 1.016794204711914, 1.043325662612915, 1.0445632934570312, 1.0166963338851929, 1.1293450593948364, 1.207751989364624, 1.4666666984558105, 1.0756912231445312, 1.1374986171722412, 1.5962809324264526, 1.247954249382019, 1.1300981044769287, 1.3014777898788452, 1.0815320014953613, 1.3705596923828125, 1.1166777610778809, 1.257846713066101, 1.071635127067566, 1.3064637184143066, 1.404927134513855, 1.0720317363739014, 1.1288061141967773, 1.1273219585418701, 1.0165985822677612, 1.3733333349227905, 1.1278067827224731]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7441444396972656] ms
 --  Average per query NF    [1.3573229312896729] ms
 --  Average per query vegas [2.3868215084075928] ms
Mean [1.159]  Median [1.120]  95th [1.425]  99th [1.641]  max [1.995]
Mean [1.159]  Median [1.120]  95th [1.425]  99th [1.641]  max [1.995]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.203251 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=0 | total-time=26.090407