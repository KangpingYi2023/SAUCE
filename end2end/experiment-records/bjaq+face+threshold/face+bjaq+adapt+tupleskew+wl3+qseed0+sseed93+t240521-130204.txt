Input arguments = Namespace(data_update='tupleskew', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 93, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.167740821838379
tensor(0.9937)
result is  tensor(379765.9375)
Enter testHyper
ReportEsts: [1.2489256858825684, 1.0955709218978882, 1.5786229372024536, 1.1577174663543701, 1.270851969718933, 1.0917423963546753, 1.1946412324905396, 1.0940062999725342, 1.1424500942230225, 1.1451436281204224, 1.0654608011245728, 1.143644094467163, 1.0577616691589355, 1.0223214626312256, 1.1373381614685059, 1.3246079683303833, 1.4195948839187622, 1.1699525117874146, 1.0755119323730469, 1.0714285373687744, 1.1473890542984009, 1.0265936851501465, 1.1346113681793213, 1.0226938724517822, 1.1127991676330566, 1.1781193017959595, 1.0715090036392212, 1.3548657894134521, 1.0394948720932007, 1.0785270929336548, 1.0975522994995117, 1.1523675918579102, 1.108779788017273, 1.0601907968521118, 1.1995964050292969, 1.2470409870147705, 1.43343985080719, 1.062987208366394, 1.0436232089996338, 1.1188024282455444, 1.0814026594161987, 1.1156264543533325, 1.0428508520126343, 1.0620063543319702, 1.1085991859436035, 1.0589568614959717, 1.086269736289978, 1.3045589923858643, 1.1181796789169312, 1.1708967685699463, 1.1582914590835571, 1.2586618661880493, 1.0522366762161255, 1.0384323596954346, 1.1432021856307983, 1.0452016592025757, 1.2514019012451172, 1.1810849905014038, 1.2350653409957886, 1.4010088443756104, 1.641156792640686, 1.1423872709274292, 1.3696160316467285, 1.1090537309646606, 1.2941176891326904, 1.2000000476837158, 1.1317689418792725, 1.005203127861023, 1.0382245779037476, 1.2736842632293701, 1.0289734601974487, 1.0800659656524658, 1.2852615118026733, 1.1617645025253296, 1.1563293933868408, 1.1242554187774658, 2.0356831550598145, 1.0060912370681763, 1.050743818283081, 1.357328176498413, 1.2735764980316162, 1.1444032192230225, 1.0454492568969727, 1.249700903892517, 1.2576390504837036, 1.0442208051681519, 1.0027443170547485, 1.119798183441162, 1.067592978477478, 1.1046521663665771, 1.0289292335510254, 1.383594274520874, 1.0389659404754639, 1.33495032787323, 1.2264150381088257, 1.0880626440048218, 1.1238436698913574, 1.2277178764343262, 1.0526316165924072, 1.177979588508606, 1.148667573928833, 1.0161586999893188, 1.0367268323898315, 1.0109809637069702, 1.0723849534988403, 1.022931694984436, 1.2374012470245361, 1.1710296869277954, 1.060956358909607, 1.0515738725662231, 1.1243059635162354, 1.1098484992980957, 1.3793789148330688, 1.0965443849563599, 1.2014604806900024, 1.1822916269302368, 1.0188137292861938, 1.0564942359924316, 1.352691650390625, 1.103656530380249, 1.1215910911560059, 1.0943838357925415, 1.1329599618911743, 1.1637104749679565, 1.323643445968628, 1.1718943119049072, 1.1991112232208252, 1.0926555395126343, 1.2653563022613525, 1.1199064254760742, 1.194009780883789, 1.064056396484375, 1.2259167432785034, 1.4642857313156128, 1.0946331024169922, 1.1627724170684814, 1.0210267305374146, 1.1040650606155396, 1.1214860677719116, 1.144823431968689, 1.1005525588989258, 1.0551557540893555, 1.117541790008545, 1.340021014213562, 1.0050718784332275, 1.027681827545166, 1.1186981201171875, 1.4663242101669312, 1.0162781476974487, 1.1397727727890015, 1.2247551679611206, 1.173695683479309, 1.351069688796997, 1.0898451805114746, 1.1311113834381104, 1.0300325155258179, 1.2014474868774414, 1.0087993144989014, 1.0073124170303345, 1.059146523475647, 1.3110743761062622, 1.0381673574447632, 1.0264294147491455, 1.2264398336410522, 1.196451187133789, 1.2208043336868286, 1.1551682949066162, 1.2012747526168823, 1.0192164182662964, 1.0099653005599976, 1.0856413841247559, 1.0617035627365112, 1.1688311100006104, 1.3073621988296509, 1.0653951168060303, 1.0062583684921265, 1.0254110097885132, 1.2380239963531494, 1.4034587144851685, 1.0947474241256714, 1.0913416147232056, 1.0213217735290527, 1.0049055814743042, 1.1225740909576416, 1.1477725505828857, 1.1014798879623413, 1.0354827642440796, 1.3079723119735718, 1.0034900903701782, 1.4201163053512573, 1.0601738691329956, 1.04464852809906, 1.484911561012268, 1.627463698387146, 1.763430118560791, 1.2527472972869873, 1.0938724279403687, 1.0704225301742554, 1.0750088691711426, 1.0390106439590454]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.6666345596313477] ms
 --  Average per query NF    [1.3656795024871826] ms
 --  Average per query vegas [2.300955057144165] ms
Mean [1.158]  Median [1.120]  95th [1.420]  99th [1.642]  max [2.036]
Mean [1.158]  Median [1.120]  95th [1.420]  99th [1.642]  max [2.036]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.822833 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=tupleskew', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
TupleSkewSample - START
0.001
TupleSkewSample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[4.5013428e-04 3.2985210e-04 2.7418137e-05 9.2983246e-06 1.4901161e-06]
Distance score: 0.00016363858594559133
SAUCE Drift detection: True
Detection latency: 0.0229s

DRIFT-DETECTED after 2-th workload
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/incremental_train.py', '--dataset=bjaq', '--end2end', '--model=face', '--model_update=adapt', '--update_size=80000', '--epochs=0']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
update_size: 76433
AdaptTask - START
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
train data shape: 80000, transfer data shape:16000
Training done; evaluating likelihood on full data:
Saved to: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
AdaptTask - END

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.002263 | Model-update-time: 2.218103


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=tupleskew', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.178479194641113
tensor(0.9960)
result is  tensor(456750.1875)
Enter testHyper
ReportEsts: [1.1206693649291992, 1.0111677646636963, 1.0424928665161133, 1.331416130065918, 1.0382118225097656, 1.0215082168579102, 1.2297149896621704, 1.049808382987976, 1.0684850215911865, 1.7095588445663452, 1.0116013288497925, 1.2748701572418213, 1.1312649250030518, 1.1875802278518677, 1.125661015510559, 1.026235580444336, 1.1040327548980713, 1.0866634845733643, 1.0400314331054688, 1.3073288202285767, 1.0269005298614502, 2.174926996231079, 1.1338800191879272, 1.0033187866210938, 1.0639235973358154, 1.157467246055603, 1.0915169715881348, 1.0780532360076904, 1.2883081436157227, 1.3703007698059082, 1.2606881856918335, 1.48305082321167, 1.0380676984786987, 4.990825653076172, 1.1001394987106323, 1.1731390953063965, 1.0985581874847412, 1.0863239765167236, 1.062177300453186, 1.2000312805175781, 1.022678256034851, 1.1494252681732178, 1.823624610900879, 1.1209348440170288, 1.087549090385437, 1.1212282180786133, 1.1465845108032227, 1.0053890943527222, 1.3952380418777466, 1.1783335208892822, 1.0921540260314941, 1.0622048377990723, 1.00741446018219, 1.1111221313476562, 1.1052682399749756, 1.154071569442749, 1.198960304260254, 1.1615339517593384, 1.156933307647705, 1.1239875555038452, 1.3234567642211914, 1.0087223052978516, 1.1340254545211792, 1.090147852897644, 1.0768344402313232, 1.1390656232833862, 1.3791958093643188, 1.0237772464752197, 1.2102912664413452, 1.2066761255264282, 1.0541690587997437, 1.154300332069397, 1.1409149169921875, 1.00703763961792, 1.249954104423523, 1.3086028099060059, 1.0819369554519653, 1.1580002307891846, 1.514072060585022, 1.1933326721191406, 1.0510278940200806, 1.1094106435775757, 1.101114273071289, 1.124049186706543, 1.3408876657485962, 1.591489315032959, 1.1224205493927002, 1.6874585151672363, 1.1978123188018799, 1.4085257053375244, 1.1320754289627075, 1.046573519706726, 1.3810251951217651, 1.351894497871399, 1.0300581455230713, 1.0241867303848267, 1.0696526765823364, 1.288772463798523, 1.227429986000061, 1.0579653978347778, 1.1605581045150757, 1.090378999710083, 1.0171568393707275, 1.1184664964675903, 1.1390340328216553, 1.0749669075012207, 1.0214768648147583, 1.144956350326538, 1.054441213607788, 1.0662429332733154, 1.0334625244140625, 1.0935765504837036, 1.0634875297546387, 1.3607919216156006, 1.0280334949493408, 1.139345645904541, 1.1424800157546997, 1.1304717063903809, 1.087804913520813, 2.7767856121063232, 1.1303070783615112, 1.3925234079360962, 1.009700894355774, 1.325392484664917, 1.0204577445983887, 1.1012046337127686, 1.1257002353668213, 1.0995105504989624, 1.0423955917358398, 1.0130923986434937, 1.0912038087844849, 1.1531949043273926, 1.0345501899719238, 1.7986347675323486, 1.7026406526565552, 1.176996111869812, 1.0057295560836792, 1.1517874002456665, 1.029520869255066, 1.0927718877792358, 1.124163031578064, 1.2525298595428467, 1.0775357484817505, 1.0667486190795898, 1.0033390522003174, 1.029860258102417, 1.2267441749572754, 1.008640170097351, 1.1936001777648926, 1.040861964225769, 1.1086537837982178, 1.0673047304153442, 1.1487739086151123, 1.0105242729187012, 1.017891526222229, 1.105263113975525, 1.0437133312225342, 1.0959999561309814, 1.1343947649002075, 1.0769833326339722, 1.1570463180541992, 1.0988428592681885, 1.533210277557373, 1.016758918762207, 1.0529299974441528, 1.1600022315979004, 1.0438238382339478, 1.0064562559127808, 1.0118510723114014, 1.234850287437439, 1.142380952835083, 1.2228457927703857, 1.3819060325622559, 1.0593011379241943, 1.0668405294418335, 1.0061765909194946, 1.044657588005066, 1.0113848447799683, 1.01788330078125, 1.1981528997421265, 1.7105263471603394, 1.0734800100326538, 1.0474361181259155, 1.5493971109390259, 1.2834055423736572, 1.4318697452545166, 1.5900483131408691, 1.356360673904419, 1.4478330612182617, 1.0064197778701782, 1.1424789428710938, 1.2793711423873901, 1.3007385730743408, 1.9111826419830322, 1.0626063346862793, 1.1674095392227173, 1.535398244857788, 1.0281453132629395, 1.4788494110107422, 1.0063786506652832]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.6351776123046875] ms
 --  Average per query NF    [1.3574421405792236] ms
 --  Average per query vegas [2.277735471725464] ms
Mean [1.199]  Median [1.121]  95th [1.596]  99th [2.181]  max [4.991]
Mean [1.199]  Median [1.121]  95th [1.596]  99th [2.181]  max [4.991]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.360058 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=1 | total-time=28.463889