Input arguments = Namespace(data_update='sample', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 51, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.170311212539673
tensor(0.9939)
result is  tensor(379821.8438)
Enter testHyper
ReportEsts: [1.0891327857971191, 1.0640021562576294, 1.339974284172058, 1.1109707355499268, 1.294458031654358, 1.0938386917114258, 1.2301534414291382, 1.1105930805206299, 1.0776351690292358, 1.1124458312988281, 1.1696813106536865, 1.1311440467834473, 1.0554494857788086, 1.0558035373687744, 1.1651057004928589, 1.3340047597885132, 1.3132827281951904, 1.2900238037109375, 1.1507912874221802, 1.0535714626312256, 1.0486422777175903, 1.1623616218566895, 1.1420695781707764, 1.0744341611862183, 1.1131259202957153, 1.0533454418182373, 1.060247778892517, 1.5214319229125977, 1.0179122686386108, 1.0824941396713257, 1.1312521696090698, 1.077465534210205, 1.0707067251205444, 1.001060128211975, 1.0950008630752563, 1.0090501308441162, 1.3673741817474365, 1.2140640020370483, 1.0765262842178345, 1.2299401760101318, 1.0883240699768066, 1.1606192588806152, 1.0964516401290894, 1.0649513006210327, 1.0796535015106201, 1.0147392749786377, 1.1521546840667725, 1.2535009384155273, 1.0953068733215332, 1.0490694046020508, 1.2068063020706177, 1.3099160194396973, 1.1205326318740845, 1.2240792512893677, 1.1625235080718994, 1.000463843345642, 1.3803738355636597, 1.1864842176437378, 1.1180033683776855, 1.4879463911056519, 1.3348623514175415, 1.169182300567627, 1.2488659620285034, 1.1647979021072388, 1.2692307233810425, 1.2285714149475098, 1.1126885414123535, 1.0515080690383911, 1.162251353263855, 1.3473684787750244, 1.0596760511398315, 1.0456056594848633, 1.1955622434616089, 1.2643581628799438, 1.1406517028808594, 1.0086249113082886, 2.016676664352417, 1.0048670768737793, 1.0009225606918335, 1.2133896350860596, 1.1442840099334717, 1.0841543674468994, 1.0544322729110718, 1.2282103300094604, 1.224539041519165, 1.086350440979004, 1.191152811050415, 1.1519798040390015, 1.0840986967086792, 1.0835890769958496, 1.0440006256103516, 1.3548184633255005, 1.0003607273101807, 1.2458125352859497, 1.107954502105713, 1.0191293954849243, 1.1093690395355225, 1.2256171703338623, 1.01694917678833, 1.1751708984375, 1.1852388381958008, 1.1661098003387451, 1.0207480192184448, 1.012445092201233, 1.1084728240966797, 1.050549864768982, 1.2444572448730469, 1.1937172412872314, 1.0592401027679443, 1.0009218454360962, 1.0415760278701782, 1.0772058963775635, 1.2381137609481812, 1.165626049041748, 1.0616668462753296, 1.1701030731201172, 1.0353847742080688, 1.0291500091552734, 1.3418481349945068, 1.0436031818389893, 1.2210665941238403, 1.1286739110946655, 1.0490097999572754, 1.2301973104476929, 1.3318798542022705, 1.2346265316009521, 1.1116652488708496, 1.1273627281188965, 1.2252180576324463, 1.0958583354949951, 1.1742570400238037, 1.0721490383148193, 1.258234977722168, 1.3928571939468384, 1.210017442703247, 1.1835126876831055, 1.0307259559631348, 1.2266666889190674, 1.091556191444397, 1.192643404006958, 1.2104136943817139, 1.0483081340789795, 1.1071040630340576, 1.2171902656555176, 1.2090914249420166, 1.2017875909805298, 1.0355346202850342, 1.2683123350143433, 1.1278932094573975, 1.0359375476837158, 1.101171612739563, 1.1615177392959595, 1.3349593877792358, 1.2449777126312256, 1.082543969154358, 1.0604363679885864, 1.1989301443099976, 1.0087225437164307, 1.12587571144104, 1.2974634170532227, 1.1331818103790283, 1.0258179903030396, 1.0568901300430298, 1.2941988706588745, 1.1442424058914185, 1.1901979446411133, 1.277428150177002, 1.2169923782348633, 1.0397220849990845, 1.141033411026001, 1.0931556224822998, 1.0495009422302246, 1.149350643157959, 1.0720057487487793, 1.1297683715820312, 1.0351088047027588, 1.0121476650238037, 1.2228559255599976, 1.1286132335662842, 1.116442084312439, 1.0733481645584106, 1.0183517932891846, 1.0091086626052856, 1.100102186203003, 1.1140891313552856, 1.1575052738189697, 1.0015923976898193, 1.2415342330932617, 1.028178334236145, 1.3171111345291138, 1.0085480213165283, 1.1082571744918823, 1.4045275449752808, 1.3980016708374023, 1.6778665781021118, 1.0243128538131714, 1.0992913246154785, 1.1343283653259277, 1.0194448232650757, 1.1359230279922485]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7845218181610107] ms
 --  Average per query NF    [1.373199224472046] ms
 --  Average per query vegas [2.411322593688965] ms
Mean [1.151]  Median [1.128]  95th [1.348]  99th [1.523]  max [2.017]
Mean [1.151]  Median [1.128]  95th [1.348]  99th [1.523]  max [2.017]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.856631 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=sample', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
Sample - START
Sample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[2.3841858e-07 5.9604645e-07 1.4901161e-06 2.3841858e-06 1.7881393e-07]
Distance score: 9.775161515790387e-07
SAUCE Drift detection: False
Detection latency: 0.0233s

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.024084 | Model-update-time: 0.000000


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=sample', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.164599418640137
tensor(0.9940)
result is  tensor(455826.6562)
Enter testHyper
ReportEsts: [1.1068181991577148, 1.0040974617004395, 1.1758241653442383, 1.1284549236297607, 1.02891206741333, 1.3357915878295898, 1.19171941280365, 1.0017130374908447, 1.0776005983352661, 1.1529287099838257, 1.0054210424423218, 1.1168088912963867, 1.2309582233428955, 1.0011649131774902, 1.0045201778411865, 1.0723944902420044, 1.0303524732589722, 1.1384289264678955, 1.0023446083068848, 1.3132580518722534, 1.0840526819229126, 1.2881076335906982, 1.0298668146133423, 1.033962607383728, 1.1438753604888916, 1.125787615776062, 1.182436227798462, 1.0900321006774902, 1.1190903186798096, 1.2846661806106567, 1.1017274856567383, 1.2391303777694702, 1.1122759580612183, 1.2159359455108643, 1.0764880180358887, 1.0560619831085205, 1.0198910236358643, 1.0130759477615356, 1.4218308925628662, 1.0477395057678223, 1.0106233358383179, 1.0042918920516968, 1.4103944301605225, 1.1870307922363281, 1.1018272638320923, 1.1237903833389282, 1.2555480003356934, 1.0477440357208252, 1.1712062358856201, 1.263680100440979, 1.0336359739303589, 1.045095682144165, 1.0721385478973389, 1.0120482444763184, 1.0124927759170532, 1.3069767951965332, 1.0040953159332275, 1.1016355752944946, 1.2428123950958252, 1.1312434673309326, 1.4391891956329346, 1.0342698097229004, 1.0534552335739136, 1.2376891374588013, 1.0242916345596313, 1.0308892726898193, 1.4690154790878296, 1.057373285293579, 1.1284195184707642, 1.0519551038742065, 1.2878245115280151, 1.3629368543624878, 1.1447497606277466, 1.0944105386734009, 1.0724130868911743, 1.0442359447479248, 1.1269841194152832, 1.1468677520751953, 1.2261732816696167, 1.1535426378250122, 1.2279279232025146, 1.0103386640548706, 1.4063624143600464, 1.3277761936187744, 1.2153141498565674, 1.3263157606124878, 1.255089282989502, 1.4624183177947998, 1.0309101343154907, 1.349806308746338, 1.1753491163253784, 1.172521710395813, 1.277371883392334, 1.0342813730239868, 1.2486828565597534, 1.049312710762024, 1.0015032291412354, 1.2245358228683472, 1.107391119003296, 1.0402969121932983, 1.2066208124160767, 1.1085307598114014, 1.229426383972168, 1.2554340362548828, 1.0637776851654053, 1.0210565328598022, 1.1916701793670654, 1.1629469394683838, 1.1504178047180176, 1.0707534551620483, 1.012557029724121, 1.0771313905715942, 1.2182263135910034, 1.2995983362197876, 1.101751446723938, 1.0551248788833618, 1.1743643283843994, 1.0091495513916016, 1.0560203790664673, 1.1555556058883667, 1.0052493810653687, 1.1625258922576904, 1.0639829635620117, 2.2857143878936768, 1.0601255893707275, 1.0177839994430542, 1.0416157245635986, 1.3419773578643799, 1.1360172033309937, 1.0134528875350952, 1.1657148599624634, 1.13888680934906, 1.1427496671676636, 1.5834165811538696, 1.7902584075927734, 1.2355725765228271, 1.0063854455947876, 1.2432574033737183, 1.0667558908462524, 1.0199249982833862, 1.0114496946334839, 1.129422903060913, 1.0098761320114136, 1.0596026182174683, 1.0302722454071045, 1.0877742767333984, 1.5, 1.1176464557647705, 1.2069441080093384, 1.134010672569275, 1.1371889114379883, 1.0818639993667603, 1.1733200550079346, 1.020372748374939, 1.052757740020752, 1.1090185642242432, 1.0260322093963623, 1.3203125, 1.0706666707992554, 1.1053730249404907, 1.019372820854187, 1.1591713428497314, 1.2984365224838257, 1.1443493366241455, 1.0262925624847412, 1.1807318925857544, 1.1327265501022339, 1.2578766345977783, 1.0725806951522827, 1.256341576576233, 1.0384451150894165, 1.2100969552993774, 1.4005167484283447, 1.1403508186340332, 1.0346838235855103, 1.0432307720184326, 1.1850696802139282, 1.0335826873779297, 1.0921505689620972, 1.074049472808838, 1.7209302186965942, 1.1616655588150024, 1.028127908706665, 1.8539109230041504, 1.1809338331222534, 1.0821361541748047, 1.0528942346572876, 1.0292737483978271, 1.4047837257385254, 1.024617075920105, 1.1214841604232788, 1.0167964696884155, 1.417634129524231, 2.1554267406463623, 1.0201934576034546, 1.0361111164093018, 1.7708945274353027, 1.061784029006958, 1.4132379293441772, 1.0962928533554077]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.763549327850342] ms
 --  Average per query NF    [1.3669347763061523] ms
 --  Average per query vegas [2.3966145515441895] ms
Mean [1.162]  Median [1.117]  95th [1.440]  99th [1.857]  max [2.286]
Mean [1.162]  Median [1.117]  95th [1.440]  99th [1.857]  max [2.286]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.223148 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=0 | total-time=26.166928