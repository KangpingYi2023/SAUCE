Input arguments = Namespace(data_update='valueskew', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 28, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.161151647567749
tensor(0.9946)
result is  tensor(380098.4688)
Enter testHyper
ReportEsts: [1.2106516361236572, 1.0610626935958862, 1.1014761924743652, 1.0355864763259888, 1.269713282585144, 1.1144946813583374, 1.1822090148925781, 1.0951884984970093, 1.1073949337005615, 1.1675596237182617, 1.1696813106536865, 1.1552965641021729, 1.0330055952072144, 1.046875, 1.0219898223876953, 1.4274780750274658, 1.4280915260314941, 1.2258907556533813, 1.1583703756332397, 1.0204081535339355, 1.0204827785491943, 1.0931427478790283, 1.1185877323150635, 1.0673259496688843, 1.1021808385849, 1.2206147909164429, 1.0323761701583862, 1.3892472982406616, 1.0124709606170654, 1.0157665014266968, 1.1106775999069214, 1.3285638093948364, 1.1381258964538574, 1.006194829940796, 1.2000082731246948, 1.1725945472717285, 1.4079262018203735, 1.275465726852417, 1.0894851684570312, 1.0244141817092896, 1.0368098020553589, 1.0231010913848877, 1.0308903455734253, 1.173703908920288, 1.0900063514709473, 1.0328798294067383, 1.077757716178894, 1.3628733158111572, 1.0555511713027954, 1.1641285419464111, 1.1974025964736938, 1.3386276960372925, 1.1346632242202759, 1.27047860622406, 1.025270938873291, 1.0169216394424438, 1.3355140686035156, 1.1103802919387817, 1.1182925701141357, 1.3659836053848267, 1.2613275051116943, 1.2070627212524414, 1.233278512954712, 1.0897616147994995, 1.330645203590393, 1.2857142686843872, 1.2104246616363525, 1.0521646738052368, 1.128012776374817, 1.4105262756347656, 1.1150442361831665, 1.0012518167495728, 1.176361322402954, 1.109430193901062, 1.0630741119384766, 1.0018482208251953, 1.974686861038208, 1.0450108051300049, 1.0197209119796753, 1.3565188646316528, 1.0854461193084717, 1.0707478523254395, 1.028596043586731, 1.3675740957260132, 1.2535468339920044, 1.119246244430542, 1.0619393587112427, 1.1880453824996948, 1.0054055452346802, 1.015424132347107, 1.0471328496932983, 1.3419463634490967, 1.0173097848892212, 1.2935370206832886, 1.0427807569503784, 1.0388262271881104, 1.142108678817749, 1.1059074401855469, 1.034482717514038, 1.1165621280670166, 1.2352941036224365, 1.2265067100524902, 1.0078248977661133, 1.0141054391860962, 1.1724895238876343, 1.099984884262085, 1.1371279954910278, 1.2006981372833252, 1.0857757329940796, 1.0533591508865356, 1.006693959236145, 1.0772058963775635, 1.0760084390640259, 1.0442601442337036, 1.1754955053329468, 1.026431679725647, 1.101645827293396, 1.1039597988128662, 1.2718732357025146, 1.152586579322815, 1.2453230619430542, 1.1204636096954346, 1.0480762720108032, 1.162563443183899, 1.215116262435913, 1.2007842063903809, 1.003965973854065, 1.1871792078018188, 1.170454502105713, 1.1189044713974, 1.3087158203125, 1.00413179397583, 1.2476693391799927, 1.4642857313156128, 1.3022327423095703, 1.1241796016693115, 1.0717005729675293, 1.1258536577224731, 1.0942260026931763, 1.275333285331726, 1.1709891557693481, 1.0286386013031006, 1.177910327911377, 1.3139543533325195, 1.1988861560821533, 1.1088438034057617, 1.0810520648956299, 1.3774499893188477, 1.0298696756362915, 1.102130651473999, 1.0764750242233276, 1.1462632417678833, 1.3356833457946777, 1.0934202671051025, 1.0318505764007568, 1.0181735754013062, 1.0386531352996826, 1.0042206048965454, 1.158388376235962, 1.1064757108688354, 1.100182294845581, 1.0105949640274048, 1.0598185062408447, 1.3698830604553223, 1.0800914764404297, 1.12109375, 1.0842711925506592, 1.423715353012085, 1.0494670867919922, 1.003744125366211, 1.039565086364746, 1.1130518913269043, 1.1168831586837769, 1.1324750185012817, 1.0030653476715088, 1.0300722122192383, 1.0274587869644165, 1.3929258584976196, 1.3317031860351562, 1.2446309328079224, 1.0465165376663208, 1.0419005155563354, 1.0210002660751343, 1.0858018398284912, 1.206809163093567, 1.0866807699203491, 1.1188491582870483, 1.2985183000564575, 1.032329797744751, 1.3907089233398438, 1.1124073266983032, 1.135239839553833, 1.5088554620742798, 1.0813653469085693, 1.6195096969604492, 1.3192647695541382, 1.135389804840088, 1.1176470518112183, 1.0603171586990356, 1.0304129123687744]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7664175033569336] ms
 --  Average per query NF    [1.3683104515075684] ms
 --  Average per query vegas [2.3981070518493652] ms
Mean [1.149]  Median [1.113]  95th [1.391]  99th [1.510]  max [1.975]
Mean [1.149]  Median [1.113]  95th [1.391]  99th [1.510]  max [1.975]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.827884 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=valueskew', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
ValueSample - START
ValueSample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[1.7881393e-07 1.1071682e-02 0.0000000e+00 0.0000000e+00 5.9604645e-08]
Distance score: 0.0022143840324133635
SAUCE Drift detection: True
Detection latency: 0.0234s

DRIFT-DETECTED after 2-th workload
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/incremental_train.py', '--dataset=bjaq', '--end2end', '--model=face', '--model_update=adapt', '--update_size=80000', '--epochs=0']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
update_size: 76433
AdaptTask - START
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
train data shape: 80000, transfer data shape:16000
Training done; evaluating likelihood on full data:
Saved to: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
AdaptTask - END

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.043597 | Model-update-time: 2.227948


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=valueskew', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.17850923538208
tensor(0.9942)
result is  tensor(455954.8125)
Enter testHyper
ReportEsts: [1.0456726551055908, 1.237331748008728, 1.2986425161361694, 1.3370786905288696, 1.0261050462722778, 1.169795274734497, 1.2063612937927246, 1.0421197414398193, 1.0776053667068481, 1.2182554006576538, 1.2651177644729614, 1.116599440574646, 1.106430172920227, 1.0182021856307983, 259.21112060546875, 1.209826111793518, 1.2842592000961304, 1.2724230289459229, 1.028836965560913, 1.2693957090377808, 1.1160293817520142, 6.151975631713867, 1.1545442342758179, 1.3510279655456543, 1.09980046749115, 1.163018822669983, 1.0936483144760132, 1.311972975730896, 1.1813969612121582, 1.7265625, 1.3519814014434814, 1.2083333730697632, 1.06010901927948, 1.1502710580825806, 1.0891468524932861, 1.0041451454162598, 1.4713019132614136, 4.592278957366943, 1.1046110391616821, 1.009096384048462, 1.1047556400299072, 1.1749681234359741, 1.2024593353271484, 1.659094214439392, 1.119260311126709, 1.0187867879867554, 1.2597379684448242, 1.199000597000122, 1.3666666746139526, 1.2399922609329224, 1.3198710680007935, 1.2530821561813354, 1.0898334980010986, 1.0179762840270996, 1.0346119403839111, 1.386950135231018, 1.2952325344085693, 1.0578504800796509, 1.0606399774551392, 1.0903804302215576, 1.3722944259643555, 1.0024703741073608, 1.0728100538253784, 1.3772132396697998, 1.0486276149749756, 1.4346457719802856, 1.2511180639266968, 1.1136211156845093, 1.1965824365615845, 1.2716809511184692, 1.1264454126358032, 1.1359541416168213, 1.0517654418945312, 1.4048691987991333, 1.8460333347320557, 1.2658288478851318, 149.74789428710938, 1.0973292589187622, 1.4324090480804443, 1.0918242931365967, 1.3492525815963745, 1.083698034286499, 1.1918504238128662, 1.27781081199646, 1.3082127571105957, 1.578723430633545, 1.0264908075332642, 1.2255319356918335, 1.0024360418319702, 1.1799544095993042, 1.0445367097854614, 1.3319025039672852, 1.0953575372695923, 1.2031880617141724, 70.91740417480469, 1.2473820447921753, 1.1926945447921753, 1.2343567609786987, 2.1567249298095703, 2.127406358718872, 1.136674404144287, 1.3368653059005737, 1.2474747896194458, 1.0106256008148193, 1.058637022972107, 1.287327527999878, 1.1100525856018066, 1.1056817770004272, 1.0372493267059326, 1.0523333549499512, 2.0969321727752686, 1.0965824127197266, 1.162211298942566, 1.2708286046981812, 1.3336678743362427, 1.103773593902588, 1.3877716064453125, 1.0086742639541626, 1.2346590757369995, 1.0578511953353882, 1.1489970684051514, 1.0601922273635864, 1.1414216756820679, 1.0031298398971558, 1.109706163406372, 1.1460657119750977, 1.5052825212478638, 1.3048386573791504, 1.3202433586120605, 1.1444374322891235, 1.1696268320083618, 1.0201398134231567, 1.1480677127838135, 2.048969030380249, 3.754901885986328, 1.0252981185913086, 1.0816007852554321, 1.0640889406204224, 1.4805784225463867, 1.1883999109268188, 1.1071176528930664, 1.0254124402999878, 1.2353713512420654, 1.010961651802063, 1.001015543937683, 1.1848647594451904, 1.3701298236846924, 1.1180620193481445, 1.0678471326828003, 1.086011290550232, 1.1640435457229614, 1.0714524984359741, 1.365220308303833, 1.2011641263961792, 1.150022029876709, 1.5984326601028442, 2.532202959060669, 1.0703125, 1.1040877103805542, 1.1137276887893677, 1.496809482574463, 1.1672619581222534, 1.0280447006225586, 1.0972996950149536, 1.2820998430252075, 1.049304723739624, 1.313280701637268, 1.734601378440857, 819.0, 1.203321099281311, 1.1602907180786133, 1.129462480545044, 1.1513409614562988, 1.0044115781784058, 9.860092163085938, 1.326517939567566, 1.6805272102355957, 1.1647077798843384, 1.179890513420105, 1.2678776979446411, 1.7209302186965942, 1.3486683368682861, 1.0345889329910278, 1.6618856191635132, 1.5244780778884888, 1.333677887916565, 1.5283018350601196, 1.0048350095748901, 1.5190644264221191, 1.0709220170974731, 1.1519896984100342, 1.164294719696045, 1.1967791318893433, 2.449204921722412, 1.0292942523956299, 2.1458332538604736, 1.5307064056396484, 1.1707426309585571, 1.0608974695205688, 1.141931414604187]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7193095684051514] ms
 --  Average per query NF    [1.3543903827667236] ms
 --  Average per query vegas [2.3649191856384277] ms
Mean [7.808]  Median [1.177]  95th [2.171]  99th [150.843]  max [819.000]
Mean [7.808]  Median [1.177]  95th [2.171]  99th [150.843]  max [819.000]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.386853 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=1 | total-time=28.511615