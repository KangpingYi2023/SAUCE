Input arguments = Namespace(data_update='tupleskew', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 7, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.163225889205933
tensor(0.9986)
result is  tensor(381617.5312)
Enter testHyper
ReportEsts: [1.1449071168899536, 1.1044389009475708, 1.4697588682174683, 1.0477995872497559, 1.325537919998169, 1.0911967754364014, 1.182509422302246, 1.239058494567871, 1.0919818878173828, 1.051058292388916, 1.1291989088058472, 1.184533953666687, 1.028243064880371, 1.0513392686843872, 1.0418521165847778, 1.2695876359939575, 1.3813698291778564, 1.2644892930984497, 1.156245231628418, 1.026178002357483, 1.085849404335022, 1.0060040950775146, 1.1162694692611694, 1.0674364566802979, 1.0891121625900269, 1.0795660018920898, 1.0323761701583862, 1.3827054500579834, 1.0493336915969849, 1.0242091417312622, 1.2121319770812988, 1.1459131240844727, 1.068768858909607, 1.0319273471832275, 1.1881897449493408, 1.122873306274414, 1.358769416809082, 1.0759347677230835, 1.0807855129241943, 1.1364071369171143, 1.1085792779922485, 1.1173198223114014, 1.0825703144073486, 1.0161694288253784, 1.0971899032592773, 1.021541953086853, 1.1541999578475952, 1.1825881004333496, 1.0714454650878906, 1.1201353073120117, 1.2195767164230347, 1.422207236289978, 1.106668472290039, 1.0847504138946533, 1.2263195514678955, 1.000463843345642, 1.2186915874481201, 1.298068881034851, 1.057054042816162, 1.4612011909484863, 1.1918845176696777, 1.1617393493652344, 1.4070061445236206, 1.1596029996871948, 1.3807531595230103, 1.0571428537368774, 1.0913838148117065, 1.0665955543518066, 1.104597568511963, 1.2105263471603394, 1.098954200744629, 1.0417088270187378, 1.335723638534546, 1.1696324348449707, 1.1290740966796875, 1.1781100034713745, 1.8455573320388794, 1.0152223110198975, 1.1003488302230835, 1.354867935180664, 1.4340364933013916, 1.1114521026611328, 1.0154874324798584, 1.1485316753387451, 1.1974387168884277, 1.0033798217773438, 1.0702942609786987, 1.1355359554290771, 1.0872619152069092, 1.0724769830703735, 1.0503257513046265, 1.4627370834350586, 1.0032562017440796, 1.2313199043273926, 1.1271675825119019, 1.007849097251892, 1.0612688064575195, 1.2628132104873657, 1.034482717514038, 1.258683681488037, 1.2638888359069824, 1.0841187238693237, 1.0403035879135132, 1.002196192741394, 1.0218042135238647, 1.044319748878479, 1.2593642473220825, 1.1832460165023804, 1.0738409757614136, 1.025558352470398, 1.0654096603393555, 1.1172544956207275, 1.1380226612091064, 1.0247855186462402, 1.0188941955566406, 1.0271493196487427, 1.022621512413025, 1.002450704574585, 1.0989515781402588, 1.225088119506836, 1.2334288358688354, 1.098454475402832, 1.250183343887329, 1.1766042709350586, 1.1642441749572754, 1.1877837181091309, 1.1649625301361084, 1.3386870622634888, 1.2089202404022217, 1.1255844831466675, 1.1419025659561157, 1.102575659751892, 1.2790553569793701, 1.5357142686843872, 1.1448267698287964, 1.0217905044555664, 1.069461703300476, 1.1268292665481567, 1.023267149925232, 1.0459266901016235, 1.1015480756759644, 1.116916298866272, 1.0412397384643555, 1.367247223854065, 1.1266180276870728, 1.0625288486480713, 1.0085006952285767, 1.6348787546157837, 1.0045881271362305, 1.1170454025268555, 1.1612434387207031, 1.1686962842941284, 1.3087141513824463, 1.1584153175354004, 1.155086874961853, 1.0888592004776, 1.189856767654419, 1.0227912664413452, 1.1440109014511108, 1.1925395727157593, 1.0960514545440674, 1.074613094329834, 1.0051977634429932, 1.2730978727340698, 1.1512194871902466, 1.0175800323486328, 1.0649447441101074, 1.3025370836257935, 1.0970127582550049, 1.0315390825271606, 1.0794663429260254, 1.168314814567566, 1.1233766078948975, 1.2355235815048218, 1.1454359292984009, 1.1541212797164917, 1.0068026781082153, 1.2667396068572998, 1.1343567371368408, 1.0871422290802002, 1.0491806268692017, 1.1296380758285522, 1.0028635263442993, 1.1041879653930664, 1.1839913129806519, 1.0761098861694336, 1.01706862449646, 1.287813663482666, 1.0909641981124878, 1.2517133951187134, 1.0342072248458862, 1.093489646911621, 1.6051743030548096, 1.34967839717865, 1.5603779554367065, 1.1853210926055908, 1.2049187421798706, 1.0704225301742554, 1.0359158515930176, 1.1916003227233887]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7621378898620605] ms
 --  Average per query NF    [1.3613057136535645] ms
 --  Average per query vegas [2.400832176208496] ms
Mean [1.150]  Median [1.117]  95th [1.408]  99th [1.605]  max [1.846]
Mean [1.150]  Median [1.117]  95th [1.408]  99th [1.605]  max [1.846]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.825123 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=tupleskew', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
TupleSkewSample - START
0.001
TupleSkewSample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[2.8908253e-05 1.0430813e-05 2.4753809e-04 2.5641918e-04 7.3313713e-06]
Distance score: 0.0001101255402318202
SAUCE Drift detection: True
Detection latency: 0.0228s

DRIFT-DETECTED after 2-th workload
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/incremental_train.py', '--dataset=bjaq', '--end2end', '--model=face', '--model_update=adapt', '--update_size=80000', '--epochs=0']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
update_size: 76433
AdaptTask - START
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
train data shape: 80000, transfer data shape:16000
Training done; evaluating likelihood on full data:
Saved to: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
AdaptTask - END

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.007166 | Model-update-time: 2.222741


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=tupleskew', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.16777491569519
tensor(0.9927)
result is  tensor(455254.5312)
Enter testHyper
ReportEsts: [1.1870293617248535, 1.0379747152328491, 1.8522727489471436, 1.1013903617858887, 1.1346007585525513, 1.0056406259536743, 1.1594959497451782, 1.0110104084014893, 1.0551471710205078, 1.142581582069397, 1.1897685527801514, 1.0623029470443726, 1.3235293626785278, 1.1317535638809204, 1.109580159187317, 1.0321853160858154, 1.186233639717102, 1.0975698232650757, 1.0620675086975098, 1.3199788331985474, 1.1115827560424805, 1.0535856485366821, 1.378894567489624, 1.0834001302719116, 1.1160986423492432, 1.2200497388839722, 1.008851170539856, 1.1844757795333862, 1.024279236793518, 1.0217238664627075, 1.4149184226989746, 1.491525411605835, 1.182525396347046, 1.0578047037124634, 1.1584124565124512, 1.2048532962799072, 1.0191282033920288, 1.1634923219680786, 1.0766724348068237, 1.0646721124649048, 1.0153526067733765, 1.2132822275161743, 1.192160725593567, 1.1053446531295776, 1.0199596881866455, 1.0867186784744263, 1.0132191181182861, 1.1226180791854858, 1.2571429014205933, 1.1452218294143677, 1.0295178890228271, 1.1059443950653076, 1.179957389831543, 1.0209171772003174, 1.1298894882202148, 1.5999507904052734, 1.246866226196289, 1.1326100826263428, 1.186987280845642, 1.1867015361785889, 1.2822966575622559, 1.018057942390442, 1.0530680418014526, 1.0757498741149902, 1.070054292678833, 1.166567087173462, 1.3318085670471191, 1.1251581907272339, 1.0914915800094604, 1.1647847890853882, 1.1040586233139038, 1.1140730381011963, 1.0519436597824097, 1.0632398128509521, 1.100407361984253, 1.0136423110961914, 1.2675474882125854, 1.0327084064483643, 1.4739792346954346, 1.0296239852905273, 1.008600115776062, 1.0987178087234497, 1.171360969543457, 1.059287190437317, 1.3056132793426514, 1.621276617050171, 1.327813744544983, 1.7599029541015625, 1.5682519674301147, 1.565151572227478, 1.323642373085022, 1.1102153062820435, 1.4101850986480713, 1.1620521545410156, 1.2241429090499878, 1.0197936296463013, 1.0313353538513184, 1.1715099811553955, 1.3402798175811768, 1.2405754327774048, 1.2052013874053955, 1.0567543506622314, 1.058823585510254, 1.214745283126831, 1.332885503768921, 1.1566951274871826, 1.1166495084762573, 1.1914281845092773, 1.0630372762680054, 1.0728074312210083, 1.0060553550720215, 1.0110325813293457, 1.1784414052963257, 1.2062206268310547, 1.0984911918640137, 1.0656920671463013, 1.0172737836837769, 1.0628314018249512, 1.5035858154296875, 1.0973451137542725, 1.0235594511032104, 1.0541625022888184, 1.1830344200134277, 1.538848876953125, 1.1560026407241821, 1.0870248079299927, 1.1341575384140015, 1.0564262866973877, 1.069777488708496, 1.0504934787750244, 1.09630286693573, 1.123474359512329, 1.1270232200622559, 2.056216239929199, 2.0179049968719482, 1.2858705520629883, 1.054430603981018, 1.0281696319580078, 1.053346037864685, 1.1145658493041992, 1.1097246408462524, 1.149817705154419, 1.1094640493392944, 1.1529868841171265, 1.1049648523330688, 1.0267455577850342, 1.2787878513336182, 1.1340194940567017, 1.081120491027832, 1.0357791185379028, 1.4993188381195068, 1.0564543008804321, 1.1048884391784668, 1.1046313047409058, 1.0101509094238281, 1.1701656579971313, 1.203722596168518, 1.0873016119003296, 1.255839467048645, 1.0621129274368286, 1.2228772640228271, 1.0666372776031494, 1.1480746269226074, 1.2188054323196411, 1.2179136276245117, 1.117607593536377, 1.1493868827819824, 1.1872968673706055, 1.1764975786209106, 1.4220865964889526, 1.1310855150222778, 1.022233009338379, 1.553206443786621, 1.0315582752227783, 1.1820015907287598, 1.0669265985488892, 1.245362401008606, 1.0248143672943115, 1.1034772396087646, 1.0778403282165527, 1.8421052694320679, 1.2025126218795776, 1.0678961277008057, 1.6466997861862183, 1.1900663375854492, 1.3594554662704468, 1.28855562210083, 1.1279817819595337, 1.3518861532211304, 1.1986768245697021, 1.0200024843215942, 1.035810112953186, 1.3077510595321655, 1.660987377166748, 1.0924935340881348, 1.0069509744644165, 1.3232028484344482, 1.1931315660476685, 1.3359746932983398, 1.1375905275344849]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.776198625564575] ms
 --  Average per query NF    [1.3626813888549805] ms
 --  Average per query vegas [2.4135172367095947] ms
Mean [1.179]  Median [1.128]  95th [1.565]  99th [1.854]  max [2.056]
Mean [1.179]  Median [1.128]  95th [1.565]  99th [1.854]  max [2.056]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.403216 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=1 | total-time=28.497025