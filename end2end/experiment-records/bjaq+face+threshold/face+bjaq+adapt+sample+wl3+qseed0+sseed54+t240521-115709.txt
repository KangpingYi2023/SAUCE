Input arguments = Namespace(data_update='sample', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 54, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.174816846847534
tensor(0.9984)
result is  tensor(381545.1562)
Enter testHyper
ReportEsts: [1.1999410390853882, 1.0192179679870605, 1.6988708972930908, 1.0783323049545288, 1.264802098274231, 1.1554811000823975, 1.2149415016174316, 1.046403408050537, 1.0083125829696655, 1.1793478727340698, 1.1326442956924438, 1.20444917678833, 1.0056538581848145, 1.0491071939468384, 1.1060649156570435, 1.1763721704483032, 1.4134166240692139, 1.179691195487976, 1.1521937847137451, 1.1122448444366455, 1.2309538125991821, 1.1230747699737549, 1.1734204292297363, 1.0129274129867554, 1.2459365129470825, 1.0524412393569946, 1.0163090229034424, 1.363444447517395, 1.0907002687454224, 1.0161733627319336, 1.1961688995361328, 1.1999669075012207, 1.1198835372924805, 1.0056440830230713, 1.0598747730255127, 1.1027816534042358, 1.3089497089385986, 1.1430175304412842, 1.0601933002471924, 1.0859880447387695, 1.133995532989502, 1.1947267055511475, 1.070348858833313, 1.0450778007507324, 1.071624755859375, 1.019274353981018, 1.1168019771575928, 1.4199715852737427, 1.1495137214660645, 1.1793570518493652, 1.2099738121032715, 1.3247406482696533, 1.0462186336517334, 1.186618685722351, 1.2024623155593872, 1.0247031450271606, 1.351401925086975, 1.1634681224822998, 1.0757510662078857, 1.4689290523529053, 1.241122841835022, 1.1694363355636597, 1.073482871055603, 1.170861840248108, 1.2547528743743896, 1.3142857551574707, 1.1317689418792725, 1.0017566680908203, 1.071623682975769, 1.2315789461135864, 1.0205254554748535, 1.0868223905563354, 1.2352772951126099, 1.3669047355651855, 1.1097378730773926, 1.144710898399353, 2.040797472000122, 1.002427577972412, 1.0339205265045166, 1.260418176651001, 1.181228518486023, 1.0605717897415161, 1.015139102935791, 1.2451696395874023, 1.2151148319244385, 1.0544260740280151, 1.080392599105835, 1.0926607847213745, 1.0397616624832153, 1.0218923091888428, 1.10536527633667, 1.331541895866394, 1.0093761682510376, 1.2905040979385376, 1.0, 1.0394126176834106, 1.087121605873108, 1.1368755102157593, 1.0909091234207153, 1.169927954673767, 1.2877358198165894, 1.2817522287368774, 1.0680450201034546, 1.0080527067184448, 1.0401673316955566, 1.0694886445999146, 1.1361021995544434, 1.1762652397155762, 1.0771830081939697, 1.0697044134140015, 1.294511079788208, 1.0963517427444458, 1.0354747772216797, 1.1061758995056152, 1.1076852083206177, 1.1884816884994507, 1.0051559209823608, 1.1997935771942139, 1.3904823064804077, 1.0377240180969238, 1.1491369009017944, 1.067062258720398, 1.2055743932724, 1.075514554977417, 1.3202519416809082, 1.174576997756958, 1.171617865562439, 1.0584298372268677, 1.3250428438186646, 1.08016037940979, 1.06107497215271, 1.088989019393921, 1.1730889081954956, 1.3928571939468384, 1.1268738508224487, 1.0015777349472046, 1.0339142084121704, 1.0308942794799805, 1.1711530685424805, 1.3625355958938599, 1.0692917108535767, 1.1577554941177368, 1.2590690851211548, 1.225691556930542, 1.039490818977356, 1.0700633525848389, 1.0061066150665283, 1.5158681869506836, 1.0622715950012207, 1.004494547843933, 1.207218885421753, 1.1358799934387207, 1.351811170578003, 1.1693994998931885, 1.180196762084961, 1.0074290037155151, 1.155609130859375, 1.0185706615447998, 1.1092381477355957, 1.207758903503418, 1.248895287513733, 1.0917061567306519, 1.0103955268859863, 1.2526737451553345, 1.2967033386230469, 1.0820908546447754, 1.238751769065857, 1.3080084323883057, 1.189274549484253, 1.027425765991211, 1.0962321758270264, 1.172587513923645, 1.1753246784210205, 1.0682717561721802, 1.0098774433135986, 1.0358309745788574, 1.0238806009292603, 1.3323360681533813, 1.2026498317718506, 1.2234405279159546, 1.0981075763702393, 1.0104657411575317, 1.0049055814743042, 1.2257405519485474, 1.153205394744873, 1.1384778022766113, 1.0135443210601807, 1.269162893295288, 1.0479114055633545, 1.421547770500183, 1.0167704820632935, 1.0194426774978638, 1.689757227897644, 1.2627224922180176, 1.8289306163787842, 1.215047001838684, 1.238182544708252, 1.0704225301742554, 1.0630115270614624, 1.0783864259719849]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.797405958175659] ms
 --  Average per query NF    [1.3685870170593262] ms
 --  Average per query vegas [2.428818941116333] ms
Mean [1.157]  Median [1.132]  95th [1.391]  99th [1.700]  max [2.041]
Mean [1.157]  Median [1.132]  95th [1.391]  99th [1.700]  max [2.041]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.832269 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=sample', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
Sample - START
Sample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[6.5565109e-07 1.1920929e-06 5.3644180e-07 7.7486038e-07 1.1920929e-07]
Distance score: 6.556510925292969e-07
SAUCE Drift detection: False
Detection latency: 0.0233s

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.030426 | Model-update-time: 0.000000


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=sample', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.19875168800354
tensor(0.9920)
result is  tensor(454936.0938)
Enter testHyper
ReportEsts: [1.0460871458053589, 1.0752065181732178, 1.1834733486175537, 1.5872093439102173, 1.1021077632904053, 1.350711703300476, 1.237908959388733, 1.0234360694885254, 1.0986918210983276, 1.0161290168762207, 1.0806523561477661, 1.2709932327270508, 1.1301369667053223, 1.131852388381958, 1.0620583295822144, 1.0775957107543945, 1.545454502105713, 1.2234169244766235, 1.1140761375427246, 1.2396891117095947, 1.1213500499725342, 1.26455819606781, 1.110945224761963, 1.1385101079940796, 1.1815052032470703, 1.120149850845337, 1.0385334491729736, 1.163063883781433, 1.2986435890197754, 1.328818678855896, 1.1531749963760376, 1.2758620977401733, 1.014023780822754, 1.048377513885498, 1.1044869422912598, 1.132090449333191, 1.1555027961730957, 1.0686661005020142, 1.336524248123169, 1.0508521795272827, 1.042296290397644, 1.1188005208969116, 1.027298092842102, 1.1225899457931519, 1.0840520858764648, 1.1410737037658691, 1.1771889925003052, 1.0082142353057861, 1.0728745460510254, 1.1040068864822388, 1.04936683177948, 1.0713167190551758, 1.0228430032730103, 1.1796060800552368, 1.174895167350769, 1.1765996217727661, 1.2360461950302124, 1.0885568857192993, 1.2919042110443115, 1.0575361251831055, 1.3058350086212158, 1.022321105003357, 1.0307388305664062, 1.3587015867233276, 1.0689284801483154, 1.0494943857192993, 1.1686924695968628, 1.0096505880355835, 1.220984935760498, 1.0842798948287964, 1.0197221040725708, 1.141027808189392, 1.0183794498443604, 1.093927264213562, 1.0033793449401855, 1.1515953540802002, 1.0034675598144531, 1.2423890829086304, 1.342737078666687, 1.1336629390716553, 1.2227003574371338, 1.141931176185608, 1.042585015296936, 1.279828429222107, 1.2858128547668457, 1.3202847242355347, 1.2135305404663086, 1.528751254081726, 1.0560119152069092, 1.092279076576233, 1.0452455282211304, 1.1993790864944458, 1.3075034618377686, 1.1941736936569214, 1.6433216333389282, 1.0409575700759888, 1.1971938610076904, 1.1405136585235596, 1.2110605239868164, 1.2599289417266846, 1.1668484210968018, 1.1132563352584839, 1.2400000095367432, 1.151552677154541, 1.1679518222808838, 1.0125820636749268, 1.1481738090515137, 1.1134835481643677, 1.220588207244873, 1.0930688381195068, 1.0908445119857788, 1.0715892314910889, 1.0467002391815186, 1.0377428531646729, 1.1066054105758667, 1.1820967197418213, 1.0687031745910645, 1.2257940769195557, 1.205643653869629, 1.1550387144088745, 1.0772655010223389, 1.076564908027649, 1.0070470571517944, 1.2110977172851562, 1.045821189880371, 1.294950008392334, 1.0124285221099854, 1.2170542478561401, 1.0698543787002563, 1.0487275123596191, 1.0217856168746948, 1.070046305656433, 1.0737894773483276, 1.4824074506759644, 1.6988636255264282, 1.0490061044692993, 1.014836072921753, 1.0831589698791504, 1.0550529956817627, 1.0138107538223267, 1.0037434101104736, 1.1442078351974487, 1.0883408784866333, 1.1732637882232666, 1.003534197807312, 1.0938169956207275, 1.3736263513565063, 1.0266329050064087, 1.2229928970336914, 1.0212719440460205, 1.1818927526474, 1.008140206336975, 1.0979948043823242, 1.0218288898468018, 1.0798953771591187, 1.007240653038025, 1.0498027801513672, 1.3359999656677246, 1.0767847299575806, 1.1216293573379517, 1.0439311265945435, 1.056874394416809, 1.106289029121399, 1.0450775623321533, 1.2574118375778198, 1.210894227027893, 1.0683071613311768, 1.206092357635498, 1.124385118484497, 1.2940170764923096, 1.050882339477539, 1.1734285354614258, 1.536550760269165, 1.0056496858596802, 1.0562939643859863, 1.0303515195846558, 1.0059250593185425, 1.1275321245193481, 1.124433159828186, 1.0223257541656494, 1.5, 1.0653859376907349, 1.0873597860336304, 1.4204692840576172, 1.2636265754699707, 1.1473076343536377, 1.5785646438598633, 1.0896754264831543, 1.380922555923462, 1.0101349353790283, 1.194381833076477, 1.009429693222046, 1.1725749969482422, 1.5416507720947266, 1.015562891960144, 1.4930510520935059, 1.350829005241394, 1.1791044473648071, 1.353140950202942, 1.1290767192840576]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.779653310775757] ms
 --  Average per query NF    [1.377573013305664] ms
 --  Average per query vegas [2.4020802974700928] ms
Mean [1.154]  Median [1.119]  95th [1.483]  99th [1.588]  max [1.699]
Mean [1.154]  Median [1.119]  95th [1.483]  99th [1.588]  max [1.699]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.260596 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=0 | total-time=26.195088