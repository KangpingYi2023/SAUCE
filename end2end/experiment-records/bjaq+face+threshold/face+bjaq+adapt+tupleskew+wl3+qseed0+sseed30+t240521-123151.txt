Input arguments = Namespace(data_update='tupleskew', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 30, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.172906160354614
tensor(0.9914)
result is  tensor(378884.3125)
Enter testHyper
ReportEsts: [1.2189934253692627, 1.1449249982833862, 1.5028729438781738, 1.1038113832473755, 1.2411679029464722, 1.118395209312439, 1.1865017414093018, 1.035999059677124, 1.0696502923965454, 1.0769741535186768, 1.03445303440094, 1.1493643522262573, 1.0350019931793213, 1.034641981124878, 1.1896557807922363, 1.361875295639038, 1.1560518741607666, 1.2902612686157227, 1.2046830654144287, 1.0637755393981934, 1.112135410308838, 1.021268367767334, 1.1673169136047363, 1.0620959997177124, 1.185820460319519, 1.2079565525054932, 1.050957202911377, 1.3286713361740112, 1.0183802843093872, 1.0727291107177734, 1.1018091440200806, 1.270106315612793, 1.0890779495239258, 1.0165408849716187, 1.1410393714904785, 1.1180269718170166, 1.3967607021331787, 1.1272954940795898, 1.2442758083343506, 1.0214067697525024, 1.0039925575256348, 1.236695647239685, 1.004878044128418, 1.1323210000991821, 1.0650750398635864, 1.0091533660888672, 1.0981115102767944, 1.259379506111145, 1.0044876337051392, 1.160744547843933, 1.1641414165496826, 1.4491058588027954, 1.038228154182434, 1.070655107498169, 1.1893850564956665, 1.0242165327072144, 1.314018726348877, 1.0225826501846313, 1.1949832439422607, 1.4541884660720825, 1.1672574281692505, 1.1859235763549805, 1.2635129690170288, 1.0646893978118896, 1.330645203590393, 1.1714285612106323, 1.1266846656799316, 1.0109844207763672, 1.079847812652588, 1.48421049118042, 1.0595333576202393, 1.0331169366836548, 1.2452356815338135, 1.206461787223816, 1.1859859228134155, 1.2079178094863892, 1.746039867401123, 1.0811278820037842, 1.1738985776901245, 1.195016622543335, 1.2555567026138306, 1.1463414430618286, 1.03341805934906, 1.2087854146957397, 1.2419084310531616, 1.1509591341018677, 1.124782681465149, 1.1868852376937866, 1.1027754545211792, 1.0718135833740234, 1.0502333641052246, 1.4221322536468506, 1.012043833732605, 1.34506356716156, 1.0714285373687744, 1.03225576877594, 1.126076579093933, 1.358868956565857, 1.0714285373687744, 1.1806946992874146, 1.1835260391235352, 1.2412885427474976, 1.0131728649139404, 1.0087847709655762, 1.1076359748840332, 1.1428571939468384, 1.2221165895462036, 1.1780104637145996, 1.0813658237457275, 1.054638147354126, 1.1286735534667969, 1.0732600688934326, 1.0996885299682617, 1.10211980342865, 1.096441388130188, 1.15816330909729, 1.0236282348632812, 1.087965965270996, 1.33734130859375, 1.0544365644454956, 1.2266337871551514, 1.1407479047775269, 1.1564313173294067, 1.1223739385604858, 1.261143445968628, 1.2148163318634033, 1.0434870719909668, 1.0983515977859497, 1.228139877319336, 1.1406145095825195, 1.0808275938034058, 1.1318068504333496, 1.377563714981079, 1.3928571939468384, 1.0550322532653809, 1.079648494720459, 1.0877618789672852, 1.2933332920074463, 1.0860735177993774, 1.2951929569244385, 1.115286946296692, 1.0283933877944946, 1.0114176273345947, 1.3265154361724854, 1.1159510612487793, 1.119683861732483, 1.1040908098220825, 1.499537467956543, 1.1455491781234741, 1.0780539512634277, 1.3346266746520996, 1.1815152168273926, 1.337133526802063, 1.0313572883605957, 1.2038542032241821, 1.0606977939605713, 1.2140346765518188, 1.0267304182052612, 1.061700701713562, 1.0999701023101807, 1.0270503759384155, 1.0378315448760986, 1.0134789943695068, 1.2818057537078857, 1.1359807252883911, 1.0213810205459595, 1.096818208694458, 1.2618041038513184, 1.0103801488876343, 1.0728733539581299, 1.0552289485931396, 1.0450804233551025, 1.1558442115783691, 1.1675305366516113, 1.0371253490447998, 1.104329228401184, 1.0193164348602295, 1.3035352230072021, 1.276933193206787, 1.1444801092147827, 1.002938985824585, 1.1313073635101318, 1.004162073135376, 1.0949949026107788, 1.2147772312164307, 1.1183931827545166, 1.0312484502792358, 1.2598177194595337, 1.0251107215881348, 1.3440279960632324, 1.007299542427063, 1.0456091165542603, 1.5961968898773193, 1.4022828340530396, 1.6736159324645996, 1.2758393287658691, 1.1224260330200195, 1.085714340209961, 1.1963295936584473, 1.1405378580093384]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.675355911254883] ms
 --  Average per query NF    [1.3606750965118408] ms
 --  Average per query vegas [2.314680814743042] ms
Mean [1.156]  Median [1.126]  95th [1.397]  99th [1.597]  max [1.746]
Mean [1.156]  Median [1.126]  95th [1.397]  99th [1.597]  max [1.746]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.802373 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=tupleskew', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
TupleSkewSample - START
0.001
TupleSkewSample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[4.2438507e-05 5.6689978e-04 2.0265579e-06 3.1054020e-05 1.9252300e-05]
Distance score: 0.00013233422941993922
SAUCE Drift detection: True
Detection latency: 0.0229s

DRIFT-DETECTED after 2-th workload
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/incremental_train.py', '--dataset=bjaq', '--end2end', '--model=face', '--model_update=adapt', '--update_size=80000', '--epochs=0']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
update_size: 76433
AdaptTask - START
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
train data shape: 80000, transfer data shape:16000
Training done; evaluating likelihood on full data:
Saved to: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
AdaptTask - END

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.004435 | Model-update-time: 2.236383


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=tupleskew', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.201183557510376
tensor(1.0045)
result is  tensor(460649.9688)
Enter testHyper
ReportEsts: [1.0340800285339355, 1.0567295551300049, 1.0764873027801514, 1.5572078227996826, 1.0654895305633545, 1.3923611640930176, 1.1599879264831543, 1.2261775732040405, 1.0609627962112427, 1.2804746627807617, 1.1671431064605713, 1.1978310346603394, 1.0692124366760254, 1.0076292753219604, 1.0916591882705688, 1.0429418087005615, 1.5372740030288696, 1.1800446510314941, 1.0092380046844482, 1.3373584747314453, 1.1717790365219116, 1.9772727489471436, 1.015775203704834, 1.0671111345291138, 1.1312949657440186, 1.2282583713531494, 1.1240164041519165, 1.0176174640655518, 1.7721519470214844, 1.0997319221496582, 1.068818211555481, 1.6864407062530518, 1.129096269607544, 1.1744579076766968, 1.0694891214370728, 1.0917247533798218, 1.0096555948257446, 1.0203073024749756, 1.0892702341079712, 1.1160858869552612, 1.0837881565093994, 1.251596450805664, 1.07635498046875, 1.1575775146484375, 1.0826189517974854, 1.1963363885879517, 1.3088154792785645, 1.0119725465774536, 1.4047619104385376, 1.1518644094467163, 1.0120187997817993, 1.096915602684021, 1.0769884586334229, 1.0257432460784912, 1.0277073383331299, 1.3559828996658325, 1.1931805610656738, 1.1226177215576172, 1.2061235904693604, 1.143031358718872, 2.138568162918091, 1.0032708644866943, 1.0478814840316772, 1.050201416015625, 1.069029688835144, 1.0142182111740112, 1.3720417022705078, 1.021470546722412, 1.1636874675750732, 1.1631721258163452, 1.0305620431900024, 1.2238050699234009, 1.0014116764068604, 1.122471570968628, 1.0130568742752075, 1.0054234266281128, 1.1427589654922485, 1.0308517217636108, 1.6989552974700928, 1.1528534889221191, 1.1291513442993164, 1.2213014364242554, 1.1305161714553833, 1.2675070762634277, 1.2000945806503296, 1.5829787254333496, 1.2580955028533936, 2.0039875507354736, 1.1870197057724, 1.2799456119537354, 1.3514796495437622, 1.0919584035873413, 1.5691616535186768, 1.0463037490844727, 1.3750325441360474, 1.1603409051895142, 1.0777957439422607, 1.2376677989959717, 1.0217245817184448, 1.0778425931930542, 1.0938374996185303, 1.1151864528656006, 1.0098038911819458, 1.0742583274841309, 1.3036378622055054, 1.3977456092834473, 1.068004846572876, 1.2438578605651855, 1.051204800605774, 1.1359686851501465, 1.0918508768081665, 1.0867892503738403, 1.0760749578475952, 1.2422622442245483, 1.3035625219345093, 1.0524660348892212, 1.0874918699264526, 1.292985439300537, 1.1805384159088135, 1.017699122428894, 1.0089375972747803, 1.200991153717041, 1.0023044347763062, 1.5311789512634277, 1.1513158082962036, 1.0560404062271118, 1.1323951482772827, 1.1013071537017822, 1.0623193979263306, 1.1149744987487793, 1.1225510835647583, 1.093703269958496, 1.0585986375808716, 1.9003286361694336, 2.029315948486328, 1.1233681440353394, 1.0653396844863892, 1.089188814163208, 1.1992299556732178, 1.095966100692749, 1.0974615812301636, 1.152437686920166, 1.1106916666030884, 1.04759681224823, 1.0430525541305542, 1.0539859533309937, 1.2196531295776367, 1.0612907409667969, 1.1587748527526855, 1.1315021514892578, 1.0426948070526123, 1.2208820581436157, 1.093279480934143, 1.020362138748169, 1.0365030765533447, 1.0087790489196777, 1.1406843662261963, 1.1048387289047241, 1.8974943161010742, 1.153916358947754, 1.014350175857544, 1.334592580795288, 1.7600399255752563, 1.0397602319717407, 1.1853058338165283, 1.0328280925750732, 1.0975385904312134, 1.0226621627807617, 1.1479147672653198, 1.3158223628997803, 1.0049283504486084, 1.1238224506378174, 1.7800829410552979, 1.426556944847107, 1.5885729789733887, 1.0763176679611206, 1.1222683191299438, 1.0434660911560059, 1.0706877708435059, 1.1645129919052124, 1.9210525751113892, 1.0039196014404297, 1.1409462690353394, 1.603773593902588, 1.3879767656326294, 1.1714822053909302, 1.0257660150527954, 1.0316792726516724, 1.5609210729599, 1.037911057472229, 1.2124083042144775, 1.0585761070251465, 1.2371538877487183, 2.316044569015503, 1.1029534339904785, 1.2191835641860962, 1.0673270225524902, 1.0454607009887695, 1.072933554649353, 1.0855658054351807]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.746427297592163] ms
 --  Average per query NF    [1.3609838485717773] ms
 --  Average per query vegas [2.3854434490203857] ms
Mean [1.194]  Median [1.119]  95th [1.761]  99th [2.030]  max [2.316]
Mean [1.194]  Median [1.119]  95th [1.761]  99th [2.030]  max [2.316]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.404109 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=1 | total-time=28.491628