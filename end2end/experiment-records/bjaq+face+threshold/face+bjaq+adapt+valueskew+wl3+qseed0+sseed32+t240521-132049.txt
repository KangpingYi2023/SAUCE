Input arguments = Namespace(data_update='valueskew', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 32, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.210459470748901
tensor(0.9958)
result is  tensor(380571.9062)
Enter testHyper
ReportEsts: [1.112356424331665, 1.0125559568405151, 1.362287163734436, 1.0383238792419434, 1.161475419998169, 1.0896539688110352, 1.1196808815002441, 1.1418739557266235, 1.000277042388916, 1.0982033014297485, 1.0465116500854492, 1.0072033405303955, 1.0346921682357788, 1.0089285373687744, 1.040901780128479, 1.3090872764587402, 1.3398771286010742, 1.1709026098251343, 1.1236071586608887, 1.1122448444366455, 1.0849697589874268, 1.1075949668884277, 1.1391708850860596, 1.0290591716766357, 1.1484930515289307, 1.083182692527771, 1.0201033353805542, 1.3744680881500244, 1.0284638404846191, 1.1973350048065186, 1.1514722108840942, 1.0610331296920776, 1.174390435218811, 1.0529476404190063, 1.1057897806167603, 1.1341475248336792, 1.5287269353866577, 1.0025763511657715, 1.0978443622589111, 1.0177961587905884, 1.1074086427688599, 1.1176825761795044, 1.0905591249465942, 1.0628713369369507, 1.0885273218154907, 1.0600906610488892, 1.1003923416137695, 1.4576200246810913, 1.1614344120025635, 1.2419627904891968, 1.2664835453033447, 1.3210030794143677, 1.123421549797058, 1.2184226512908936, 1.0715126991271973, 1.0702059268951416, 1.3775701522827148, 1.2383289337158203, 1.2782713174819946, 1.375, 1.5447194576263428, 1.2019424438476562, 1.4765986204147339, 1.2025398015975952, 1.330645203590393, 1.0, 1.152573585510254, 1.021790862083435, 1.146325945854187, 1.357894778251648, 1.0560747385025024, 1.1299808025360107, 1.247291922569275, 1.247507929801941, 1.1665016412734985, 1.1095010042190552, 1.9948216676712036, 1.0913336277008057, 1.0323694944381714, 1.2081784009933472, 1.304415225982666, 1.09158456325531, 1.0139802694320679, 1.252886176109314, 1.2839621305465698, 1.1173077821731567, 1.042534589767456, 1.0008070468902588, 1.0454081296920776, 1.1408905982971191, 1.0745413303375244, 1.198873519897461, 1.0198602676391602, 1.2563341856002808, 1.0773481130599976, 1.0496238470077515, 1.1833014488220215, 1.2762057781219482, 1.0909091234207153, 1.0513060092926025, 1.1699999570846558, 1.0603221654891968, 1.0646419525146484, 1.0007320642471313, 1.005786418914795, 1.010956048965454, 1.2070845365524292, 1.165794014930725, 1.0606776475906372, 1.04600191116333, 1.2645089626312256, 1.0801843404769897, 1.2551567554473877, 1.005849003791809, 1.2457401752471924, 1.1884816884994507, 1.0610967874526978, 1.0652650594711304, 1.3739867210388184, 1.05337393283844, 1.1852055788040161, 1.0936939716339111, 1.0762152671813965, 1.165855884552002, 1.3178294897079468, 1.208109736442566, 1.2345292568206787, 1.1447550058364868, 1.3376623392105103, 1.120908498764038, 1.2020983695983887, 1.0457555055618286, 1.2293349504470825, 1.4642857313156128, 1.0423734188079834, 1.031241774559021, 1.0888168811798096, 1.0145167112350464, 1.038718342781067, 1.3066940307617188, 1.1159838438034058, 1.1135400533676147, 1.0255192518234253, 1.2436600923538208, 1.0255498886108398, 1.0498448610305786, 1.030388593673706, 1.4542717933654785, 1.0463725328445435, 1.0147016048431396, 1.1447125673294067, 1.1429303884506226, 1.3422343730926514, 1.071902871131897, 1.1359806060791016, 1.0618809461593628, 1.1620076894760132, 1.023353934288025, 1.0269235372543335, 1.109519600868225, 1.1294397115707397, 1.1015931367874146, 1.0804334878921509, 1.3178621530532837, 1.4195488691329956, 1.16365647315979, 1.060632348060608, 1.2558302879333496, 1.084546685218811, 1.0217381715774536, 1.0846962928771973, 1.1142557859420776, 1.103896141052246, 1.3403555154800415, 1.0388283729553223, 1.0603830814361572, 1.0478614568710327, 1.2351183891296387, 1.1767377853393555, 1.0003949403762817, 1.006919264793396, 1.0023196935653687, 1.0651427507400513, 1.148110270500183, 1.0865628719329834, 1.084566593170166, 1.0464272499084473, 1.2415342330932617, 1.117875099182129, 1.4620745182037354, 1.0203206539154053, 1.0363070964813232, 1.6128849983215332, 1.1667824983596802, 1.8505982160568237, 1.268324613571167, 1.0498957633972168, 1.085714340209961, 1.0344923734664917, 1.1123838424682617]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7988853454589844] ms
 --  Average per query NF    [1.361382007598877] ms
 --  Average per query vegas [2.4375033378601074] ms
Mean [1.152]  Median [1.111]  95th [1.421]  99th [1.615]  max [1.995]
Mean [1.152]  Median [1.111]  95th [1.421]  99th [1.615]  max [1.995]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.895208 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=valueskew', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
ValueSample - START
ValueSample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[5.3644180e-07 6.5565109e-07 5.9604645e-07 2.3609459e-02 5.9604645e-08]
Distance score: 0.00472226133570075
SAUCE Drift detection: True
Detection latency: 0.0234s

DRIFT-DETECTED after 2-th workload
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/incremental_train.py', '--dataset=bjaq', '--end2end', '--model=face', '--model_update=adapt', '--update_size=80000', '--epochs=0']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
update_size: 76433
AdaptTask - START
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
train data shape: 80000, transfer data shape:16000
Training done; evaluating likelihood on full data:
Saved to: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
AdaptTask - END

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.050995 | Model-update-time: 2.242165


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=valueskew', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.16845440864563
tensor(0.9986)
result is  tensor(457958.0938)
Enter testHyper
ReportEsts: [1.0557899475097656, 1.044701099395752, 1.1332262754440308, 1.1854219436645508, 1.275297999382019, 1.344799518585205, 1.1247605085372925, 1.0334036350250244, 1.1697285175323486, 1.8970366716384888, 1.0015122890472412, 1.0700204372406006, 1.0047961473464966, 1.0570287704467773, 1.0007519721984863, 1.140364170074463, 1.50065016746521, 1.379470705986023, 1.2913209199905396, 1.3678011894226074, 1.0381120443344116, 1.0481159687042236, 1.3348177671432495, 10.851278305053711, 1.10841703414917, 1.2573667764663696, 1.1509672403335571, 1.2083333730697632, 1.3070439100265503, 1.5691202878952026, 1.196969747543335, 1.3644068241119385, 1.1006720066070557, 1.023987889289856, 1.1080901622772217, 1.0090094804763794, 1.0045485496520996, 1.4033970832824707, 1.18310546875, 1.157820701599121, 1.1117850542068481, 1.0235798358917236, 1446.1666259765625, 1.0520824193954468, 1.022816777229309, 1.1123292446136475, 1.1523053646087646, 1.0424683094024658, 1.409523844718933, 4.474576473236084, 1.030084490776062, 1.1166794300079346, 1.138088345527649, 1.064613699913025, 1.0839424133300781, 1.1711840629577637, 1.0136799812316895, 1.0480461120605469, 1.0834999084472656, 1.027536153793335, 1.377892017364502, 1.0054925680160522, 1.0444618463516235, 1.644443154335022, 1.0413196086883545, 1.0182616710662842, 1.0314358472824097, 1.2113854885101318, 1.0578933954238892, 1.093894362449646, 1.1875096559524536, 1.0483978986740112, 1.061544418334961, 1.0828458070755005, 2.2592527866363525, 1.0979808568954468, 1.26168954372406, 1.338528037071228, 1.328872561454773, 1.005005121231079, 2.330927848815918, 1.0126521587371826, 1.0920673608779907, 1.2382969856262207, 1.1068648099899292, 1.3581560850143433, 1.0077096223831177, 1.3579977750778198, 1.2736232280731201, 1.125430703163147, 1.0431535243988037, 1.4245377779006958, 1.086054801940918, 1.0707521438598633, 118.80915832519531, 1.0137741565704346, 1.0785043239593506, 1.2369954586029053, 1.4480022192001343, 1.1980698108673096, 1.1891511678695679, 1.1736363172531128, 1.0355329513549805, 1.0693638324737549, 4.049591541290283, 1.1428197622299194, 1.1674469709396362, 1.1219208240509033, 1.0028735399246216, 1.026059627532959, 1.2206770181655884, 1.0726193189620972, 1.1157525777816772, 1.1065411567687988, 1.1075763702392578, 1.828734040260315, 1.0591284036636353, 1.3482239246368408, 1.1128225326538086, 1.0619468688964844, 1.029589295387268, 1.0408504009246826, 1.0039142370224, 1.1721760034561157, 1.0874958038330078, 1.2289314270019531, 1.0032416582107544, 1.0664557218551636, 1.2839497327804565, 1.0857574939727783, 1.059633493423462, 1.0386569499969482, 1.2007701396942139, 1.8327566385269165, 1.1640502214431763, 1.075217843055725, 1.2678462266921997, 1.479032278060913, 1.0772125720977783, 1.0313441753387451, 1.0531264543533325, 1.1820387840270996, 1.0108987092971802, 1.036596417427063, 1.0062103271484375, 1.8565260171890259, 1.185393214225769, 1.000177264213562, 1.1010370254516602, 1.1355947256088257, 63.97142791748047, 1.2555598020553589, 1.393836498260498, 1.0351752042770386, 1.0507267713546753, 1.1279854774475098, 1.014801263809204, 1.0620155334472656, 1.1894720792770386, 1.1115440130233765, 1.060988426208496, 1.0405138731002808, 1.1618784666061401, 1.0890272855758667, 1.1731120347976685, 1.0271012783050537, 1.0698270797729492, 1.1553226709365845, 1.1174747943878174, 1.0508451461791992, 1.2091825008392334, 1.0454071760177612, 1.4477512836456299, 1.1477526426315308, 1.0689513683319092, 1.0964703559875488, 2.050534963607788, 1.0342564582824707, 1.2013003826141357, 1.0026580095291138, 1.8421052694320679, 1.489709496498108, 1.0655159950256348, 1.6714997291564941, 1.1775842905044556, 1.3678077459335327, 1.105263113975525, 1.1754323244094849, 1.3100558519363403, 1.0531387329101562, 1.0016276836395264, 1.096309781074524, 1.2830603122711182, 1.982090950012207, 1.0021014213562012, 1.0415561199188232, 1.3820605278015137, 1.0679612159729004, 1.1696113348007202, 1.0552585124969482]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.6500537395477295] ms
 --  Average per query NF    [1.3618052005767822] ms
 --  Average per query vegas [2.2882485389709473] ms
Mean [9.390]  Median [1.112]  95th [1.901]  99th [64.520]  max [1446.167]
Mean [9.390]  Median [1.112]  95th [1.901]  99th [64.520]  max [1446.167]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.343256 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=1 | total-time=28.594108