Input arguments = Namespace(data_update='valueskew', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 33, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.158702850341797
tensor(0.9997)
result is  tensor(382069.3750)
Enter testHyper
ReportEsts: [1.2124552726745605, 1.0528370141983032, 1.3625415563583374, 1.1427669525146484, 1.241530418395996, 1.0660699605941772, 1.2844728231430054, 1.0480362176895142, 1.0561896562576294, 1.1166353225708008, 1.0422049760818481, 1.1461864709854126, 1.0005857944488525, 1.0357142686843872, 1.2311397790908813, 1.121459722518921, 1.3533551692962646, 1.2970309257507324, 1.2108548879623413, 1.0051020383834839, 1.1383757591247559, 1.0416507720947266, 1.1358076333999634, 1.1318343877792358, 1.1470228433609009, 1.1220614910125732, 1.0723536014556885, 1.5880038738250732, 1.0109684467315674, 1.0652018785476685, 1.1496984958648682, 1.143741488456726, 1.2586565017700195, 1.0055049657821655, 1.2655657529830933, 1.1716773509979248, 1.3523707389831543, 1.0989232063293457, 1.0455271005630493, 1.0102994441986084, 1.0156782865524292, 1.2333091497421265, 1.0923113822937012, 1.0510203838348389, 1.078597068786621, 1.1405895948410034, 1.0324070453643799, 1.3246062994003296, 1.0482761859893799, 1.165820598602295, 1.1553884744644165, 1.3365049362182617, 1.0610136985778809, 1.179540753364563, 1.1052073240280151, 1.025034785270691, 1.294392466545105, 1.267864465713501, 1.227584958076477, 1.4039595127105713, 1.3173658847808838, 1.150443434715271, 1.3253240585327148, 1.0300205945968628, 1.2992125749588013, 1.0571428537368774, 1.0690536499023438, 1.0083383321762085, 1.0458521842956543, 1.263157844543457, 1.0072405338287354, 1.2041682004928589, 1.2029690742492676, 1.1520003080368042, 1.1262797117233276, 1.06105375289917, 1.7882369756698608, 1.025363564491272, 1.097335934638977, 1.292070984840393, 1.099382758140564, 1.1316426992416382, 1.0427190065383911, 1.1631866693496704, 1.1837512254714966, 1.182808756828308, 1.0901116132736206, 1.0225472450256348, 1.0395337343215942, 1.0966912508010864, 1.0388188362121582, 1.4161356687545776, 1.0025306940078735, 1.3272244930267334, 1.0833333730697632, 1.1470690965652466, 1.1022813320159912, 1.2419089078903198, 1.01694917678833, 1.1434322595596313, 1.1956204175949097, 1.0106945037841797, 1.0023609399795532, 1.0161054134368896, 1.2441422939300537, 1.0532358884811401, 1.083621621131897, 1.2094241380691528, 1.0851922035217285, 1.0394926071166992, 1.1203802824020386, 1.0882079601287842, 1.1333858966827393, 1.038081169128418, 1.0818361043930054, 1.1761658191680908, 1.0095151662826538, 1.1154391765594482, 1.4554755687713623, 1.0579142570495605, 1.2559813261032104, 1.098454475402832, 1.1038874387741089, 1.0876224040985107, 1.2122093439102173, 1.1749897003173828, 1.1134356260299683, 1.1408034563064575, 1.3227739334106445, 1.1239144802093506, 1.1208604574203491, 1.1840488910675049, 1.1441888809204102, 1.4642857313156128, 1.117562174797058, 1.148332953453064, 1.0704370737075806, 1.0273170471191406, 1.098060131072998, 1.3644793033599854, 1.1495842933654785, 1.0268901586532593, 1.2782831192016602, 1.199410319328308, 1.034867763519287, 1.062842845916748, 1.1051663160324097, 1.3829090595245361, 1.1115480661392212, 1.1180397272109985, 1.3007365465164185, 1.173695683479309, 1.2915574312210083, 1.0734648704528809, 1.1768473386764526, 1.0380440950393677, 1.1294907331466675, 1.0095666646957397, 1.0014358758926392, 1.0761563777923584, 1.0287171602249146, 1.1104726791381836, 1.065721035003662, 1.246010661125183, 1.0963995456695557, 1.0325429439544678, 1.2223124504089355, 1.2999364137649536, 1.0492420196533203, 1.0201303958892822, 1.1259918212890625, 1.0502711534500122, 1.149350643157959, 1.13760244846344, 1.0183923244476318, 1.0360028743743896, 1.156462550163269, 1.1896835565567017, 1.2162808179855347, 1.1903575658798218, 1.0084221363067627, 1.0442947149276733, 1.001013159751892, 1.0643513202667236, 1.1466859579086304, 1.1479915380477905, 1.0094871520996094, 1.2736618518829346, 1.0507357120513916, 1.3023136854171753, 1.0355442762374878, 1.0783339738845825, 1.4993432760238647, 1.2128582000732422, 1.8995985984802246, 1.1948212385177612, 1.10416841506958, 1.1014492511749268, 1.253901720046997, 1.0222991704940796]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7726640701293945] ms
 --  Average per query NF    [1.3584315776824951] ms
 --  Average per query vegas [2.4142324924468994] ms
Mean [1.148]  Median [1.121]  95th [1.363]  99th [1.590]  max [1.900]
Mean [1.148]  Median [1.121]  95th [1.363]  99th [1.590]  max [1.900]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.836364 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=valueskew', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
ValueSample - START
ValueSample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[1.4901161e-06 1.5497208e-06 9.1022253e-03 1.6093254e-06 5.9604645e-08]
Distance score: 0.0018213868606835604
SAUCE Drift detection: True
Detection latency: 0.0231s

DRIFT-DETECTED after 2-th workload
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/incremental_train.py', '--dataset=bjaq', '--end2end', '--model=face', '--model_update=adapt', '--update_size=80000', '--epochs=0']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
update_size: 76433
AdaptTask - START
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
train data shape: 80000, transfer data shape:16000
Training done; evaluating likelihood on full data:
Saved to: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
AdaptTask - END

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.053814 | Model-update-time: 2.222668


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=valueskew', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.168462991714478
tensor(0.9974)
result is  tensor(457391.4062)
Enter testHyper
ReportEsts: [1.8979376554489136, 1.136769413948059, 1.010014295578003, 1.2101911306381226, 1.0703343152999878, 1.1284009218215942, 1.1365015506744385, 1.2594410181045532, 1.135841965675354, 1.1133143901824951, 1.081397294998169, 1.4632391929626465, 1.1873478889465332, 1.3817819356918335, 1.033188819885254, 1.0253452062606812, 1.317460298538208, 1.281100869178772, 1.0573891401290894, 1.0221012830734253, 1.036353349685669, 1.4434970617294312, 1.1242238283157349, 1.541796326637268, 1.0253446102142334, 1.120469570159912, 1.0603125095367432, 1.3350197076797485, 1.2438814640045166, 1.191176414489746, 1.4468917846679688, 1.3474576473236084, 1.0305756330490112, 17.294971466064453, 1.088853359222412, 1.026179552078247, 1.1134235858917236, 1.14339017868042, 1.1707292795181274, 1.1152642965316772, 1.060408115386963, 1.1716171503067017, 1.3738561868667603, 1.012852430343628, 1.0596932172775269, 1.2347882986068726, 1.374407172203064, 1.1637952327728271, 1.1490195989608765, 1.034744143486023, 1.2753371000289917, 1.0167734622955322, 1.001234769821167, 1.1850069761276245, 1.150254726409912, 4.359804153442383, 1.2713810205459595, 1.088857889175415, 1.2653145790100098, 1.2482287883758545, 1.1502145528793335, 1.1173222064971924, 1.5386717319488525, 1.5194733142852783, 1.065972089767456, 1.2856618165969849, 1.1555675268173218, 1.1272504329681396, 1.0429482460021973, 1.1519184112548828, 1.4892085790634155, 1.1165881156921387, 1.0529206991195679, 1.2017608880996704, 1.0356099605560303, 2.033365249633789, 30.895408630371094, 1.0018033981323242, 1.3089346885681152, 1.130773663520813, 1.8192118406295776, 3.0257503986358643, 1.2926864624023438, 1.0923452377319336, 1.3468997478485107, 1.285223364830017, 1.2750972509384155, 1.8595691919326782, 1.3531668186187744, 1.0164120197296143, 1.1536201238632202, 1.1175212860107422, 1.2793859243392944, 1.0663304328918457, 1.1276001930236816, 1.1413094997406006, 1.504504680633545, 1.2108638286590576, 1.2180464267730713, 1.0076535940170288, 1.091947317123413, 1.0323486328125, 1.029411792755127, 1.1700745820999146, 1.0955079793930054, 1.7224154472351074, 1.059394359588623, 1.1738454103469849, 1.0372493267059326, 1.0239710807800293, 1.0376060009002686, 1.0775755643844604, 1.3561862707138062, 1.1881431341171265, 1.098544716835022, 1.0299595594406128, 1.007528305053711, 1.434396505355835, 1.2493520975112915, 1.0973451137542725, 1.0448356866836548, 1.4704049825668335, 3.0999677181243896, 1.3027459383010864, 1.114540696144104, 1.120579481124878, 1.1593072414398193, 1.0181268453598022, 1.1394950151443481, 1.0281182527542114, 1.1668343544006348, 1.0058194398880005, 1.1726253032684326, 2.475987195968628, 3.2419028282165527, 1.362194299697876, 1.2822012901306152, 2.6820316314697266, 1.0884822607040405, 1.1244785785675049, 1.1436705589294434, 1.0357779264450073, 1.0072927474975586, 1.408434271812439, 1.2841119766235352, 1.0848376750946045, 1.485029935836792, 1.1233001947402954, 1.0553699731826782, 1.0395346879959106, 14.966198921203613, 1.013149619102478, 1.207048773765564, 1.026558518409729, 1.025721788406372, 1.2516756057739258, 1.2280800342559814, 1.2619047164916992, 1.2464821338653564, 1.2236231565475464, 1.039412498474121, 1.1473631858825684, 1.7324438095092773, 1.0538408756256104, 1.1874973773956299, 1.0101109743118286, 1.2638287544250488, 1.1044459342956543, 32.28571319580078, 1.240620493888855, 1.03035306930542, 1.0126523971557617, 1.45991849899292, 1.108046531677246, 1.127882480621338, 1.0553597211837769, 1.0964828729629517, 1.0349185466766357, 1.1003066301345825, 1.2655737400054932, 1.3333333730697632, 1.489305853843689, 1.5395594835281372, 1.3054426908493042, 1.2121500968933105, 2.5585479736328125, 1.3630350828170776, 1.0750117301940918, 1.0980576276779175, 1.2100471258163452, 1.1925163269042969, 1.6078623533248901, 1.2301949262619019, 1.4716081619262695, 1.2396726608276367, 1.0673027038574219, 1.312422513961792, 1.0138405561447144, 1.4174067974090576, 1.0651627779006958]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7401318550109863] ms
 --  Average per query NF    [1.3560140132904053] ms
 --  Average per query vegas [2.384117841720581] ms
Mean [1.717]  Median [1.153]  95th [2.480]  99th [17.431]  max [32.286]
Mean [1.717]  Median [1.153]  95th [2.480]  99th [17.431]  max [32.286]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.425596 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=1 | total-time=28.597588