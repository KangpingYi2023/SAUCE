Input arguments = Namespace(data_update='sample', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 11, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.167115688323975
tensor(0.9947)
result is  tensor(380145.6250)
Enter testHyper
ReportEsts: [1.1911592483520508, 1.0327297449111938, 1.1655858755111694, 1.0096862316131592, 1.2271939516067505, 1.1164891719818115, 1.2076637744903564, 1.0749768018722534, 1.0427621603012085, 1.1324434280395508, 1.0111972093582153, 1.1826270818710327, 1.1198368072509766, 1.0334821939468384, 1.0894283056259155, 1.2718138694763184, 1.412579894065857, 1.0730403661727905, 1.206990122795105, 1.082872986793518, 1.1497766971588135, 1.040978193283081, 1.19423508644104, 1.0329631567001343, 1.1285632848739624, 1.1573237180709839, 1.1497747898101807, 1.4074074029922485, 1.007112979888916, 1.2253077030181885, 1.131961703300476, 1.188818335533142, 1.0929604768753052, 1.0771764516830444, 1.0815352201461792, 1.134408950805664, 1.274579644203186, 1.238637924194336, 1.0307507514953613, 1.1764072179794312, 1.0660229921340942, 1.236816644668579, 1.0512797832489014, 1.064625859260559, 1.0758503675460815, 1.0963718891143799, 1.1483622789382935, 1.2505820989608765, 1.095959186553955, 1.1133671998977661, 1.2099738121032715, 1.16537606716156, 1.0825368165969849, 1.2668161392211914, 1.1473256349563599, 1.001854419708252, 1.351401925086975, 1.134775161743164, 1.240735650062561, 1.3412474393844604, 1.5456734895706177, 1.1596122980117798, 1.4901924133300781, 1.0468244552612305, 1.3580247163772583, 1.3142857551574707, 1.1087533235549927, 1.028589129447937, 1.152278184890747, 1.4105262756347656, 1.101367712020874, 1.195855736732483, 1.2922415733337402, 1.2395169734954834, 1.0728139877319336, 1.0756793022155762, 1.7982194423675537, 1.0066167116165161, 1.079575538635254, 1.3183422088623047, 1.043398380279541, 1.041027307510376, 1.1187574863433838, 1.072562336921692, 1.2315856218338013, 1.099743366241455, 1.1020435094833374, 1.2637578248977661, 1.0562236309051514, 1.08292555809021, 1.0059971809387207, 1.4365969896316528, 1.0147854089736938, 1.3843058347702026, 1.0, 1.0917444229125977, 1.1890361309051514, 1.324061393737793, 1.0, 1.1788221597671509, 1.2638888359069824, 1.2506765127182007, 1.1832853555679321, 1.0087847709655762, 1.1104602813720703, 1.0113105773925781, 1.1474668979644775, 1.1518324613571167, 1.1224461793899536, 1.0380018949508667, 1.1852582693099976, 1.057761788368225, 1.1142635345458984, 1.2016173601150513, 1.0780109167099, 1.164102554321289, 1.080878734588623, 1.2333290576934814, 1.1101011037826538, 1.0706660747528076, 1.3438085317611694, 1.1479922533035278, 1.0523438453674316, 1.1771353483200073, 1.2417635917663574, 1.2365869283676147, 1.0537818670272827, 1.1608288288116455, 1.239967942237854, 1.0908483266830444, 1.0611921548843384, 1.1730648279190063, 1.2153511047363281, 1.4642857313156128, 1.1442346572875977, 1.1367813348770142, 1.0211459398269653, 1.1837397813796997, 1.2988086938858032, 1.2710963487625122, 1.1036885976791382, 1.109776258468628, 1.096133828163147, 1.302291750907898, 1.153049349784851, 1.0024930238723755, 1.167759656906128, 1.2735198736190796, 1.11830735206604, 1.0174006223678589, 1.1972107887268066, 1.1872836351394653, 1.2656731605529785, 1.060359001159668, 1.1652883291244507, 1.2118643522262573, 1.1216762065887451, 1.008159875869751, 1.0591520071029663, 1.1039092540740967, 1.0481009483337402, 1.0481289625167847, 1.0162100791931152, 1.2888582944869995, 1.1079812049865723, 1.0852526426315308, 1.0479958057403564, 1.4134596586227417, 1.0528208017349243, 1.0320967435836792, 1.114663004875183, 1.0017359256744385, 1.2077921628952026, 1.123948097229004, 1.1089918613433838, 1.0138921737670898, 1.0383450984954834, 1.2128640413284302, 1.1482431888580322, 1.0122756958007812, 1.0248992443084717, 1.0984899997711182, 1.0207785367965698, 1.0980592966079712, 1.0688155889511108, 1.1427061557769775, 1.0085394382476807, 1.2449756860733032, 1.0273517370224, 1.2349679470062256, 1.0553514957427979, 1.0726920366287231, 1.563407301902771, 1.375477910041809, 1.6210827827453613, 1.2527472972869873, 1.121133804321289, 1.0704225301742554, 1.0347720384597778, 1.187018632888794]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.8036155700683594] ms
 --  Average per query NF    [1.3620758056640625] ms
 --  Average per query vegas [2.441539764404297] ms
Mean [1.154]  Median [1.122]  95th [1.408]  99th [1.564]  max [1.798]
Mean [1.154]  Median [1.122]  95th [1.408]  99th [1.564]  max [1.798]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.834364 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=sample', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
Sample - START
Sample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[ 5.9604645e-08  1.0728836e-06 -2.9802322e-08  2.3841858e-07
  5.9604645e-08]
Distance score: 2.8014181907565217e-07
SAUCE Drift detection: False
Detection latency: 0.0233s

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.019804 | Model-update-time: 0.000000


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=sample', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.167965412139893
tensor(0.9941)
result is  tensor(455885.9688)
Enter testHyper
ReportEsts: [1.0671446323394775, 1.1234374046325684, 1.1197847127914429, 1.163582444190979, 1.0115909576416016, 1.3692909479141235, 1.25406014919281, 1.0719757080078125, 1.0272268056869507, 1.0819672346115112, 1.117300033569336, 1.1487150192260742, 1.2706767320632935, 1.0485516786575317, 1.280428171157837, 1.0671508312225342, 1.1813559532165527, 1.0998814105987549, 1.0512604713439941, 1.3202439546585083, 1.0856645107269287, 1.5034993886947632, 1.0273144245147705, 1.010464072227478, 1.0791739225387573, 1.1037366390228271, 1.0808621644973755, 1.077915906906128, 1.1167134046554565, 1.1732070446014404, 1.0956820249557495, 1.304964542388916, 1.015163779258728, 1.1047619581222534, 1.032374382019043, 1.0008866786956787, 1.0528244972229004, 1.0122201442718506, 1.0762410163879395, 1.0901085138320923, 1.02743399143219, 1.0833333730697632, 1.0040009021759033, 1.1546026468276978, 1.1469857692718506, 1.0936272144317627, 1.1119272708892822, 1.1557629108428955, 1.2071713209152222, 1.179261326789856, 1.0098506212234497, 1.0680065155029297, 1.1514068841934204, 1.160148024559021, 1.004145860671997, 1.29641854763031, 1.1493428945541382, 1.0793259143829346, 1.2253539562225342, 1.075435757637024, 1.4449437856674194, 1.0875383615493774, 1.0310075283050537, 1.653594732284546, 1.084182620048523, 1.0680468082427979, 1.3056856393814087, 1.0896015167236328, 1.1174776554107666, 1.1103994846343994, 1.1087872982025146, 1.1166115999221802, 1.2584344148635864, 1.0948050022125244, 1.2136067152023315, 1.0300369262695312, 1.1487140655517578, 1.236707091331482, 1.0136607885360718, 1.137685775756836, 1.1200546026229858, 1.0651326179504395, 1.0506821870803833, 1.1798315048217773, 1.2744694948196411, 1.375, 1.2953828573226929, 1.476143479347229, 1.1192386150360107, 1.1186683177947998, 1.1714518070220947, 1.1945433616638184, 1.324012041091919, 1.2252362966537476, 1.9841629266738892, 1.0339382886886597, 1.0177603960037231, 1.0608593225479126, 1.1003726720809937, 1.0439610481262207, 1.1130867004394531, 1.1327993869781494, 1.301886796951294, 1.0588552951812744, 1.0365262031555176, 1.1441253423690796, 1.0356097221374512, 1.1005439758300781, 1.1601123809814453, 1.0345393419265747, 1.1517442464828491, 1.0741735696792603, 1.2029310464859009, 1.3616726398468018, 1.140703558921814, 1.1444034576416016, 1.0412120819091797, 1.0682233572006226, 1.0342743396759033, 1.0952380895614624, 1.1685465574264526, 1.2267717123031616, 1.0333468914031982, 1.2564752101898193, 1.0072373151779175, 1.140471339225769, 1.108375072479248, 1.2175856828689575, 1.0375727415084839, 1.1812429428100586, 1.0971956253051758, 1.0697894096374512, 1.1674072742462158, 2.2074689865112305, 1.387965202331543, 1.0219273567199707, 1.069887638092041, 1.099642276763916, 1.0314782857894897, 1.0274107456207275, 1.0137838125228882, 1.1920580863952637, 1.020389199256897, 1.0648534297943115, 1.0503363609313965, 1.026158332824707, 1.5481927394866943, 1.0871880054473877, 1.1595549583435059, 1.1386576890945435, 1.0149942636489868, 1.0906816720962524, 1.1693756580352783, 1.1272141933441162, 1.0796104669570923, 1.0268231630325317, 1.1923238039016724, 1.2992125749588013, 1.0486950874328613, 1.2295907735824585, 1.081218957901001, 1.1213901042938232, 1.1388905048370361, 1.0193910598754883, 1.0516823530197144, 1.0137131214141846, 1.0158934593200684, 1.103826642036438, 1.007573127746582, 1.2738933563232422, 1.0898760557174683, 1.229084849357605, 1.4117647409439087, 1.0617038011550903, 1.0281487703323364, 1.0412191152572632, 1.1576646566390991, 1.0564030408859253, 1.0511465072631836, 1.0982680320739746, 1.45652174949646, 1.1132328510284424, 1.0780442953109741, 1.637306809425354, 1.4613229036331177, 1.1956714391708374, 1.103413701057434, 1.0873372554779053, 1.4364075660705566, 1.0009349584579468, 1.1891626119613647, 1.028501033782959, 1.1861239671707153, 1.6812244653701782, 1.050695776939392, 1.3784722089767456, 1.455505609512329, 1.0624114274978638, 1.2272024154663086, 1.0901284217834473]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.724735975265503] ms
 --  Average per query NF    [1.3595211505889893] ms
 --  Average per query vegas [2.3652148246765137] ms
Mean [1.152]  Median [1.104]  95th [1.456]  99th [1.684]  max [2.207]
Mean [1.152]  Median [1.104]  95th [1.456]  99th [1.684]  max [2.207]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.206043 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=0 | total-time=26.132979