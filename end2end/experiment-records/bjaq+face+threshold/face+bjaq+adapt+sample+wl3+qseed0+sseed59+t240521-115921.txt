Input arguments = Namespace(data_update='sample', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 59, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.171080827713013
tensor(0.9953)
result is  tensor(380380.2188)
Enter testHyper
ReportEsts: [1.2024232149124146, 1.0841094255447388, 1.3898147344589233, 1.1663508415222168, 1.2731356620788574, 1.0655497312545776, 1.2641079425811768, 1.0289537906646729, 1.0655447244644165, 1.1718857288360596, 1.1214470863342285, 1.0866525173187256, 1.0322571992874146, 1.0401785373687744, 1.0670735836029053, 1.4079060554504395, 1.3373483419418335, 1.1900237798690796, 1.232361078262329, 1.0892857313156128, 1.1786673069000244, 1.0939018726348877, 1.1130398511886597, 1.024565577507019, 1.1395900249481201, 1.0587702989578247, 1.0791103839874268, 1.524303913116455, 1.068138837814331, 1.0271589756011963, 1.1805604696273804, 1.2721587419509888, 1.0687497854232788, 1.008533239364624, 1.13601553440094, 1.1468327045440674, 1.5119951963424683, 1.1244219541549683, 1.009584665298462, 1.0759280920028687, 1.1014704704284668, 1.0994194746017456, 1.1381025314331055, 1.0269763469696045, 1.0614831447601318, 1.0306122303009033, 1.087591290473938, 1.099008321762085, 1.0367902517318726, 1.074450135231018, 1.1974025964736938, 1.4093645811080933, 1.0109808444976807, 1.1574480533599854, 1.1806079149246216, 1.014603614807129, 1.1757009029388428, 1.2430249452590942, 1.1589131355285645, 1.368788480758667, 1.4613722562789917, 1.2034201622009277, 1.3711901903152466, 1.0693721771240234, 1.2222222089767456, 1.4285714626312256, 1.1431175470352173, 1.0808998346328735, 1.2069405317306519, 1.2947368621826172, 1.2405470609664917, 1.1210544109344482, 1.1801215410232544, 1.1266369819641113, 1.1639925241470337, 1.0439871549606323, 2.045825242996216, 1.0108410120010376, 1.0406864881515503, 1.318076491355896, 1.1964601278305054, 1.1647553443908691, 1.0027661323547363, 1.156212568283081, 1.313377857208252, 1.0392160415649414, 1.1328136920928955, 1.051500678062439, 1.0224604606628418, 1.1340078115463257, 1.0821664333343506, 1.3811917304992676, 1.0201947689056396, 1.2424379587173462, 1.2264150381088257, 1.118777871131897, 1.1231087446212769, 1.2546501159667969, 1.0166666507720947, 1.141372561454773, 1.2390317916870117, 1.0982288122177124, 1.1326878070831299, 1.009608268737793, 1.1234309673309326, 1.0732817649841309, 1.0931843519210815, 1.1727749109268188, 1.1132144927978516, 1.0158876180648804, 1.1895699501037598, 1.1172544956207275, 1.184842824935913, 1.0314174890518188, 1.0842703580856323, 1.1761658191680908, 1.063774585723877, 1.2013413906097412, 1.2856515645980835, 1.1105636358261108, 1.2663267850875854, 1.1457154750823975, 1.14262855052948, 1.1995667219161987, 1.3347867727279663, 1.190672755241394, 1.032975196838379, 1.043988585472107, 1.3458187580108643, 1.1342685222625732, 1.0597268342971802, 1.1220632791519165, 1.1376631259918213, 1.4642857313156128, 1.1119049787521362, 1.0842740535736084, 1.0578827857971191, 1.0299186706542969, 1.0485743284225464, 1.3022464513778687, 1.0849719047546387, 1.1431653499603271, 1.1840664148330688, 1.3915883302688599, 1.1588339805603027, 1.0007576942443848, 1.1009680032730103, 1.3050411939620972, 1.014419674873352, 1.065411925315857, 1.2806763648986816, 1.2004871368408203, 1.2604912519454956, 1.0945062637329102, 1.0919373035430908, 1.0437761545181274, 1.0932501554489136, 1.0731569528579712, 1.0129631757736206, 1.079200267791748, 1.0769206285476685, 1.1709883213043213, 1.0044243335723877, 1.2560322284698486, 1.2603471279144287, 1.0869340896606445, 1.1743124723434448, 1.2212464809417725, 1.18626868724823, 1.008305549621582, 1.0119885206222534, 1.0666643381118774, 1.1623376607894897, 1.1861450672149658, 1.1280653476715088, 1.1226574182510376, 1.0165208578109741, 1.3766944408416748, 1.259307861328125, 1.0024363994598389, 1.145998477935791, 1.0401326417922974, 1.0141990184783936, 1.1041879653930664, 1.100688099861145, 1.0961945056915283, 1.066114068031311, 1.2554157972335815, 1.1181138753890991, 1.436997652053833, 1.0239696502685547, 1.0237292051315308, 1.6364679336547852, 1.3182412385940552, 1.9141615629196167, 1.2336091995239258, 1.0656523704528809, 1.1692308187484741, 1.084006905555725, 1.0226759910583496]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7571847438812256] ms
 --  Average per query NF    [1.3607752323150635] ms
 --  Average per query vegas [2.396409511566162] ms
Mean [1.158]  Median [1.123]  95th [1.408]  99th [1.639]  max [2.046]
Mean [1.158]  Median [1.123]  95th [1.408]  99th [1.639]  max [2.046]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.807524 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=sample', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
Sample - START
Sample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[7.1525574e-07 1.7881393e-07 9.5367432e-07 2.3841858e-07 1.1920929e-07]
Distance score: 4.410743770222325e-07
SAUCE Drift detection: False
Detection latency: 0.0237s

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.017893 | Model-update-time: 0.000000


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=sample', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.17360782623291
tensor(0.9946)
result is  tensor(456117.0938)
Enter testHyper
ReportEsts: [1.165816068649292, 1.0196377038955688, 1.2100719213485718, 1.101047158241272, 1.0410888195037842, 1.2870876789093018, 1.1500109434127808, 1.0751147270202637, 1.1050364971160889, 1.066152811050415, 1.009572982788086, 1.1376551389694214, 1.2177033424377441, 1.2336947917938232, 1.0865800380706787, 1.0733290910720825, 1.032073736190796, 1.094429850578308, 1.1442209482192993, 1.361014723777771, 1.048400640487671, 1.1053515672683716, 1.0179506540298462, 1.100564956665039, 1.108275055885315, 1.0766855478286743, 1.1237417459487915, 1.1535249948501587, 1.102652668952942, 1.320359230041504, 1.0112031698226929, 1.2464789152145386, 1.087785243988037, 1.0395711660385132, 1.1288384199142456, 1.0437637567520142, 1.1458723545074463, 1.2368314266204834, 1.3503965139389038, 1.0072883367538452, 1.0091099739074707, 1.0177383422851562, 1.0149363279342651, 1.0204981565475464, 1.0477999448776245, 1.2004119157791138, 1.214870572090149, 1.0343410968780518, 1.086419701576233, 1.208271861076355, 1.084813117980957, 1.0157215595245361, 1.0198992490768433, 1.0453922748565674, 1.0274089574813843, 1.5388377904891968, 1.3054286241531372, 1.2004295587539673, 1.2835146188735962, 1.1535801887512207, 1.7352941036224365, 1.087540626525879, 1.0018784999847412, 1.632741928100586, 1.0999031066894531, 1.0986049175262451, 1.50261390209198, 1.1609632968902588, 1.1825838088989258, 1.0938760042190552, 1.0437836647033691, 1.2302345037460327, 1.0328562259674072, 1.073975682258606, 1.0095562934875488, 1.0063586235046387, 1.1160221099853516, 1.2132973670959473, 1.3077081441879272, 1.0989460945129395, 1.1321839094161987, 1.002760648727417, 1.041622519493103, 1.1949208974838257, 1.2733845710754395, 1.3449476957321167, 1.170426368713379, 1.489452838897705, 1.023206114768982, 1.0448617935180664, 1.220900535583496, 1.1067173480987549, 1.4958405494689941, 1.110260009765625, 2.072681427001953, 1.0027986764907837, 1.149194598197937, 1.2672176361083984, 1.1042345762252808, 1.0960999727249146, 1.1837822198867798, 1.142811894416809, 1.170212745666504, 1.1522184610366821, 1.0785359144210815, 1.2500576972961426, 1.1529520750045776, 1.12677001953125, 1.1955307722091675, 1.0622875690460205, 1.0941565036773682, 1.0781772136688232, 1.0632028579711914, 1.168946623802185, 1.0271512269973755, 1.0496797561645508, 1.1039761304855347, 1.066573977470398, 1.0217150449752808, 1.1417909860610962, 1.0256638526916504, 1.0907634496688843, 1.0171730518341064, 1.2829132080078125, 1.0185658931732178, 1.1254487037658691, 1.033539891242981, 1.2594937086105347, 1.0472620725631714, 1.0915296077728271, 1.2649025917053223, 1.0922362804412842, 1.059377908706665, 1.612740159034729, 1.7784491777420044, 1.17197585105896, 1.0122185945510864, 1.0111513137817383, 1.0595579147338867, 1.0137486457824707, 1.0841577053070068, 1.255502462387085, 1.1179527044296265, 1.0237836837768555, 1.039881944656372, 1.0492562055587769, 1.5527950525283813, 1.0225542783737183, 1.1379183530807495, 1.1062216758728027, 1.1631782054901123, 1.016809344291687, 1.1908594369888306, 1.0747946500778198, 1.0477502346038818, 1.0527156591415405, 1.10525643825531, 1.452380895614624, 1.0059630870819092, 1.1135929822921753, 1.038290023803711, 1.0014925003051758, 1.204403281211853, 1.012690544128418, 1.1932450532913208, 1.0553532838821411, 1.069883942604065, 1.1977357864379883, 1.057112216949463, 1.265821099281311, 1.1967591047286987, 1.1193363666534424, 1.4583615064620972, 1.0142735242843628, 1.1091880798339844, 1.0226776599884033, 1.0092583894729614, 1.1882675886154175, 1.0956546068191528, 1.1637898683547974, 1.6590908765792847, 1.1516579389572144, 1.028694748878479, 1.703703761100769, 1.1802312135696411, 1.0933187007904053, 1.372340440750122, 1.037536859512329, 1.5171736478805542, 1.0465874671936035, 1.2088911533355713, 1.048128366470337, 1.240777850151062, 1.6866226196289062, 1.0838383436203003, 1.048625111579895, 1.3492594957351685, 1.1773465871810913, 1.3838210105895996, 1.2486990690231323]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7738037109375] ms
 --  Average per query NF    [1.3599705696105957] ms
 --  Average per query vegas [2.4138331413269043] ms
Mean [1.157]  Median [1.105]  95th [1.518]  99th [1.736]  max [2.073]
Mean [1.157]  Median [1.105]  95th [1.518]  99th [1.736]  max [2.073]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.226242 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=0 | total-time=26.076572