Input arguments = Namespace(data_update='valueskew', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 88, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.213586330413818
tensor(0.9946)
result is  tensor(380122.2812)
Enter testHyper
ReportEsts: [1.1825051307678223, 1.0212922096252441, 1.2596230506896973, 1.0048431158065796, 1.278496265411377, 1.1044423580169678, 1.2286592721939087, 1.049397587776184, 1.078601360321045, 1.1664996147155762, 1.1007752418518066, 1.0872881412506104, 1.0289344787597656, 1.0245535373687744, 1.1716140508651733, 1.372139811515808, 1.2557462453842163, 1.150593876838684, 1.178404450416565, 1.0663264989852905, 1.1268378496170044, 1.0035682916641235, 1.1223171949386597, 1.0760363340377808, 1.1407334804534912, 1.1537070274353027, 1.011542797088623, 1.4273089170455933, 1.0305486917495728, 1.0407893657684326, 1.128769040107727, 1.2750704288482666, 1.3714220523834229, 1.1014899015426636, 1.1429336071014404, 1.169450044631958, 1.4127368927001953, 1.1789206266403198, 1.1237353086471558, 1.3083832263946533, 1.0689080953598022, 1.131833553314209, 1.0356805324554443, 1.0616154670715332, 1.0925416946411133, 1.0793651342391968, 1.116279125213623, 1.3450201749801636, 1.0355250835418701, 1.1505922079086304, 1.188144326210022, 1.3717447519302368, 1.0213912725448608, 1.1338876485824585, 1.1333647966384888, 1.043115496635437, 1.2037383317947388, 1.1702260971069336, 1.0792288780212402, 1.398657202720642, 1.3193104267120361, 1.1503205299377441, 1.2638599872589111, 1.1327658891677856, 1.3524590730667114, 1.3142857551574707, 1.223414659500122, 1.0246148109436035, 1.1281307935714722, 1.3894736766815186, 1.0097482204437256, 1.0768872499465942, 1.2890044450759888, 1.1980091333389282, 1.0939736366271973, 1.081412434577942, 1.8271478414535522, 1.032505750656128, 1.0882251262664795, 1.4098833799362183, 1.3574568033218384, 1.1353577375411987, 1.0190461874008179, 1.198670744895935, 1.3051904439926147, 1.0238133668899536, 1.0150541067123413, 1.005800724029541, 1.0137382745742798, 1.0217264890670776, 1.058038353919983, 1.3544541597366333, 1.0032455921173096, 1.3189551830291748, 1.167664647102356, 1.0524303913116455, 1.1556389331817627, 1.4166510105133057, 1.034482717514038, 1.105139970779419, 1.273716926574707, 1.0476865768432617, 1.074500560760498, 1.021229863166809, 1.007588505744934, 1.0346143245697021, 1.2880488634109497, 1.1972076892852783, 1.0510151386260986, 1.0710234642028809, 1.1849932670593262, 1.0772058963775635, 1.1621454954147339, 1.0644100904464722, 1.1707429885864258, 1.096618413925171, 1.0449581146240234, 1.1586482524871826, 1.273461937904358, 1.0434719324111938, 1.1351969242095947, 1.1720021963119507, 1.1704341173171997, 1.077893614768982, 1.340116262435913, 1.2358646392822266, 1.0614906549453735, 1.2296087741851807, 1.2079750299453735, 1.1409485340118408, 1.0579098463058472, 1.1171470880508423, 1.1143567562103271, 1.5, 1.0762414932250977, 1.1380939483642578, 1.046694278717041, 1.1317073106765747, 1.0699511766433716, 1.2001254558563232, 1.1520235538482666, 1.132663369178772, 1.00198495388031, 1.3163700103759766, 1.029252529144287, 1.017432689666748, 1.0985045433044434, 1.2799103260040283, 1.0556715726852417, 1.0590908527374268, 1.2452455759048462, 1.1775413751602173, 1.355531096458435, 1.0115846395492554, 1.1419692039489746, 1.0710433721542358, 1.0151046514511108, 1.0067529678344727, 1.0382513999938965, 1.1623395681381226, 1.26396906375885, 1.004120945930481, 1.0177531242370605, 1.2818057537078857, 1.2826087474822998, 1.1595959663391113, 1.1666533946990967, 1.1754472255706787, 1.119815707206726, 1.0604941844940186, 1.0611822605133057, 1.0885844230651855, 1.1363636255264282, 1.1879284381866455, 1.1689373254776, 1.128090500831604, 1.025267243385315, 1.3839349746704102, 1.0201876163482666, 1.1492806673049927, 1.0766726732254028, 1.0001896619796753, 1.0248253345489502, 1.256384015083313, 1.0992393493652344, 1.1353065967559814, 1.0532234907150269, 1.339172601699829, 1.0222817659378052, 1.2767049074172974, 1.0261797904968262, 1.0247820615768433, 1.5393743515014648, 1.3661513328552246, 1.64113450050354, 1.1918818950653076, 1.1388078927993774, 1.1875, 1.0004829168319702, 1.1121513843536377]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7673914432525635] ms
 --  Average per query NF    [1.359848976135254] ms
 --  Average per query vegas [2.4075424671173096] ms
Mean [1.153]  Median [1.132]  95th [1.384]  99th [1.540]  max [1.827]
Mean [1.153]  Median [1.132]  95th [1.384]  99th [1.540]  max [1.827]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.882730 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=valueskew', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
ValueSample - START
ValueSample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[2.4437904e-06 9.0517402e-03 8.3446503e-07 6.5565109e-07 5.9604645e-08]
Distance score: 0.0018111467361450195
SAUCE Drift detection: True
Detection latency: 0.0232s

DRIFT-DETECTED after 2-th workload
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/incremental_train.py', '--dataset=bjaq', '--end2end', '--model=face', '--model_update=adapt', '--update_size=80000', '--epochs=0']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
update_size: 76433
AdaptTask - START
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
train data shape: 80000, transfer data shape:16000
Training done; evaluating likelihood on full data:
Saved to: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
AdaptTask - END

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.048251 | Model-update-time: 2.222687


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=valueskew', '--model_update=adapt']
/home/kangping/code_copy/SAUCE/./FACE/FACE_utils/dataUtils.py:321: RuntimeWarning: invalid value encountered in cast
  oracle_cards = oracle_cards.astype(np.int32)
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.16728401184082
tensor(0.9964)
result is  tensor(456956.5625)
Enter testHyper
ReportEsts: [1.0414944887161255, 1.3707607984542847, 1.3194650411605835, 1.2919418811798096, 1.0264830589294434, 1.3999420404434204, 1.204246997833252, 1.007555365562439, 1.0234638452529907, 2.3514301776885986, 1.463762640953064, 1.0060272216796875, 1.2494004964828491, 1.0992403030395508, 14.402359008789062, 1.067228078842163, 1.180801510810852, 1.2604598999023438, 1.0161716938018799, 1.2797603607177734, 1.1050102710723877, 5.309027671813965, 1.0459002256393433, 8.488371849060059, 1.1405391693115234, 1.1983352899551392, 1.031057357788086, 1.2922990322113037, 2.2379953861236572, 1.2598992586135864, 1.297481894493103, 1.2323943376541138, 1.3565243482589722, 1.095626711845398, 1.3689727783203125, 1.1410316228866577, 1.2977877855300903, 1.5759680271148682, 1.266221284866333, 1.0232009887695312, 1.271446704864502, 1.2490421533584595, 1.0131689310073853, 1.3209692239761353, 1.4303299188613892, 1.076642632484436, 1.5324556827545166, 1.3843514919281006, 1.3190475702285767, 1.174723744392395, 1.1802388429641724, 1.0185843706130981, 1.0157829523086548, 1.0027562379837036, 1.061474323272705, 1.2420076131820679, 1.1118284463882446, 1.3031861782073975, 1.0903476476669312, 1.3786101341247559, 1.5096617937088013, 1.0718536376953125, 2.2966902256011963, 1.452380895614624, 1.0095372200012207, 5.938906669616699, 1.3754518032073975, 1.070402979850769, 1.1103687286376953, 1.252044439315796, 1.0891767740249634, 1.252882480621338, 1.3404349088668823, 1.2007936239242554, 1.6147332191467285, 1.3525944948196411, 20.80912208557129, 1.3466914892196655, 1.179430603981018, 1.141987681388855, 1.3539879322052002, 1.005492925643921, 1.051838994026184, 1.2212377786636353, 1.3194606304168701, 1.5829787254333496, 1.9261221885681152, 1.2372769117355347, 1.0560953617095947, 1.1088865995407104, 1.1192255020141602, 1.190624713897705, 1.400207281112671, 1.0496183633804321, 43.491451263427734, 1.808517336845398, 1.027345895767212, 1.2511374950408936, 1.0281065702438354, 1.061020016670227, 1.1943124532699585, 1.3333333730697632, 1.2634271383285522, 1.072791337966919, 1.094683289527893, 1.2478814125061035, 1.0737229585647583, 1.0639172792434692, 1.0234603881835938, 1.0103830099105835, 2.27765154838562, 1.5011411905288696, 1.2681435346603394, 1.3001564741134644, 1.3517310619354248, 1.0027509927749634, 1.0948621034622192, 1.2818034887313843, 1.018369436264038, 1.0983606576919556, 1.0276787281036377, 1.0804890394210815, 1.08839750289917, 1.5943479537963867, 1.1316474676132202, 1.000184178352356, 1.1603294610977173, 1.2875399589538574, 1.270308017730713, 1.1349481344223022, 1.0479462146759033, 1.1011000871658325, 1.2534393072128296, 1.6483970880508423, 1.5480166673660278, 1.0725253820419312, 1.1462862491607666, 1.1909923553466797, 1.3070706129074097, 1.385475516319275, 1.2111740112304688, 1.0795809030532837, 1.2980120182037354, 1.003731369972229, 1.0493601560592651, 1.1883752346038818, 1.2411764860153198, 1.017281413078308, 1.1859031915664673, 1.1068964004516602, 1.1680954694747925, 1.0475445985794067, 1.1344817876815796, 1.2825586795806885, 1.240437388420105, 1.684816598892212, 1.0374964475631714, 1.0873016119003296, 1.3072763681411743, 1.1188931465148926, 2.804842233657837, 1.2815476655960083, 1.0045384168624878, 1.0892524719238281, 1.0024542808532715, 1.2971842288970947, 1.3217140436172485, 1.3329322338104248, 49.26688003540039, 1.269551396369934, 1.033502221107483, 1.4263769388198853, 1.4670463800430298, 1.1183713674545288, 1.1769596338272095, 1.3953860998153687, 1.4223153591156006, 1.0484695434570312, 1.1255226135253906, 1.2490917444229126, 1.4199999570846558, 1.2982243299484253, 1.1072807312011719, 1.3729175329208374, 1.2325928211212158, 1.2773585319519043, 2.1800737380981445, 1.0631831884384155, 1.4548354148864746, 1.1145129203796387, 1.162320852279663, 1.1651954650878906, 1.1530126333236694, 1.568129301071167, 1.07900869846344, 1.0824142694473267, 1.1628386974334717, 13.871794700622559, 1.0725075006484985, 1.0447545051574707]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.6373579502105713] ms
 --  Average per query NF    [1.3559937477111816] ms
 --  Average per query vegas [2.2813642024993896] ms
Mean [2.006]  Median [1.203]  95th [2.299]  99th [21.036]  max [49.267]
Mean [2.006]  Median [1.203]  95th [2.299]  99th [21.036]  max [49.267]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.330245 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=1 | total-time=28.534074