Input arguments = Namespace(data_update='sample', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 81, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.16894006729126
tensor(0.9966)
result is  tensor(380855.5000)
Enter testHyper
ReportEsts: [1.1372275352478027, 1.0500210523605347, 1.0984090566635132, 1.2194145917892456, 1.2448023557662964, 1.1205953359603882, 1.2194117307662964, 1.1106373071670532, 1.0397579669952393, 1.1543385982513428, 1.0714900493621826, 1.1864407062530518, 1.0248247385025024, 1.0357142686843872, 1.0520390272140503, 1.4584131240844727, 1.27295982837677, 1.19631826877594, 1.149916410446167, 1.0102040767669678, 1.0451580286026, 1.0486018657684326, 1.1322262287139893, 1.1455352306365967, 1.190966248512268, 1.2441229820251465, 1.0813626050949097, 1.4406780004501343, 1.0226249694824219, 1.1038551330566406, 1.2486697435379028, 1.2423280477523804, 1.2128442525863647, 1.0160536766052246, 1.1892603635787964, 1.1927298307418823, 1.4230477809906006, 1.1670629978179932, 1.1067625284194946, 1.0237125158309937, 1.059012532234192, 1.104257345199585, 1.022670865058899, 1.0066511631011963, 1.064441204071045, 1.0680272579193115, 1.0802809000015259, 1.3203479051589966, 1.0039538145065308, 1.1641285419464111, 1.1612091064453125, 1.394440770149231, 1.059579610824585, 1.2916394472122192, 1.065327525138855, 1.0584144592285156, 1.241121530532837, 1.2515143156051636, 1.2868764400482178, 1.297897219657898, 1.2721635103225708, 1.2069274187088013, 1.4808073043823242, 1.1236541271209717, 1.2000000476837158, 1.2285714149475098, 1.1600370407104492, 1.0031675100326538, 1.097740888595581, 1.263157844543457, 1.0498310327529907, 1.0473617315292358, 1.1945908069610596, 1.0855463743209839, 1.043516755104065, 1.0345443487167358, 1.7781108617782593, 1.0275038480758667, 1.125144124031067, 1.3762493133544922, 1.0813097953796387, 1.0038917064666748, 1.0036258697509766, 1.1586707830429077, 1.1840423345565796, 1.0772985219955444, 1.0984807014465332, 1.010239601135254, 1.0615538358688354, 1.158470869064331, 1.0123982429504395, 1.3771642446517944, 1.0331770181655884, 1.2571951150894165, 1.107954502105713, 1.0224146842956543, 1.1374670267105103, 1.313482403755188, 1.034482717514038, 1.2679524421691895, 1.125, 1.1171168088912964, 1.1243129968643188, 1.0051244497299194, 1.055071234703064, 1.0542514324188232, 1.2013990879058838, 1.1727749109268188, 1.0904181003570557, 1.0608206987380981, 1.2581223249435425, 1.1367604732513428, 1.136972427368164, 1.0293463468551636, 1.059000849723816, 1.1822916269302368, 1.0005770921707153, 1.0251516103744507, 1.25365149974823, 1.1885716915130615, 1.151596188545227, 1.0958327054977417, 1.2267787456512451, 1.0914247035980225, 1.2839146852493286, 1.1805613040924072, 1.1036882400512695, 1.1368108987808228, 1.264320731163025, 1.1015363931655884, 1.1059726476669312, 1.069176435470581, 1.1939092874526978, 1.5, 1.1683863401412964, 1.1496455669403076, 1.0217963457107544, 1.0630894899368286, 1.0024819374084473, 1.3932993412017822, 1.137189507484436, 1.0493278503417969, 1.1163276433944702, 1.3247483968734741, 1.0056109428405762, 1.0294731855392456, 1.0024981498718262, 1.410272240638733, 1.0955307483673096, 1.1086647510528564, 1.2655272483825684, 1.1604923009872437, 1.3320714235305786, 1.1740270853042603, 1.1520307064056396, 1.0341157913208008, 1.1260292530059814, 1.0036712884902954, 1.0277212858200073, 1.1058191061019897, 1.2444993257522583, 1.153079867362976, 1.003713846206665, 1.3347578048706055, 1.273954153060913, 1.009661078453064, 1.1011617183685303, 1.3495383262634277, 1.103833794593811, 1.0302616357803345, 1.0073007345199585, 1.0695750713348389, 1.1428571939468384, 1.197068452835083, 1.0575612783432007, 1.107217788696289, 1.0719144344329834, 1.2818865776062012, 1.0862815380096436, 1.1006499528884888, 1.0792261362075806, 1.0431368350982666, 1.0143686532974243, 1.148110270500183, 1.1264034509658813, 1.1173361539840698, 1.0014206171035767, 1.2673721313476562, 1.0479518175125122, 1.2995802164077759, 1.0114386081695557, 1.0641090869903564, 1.3935546875, 1.2652599811553955, 2.422459840774536, 1.1549463272094727, 1.0506877899169922, 1.1176470518112183, 1.0253164768218994, 1.1595617532730103]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7457990646362305] ms
 --  Average per query NF    [1.3624417781829834] ms
 --  Average per query vegas [2.383357286453247] ms
Mean [1.151]  Median [1.117]  95th [1.393]  99th [1.503]  max [2.422]
Mean [1.151]  Median [1.117]  95th [1.393]  99th [1.503]  max [2.422]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.833563 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=sample', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
Sample - START
Sample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[9.5367432e-07 7.1525574e-07 1.1324883e-06 2.3841858e-06 2.3841858e-07]
Distance score: 1.0848045803868445e-06
SAUCE Drift detection: False
Detection latency: 0.0238s

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.021308 | Model-update-time: 0.000000


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=sample', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.16483211517334
tensor(0.9973)
result is  tensor(457358.4062)
Enter testHyper
ReportEsts: [1.01670241355896, 1.0614138841629028, 1.2680412530899048, 1.0582278966903687, 1.0383532047271729, 1.3052175045013428, 1.179624319076538, 1.0464892387390137, 1.1611194610595703, 1.0230118036270142, 1.0648894309997559, 1.0260214805603027, 1.1990050077438354, 1.0734189748764038, 1.0772711038589478, 1.08893883228302, 1.15733003616333, 1.1355267763137817, 1.2702642679214478, 1.3221516609191895, 1.1262071132659912, 2.0064516067504883, 1.1412367820739746, 1.1502946615219116, 1.0438071489334106, 1.2665067911148071, 1.007217288017273, 1.1287453174591064, 1.1621874570846558, 1.5668449401855469, 1.1047992706298828, 1.3235293626785278, 1.0036550760269165, 1.1179548501968384, 1.036732792854309, 1.2047243118286133, 1.1542701721191406, 1.1287636756896973, 1.182235598564148, 1.1147133111953735, 1.023620843887329, 1.012861728668213, 1.2184913158416748, 1.0501766204833984, 1.0256134271621704, 1.129418969154358, 1.9525835514068604, 1.0440667867660522, 1.1714285612106323, 1.0628741979599, 1.0427422523498535, 1.0500580072402954, 1.0990198850631714, 1.0782819986343384, 1.045165777206421, 1.428236484527588, 1.1853702068328857, 1.156520128250122, 1.2094568014144897, 1.0891180038452148, 1.5721392631530762, 1.0469218492507935, 1.0935672521591187, 1.3615883588790894, 1.000167727470398, 1.0057023763656616, 1.2571446895599365, 1.0880903005599976, 1.1349633932113647, 1.1362683773040771, 1.1609916687011719, 1.0696687698364258, 1.1548632383346558, 1.20586097240448, 1.124145269393921, 1.0548378229141235, 1.1335089206695557, 1.3008804321289062, 1.1953116655349731, 1.1957956552505493, 1.2673757076263428, 1.0359458923339844, 1.2671887874603271, 1.1571608781814575, 1.279096245765686, 1.4087591171264648, 1.3734395503997803, 1.3795329332351685, 1.0575292110443115, 1.0278162956237793, 1.2012228965759277, 1.004014253616333, 1.4165390729904175, 1.1146858930587769, 1.0375436544418335, 1.0509904623031616, 1.0076810121536255, 1.2141985893249512, 1.0780061483383179, 1.0555773973464966, 1.087969422340393, 1.2024141550064087, 1.25, 1.121934175491333, 1.126917839050293, 1.2517831325531006, 1.052878975868225, 1.0737909078598022, 1.307692289352417, 1.1408311128616333, 1.1677778959274292, 1.0204401016235352, 1.2400243282318115, 1.218011736869812, 1.1387499570846558, 1.0049151182174683, 1.0208139419555664, 1.3717771768569946, 1.011785626411438, 1.1864407062530518, 1.02493155002594, 1.1324224472045898, 1.0023411512374878, 1.8977447748184204, 1.0250481367111206, 1.0404839515686035, 1.2701516151428223, 1.2336448431015015, 1.0075206756591797, 1.0959999561309814, 1.1904278993606567, 1.0461450815200806, 1.1221635341644287, 1.6079429388046265, 1.7171814441680908, 1.1049671173095703, 1.0266391038894653, 1.0839974880218506, 1.0576605796813965, 1.01870596408844, 1.099094033241272, 1.182844877243042, 1.136950135231018, 1.1203463077545166, 1.0076814889907837, 1.1286295652389526, 1.4913294315338135, 1.0325617790222168, 1.0208615064620972, 1.1998463869094849, 1.084352731704712, 1.0043694972991943, 1.1698271036148071, 1.094367504119873, 1.0567337274551392, 1.0129138231277466, 1.0289855003356934, 1.3385826349258423, 1.4220951795578003, 1.1544843912124634, 1.0336788892745972, 1.1493728160858154, 1.9834619760513306, 1.1593719720840454, 1.1089551448822021, 1.153204321861267, 1.204207420349121, 1.1685131788253784, 1.1431134939193726, 1.2304335832595825, 1.1422145366668701, 1.1437362432479858, 1.2515795230865479, 1.1920077800750732, 1.0625081062316895, 1.1122541427612305, 1.00922429561615, 1.1203893423080444, 1.085107445716858, 1.067927598953247, 1.725000023841858, 1.1177266836166382, 1.0307248830795288, 1.5574357509613037, 1.387803077697754, 1.0621836185455322, 1.0158395767211914, 1.1561678647994995, 1.3354955911636353, 1.0853887796401978, 1.1375285387039185, 1.0645729303359985, 1.1023201942443848, 1.902234673500061, 1.1029304265975952, 1.0492647886276245, 1.3060803413391113, 1.1517857313156128, 1.3906810283660889, 1.0602542161941528]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.732173442840576] ms
 --  Average per query NF    [1.3613295555114746] ms
 --  Average per query vegas [2.3708438873291016] ms
Mean [1.170]  Median [1.128]  95th [1.558]  99th [1.953]  max [2.006]
Mean [1.170]  Median [1.128]  95th [1.558]  99th [1.953]  max [2.006]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.207167 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=0 | total-time=26.114831