Input arguments = Namespace(data_update='tupleskew', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 34, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.165257453918457
tensor(0.9927)
result is  tensor(379372.9375)
Enter testHyper
ReportEsts: [1.1175501346588135, 1.0011128187179565, 1.34004807472229, 1.3249105215072632, 1.2536125183105469, 1.077378511428833, 1.0374667644500732, 1.2833298444747925, 1.0335052013397217, 1.0697448253631592, 1.038759708404541, 1.1241525411605835, 1.1761047840118408, 1.0580357313156128, 1.1111699342727661, 1.3319438695907593, 1.2315138578414917, 1.2191210985183716, 1.0709431171417236, 1.2602040767669678, 1.127203345298767, 1.0158730745315552, 1.1440101861953735, 1.0059480667114258, 1.11957848072052, 1.1708860397338867, 1.0022573471069336, 1.500232219696045, 1.067415475845337, 1.0516687631607056, 1.1504079103469849, 1.0310786962509155, 1.0204107761383057, 1.04776930809021, 1.3349530696868896, 1.1733133792877197, 1.0907015800476074, 1.232824683189392, 1.0882225036621094, 1.1591616868972778, 1.0548536777496338, 1.165215253829956, 1.0963631868362427, 1.1363455057144165, 1.0790196657180786, 1.040816307067871, 1.0085313320159912, 1.3006706237792969, 1.0186423063278198, 1.1285955905914307, 1.2005208730697632, 1.2930346727371216, 1.0651891231536865, 1.1753343343734741, 1.0086749792099, 1.012749195098877, 1.35420560836792, 1.19758939743042, 1.1231337785720825, 1.5040613412857056, 1.5849272012710571, 1.1437220573425293, 1.367058515548706, 1.3135056495666504, 1.4102563858032227, 1.1428571939468384, 1.0829015970230103, 1.0211015939712524, 1.1081782579421997, 1.24210524559021, 1.037562608718872, 1.030722975730896, 1.1306736469268799, 1.1836203336715698, 1.17436945438385, 1.0877898931503296, 1.929216742515564, 1.0510292053222656, 1.0286731719970703, 1.3332228660583496, 1.1354985237121582, 1.0528186559677124, 1.0532283782958984, 1.1324479579925537, 1.2409483194351196, 1.1318278312683105, 1.0665613412857056, 1.0796469449996948, 1.0099101066589355, 1.0493407249450684, 1.0658533573150635, 1.2748208045959473, 1.0173097848892212, 1.3079848289489746, 1.0773481130599976, 1.0465070009231567, 1.1805531978607178, 1.296779990196228, 1.034482717514038, 1.091564416885376, 1.105263113975525, 1.0837268829345703, 1.0513620376586914, 1.0007320642471313, 1.0411087274551392, 1.0479658842086792, 1.0770189762115479, 1.1623036861419678, 1.085046410560608, 1.0731406211853027, 1.181786060333252, 1.1015037298202515, 1.2425994873046875, 1.0202322006225586, 1.0266571044921875, 1.0607476234436035, 1.1379787921905518, 1.2031471729278564, 1.2913508415222168, 1.0871853828430176, 1.1430342197418213, 1.1305367946624756, 1.0574114322662354, 1.3327314853668213, 1.2490310668945312, 1.213578224182129, 1.031036376953125, 1.126548171043396, 1.2469733953475952, 1.1469606161117554, 1.13692045211792, 1.163586974143982, 1.1059664487838745, 1.4285714626312256, 1.0346946716308594, 1.0619585514068604, 1.0120112895965576, 1.243577241897583, 1.0939491987228394, 1.338698387145996, 1.1842302083969116, 1.0609370470046997, 1.194419026374817, 1.2974774837493896, 1.026694655418396, 1.0693985223770142, 1.0549252033233643, 1.289501428604126, 1.049649715423584, 1.0889915227890015, 1.1328141689300537, 1.144212245941162, 1.2656731605529785, 1.048305630683899, 1.0460551977157593, 1.096013069152832, 1.1072590351104736, 1.0160382986068726, 1.030540943145752, 1.0814682245254517, 1.0958620309829712, 1.0361050367355347, 1.0359439849853516, 1.2888582944869995, 1.2791328430175781, 1.0147291421890259, 1.136968731880188, 1.2785861492156982, 1.0285791158676147, 1.0397322177886963, 1.0003870725631714, 1.0796267986297607, 1.1363636255264282, 1.3030707836151123, 1.0238419771194458, 1.1294469833374023, 1.0108054876327515, 1.3023622035980225, 1.0690655708312988, 1.2336418628692627, 1.1282376050949097, 1.058894395828247, 1.0443031787872314, 1.167517900466919, 1.1245925426483154, 1.1279069185256958, 1.0053993463516235, 1.2745654582977295, 1.024290680885315, 1.3346301317214966, 1.0048556327819824, 1.0570496320724487, 1.3503667116165161, 1.4823426008224487, 1.7417335510253906, 1.118291974067688, 1.041308879852295, 1.1692308187484741, 1.1116873025894165, 1.0808100700378418]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.742436170578003] ms
 --  Average per query NF    [1.3661599159240723] ms
 --  Average per query vegas [2.3762762546539307] ms
Mean [1.145]  Median [1.110]  95th [1.351]  99th [1.586]  max [1.929]
Mean [1.145]  Median [1.110]  95th [1.351]  99th [1.586]  max [1.929]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.823457 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=tupleskew', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
TupleSkewSample - START
0.001
TupleSkewSample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[5.9425831e-05 2.0551682e-04 7.2538853e-05 4.4226646e-05 1.0192394e-05]
Distance score: 7.838010787963867e-05
SAUCE Drift detection: True
Detection latency: 0.0229s

DRIFT-DETECTED after 2-th workload
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/incremental_train.py', '--dataset=bjaq', '--end2end', '--model=face', '--model_update=adapt', '--update_size=80000', '--epochs=0']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
update_size: 76433
AdaptTask - START
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
train data shape: 80000, transfer data shape:16000
Training done; evaluating likelihood on full data:
Saved to: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
AdaptTask - END

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.004586 | Model-update-time: 2.245114


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=tupleskew', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.199182748794556
tensor(0.9970)
result is  tensor(457225.2500)
Enter testHyper
ReportEsts: [1.209727168083191, 1.052977204322815, 1.0261627435684204, 1.4503257274627686, 1.0333138704299927, 1.0554134845733643, 1.2510424852371216, 1.0016987323760986, 1.052382469177246, 1.070310354232788, 1.1205761432647705, 1.0902138948440552, 1.034567952156067, 1.0727872848510742, 1.1583610773086548, 1.0221562385559082, 1.0934687852859497, 1.2329548597335815, 1.0662013292312622, 1.1846860647201538, 1.0026777982711792, 1.4561073780059814, 2.8625731468200684, 1.0109378099441528, 1.2018245458602905, 1.0645780563354492, 1.194369912147522, 1.1976107358932495, 1.0245941877365112, 1.462387204170227, 1.211398959159851, 1.48305082321167, 1.011047601699829, 1.1176989078521729, 1.0976945161819458, 1.1395148038864136, 1.1800715923309326, 1.094921588897705, 1.1885347366333008, 1.1856613159179688, 1.127874732017517, 1.1813538074493408, 1.1027684211730957, 1.1372655630111694, 1.0032498836517334, 1.2233498096466064, 1.0944509506225586, 1.138676404953003, 1.3428571224212646, 1.0569874048233032, 1.0704364776611328, 1.0260190963745117, 1.0364434719085693, 1.0157649517059326, 1.0234696865081787, 1.1784143447875977, 1.166597604751587, 1.111425518989563, 1.2811905145645142, 1.0337506532669067, 1.5458333492279053, 1.0299155712127686, 1.1493197679519653, 8.029411315917969, 1.029556393623352, 1.0515602827072144, 1.2507444620132446, 1.0512850284576416, 1.159525990486145, 1.0983127355575562, 1.2646191120147705, 1.1383029222488403, 1.0578644275665283, 1.0615479946136475, 1.016983151435852, 1.1165698766708374, 1.4040786027908325, 1.0192726850509644, 1.3158255815505981, 1.0464248657226562, 103.0, 1.0515590906143188, 1.1183656454086304, 1.0137711763381958, 1.394134521484375, 1.152230978012085, 1.1701909303665161, 1.2943954467773438, 1.1961820125579834, 1.0042363405227661, 1.0148464441299438, 1.1543350219726562, 1.2646281719207764, 1.1081637144088745, 1.3328367471694946, 1.0302467346191406, 1.0020499229431152, 1.2582886219024658, 1.1318823099136353, 1.1403471231460571, 1.1236566305160522, 1.1965101957321167, 1.0199999809265137, 1.186082124710083, 1.0741289854049683, 1.0030320882797241, 1.11997652053833, 1.1107237339019775, 1.5157593488693237, 1.0931154489517212, 1.1691542863845825, 1.109316349029541, 1.2659357786178589, 1.154475212097168, 1.0424811840057373, 1.0760270357131958, 1.0302762985229492, 1.161298394203186, 1.0133376121520996, 1.0973451137542725, 1.0435692071914673, 1.0071974992752075, 1.0934391021728516, 1.0966110229492188, 1.0424085855484009, 1.0397499799728394, 1.1519267559051514, 1.10310959815979, 1.1298648118972778, 1.1974025964736938, 1.14018976688385, 1.1929620504379272, 1.0553253889083862, 1.604821801185608, 1.4287090301513672, 1.0078520774841309, 1.0748875141143799, 1.1327483654022217, 1.1381357908248901, 1.0092403888702393, 1.1082154512405396, 1.0665661096572876, 1.0240734815597534, 1.0061719417572021, 1.0813637971878052, 1.1267074346542358, 1.2559523582458496, 1.0571643114089966, 1.1945780515670776, 1.1513234376907349, 1.0297791957855225, 1.267244577407837, 1.1285048723220825, 1.0149863958358765, 1.0548237562179565, 1.0133053064346313, 1.062149167060852, 2.7279999256134033, 1.330579161643982, 1.0662479400634766, 1.0215246677398682, 1.4689542055130005, 1.8756448030471802, 1.0500189065933228, 1.1526786088943481, 2.5727272033691406, 1.0415778160095215, 1.0741385221481323, 1.0709010362625122, 1.3702435493469238, 1.0683478116989136, 1.2385374307632446, 1.3014848232269287, 1.0556156635284424, 1.111578345298767, 1.0414495468139648, 1.206929326057434, 1.1797754764556885, 1.0130666494369507, 1.0209324359893799, 1.8421052694320679, 1.1708883047103882, 1.3559918403625488, 1.5423129796981812, 1.3211630582809448, 1.500312328338623, 1.0007827281951904, 1.1272692680358887, 1.2194325923919678, 1.1077916622161865, 1.116654396057129, 1.0592492818832397, 1.3891053199768066, 2.2089552879333496, 1.0683197975158691, 1.1741523742675781, 1.4502862691879272, 1.0237911939620972, 1.673076868057251, 1.0334521532058716]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7285399436950684] ms
 --  Average per query NF    [1.3547301292419434] ms
 --  Average per query vegas [2.373809814453125] ms
Mean [1.724]  Median [1.117]  95th [1.549]  99th [2.914]  max [103.000]
Mean [1.724]  Median [1.117]  95th [1.549]  99th [2.914]  max [103.000]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.406084 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=1 | total-time=28.531378