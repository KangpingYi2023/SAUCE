Input arguments = Namespace(data_update='sample', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 61, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.164188385009766
tensor(0.9977)
result is  tensor(381298.8125)
Enter testHyper
ReportEsts: [1.1290233135223389, 1.0352988243103027, 1.3880435228347778, 1.0937039852142334, 1.2804217338562012, 1.1009159088134766, 1.2193478345870972, 1.1607530117034912, 1.0494329929351807, 1.0051665306091309, 1.1662360429763794, 1.0868643522262573, 1.1178021430969238, 1.0245535373687744, 1.0628712177276611, 1.187901258468628, 1.3767176866531372, 1.1804038286209106, 1.1934669017791748, 1.09183669090271, 1.0093674659729004, 1.2017396688461304, 1.1155757904052734, 1.1183727979660034, 1.1823899745941162, 1.0479204654693604, 1.0416666269302368, 1.4830119609832764, 1.0326669216156006, 1.1119927167892456, 1.1135153770446777, 1.2557042837142944, 1.036278247833252, 1.035315990447998, 1.141409993171692, 1.170960545539856, 1.2508152723312378, 1.195501446723938, 1.0100847482681274, 1.0937724113464355, 1.0450844764709473, 1.1219158172607422, 1.1872161626815796, 1.1324576139450073, 1.078597068786621, 1.040816307067871, 1.0939961671829224, 1.3040716648101807, 1.0654752254486084, 1.0355329513549805, 1.226063847541809, 1.4121984243392944, 1.0883004665374756, 1.311774492263794, 1.162582516670227, 1.0589101314544678, 1.2794392108917236, 1.044541835784912, 1.3503963947296143, 1.3461227416992188, 1.2484909296035767, 1.1498291492462158, 1.258969783782959, 1.074532389640808, 1.3147410154342651, 1.3142857551574707, 1.1494041681289673, 1.0384695529937744, 1.1707303524017334, 1.3052631616592407, 1.1351568698883057, 1.0898549556732178, 1.2596582174301147, 1.307133436203003, 1.098595380783081, 1.185683012008667, 1.8128759860992432, 1.0149227380752563, 1.165148138999939, 1.3324081897735596, 1.103858470916748, 1.1463414430618286, 1.0086719989776611, 1.2744140625, 1.3064297437667847, 1.0512112379074097, 1.069875717163086, 1.1027491092681885, 1.0083383321762085, 1.0233850479125977, 1.070389747619629, 1.4386482238769531, 1.0238009691238403, 1.3559989929199219, 1.0263158082962036, 1.1326292753219604, 1.0789570808410645, 1.3009297847747803, 1.01694917678833, 1.1113191843032837, 1.215133547782898, 1.1106404066085815, 1.0145145654678345, 1.012445092201233, 1.0838912725448608, 1.033248782157898, 1.2781630754470825, 1.1535776853561401, 1.0867985486984253, 1.029634952545166, 1.168000340461731, 1.0722781419754028, 1.244905948638916, 1.0597184896469116, 1.1312159299850464, 1.2010581493377686, 1.0102999210357666, 1.0968657732009888, 1.1421709060668945, 1.1200791597366333, 1.2441233396530151, 1.1295018196105957, 1.067746877670288, 1.1418739557266235, 1.19428288936615, 1.1617828607559204, 1.0998212099075317, 1.246540904045105, 1.2821576595306396, 1.1042084693908691, 1.1189848184585571, 1.0929938554763794, 1.2821627855300903, 1.3571428060531616, 1.1692464351654053, 1.1260173320770264, 1.0184552669525146, 1.0533332824707031, 1.0699864625930786, 1.083238959312439, 1.1524217128753662, 1.1002367734909058, 1.1472361087799072, 1.2545557022094727, 1.1417567729949951, 1.1192775964736938, 1.0290066003799438, 1.2814444303512573, 1.0708696842193604, 1.0610085725784302, 1.1045231819152832, 1.1334444284439087, 1.3234820365905762, 1.041999101638794, 1.0830825567245483, 1.0239379405975342, 1.0621100664138794, 1.0022510290145874, 1.0366343259811401, 1.2698895931243896, 1.0214862823486328, 1.066335916519165, 1.1006078720092773, 1.2510013580322266, 1.1554467678070068, 1.0783945322036743, 1.1752299070358276, 1.2523168325424194, 1.1279628276824951, 1.0319795608520508, 1.0023291110992432, 1.0598348379135132, 1.1428571939468384, 1.1936688423156738, 1.1999318599700928, 1.1728276014328003, 1.0320699214935303, 1.3094322681427002, 1.3302778005599976, 1.015461802482605, 1.0633047819137573, 1.0912026166915894, 1.015197515487671, 1.134831428527832, 1.1213328838348389, 1.1014798879623413, 1.056977391242981, 1.2952414751052856, 1.0103936195373535, 1.3462374210357666, 1.0254530906677246, 1.0791525840759277, 1.6655967235565186, 1.3803781270980835, 1.6644796133041382, 1.1611742973327637, 1.1007920503616333, 1.1515151262283325, 1.0331960916519165, 1.0523571968078613]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.748619556427002] ms
 --  Average per query NF    [1.3675034046173096] ms
 --  Average per query vegas [2.3811161518096924] ms
Mean [1.150]  Median [1.119]  95th [1.356]  99th [1.664]  max [1.813]
Mean [1.150]  Median [1.119]  95th [1.356]  99th [1.664]  max [1.813]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.836194 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=sample', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
Sample - START
Sample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[1.3709068e-06 4.1723251e-07 2.9802322e-07 1.7881393e-06 5.9604645e-08]
Distance score: 7.867812996664725e-07
SAUCE Drift detection: False
Detection latency: 0.0235s

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.026599 | Model-update-time: 0.000000


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=sample', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.168298959732056
tensor(1.0003)
result is  tensor(458746.9688)
Enter testHyper
ReportEsts: [1.0871729850769043, 1.0902847051620483, 1.296754240989685, 1.0394537448883057, 1.0564842224121094, 1.1275218725204468, 1.1798269748687744, 1.040289044380188, 1.2387951612472534, 1.0661031007766724, 1.1222606897354126, 1.3470314741134644, 1.0867679119110107, 1.0056308507919312, 1.1724138259887695, 1.012832522392273, 1.289530634880066, 1.1257388591766357, 1.0591007471084595, 1.322218656539917, 1.139896273612976, 2.015721082687378, 1.0802026987075806, 1.1173369884490967, 1.0886054039001465, 1.1964446306228638, 1.0137600898742676, 1.0825560092926025, 1.1244875192642212, 1.4082934856414795, 1.0705536603927612, 1.3402777910232544, 1.0458598136901855, 1.0061864852905273, 1.0377930402755737, 1.28806734085083, 1.099318027496338, 1.2559535503387451, 1.3581647872924805, 1.161341905593872, 1.0254963636398315, 1.0161464214324951, 1.232683539390564, 1.107454776763916, 1.0582600831985474, 1.1120890378952026, 1.479516863822937, 1.0041786432266235, 1.1807228326797485, 1.220888376235962, 1.0571560859680176, 1.0817687511444092, 1.023038387298584, 1.2034130096435547, 1.0299005508422852, 1.4150727987289429, 1.1881027221679688, 1.1579749584197998, 1.2831672430038452, 1.1308897733688354, 1.1587591171264648, 1.0760143995285034, 1.0597333908081055, 1.6246381998062134, 1.1654000282287598, 1.0140944719314575, 1.1247364282608032, 1.0159485340118408, 1.1615145206451416, 1.0612518787384033, 1.060242772102356, 1.2334693670272827, 1.0821954011917114, 1.0084882974624634, 1.0091310739517212, 1.0295730829238892, 1.1627179384231567, 1.057983160018921, 1.1141349077224731, 1.0252026319503784, 1.1537264585494995, 1.0608402490615845, 1.144643783569336, 1.3178362846374512, 1.3837890625, 1.4104477167129517, 1.3225164413452148, 1.434491515159607, 1.087346076965332, 1.1171966791152954, 1.0115982294082642, 1.1648505926132202, 1.4232581853866577, 1.1108002662658691, 1.1507021188735962, 1.0556846857070923, 1.0066502094268799, 1.1698038578033447, 1.647652506828308, 1.0302858352661133, 1.1848379373550415, 1.1434674263000488, 1.2512820959091187, 1.089956521987915, 1.0561418533325195, 1.0232268571853638, 1.1762210130691528, 1.2122740745544434, 1.1263736486434937, 1.021348237991333, 1.07936692237854, 1.0392990112304688, 1.2178690433502197, 1.2279260158538818, 1.1174273490905762, 1.0521478652954102, 1.0020712614059448, 1.24467134475708, 1.0310715436935425, 1.1908396482467651, 1.1008186340332031, 1.107894778251648, 1.0480068922042847, 1.54501211643219, 1.0137370824813843, 1.0906147956848145, 1.164536952972412, 1.3141447305679321, 1.0500203371047974, 1.1711398363113403, 1.065752625465393, 1.1094127893447876, 1.1317877769470215, 1.8714953660964966, 1.798174500465393, 1.0435171127319336, 1.0826036930084229, 1.077099323272705, 1.0586698055267334, 1.0141851902008057, 1.0402542352676392, 1.2655655145645142, 1.1723015308380127, 1.0684082508087158, 1.0736057758331299, 1.0668576955795288, 1.382022500038147, 1.0134273767471313, 1.1501716375350952, 1.094049334526062, 1.0720374584197998, 1.0072853565216064, 1.0798542499542236, 1.0090796947479248, 1.0847965478897095, 1.1379040479660034, 1.111096739768982, 1.2461538314819336, 1.0440856218338013, 1.2592592239379883, 1.0302270650863647, 1.066489338874817, 1.191092848777771, 1.1199756860733032, 1.2241508960723877, 1.044354796409607, 1.0303891897201538, 1.3526967763900757, 1.0788394212722778, 1.1413509845733643, 1.0128642320632935, 1.065736174583435, 1.5186750888824463, 1.0534917116165161, 1.0385907888412476, 1.1550127267837524, 1.1801801919937134, 1.1247097253799438, 1.0745359659194946, 1.0464649200439453, 1.5833333730697632, 1.1642347574234009, 1.048774003982544, 1.6584582328796387, 1.4143227338790894, 1.023116111755371, 1.3422905206680298, 1.3766647577285767, 1.4036188125610352, 1.007601022720337, 1.1452555656433105, 1.0391145944595337, 1.1539835929870605, 1.6689711809158325, 1.079859972000122, 1.202124834060669, 1.2169767618179321, 1.1329243183135986, 1.2248061895370483, 1.2368625402450562]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7503933906555176] ms
 --  Average per query NF    [1.3674867153167725] ms
 --  Average per query vegas [2.382906675338745] ms
Mean [1.163]  Median [1.116]  95th [1.481]  99th [1.799]  max [2.016]
Mean [1.163]  Median [1.116]  95th [1.481]  99th [1.799]  max [2.016]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.213451 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=0 | total-time=26.123126