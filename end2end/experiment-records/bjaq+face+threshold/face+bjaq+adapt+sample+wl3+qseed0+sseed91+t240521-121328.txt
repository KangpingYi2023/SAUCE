Input arguments = Namespace(data_update='sample', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 91, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.171508073806763
tensor(0.9945)
result is  tensor(380065.6875)
Enter testHyper
ReportEsts: [1.1138789653778076, 1.0247044563293457, 1.4725468158721924, 1.120656967163086, 1.219099521636963, 1.1771787405014038, 1.208918809890747, 1.1589912176132202, 1.0308483839035034, 1.1289401054382324, 1.0301685333251953, 1.0957627296447754, 1.0519663095474243, 1.0625, 1.1047749519348145, 1.3916552066802979, 1.3597139120101929, 1.1795724630355835, 1.0956106185913086, 1.1122448444366455, 1.1120326519012451, 1.0656508207321167, 1.1218496561050415, 1.0828683376312256, 1.0856815576553345, 1.1473779678344727, 1.0751689672470093, 1.3744680881500244, 1.0086370706558228, 1.070287823677063, 1.0911670923233032, 1.1523492336273193, 1.0763908624649048, 1.0411614179611206, 1.2584829330444336, 1.079898476600647, 1.2541249990463257, 1.051658034324646, 1.0482103824615479, 1.0123353004455566, 1.0191839933395386, 1.1005079746246338, 1.066637396812439, 1.051450490951538, 1.0967674255371094, 1.0396825075149536, 1.102852702140808, 1.3549388647079468, 1.095603346824646, 1.1184433698654175, 1.2163587808609009, 1.3111387491226196, 1.0742653608322144, 1.1742874383926392, 1.0832351446151733, 1.0846081972122192, 1.4336448907852173, 1.2337726354599, 1.0607585906982422, 1.2663373947143555, 1.1240062713623047, 1.1952708959579468, 1.325105905532837, 1.0131540298461914, 1.3200000524520874, 1.0285714864730835, 1.1568266153335571, 1.0367459058761597, 1.0270838737487793, 1.2315789461135864, 1.0874890089035034, 1.1080890893936157, 1.2590032815933228, 1.2473952770233154, 1.2177958488464355, 1.347501277923584, 1.8170192241668701, 1.0716139078140259, 1.0980279445648193, 1.4328157901763916, 1.109731674194336, 1.0216171741485596, 1.0297547578811646, 1.2402414083480835, 1.2056834697723389, 1.0238468647003174, 1.0250129699707031, 1.2328373193740845, 1.0634580850601196, 1.0263702869415283, 1.0633938312530518, 1.249214768409729, 1.0150073766708374, 1.295668601989746, 1.0773481130599976, 1.1280555725097656, 1.0837746858596802, 1.3068068027496338, 1.034482717514038, 1.3445370197296143, 1.2352941036224365, 1.1348103284835815, 1.0460612773895264, 1.0095168352127075, 1.0384937524795532, 1.1170645952224731, 1.267922282218933, 1.1937172412872314, 1.0436805486679077, 1.0370105504989624, 1.0892468690872192, 1.107750415802002, 1.3787802457809448, 1.1002223491668701, 1.208531379699707, 1.096618413925171, 1.0055447816848755, 1.0007739067077637, 1.2263938188552856, 1.0517679452896118, 1.2594109773635864, 1.1093555688858032, 1.3395345211029053, 1.206512689590454, 1.290697693824768, 1.193871259689331, 1.0141096115112305, 1.189512848854065, 1.2291169166564941, 1.12625253200531, 1.0635367631912231, 1.143623948097229, 1.189247965812683, 1.4642857313156128, 1.2259430885314941, 1.113153100013733, 1.0323511362075806, 1.0650407075881958, 1.1237397193908691, 1.0271824598312378, 1.138135313987732, 1.1464191675186157, 1.107530117034912, 1.2815923690795898, 1.0390675067901611, 1.0022344589233398, 1.1332014799118042, 1.3789621591567993, 1.0671827793121338, 1.026917576789856, 1.1214145421981812, 1.1563901901245117, 1.304555058479309, 1.1294469833374023, 1.0051015615463257, 1.053098201751709, 1.1337913274765015, 1.0022510290145874, 1.1563581228256226, 1.1512384414672852, 1.2247533798217773, 1.0267506837844849, 1.0415822267532349, 1.3253182172775269, 1.1318944692611694, 1.0436363220214844, 1.2438993453979492, 1.2677228450775146, 1.2497446537017822, 1.009920358657837, 1.025260329246521, 1.0361188650131226, 1.1233766078948975, 1.1736609935760498, 1.1202316284179688, 1.26371169090271, 1.1482021808624268, 1.2695175409317017, 1.104123830795288, 1.0361882448196411, 1.02617609500885, 1.040063738822937, 1.0297503471374512, 1.0715014934539795, 1.1644331216812134, 1.1289640665054321, 1.0844573974609375, 1.2957086563110352, 1.0411286354064941, 1.280892014503479, 1.0382604598999023, 1.0184524059295654, 1.6257476806640625, 1.1439927816390991, 1.7187923192977905, 1.234394907951355, 1.1955814361572266, 1.0410958528518677, 1.0289524793624878, 1.1011288166046143]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.779137134552002] ms
 --  Average per query NF    [1.3672435283660889] ms
 --  Average per query vegas [2.411893606185913] ms
Mean [1.148]  Median [1.113]  95th [1.375]  99th [1.627]  max [1.817]
Mean [1.148]  Median [1.113]  95th [1.375]  99th [1.627]  max [1.817]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.835320 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=sample', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
Sample - START
Sample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[1.6093254e-06 1.8477440e-06 4.7683716e-07 1.1920929e-07 1.1920929e-07]
Distance score: 8.344650268554688e-07
SAUCE Drift detection: False
Detection latency: 0.0233s

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.032835 | Model-update-time: 0.000000


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=sample', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.165777444839478
tensor(1.0004)
result is  tensor(458772.5938)
Enter testHyper
ReportEsts: [1.1144769191741943, 1.0268290042877197, 1.1593406200408936, 1.3220363855361938, 1.0083034038543701, 1.306826114654541, 1.0793246030807495, 1.0269545316696167, 1.1192214488983154, 1.008176326751709, 1.1194872856140137, 1.122480034828186, 1.297157645225525, 1.250856876373291, 1.1235859394073486, 1.0389221906661987, 1.000417709350586, 1.175063133239746, 1.0892294645309448, 1.2638999223709106, 1.067945957183838, 1.4487004280090332, 1.09260094165802, 1.044321060180664, 1.0213944911956787, 1.172957420349121, 1.0458797216415405, 1.137930989265442, 1.1462339162826538, 1.871212124824524, 1.0921369791030884, 1.1586207151412964, 1.0104875564575195, 1.098438024520874, 1.0724197626113892, 1.0723037719726562, 1.1011340618133545, 1.0968120098114014, 1.0125036239624023, 1.1524149179458618, 1.0677086114883423, 1.0202343463897705, 1.1698533296585083, 1.0645325183868408, 1.011490821838379, 1.1162137985229492, 1.1458032131195068, 1.0909020900726318, 1.1012145280838013, 1.0417423248291016, 1.0381453037261963, 1.0006059408187866, 1.0906847715377808, 1.1774812936782837, 1.0570580959320068, 1.5035083293914795, 1.0978574752807617, 1.0736863613128662, 1.3374395370483398, 1.0353500843048096, 1.5491607189178467, 1.1478590965270996, 1.0656064748764038, 1.3417023420333862, 1.1828328371047974, 1.0777735710144043, 1.2608355283737183, 1.0260190963745117, 1.1700458526611328, 1.1847811937332153, 1.0396541357040405, 1.053328514099121, 1.2000585794448853, 1.2355494499206543, 1.1740467548370361, 1.0377888679504395, 1.0726549625396729, 1.1184418201446533, 1.3101376295089722, 1.0738033056259155, 1.2340741157531738, 1.1765586137771606, 1.203716516494751, 1.2237017154693604, 1.3478779792785645, 1.3137930631637573, 1.1237151622772217, 1.7189668416976929, 1.1682789325714111, 1.2569411993026733, 1.145468831062317, 1.0904276371002197, 1.263157844543457, 1.1054271459579468, 1.0368239879608154, 1.0088633298873901, 1.0815906524658203, 1.2018324136734009, 1.3264896869659424, 1.0308269262313843, 1.3051310777664185, 1.1573611497879028, 1.2219451665878296, 1.048506736755371, 1.0905418395996094, 1.1319018602371216, 1.0122939348220825, 1.144091010093689, 1.2292263507843018, 1.090507984161377, 1.0411152839660645, 1.115677833557129, 1.147853970527649, 1.2319095134735107, 1.038413405418396, 1.1381561756134033, 1.03319251537323, 1.4620873928070068, 1.120950698852539, 1.0697674751281738, 1.0911195278167725, 1.0856553316116333, 1.1237386465072632, 2.0333333015441895, 1.013263463973999, 1.1787891387939453, 1.1791027784347534, 1.289137363433838, 1.1597641706466675, 1.1341181993484497, 1.225577712059021, 1.0882389545440674, 1.0205549001693726, 1.7661470174789429, 1.7219512462615967, 1.101438283920288, 1.0404669046401978, 1.0506961345672607, 1.0804331302642822, 1.0171912908554077, 1.0308916568756104, 1.1792633533477783, 1.0348743200302124, 1.0659712553024292, 1.036863923072815, 1.0826255083084106, 1.4034091234207153, 1.0948197841644287, 1.2014858722686768, 1.0396045446395874, 1.0393097400665283, 1.0322884321212769, 1.213441252708435, 1.0560564994812012, 1.0189746618270874, 1.0037434101104736, 1.2483785152435303, 1.2538461685180664, 1.2487841844558716, 1.115464687347412, 1.1169630289077759, 1.0464303493499756, 1.007730484008789, 1.0497361421585083, 1.074231505393982, 1.0747889280319214, 1.017980933189392, 1.2493189573287964, 1.0900866985321045, 1.2630162239074707, 1.0452182292938232, 1.0827462673187256, 1.6677067279815674, 1.3469750881195068, 1.0650434494018555, 1.0944305658340454, 1.3803489208221436, 1.0611426830291748, 1.0093191862106323, 1.02738618850708, 1.56521737575531, 1.2134227752685547, 1.0398516654968262, 1.6360536813735962, 1.3717401027679443, 1.116385579109192, 1.0240013599395752, 1.098750352859497, 1.283158540725708, 1.0421921014785767, 1.1175618171691895, 1.006178379058838, 1.2579046487808228, 1.579698920249939, 1.024842619895935, 1.0800857543945312, 1.3118253946304321, 1.1368719339370728, 1.1234221458435059, 1.1266525983810425]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.73337984085083] ms
 --  Average per query NF    [1.3600385189056396] ms
 --  Average per query vegas [2.3733413219451904] ms
Mean [1.159]  Median [1.110]  95th [1.506]  99th [1.767]  max [2.033]
Mean [1.159]  Median [1.110]  95th [1.506]  99th [1.767]  max [2.033]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.253509 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=0 | total-time=26.146161