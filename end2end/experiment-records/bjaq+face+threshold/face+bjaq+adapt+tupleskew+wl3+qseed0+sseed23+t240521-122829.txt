Input arguments = Namespace(data_update='tupleskew', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 23, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.161096096038818
tensor(0.9952)
result is  tensor(380320.)
Enter testHyper
ReportEsts: [1.0716354846954346, 1.1242990493774414, 1.4976911544799805, 1.167614221572876, 1.2659320831298828, 1.12174654006958, 1.2285035848617554, 1.077262043952942, 1.1190698146820068, 1.1872713565826416, 1.004306674003601, 1.214194893836975, 1.033814549446106, 1.0424107313156128, 1.0208927392959595, 1.2706114053726196, 1.2302569150924683, 1.1761282682418823, 1.1929022073745728, 1.0234986543655396, 1.0634360313415527, 1.0922330617904663, 1.1348503828048706, 1.0352282524108887, 1.2177571058273315, 1.0786617994308472, 1.0236310958862305, 1.7062863111495972, 1.092922329902649, 1.0389584302902222, 1.1426037549972534, 1.1877460479736328, 1.0045571327209473, 1.015496015548706, 1.2443172931671143, 1.1975806951522827, 1.2165693044662476, 1.1661381721496582, 1.192691683769226, 1.065322756767273, 1.0488849878311157, 1.0431785583496094, 1.1234878301620483, 1.1301509141921997, 1.0847243070602417, 1.0555555820465088, 1.1547590494155884, 1.3048028945922852, 1.0649217367172241, 1.213197946548462, 1.2561308145523071, 1.325991153717041, 1.0610136985778809, 1.1574480533599854, 1.0110177993774414, 1.018080711364746, 1.2355140447616577, 1.1298527717590332, 1.5716214179992676, 1.3310703039169312, 1.2795132398605347, 1.2199183702468872, 1.3352124691009521, 1.0833052396774292, 1.226765751838684, 1.1714285612106323, 1.0520133972167969, 1.0321300029754639, 1.112967610359192, 1.4315789937973022, 1.1158487796783447, 1.0631335973739624, 1.2820792198181152, 1.0850348472595215, 1.0271892547607422, 1.1251906156539917, 2.165700674057007, 1.0293803215026855, 1.0838714838027954, 1.123408555984497, 1.2625070810317993, 1.0231366157531738, 1.0288950204849243, 1.1683911085128784, 1.2535468339920044, 1.0562593936920166, 1.0802953243255615, 1.0457502603530884, 1.0102934837341309, 1.1262128353118896, 1.0381404161453247, 1.3984454870224, 1.0100973844528198, 1.2635445594787598, 1.0893855094909668, 1.0915571451187134, 1.0241047143936157, 1.4055973291397095, 1.034482717514038, 1.1508285999298096, 1.1567796468734741, 1.408257007598877, 1.050206184387207, 1.012445092201233, 1.0608786344528198, 1.0310635566711426, 1.2298990488052368, 1.158813238143921, 1.0488312244415283, 1.0178110599517822, 1.1315648555755615, 1.0732600688934326, 1.1075373888015747, 1.0547149181365967, 1.07511305809021, 1.2404371500015259, 1.143988847732544, 1.157874345779419, 1.3051261901855469, 1.0493165254592896, 1.0912624597549438, 1.1054918766021729, 1.0425418615341187, 1.1653249263763428, 1.3759689331054688, 1.1877837181091309, 1.2022981643676758, 1.071419358253479, 1.375779151916504, 1.0778223276138306, 1.135923981666565, 1.1475332975387573, 1.1584835052490234, 1.4642857313156128, 1.0813896656036377, 1.100026249885559, 1.009153962135315, 1.1746340990066528, 1.0761281251907349, 1.2503267526626587, 1.1888097524642944, 1.2107499837875366, 1.0643519163131714, 1.2787541151046753, 1.127817988395691, 1.078908920288086, 1.0038166046142578, 1.688327431678772, 1.174265742301941, 1.0501420497894287, 1.1289671659469604, 1.16023588180542, 1.3970504999160767, 1.0926268100738525, 1.2133820056915283, 1.0555524826049805, 1.1492106914520264, 1.0022510290145874, 1.118242621421814, 1.2284691333770752, 1.1702454090118408, 1.0706636905670166, 1.0112764835357666, 1.2783082723617554, 1.1278375387191772, 1.0424302816390991, 1.0991290807724, 1.2103084325790405, 1.0690816640853882, 1.0350630283355713, 1.0085707902908325, 1.066300868988037, 1.1428571939468384, 1.0523324012756348, 1.0258855819702148, 1.0220355987548828, 1.0436105728149414, 1.3159809112548828, 1.1224559545516968, 1.0946582555770874, 1.0355428457260132, 1.0116852521896362, 1.0326231718063354, 1.1256383657455444, 1.1369068622589111, 1.1437631845474243, 1.0588818788528442, 1.2212780714035034, 1.1180964708328247, 1.421547770500183, 1.1760255098342896, 1.089989423751831, 1.6257476806640625, 1.5536705255508423, 1.7471073865890503, 1.1467455625534058, 1.1400583982467651, 1.0270270109176636, 1.017351508140564, 1.0494356155395508]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.735027313232422] ms
 --  Average per query NF    [1.3595044612884521] ms
 --  Average per query vegas [2.3755228519439697] ms
Mean [1.155]  Median [1.123]  95th [1.422]  99th [1.707]  max [2.166]
Mean [1.155]  Median [1.123]  95th [1.422]  99th [1.707]  max [2.166]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.808261 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=tupleskew', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
TupleSkewSample - START
0.001
TupleSkewSample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[7.0697069e-04 5.6260824e-04 1.1563301e-05 2.5391579e-05 2.2351742e-05]
Distance score: 0.0002657771110534668
SAUCE Drift detection: True
Detection latency: 0.0229s

DRIFT-DETECTED after 2-th workload
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/incremental_train.py', '--dataset=bjaq', '--end2end', '--model=face', '--model_update=adapt', '--update_size=80000', '--epochs=0']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
update_size: 76433
AdaptTask - START
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
train data shape: 80000, transfer data shape:16000
Training done; evaluating likelihood on full data:
Saved to: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
AdaptTask - END

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 1.998306 | Model-update-time: 2.252954


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=tupleskew', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.170120000839233
tensor(0.9939)
result is  tensor(455814.5312)
Enter testHyper
ReportEsts: [1.0246410369873047, 1.052443265914917, 1.6879756450653076, 1.321628212928772, 1.0462570190429688, 1.0989583730697632, 1.1459846496582031, 1.0651216506958008, 1.0014729499816895, 1.899999976158142, 1.009828805923462, 1.123848557472229, 1.476635456085205, 1.0651824474334717, 1.0874723196029663, 1.0251147747039795, 2.125282049179077, 1.0779894590377808, 1.0179252624511719, 1.2630605697631836, 1.158991813659668, 2.6843373775482178, 1.072656273841858, 1.0575180053710938, 1.0942230224609375, 1.0538851022720337, 1.0198616981506348, 1.191489338874817, 1.2205288410186768, 1.3006244897842407, 1.3012357950210571, 1.3559322357177734, 1.0643444061279297, 1.160774827003479, 1.1657731533050537, 1.095932960510254, 1.1979295015335083, 2.5491607189178467, 1.6527093648910522, 1.0282570123672485, 1.0124740600585938, 1.0191489458084106, 1.1217409372329712, 1.1240612268447876, 1.0657896995544434, 1.1372175216674805, 1.2156153917312622, 1.1083613634109497, 1.2476190328598022, 1.1283694505691528, 1.0451703071594238, 1.0034838914871216, 1.027372121810913, 1.0832581520080566, 1.0618833303451538, 1.1712943315505981, 1.2961950302124023, 1.1732306480407715, 1.3188544511795044, 1.1736462116241455, 2.152967929840088, 1.1494839191436768, 1.1225247383117676, 1.1773204803466797, 1.000402569770813, 1.1567360162734985, 1.2881460189819336, 1.0909548997879028, 1.1858394145965576, 1.0004719495773315, 1.1939222812652588, 1.2607060670852661, 1.0372337102890015, 1.1255005598068237, 1.0289322137832642, 1.2443026304244995, 1.0214776992797852, 1.1152281761169434, 1.312044620513916, 1.188220739364624, 1.0868449211120605, 1.0822287797927856, 1.364855408668518, 1.1185802221298218, 1.3474783897399902, 1.506382942199707, 1.076994776725769, 1.5546875, 1.143892765045166, 1.2328041791915894, 1.0031670331954956, 1.1079765558242798, 1.3339653015136719, 1.1299948692321777, 1.034844994544983, 1.0368564128875732, 1.0399423837661743, 1.2097961902618408, 1.1078141927719116, 1.0447931289672852, 1.0740113258361816, 1.1143189668655396, 1.4887781143188477, 1.0871448516845703, 1.0172760486602783, 1.0156515836715698, 1.010815143585205, 1.1381011009216309, 1.597733736038208, 1.0505714416503906, 1.17578125, 1.001338005065918, 1.1915470361709595, 1.1626712083816528, 1.0753452777862549, 1.0591856241226196, 1.107851505279541, 1.2904642820358276, 1.1001174449920654, 1.035398244857788, 1.0467671155929565, 1.3619937896728516, 1.0912352800369263, 2.20881986618042, 1.1082491874694824, 1.0318180322647095, 1.1036670207977295, 1.3465818166732788, 1.0487878322601318, 1.0964922904968262, 1.0289256572723389, 1.1200600862503052, 1.0537856817245483, 1.8832684755325317, 1.6376953125, 1.164494276046753, 1.1163461208343506, 1.04433274269104, 1.2225271463394165, 1.0087076425552368, 1.0292816162109375, 1.2070682048797607, 1.007308006286621, 1.0327290296554565, 1.010404348373413, 1.064231276512146, 1.3024691343307495, 1.0740681886672974, 1.0281851291656494, 1.088194727897644, 1.1807574033737183, 1.0025991201400757, 1.1682287454605103, 1.0102511644363403, 1.0476086139678955, 1.2510905265808105, 1.1315544843673706, 2.6587302684783936, 1.626500129699707, 1.1438696384429932, 1.0004246234893799, 1.171543836593628, 2.905109405517578, 1.0785883665084839, 1.2214546203613281, 1.2159665822982788, 1.061837077140808, 1.263897180557251, 1.004272222518921, 1.3466401100158691, 1.1552526950836182, 1.0515588521957397, 1.4702380895614624, 1.0432029962539673, 1.2405498027801514, 1.041631817817688, 1.2259740829467773, 1.1018887758255005, 1.0051125288009644, 1.0770201683044434, 1.894736886024475, 1.1758910417556763, 1.035599708557129, 1.2862492799758911, 1.0316132307052612, 1.1625056266784668, 1.0246034860610962, 1.2096000909805298, 1.4679961204528809, 1.1352821588516235, 1.1964247226715088, 1.0607120990753174, 1.2592718601226807, 1.5903918743133545, 1.0074015855789185, 1.0138216018676758, 1.493485927581787, 1.326923131942749, 1.2730768918991089, 1.1305290460586548]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.75174880027771] ms
 --  Average per query NF    [1.3682258129119873] ms
 --  Average per query vegas [2.3835229873657227] ms
Mean [1.210]  Median [1.121]  95th [1.698]  99th [2.659]  max [2.905]
Mean [1.210]  Median [1.121]  95th [1.698]  99th [2.659]  max [2.905]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.412193 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=1 | total-time=28.496779