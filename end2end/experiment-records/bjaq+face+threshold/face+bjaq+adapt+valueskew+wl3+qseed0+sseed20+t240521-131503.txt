Input arguments = Namespace(data_update='valueskew', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 20, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.158915519714355
tensor(0.9954)
result is  tensor(380399.6562)
Enter testHyper
ReportEsts: [1.1915080547332764, 1.0703505277633667, 1.3430817127227783, 1.1341334581375122, 1.2282577753067017, 1.0928350687026978, 1.2651665210723877, 1.0010045766830444, 1.0433651208877563, 1.1899056434631348, 1.0094746351242065, 1.1322033405303955, 1.0329793691635132, 1.0580357313156128, 1.204245924949646, 1.355009913444519, 1.3604892492294312, 1.262232780456543, 1.1434835195541382, 1.1326531171798706, 1.2694975137710571, 1.1291941404342651, 1.1334174871444702, 1.0221166610717773, 1.2633341550827026, 1.1247739791870117, 1.0653153657913208, 1.4222809076309204, 1.0169172286987305, 1.052893877029419, 1.115643858909607, 1.1155024766921997, 1.1250258684158325, 1.1426620483398438, 1.1642645597457886, 1.1662040948867798, 1.4001152515411377, 1.1011031866073608, 1.0875922441482544, 1.0289586782455444, 1.0066660642623901, 1.1491291522979736, 1.002610445022583, 1.0911184549331665, 1.133741855621338, 1.0521541833877563, 1.0402909517288208, 1.2958426475524902, 1.0380555391311646, 1.2284263372421265, 1.1700507402420044, 1.3390530347824097, 1.0105332136154175, 1.2003034353256226, 1.1501531600952148, 1.0452016592025757, 1.2878504991531372, 1.2318241596221924, 1.1300668716430664, 1.4560943841934204, 1.2774884700775146, 1.2388677597045898, 1.2355016469955444, 1.207413911819458, 1.375, 1.0571428537368774, 1.1287128925323486, 1.0359101295471191, 1.1114195585250854, 1.4631578922271729, 1.1058719158172607, 1.1606240272521973, 1.2119115591049194, 1.1139203310012817, 1.0016508102416992, 1.3663299083709717, 2.1708593368530273, 1.0185089111328125, 1.0322626829147339, 1.295237421989441, 1.2172893285751343, 1.0697786808013916, 1.0011214017868042, 1.13877534866333, 1.2114465236663818, 1.0523426532745361, 1.1412274837493896, 1.2454476356506348, 1.1173006296157837, 1.0678331851959229, 1.015152931213379, 1.4005188941955566, 1.0228698253631592, 1.3211714029312134, 1.107954502105713, 1.0396769046783447, 1.0513370037078857, 1.183756947517395, 1.01694917678833, 1.1530755758285522, 1.1219178438186646, 1.2930065393447876, 1.0370757579803467, 1.0051507949829102, 1.1102510690689087, 1.02113676071167, 1.1630080938339233, 1.1867364645004272, 1.0395606756210327, 1.0190051794052124, 1.0001887083053589, 1.1312741041183472, 1.070664644241333, 1.0254135131835938, 1.152544379234314, 1.0913461446762085, 1.053641438484192, 1.1598091125488281, 1.1695460081100464, 1.023482322692871, 1.2994565963745117, 1.1786255836486816, 1.1622991561889648, 1.0862629413604736, 1.359980583190918, 1.1985142230987549, 1.12483549118042, 1.099481463432312, 1.2907267808914185, 1.12859046459198, 1.2375593185424805, 1.1399081945419312, 1.2560596466064453, 1.4285714626312256, 1.0179200172424316, 1.005543828010559, 1.040509819984436, 1.0845528841018677, 1.0437489748001099, 1.3490831851959229, 1.1302205324172974, 1.1141149997711182, 1.2642453908920288, 1.2672566175460815, 1.0970609188079834, 1.0246902704238892, 1.0100620985031128, 1.4332411289215088, 1.1476383209228516, 1.1158380508422852, 1.1203999519348145, 1.1612613201141357, 1.3101063966751099, 1.0216940641403198, 1.12407386302948, 1.032646656036377, 1.165574073791504, 1.0680923461914062, 1.024490475654602, 1.10605788230896, 1.1049996614456177, 1.0516732931137085, 1.0212326049804688, 1.3160111904144287, 1.140096664428711, 1.102304458618164, 1.1905641555786133, 1.2081646919250488, 1.0642335414886475, 1.0099550485610962, 1.0912222862243652, 1.0496071577072144, 1.1168831586837769, 1.1753886938095093, 1.0800408124923706, 1.060107946395874, 1.0142927169799805, 1.3038288354873657, 1.0105022192001343, 1.2047932147979736, 1.062691569328308, 1.035352349281311, 1.0421385765075684, 1.0776302814483643, 1.0499818325042725, 1.0581395626068115, 1.035332202911377, 1.2589348554611206, 1.1677290201187134, 1.321017861366272, 1.046793818473816, 1.020100712776184, 1.6862629652023315, 1.419273018836975, 1.7288191318511963, 1.2007434368133545, 1.0927886962890625, 1.1014492511749268, 1.166132926940918, 1.0723439455032349]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7576663494110107] ms
 --  Average per query NF    [1.367027759552002] ms
 --  Average per query vegas [2.390638589859009] ms
Mean [1.153]  Median [1.124]  95th [1.400]  99th [1.687]  max [2.171]
Mean [1.153]  Median [1.124]  95th [1.400]  99th [1.687]  max [2.171]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.838356 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=valueskew', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
ValueSample - START
ValueSample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[5.9604645e-08 7.1525574e-07 1.7881393e-06 2.9802322e-07 8.6553097e-03]
Distance score: 0.0017316341400146484
SAUCE Drift detection: True
Detection latency: 0.0233s

DRIFT-DETECTED after 2-th workload
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/incremental_train.py', '--dataset=bjaq', '--end2end', '--model=face', '--model_update=adapt', '--update_size=80000', '--epochs=0']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
update_size: 76433
AdaptTask - START
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
train data shape: 80000, transfer data shape:16000
Training done; evaluating likelihood on full data:
Saved to: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
AdaptTask - END

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.079371 | Model-update-time: 2.227839


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=valueskew', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.25432801246643
tensor(0.9972)
result is  tensor(457328.5000)
Enter testHyper
ReportEsts: [1.1970062255859375, 1.0295330286026, 1.3212121725082397, 1.8202317953109741, 1.0083919763565063, 4.055859565734863, 1.2248718738555908, 1.119653582572937, 1.5649350881576538, 1.3335641622543335, 1.025692105293274, 1.7154560089111328, 1.0219511985778809, 1.366097092628479, 1.2705724239349365, 1.3598369359970093, 1.8590947389602661, 1.0238434076309204, 1.104386806488037, 1.816117525100708, 1.1478275060653687, 2.059375047683716, 3.5089991092681885, 1.0810601711273193, 1.1016689538955688, 1.324580430984497, 1.3706046342849731, 1.3546936511993408, 9.382608413696289, 1.386614203453064, 1.3607226610183716, 1.6949152946472168, 1.1576926708221436, 85.53125, 1.1568468809127808, 1.1119760274887085, 1.0307167768478394, 1.0446629524230957, 1.351293683052063, 1.0323699712753296, 1.0949457883834839, 1.2848020792007446, 53.057777404785156, 1.1100724935531616, 1.3009835481643677, 1.1809847354888916, 1.0308308601379395, 1.064581036567688, 1.3619047403335571, 1.0649234056472778, 1.0586881637573242, 1.0733733177185059, 1.0388425588607788, 1.0078338384628296, 1.0580395460128784, 1.630056619644165, 1.1815147399902344, 1.1165320873260498, 1.2853913307189941, 1.16245698928833, 1.243619441986084, 1.058166265487671, 1.1971440315246582, 1.6391061544418335, 1.0884066820144653, 1.026205062866211, 1.3373746871948242, 1.9154736995697021, 1.22589111328125, 1.0912407636642456, 1.0579862594604492, 1.1749476194381714, 1.0466294288635254, 1.0790903568267822, 1.0440824031829834, 1.0258581638336182, 1.1200517416000366, 1.1555417776107788, 1.0316941738128662, 1.0396877527236938, 1.1606837511062622, 1.1519830226898193, 1.4156550168991089, 1.0298174619674683, 1.3487168550491333, 1.6510637998580933, 1.4402670860290527, 1.5716795921325684, 1.0173436403274536, 1.807738184928894, 1.1031321287155151, 1.2311694622039795, 1.1466362476348877, 1.844208836555481, 1.3018090724945068, 1.0369089841842651, 1.3337063789367676, 1.1547472476959229, 1.3854598999023438, 2.3844072818756104, 1.1703274250030518, 1.097575068473816, 1.1619718074798584, 1.2188571691513062, 1.0878609418869019, 1.248185634613037, 1.0901179313659668, 1.1029267311096191, 1.214084506034851, 1.0937085151672363, 1.0424836874008179, 1.0696992874145508, 1.2319490909576416, 1.3289183378219604, 1.042128562927246, 1.183524489402771, 1.2929387092590332, 1.1836568117141724, 3.326765537261963, 1.194690227508545, 1.0223253965377808, 1.0950202941894531, 1.0873438119888306, 1.7805113792419434, 1.0279542207717896, 1.2417272329330444, 1.2323042154312134, 1.3455759286880493, 1.280559778213501, 1.1173813343048096, 1.116236686706543, 1.3530410528182983, 1.0916173458099365, 1.7191157341003418, 1.650925874710083, 1.2566920518875122, 1.236083984375, 1.0575382709503174, 1.0724966526031494, 1.0306352376937866, 1.1231015920639038, 1.101458191871643, 1.0064506530761719, 1.6089316606521606, 1.0458858013153076, 1.198556661605835, 1.2865853309631348, 1.0434422492980957, 1.0193836688995361, 1.2392377853393555, 1.0454784631729126, 1.0416125059127808, 1.2212308645248413, 1.0953336954116821, 1.0110135078430176, 1.2907806634902954, 1.158448338508606, 1.2992125749588013, 14.554147720336914, 1.1712054014205933, 1.0183444023132324, 1.0405628681182861, 1.6231657266616821, 1.054481029510498, 1.1493566036224365, 10.159727096557617, 1.2442008256912231, 1.263435959815979, 1.009202480316162, 1.2962400913238525, 1.078223705291748, 1.0809240341186523, 1.4730392694473267, 1.722636342048645, 1.0924783945083618, 1.270555853843689, 1.0970406532287598, 1.3301386833190918, 1.1004741191864014, 1.4394328594207764, 1.8157894611358643, 1.1401711702346802, 1.0072243213653564, 1.4447811841964722, 1.176708459854126, 1.829166054725647, 2.306873083114624, 1.1654131412506104, 1.1598128080368042, 1.0133090019226074, 1.2000987529754639, 1.0471771955490112, 1.0893244743347168, 1.7953463792800903, 1.0971720218658447, 3.154226064682007, 1.0435497760772705, 1.123870611190796, 1.0091463327407837, 1.0845472812652588]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [4.5422375202178955] ms
 --  Average per query NF    [1.4913499355316162] ms
 --  Average per query vegas [3.0508875846862793] ms
Mean [2.119]  Median [1.164]  95th [2.311]  99th [14.939]  max [85.531]
Mean [2.119]  Median [1.164]  95th [2.311]  99th [14.939]  max [85.531]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.637941 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=1 | total-time=28.847142