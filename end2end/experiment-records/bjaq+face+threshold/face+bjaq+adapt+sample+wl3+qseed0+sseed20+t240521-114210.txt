Input arguments = Namespace(data_update='sample', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 20, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.167619228363037
tensor(0.9967)
result is  tensor(380906.2812)
Enter testHyper
ReportEsts: [1.1925556659698486, 1.0487364530563354, 1.3140125274658203, 1.0722256898880005, 1.2495590448379517, 1.0833470821380615, 1.1315746307373047, 1.1496689319610596, 1.0491279363632202, 1.100967526435852, 1.213608980178833, 1.1519067287445068, 1.0429919958114624, 1.0491071939468384, 1.1487326622009277, 1.2046239376068115, 1.2921925783157349, 1.1745842695236206, 1.1787718534469604, 1.03316330909729, 1.021796464920044, 1.0229841470718384, 1.1151138544082642, 1.0720586776733398, 1.0693457126617432, 1.1139240264892578, 1.0346283912658691, 1.5717761516571045, 1.0035101175308228, 1.0048037767410278, 1.146151065826416, 1.1933236122131348, 1.205113410949707, 1.020766019821167, 1.2347636222839355, 1.1188983917236328, 1.321380853652954, 1.1174527406692505, 1.0377123355865479, 1.0094610452651978, 1.0127218961715698, 1.1383647918701172, 1.0439246892929077, 1.076745629310608, 1.106908917427063, 1.0327868461608887, 1.0502973794937134, 1.2701473236083984, 1.0875968933105469, 1.160744547843933, 1.1820513010025024, 1.385728359222412, 1.0315444469451904, 1.1916239261627197, 1.3025447130203247, 1.0595735311508179, 1.3130841255187988, 1.2589677572250366, 1.001201868057251, 1.4158878326416016, 1.265281319618225, 1.1672810316085815, 1.5025655031204224, 1.1253126859664917, 1.2992125749588013, 1.1142857074737549, 1.1578947305679321, 1.0063148736953735, 1.108722448348999, 1.3473684787750244, 1.0297666788101196, 1.0106134414672852, 1.2539409399032593, 1.0899996757507324, 1.2714630365371704, 1.1760613918304443, 2.037125825881958, 1.0551807880401611, 1.0699890851974487, 1.1359935998916626, 1.148538589477539, 1.0856081247329712, 1.0098142623901367, 1.1649705171585083, 1.2449586391448975, 1.0214070081710815, 1.0288008451461792, 1.0584111213684082, 1.079835295677185, 1.0883574485778809, 1.0142014026641846, 1.3136028051376343, 1.045625925064087, 1.2360206842422485, 1.0955055952072144, 1.1961984634399414, 1.132636547088623, 1.324061393737793, 1.01694917678833, 1.0659114122390747, 1.1886792182922363, 1.2547639608383179, 1.0087237358093262, 1.0, 1.0654184818267822, 1.0172746181488037, 1.1179494857788086, 1.2303664684295654, 1.0780937671661377, 1.0179599523544312, 1.0393633842468262, 1.0683683156967163, 1.304412603378296, 1.0554251670837402, 1.0414975881576538, 1.164102554321289, 1.0035390853881836, 1.0332773923873901, 1.1708077192306519, 1.0136107206344604, 1.2781076431274414, 1.141575813293457, 1.186637282371521, 1.1362661123275757, 1.1531007289886475, 1.1942839622497559, 1.1493797302246094, 1.1663352251052856, 1.2994112968444824, 1.1108884811401367, 1.0565617084503174, 1.1401309967041016, 1.3098198175430298, 1.5357142686843872, 1.1319810152053833, 1.0266846418380737, 1.0709850788116455, 1.0461788177490234, 1.1316004991531372, 1.3284722566604614, 1.1498830318450928, 1.0823390483856201, 1.1111726760864258, 1.4242520332336426, 1.111430287361145, 1.1038577556610107, 1.0063198804855347, 1.3582009077072144, 1.0944656133651733, 1.0252131223678589, 1.2842624187469482, 1.150749921798706, 1.3645429611206055, 1.014918565750122, 1.076788067817688, 1.0499119758605957, 1.0779014825820923, 1.0162997245788574, 1.102603554725647, 1.1755893230438232, 1.2623134851455688, 1.03871488571167, 1.071535587310791, 1.3215796947479248, 1.22756826877594, 1.0804243087768555, 1.2042734622955322, 1.2286841869354248, 1.107723593711853, 1.0351511240005493, 1.0858948230743408, 1.031650185585022, 1.1363636255264282, 1.092738151550293, 1.0269073247909546, 1.1765413284301758, 1.0140913724899292, 1.489323377609253, 1.2784606218338013, 1.2310278415679932, 1.0722301006317139, 1.0035662651062012, 1.0566422939300537, 1.0776302814483643, 1.0843896865844727, 1.1099365949630737, 1.1654597520828247, 1.3108354806900024, 1.0952810049057007, 1.4349669218063354, 1.010046124458313, 1.0202134847640991, 1.4446974992752075, 1.1719404458999634, 2.3863637447357178, 1.1867728233337402, 1.0656940937042236, 1.1692308187484741, 1.0114145278930664, 1.1648074388504028]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.777984380722046] ms
 --  Average per query NF    [1.3611388206481934] ms
 --  Average per query vegas [2.4168455600738525] ms
Mean [1.152]  Median [1.114]  95th [1.387]  99th [1.576]  max [2.386]
Mean [1.152]  Median [1.114]  95th [1.387]  99th [1.576]  max [2.386]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.855563 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=sample', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
Sample - START
Sample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[5.9604645e-08 6.5565109e-07 1.7881393e-06 2.9802322e-07 4.1723251e-07]
Distance score: 6.437301749429025e-07
SAUCE Drift detection: False
Detection latency: 0.0231s

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.024673 | Model-update-time: 0.000000


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=sample', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.209948301315308
tensor(0.9959)
result is  tensor(456702.1875)
Enter testHyper
ReportEsts: [1.1478172540664673, 1.0353091955184937, 1.2804698944091797, 1.0534778833389282, 1.051619529724121, 1.3945765495300293, 1.2265572547912598, 1.00979745388031, 1.097561001777649, 1.1184614896774292, 1.1991926431655884, 1.0075550079345703, 1.2106537818908691, 1.0339550971984863, 1.0446743965148926, 1.0451399087905884, 1.428841471672058, 1.0653305053710938, 1.0756282806396484, 1.4061059951782227, 1.0162315368652344, 1.2216335535049438, 1.0045101642608643, 1.097844123840332, 1.3550547361373901, 1.188034176826477, 1.109400987625122, 1.1066974401474, 1.1690140962600708, 1.4076738357543945, 1.198163390159607, 1.2430555820465088, 1.0778720378875732, 1.077467918395996, 1.0449298620224, 1.1973905563354492, 1.0558668375015259, 1.1468830108642578, 1.3867242336273193, 1.0380276441574097, 1.0053441524505615, 1.1143473386764526, 1.0808333158493042, 1.0116310119628906, 1.0002282857894897, 1.09364914894104, 1.3861461877822876, 1.0224804878234863, 1.1434108018875122, 1.1352570056915283, 1.0384305715560913, 1.1171001195907593, 1.0382366180419922, 1.0026415586471558, 1.0645734071731567, 1.3548387289047241, 1.1082918643951416, 1.0202243328094482, 1.255069613456726, 1.1363664865493774, 1.4215246438980103, 1.0815857648849487, 1.0864732265472412, 1.6536223888397217, 1.0782958269119263, 1.0125412940979004, 1.3612078428268433, 1.1553138494491577, 1.1003427505493164, 1.0654562711715698, 1.2580162286758423, 1.0671252012252808, 1.1076135635375977, 1.0927391052246094, 1.0167895555496216, 1.0842273235321045, 1.1449837684631348, 1.1357688903808594, 1.3436970710754395, 1.0862809419631958, 1.164102554321289, 1.0102968215942383, 1.028857946395874, 1.143853783607483, 1.2200956344604492, 1.3719298839569092, 1.1472948789596558, 1.556909203529358, 1.2377266883850098, 1.0974544286727905, 1.146980881690979, 1.4273052215576172, 1.3892029523849487, 1.182657241821289, 1.030725121498108, 1.0801252126693726, 1.1292661428451538, 1.1722809076309204, 1.418197512626648, 1.1092371940612793, 1.0557265281677246, 1.1266433000564575, 1.337837815284729, 1.068987488746643, 1.174739122390747, 1.0729752779006958, 1.0842061042785645, 1.0375330448150635, 1.2244318723678589, 1.028086543083191, 1.0413165092468262, 1.1460392475128174, 1.1678297519683838, 1.2903602123260498, 1.0335289239883423, 1.040560007095337, 1.0194214582443237, 1.1541168689727783, 1.0242798328399658, 1.0940171480178833, 1.0333251953125, 1.1178861856460571, 1.0537763833999634, 1.355500340461731, 1.0096724033355713, 1.0308542251586914, 1.1074309349060059, 1.2834395170211792, 1.1101957559585571, 1.0869696140289307, 1.0372756719589233, 1.079296588897705, 1.243141531944275, 1.6244897842407227, 1.8808016777038574, 1.1384330987930298, 1.0678428411483765, 1.119347095489502, 1.037176489830017, 1.0524920225143433, 1.0683010816574097, 1.19241201877594, 1.1039962768554688, 1.0584932565689087, 1.0534486770629883, 1.115325689315796, 1.5361446142196655, 1.061164140701294, 1.1397455930709839, 1.0725394487380981, 1.0177851915359497, 1.015852928161621, 1.1526260375976562, 1.0128003358840942, 1.0508230924606323, 1.17362642288208, 1.2521777153015137, 1.2992125749588013, 1.0838327407836914, 1.1931864023208618, 1.0253441333770752, 1.0395843982696533, 1.001967430114746, 1.1255320310592651, 1.081545352935791, 1.0457477569580078, 1.0828577280044556, 1.059192419052124, 1.0481417179107666, 1.3324531316757202, 1.0153605937957764, 1.076451301574707, 1.3675538301467896, 1.0778748989105225, 1.0152404308319092, 1.0650501251220703, 1.106382966041565, 1.3060194253921509, 1.1521981954574585, 1.1699172258377075, 1.5319149494171143, 1.1472218036651611, 1.0732226371765137, 1.5373916625976562, 1.3863306045532227, 1.7583869695663452, 1.2574214935302734, 1.102331519126892, 1.372654914855957, 1.029935359954834, 1.1278430223464966, 1.0657809972763062, 1.1933465003967285, 1.8953542709350586, 1.0301491022109985, 1.111644983291626, 1.3251644372940063, 1.1054158210754395, 1.2910568714141846, 1.1016026735305786]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7369823455810547] ms
 --  Average per query NF    [1.3577771186828613] ms
 --  Average per query vegas [2.3792052268981934] ms
Mean [1.158]  Median [1.107]  95th [1.427]  99th [1.760]  max [1.895]
Mean [1.158]  Median [1.107]  95th [1.427]  99th [1.760]  max [1.895]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.248038 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=0 | total-time=26.189099