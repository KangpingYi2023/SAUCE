Input arguments = Namespace(data_update='sample', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 52, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.160252094268799
tensor(0.9949)
result is  tensor(380226.6250)
Enter testHyper
ReportEsts: [1.1359575986862183, 1.0803053379058838, 1.2558295726776123, 1.0482206344604492, 1.2229573726654053, 1.1814247369766235, 1.1285666227340698, 1.2128015756607056, 1.1046831607818604, 1.0492701530456543, 1.0256184339523315, 1.1769068241119385, 1.0182461738586426, 1.0825892686843872, 1.1073832511901855, 1.2807971239089966, 1.1308809518814087, 1.2040380239486694, 1.1523693799972534, 1.0280612707138062, 1.0981985330581665, 1.000508189201355, 1.1384484767913818, 1.0440306663513184, 1.0645266771316528, 1.2206147909164429, 1.130912184715271, 1.3124746084213257, 1.010512113571167, 1.0076289176940918, 1.1397658586502075, 1.3405894041061401, 1.0936144590377808, 1.0200035572052002, 1.2005023956298828, 1.0384302139282227, 1.569259762763977, 1.1234641075134277, 1.004126787185669, 1.044925570487976, 1.0047944784164429, 1.0626511573791504, 1.0414559841156006, 1.0080794095993042, 1.0912740230560303, 1.0136054754257202, 1.0990395545959473, 1.025106430053711, 1.0027281045913696, 1.1387479305267334, 1.1760203838348389, 1.3606716394424438, 1.0207804441452026, 1.1632353067398071, 1.1251177787780762, 1.0055943727493286, 1.2551401853561401, 1.2449345588684082, 1.1155585050582886, 1.4728237390518188, 1.3376449346542358, 1.1700717210769653, 1.3547545671463013, 1.0170024633407593, 1.3360323905944824, 1.0571428537368774, 1.1578947305679321, 1.2121775150299072, 1.0070325136184692, 1.2315789461135864, 1.032984733581543, 1.197105884552002, 1.3702483177185059, 1.0886427164077759, 1.1583362817764282, 1.0110892057418823, 1.8202942609786987, 1.0069674253463745, 1.0741552114486694, 1.284616470336914, 1.3612427711486816, 1.0738167762756348, 1.0569735765457153, 1.158028483390808, 1.2652391195297241, 1.1478240489959717, 1.180881381034851, 1.2459521293640137, 1.0348528623580933, 1.075296401977539, 1.0706015825271606, 1.2889552116394043, 1.0010818243026733, 1.2520473003387451, 1.0540540218353271, 1.1691999435424805, 1.1392961740493774, 1.4033679962158203, 1.034482717514038, 1.082857370376587, 1.2205662727355957, 1.2067601680755615, 1.1066911220550537, 1.0161054134368896, 1.0739539861679077, 1.0344387292861938, 1.1639710664749146, 1.1762652397155762, 1.0197827816009521, 1.0437394380569458, 1.176827311515808, 1.1035782098770142, 1.30959153175354, 1.0495965480804443, 1.2270777225494385, 1.1522842645645142, 1.011669635772705, 1.0857023000717163, 1.2742335796356201, 1.0124211311340332, 1.2327224016189575, 1.1110115051269531, 1.1545642614364624, 1.239819884300232, 1.2286821603775024, 1.2303961515426636, 1.1905720233917236, 1.066204309463501, 1.2117646932601929, 1.1132264137268066, 1.1851005554199219, 1.248621940612793, 1.145742654800415, 1.5357142686843872, 1.054583191871643, 1.057495355606079, 1.0410211086273193, 1.0656911134719849, 1.0721616744995117, 1.2349903583526611, 1.1483896970748901, 1.138211727142334, 1.116263747215271, 1.2492148876190186, 1.0584832429885864, 1.124584674835205, 1.1085319519042969, 1.5632641315460205, 1.0576379299163818, 1.069886326789856, 1.0307879447937012, 1.1610050201416016, 1.2888540029525757, 1.0976803302764893, 1.0722535848617554, 1.0072914361953735, 1.0422543287277222, 1.0174450874328613, 1.0656267404556274, 1.229006290435791, 1.2036131620407104, 1.0396416187286377, 1.1199012994766235, 1.2476698160171509, 1.3428164720535278, 1.0858125686645508, 1.2091130018234253, 1.2756255865097046, 1.019788146018982, 1.0808298587799072, 1.0275698900222778, 1.0637422800064087, 1.1298701763153076, 1.2159059047698975, 1.107629418373108, 1.003173589706421, 1.013293981552124, 1.1420398950576782, 1.1759673357009888, 1.036553144454956, 1.0161750316619873, 1.042312502861023, 1.008546233177185, 1.1287027597427368, 1.0796812772750854, 1.1257928609848022, 1.0323467254638672, 1.2727594375610352, 1.063336968421936, 1.4154446125030518, 1.023558497428894, 1.1207473278045654, 1.5473028421401978, 1.0292195081710815, 1.8303030729293823, 1.2447013854980469, 1.149062156677246, 1.1343283653259277, 1.0399682521820068, 1.080644130706787]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.677222728729248] ms
 --  Average per query NF    [1.3623952865600586] ms
 --  Average per query vegas [2.3148274421691895] ms
Mean [1.146]  Median [1.118]  95th [1.362]  99th [1.572]  max [1.830]
Mean [1.146]  Median [1.118]  95th [1.362]  99th [1.572]  max [1.830]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.781431 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=sample', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
Sample - START
Sample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[5.9604645e-08 3.5762787e-07 2.9802322e-07 5.9604645e-08 4.1723251e-07]
Distance score: 2.384185791015625e-07
SAUCE Drift detection: False
Detection latency: 0.0237s

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.026900 | Model-update-time: 0.000000


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=sample', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.212379455566406
tensor(0.9925)
result is  tensor(455164.1250)
Enter testHyper
ReportEsts: [1.1167432069778442, 1.0162694454193115, 1.1745810508728027, 1.062734842300415, 1.081269383430481, 1.5794684886932373, 1.0320745706558228, 1.048844575881958, 1.0088495016098022, 1.098516583442688, 1.0834020376205444, 1.1888244152069092, 1.309333324432373, 1.1853102445602417, 1.1001125574111938, 1.0681885480880737, 1.1690921783447266, 1.0786494016647339, 1.0573405027389526, 1.402002215385437, 1.1311742067337036, 1.6890244483947754, 1.1234753131866455, 1.187914490699768, 1.0458368062973022, 1.1104086637496948, 1.092356562614441, 1.14009428024292, 1.0281895399093628, 1.326952576637268, 1.0419716835021973, 1.3219177722930908, 1.1063122749328613, 1.1697468757629395, 1.0782444477081299, 1.0968379974365234, 1.2330195903778076, 1.3094534873962402, 1.3386712074279785, 1.070697546005249, 1.0140172243118286, 1.0302702188491821, 1.4034401178359985, 1.0787760019302368, 1.0225841999053955, 1.1732550859451294, 2.8380565643310547, 1.0122286081314087, 1.04365074634552, 1.1575459241867065, 1.0227609872817993, 1.1219111680984497, 1.0346062183380127, 1.0417215824127197, 1.0490912199020386, 1.3395960330963135, 1.278562068939209, 1.142092227935791, 1.2098453044891357, 1.0951132774353027, 1.2667983770370483, 1.0672948360443115, 1.0634920597076416, 1.5654356479644775, 1.0337647199630737, 1.0711114406585693, 1.3487523794174194, 1.1234641075134277, 1.136715292930603, 1.0564814805984497, 1.0255227088928223, 1.2082668542861938, 1.0256367921829224, 1.0550503730773926, 1.1475040912628174, 1.0189064741134644, 1.3273481130599976, 1.202427864074707, 1.2302398681640625, 1.1333813667297363, 1.23828125, 1.0642623901367188, 1.0265158414840698, 1.1230231523513794, 1.303966760635376, 1.4064748287200928, 1.1381837129592896, 1.6379562616348267, 1.125307321548462, 1.1143122911453247, 1.1044660806655884, 1.040510892868042, 1.3207026720046997, 1.099084734916687, 1.0902305841445923, 1.0380492210388184, 1.2857396602630615, 1.166182518005371, 1.3158586025238037, 1.109739899635315, 1.141150712966919, 1.160215973854065, 1.1937799453735352, 1.0026209354400635, 1.2427400350570679, 1.1606905460357666, 1.0425302982330322, 1.0109198093414307, 1.1724138259887695, 1.0953768491744995, 1.037651777267456, 1.005528450012207, 1.1407073736190796, 1.3066903352737427, 1.0988125801086426, 1.3638439178466797, 1.0948154926300049, 1.4303606748580933, 1.0739299058914185, 1.0272108316421509, 1.1118806600570679, 1.0445259809494019, 1.0996835231781006, 1.511199951171875, 1.0636123418807983, 1.150201439857483, 1.3081262111663818, 1.295418620109558, 1.0177943706512451, 1.1158016920089722, 1.2277361154556274, 1.1187933683395386, 1.2114136219024658, 2.1134846210479736, 1.969832420349121, 1.0402560234069824, 1.0868761539459229, 1.0360009670257568, 1.059334635734558, 1.0125913619995117, 1.0744938850402832, 1.2548413276672363, 1.0669058561325073, 1.037917137145996, 1.0161772966384888, 1.1285399198532104, 1.6645569801330566, 1.0196220874786377, 1.1883125305175781, 1.0829565525054932, 1.018836259841919, 1.0501587390899658, 1.0531340837478638, 1.043750286102295, 1.0195242166519165, 1.2982456684112549, 1.1269546747207642, 1.312000036239624, 1.0877432823181152, 1.0162957906723022, 1.0502738952636719, 1.1298701763153076, 1.274976134300232, 1.0503202676773071, 1.1206356287002563, 1.0156856775283813, 1.0628889799118042, 1.201762080192566, 1.007698893547058, 1.3079745769500732, 1.045335054397583, 1.1499727964401245, 1.727128028869629, 1.107001781463623, 1.1687037944793701, 1.1830166578292847, 1.1559419631958008, 1.0043580532073975, 1.0019588470458984, 1.0298771858215332, 1.4680850505828857, 1.1083403825759888, 1.0434986352920532, 1.571921944618225, 1.3956282138824463, 1.0755645036697388, 1.317780613899231, 1.020355463027954, 1.3260091543197632, 1.0407931804656982, 1.1645855903625488, 1.0324088335037231, 1.2353920936584473, 2.151132106781006, 1.064241647720337, 1.1553032398223877, 1.2214158773422241, 1.1858108043670654, 1.2257053852081299, 1.158328890800476]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7133359909057617] ms
 --  Average per query NF    [1.3594257831573486] ms
 --  Average per query vegas [2.353910207748413] ms
Mean [1.176]  Median [1.115]  95th [1.566]  99th [2.114]  max [2.838]
Mean [1.176]  Median [1.115]  95th [1.566]  99th [2.114]  max [2.838]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.236761 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=0 | total-time=26.089274