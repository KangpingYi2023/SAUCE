Input arguments = Namespace(data_update='sample', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 16, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.16669511795044
tensor(0.9984)
result is  tensor(381553.5312)
Enter testHyper
ReportEsts: [1.1533446311950684, 1.0034087896347046, 1.314178228378296, 1.049062967300415, 1.2610501050949097, 1.1510146856307983, 1.2516758441925049, 1.1872044801712036, 1.0782790184020996, 1.0572926998138428, 1.0206718444824219, 1.116949200630188, 1.0575172901153564, 1.0357142686843872, 1.185597538948059, 1.297011137008667, 1.4432703256607056, 1.116389513015747, 1.1374642848968506, 1.1045918464660645, 1.1289397478103638, 1.042285680770874, 1.1348503828048706, 1.0743052959442139, 1.0905823707580566, 1.0840867757797241, 1.0869932174682617, 1.3669065237045288, 1.0005743503570557, 1.0331604480743408, 1.1206101179122925, 1.2709085941314697, 1.1116572618484497, 1.0270708799362183, 1.200255274772644, 1.009868860244751, 1.1372113227844238, 1.1259413957595825, 1.0735262632369995, 1.0034852027893066, 1.0895490646362305, 1.076923131942749, 1.095003366470337, 1.009232997894287, 1.0483837127685547, 1.0464853048324585, 1.1725550889968872, 1.3839445114135742, 1.0127313137054443, 1.1082910299301147, 1.2163587808609009, 1.3403308391571045, 1.2051360607147217, 1.1254980564117432, 1.0927780866622925, 1.0356976985931396, 1.2925233840942383, 1.1506192684173584, 1.075891375541687, 1.4329320192337036, 1.536185622215271, 1.2437334060668945, 1.2465944290161133, 1.1989498138427734, 1.3147410154342651, 1.0571428537368774, 1.202301025390625, 1.0077306032180786, 1.1377485990524292, 1.263157844543457, 1.0454163551330566, 1.014909267425537, 1.049057126045227, 1.191603183746338, 1.171209692955017, 1.1923019886016846, 2.2151284217834473, 1.0715477466583252, 1.0030510425567627, 1.5487184524536133, 1.0964683294296265, 1.0497496128082275, 1.0109208822250366, 1.1542959213256836, 1.2117513418197632, 1.0547549724578857, 1.1646640300750732, 1.1708449125289917, 1.0194752216339111, 1.1935484409332275, 1.0743223428726196, 1.2918198108673096, 1.01694917678833, 1.2950588464736938, 1.0833333730697632, 1.136450171470642, 1.1600741147994995, 1.2361425161361694, 1.034482717514038, 1.189120888710022, 1.1633522510528564, 1.0056118965148926, 1.0490273237228394, 1.002936840057373, 1.0258368253707886, 1.0892415046691895, 1.2152866125106812, 1.1884816884994507, 1.0578988790512085, 1.0284157991409302, 1.3731439113616943, 1.089219331741333, 1.3884531259536743, 1.101240873336792, 1.1494146585464478, 1.008888840675354, 1.0493876934051514, 1.0484973192214966, 1.4126081466674805, 1.1297879219055176, 1.3264174461364746, 1.0785841941833496, 1.1214243173599243, 1.2307283878326416, 1.2407945394515991, 1.229673981666565, 1.1777182817459106, 1.1533828973770142, 1.3856502771377563, 1.1299265623092651, 1.1786531209945679, 1.188058614730835, 1.1591050624847412, 1.5357142686843872, 1.167285442352295, 1.043318510055542, 1.0601083040237427, 1.036747932434082, 1.1080951690673828, 1.085698127746582, 1.1633729934692383, 1.107457160949707, 1.0563424825668335, 1.2739306688308716, 1.0892223119735718, 1.1341235637664795, 1.0656465291976929, 1.4846506118774414, 1.141234278678894, 1.1101562976837158, 1.11531662940979, 1.222407341003418, 1.302485466003418, 1.1312428712844849, 1.1557613611221313, 1.075156807899475, 1.0884250402450562, 1.0486775636672974, 1.0193120241165161, 1.1327364444732666, 1.0917993783950806, 1.08678138256073, 1.2726632356643677, 1.2526737451553345, 1.2896175384521484, 1.118115782737732, 1.130462408065796, 1.2437266111373901, 1.2581427097320557, 1.061684489250183, 1.0859825611114502, 1.0286415815353394, 1.1558442115783691, 1.078526496887207, 1.0524523258209229, 1.3296654224395752, 1.0748299360275269, 1.013128399848938, 1.1070973873138428, 1.051169514656067, 1.036515474319458, 1.0006449222564697, 1.0159071683883667, 1.1654750108718872, 1.107569694519043, 1.1363636255264282, 1.0039968490600586, 1.2241908311843872, 1.1129521131515503, 1.4330228567123413, 1.076138973236084, 1.0622084140777588, 1.6006730794906616, 1.405805230140686, 1.4328964948654175, 1.1618704795837402, 1.226427674293518, 1.1014492511749268, 1.0315425395965576, 1.1408698558807373]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7023520469665527] ms
 --  Average per query NF    [1.3612043857574463] ms
 --  Average per query vegas [2.3411476612091064] ms
Mean [1.155]  Median [1.121]  95th [1.414]  99th [1.549]  max [2.215]
Mean [1.155]  Median [1.121]  95th [1.414]  99th [1.549]  max [2.215]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.801123 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=sample', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
Sample - START
Sample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[5.9604645e-07 1.3709068e-06 4.1723251e-07 1.7881393e-07 1.1920929e-07]
Distance score: 5.364418029785156e-07
SAUCE Drift detection: False
Detection latency: 0.0233s

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.018648 | Model-update-time: 0.000000


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=sample', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.229001760482788
tensor(0.9972)
result is  tensor(457335.8438)
Enter testHyper
ReportEsts: [1.0203711986541748, 1.0740416049957275, 1.1279683113098145, 1.156480312347412, 1.036075234413147, 1.182061791419983, 1.11111581325531, 1.0607887506484985, 1.183300495147705, 1.1318492889404297, 1.0664438009262085, 1.237650990486145, 1.1803278923034668, 1.0478698015213013, 1.1134413480758667, 1.0206197500228882, 1.586309552192688, 1.0621436834335327, 1.0916731357574463, 1.3708808422088623, 1.1158344745635986, 1.682584285736084, 1.085472822189331, 1.118709683418274, 1.2149772644042969, 1.240958333015442, 1.0019108057022095, 1.1541353464126587, 1.2683533430099487, 1.199324369430542, 1.0882927179336548, 1.1791044473648071, 1.0049227476119995, 1.0398969650268555, 1.075399398803711, 1.1202547550201416, 1.042203426361084, 1.3298553228378296, 1.2214586734771729, 1.089539885520935, 1.0339137315750122, 1.0329787731170654, 1.0164250135421753, 1.0083370208740234, 1.069429874420166, 1.0791786909103394, 1.3425320386886597, 1.0459591150283813, 1.1325300931930542, 1.0819672346115112, 1.0945695638656616, 1.0218286514282227, 1.0647040605545044, 1.046984314918518, 1.0391117334365845, 1.3438315391540527, 1.0844639539718628, 1.0595805644989014, 1.254719614982605, 1.1652441024780273, 1.4253393411636353, 1.0499669313430786, 1.0479224920272827, 1.678138256072998, 1.0056731700897217, 1.0542088747024536, 1.025028944015503, 1.0852066278457642, 1.1323298215866089, 1.1025760173797607, 1.1021722555160522, 1.1248023509979248, 1.0052465200424194, 1.0720547437667847, 1.004892349243164, 1.3584859371185303, 1.1226606369018555, 1.1464849710464478, 1.2959107160568237, 1.030874490737915, 1.269698143005371, 1.0997103452682495, 1.0495579242706299, 1.2121433019638062, 1.2391064167022705, 1.3816254138946533, 1.1600866317749023, 1.4241653680801392, 1.1194636821746826, 1.0983809232711792, 1.1588709354400635, 1.1012853384017944, 1.2995232343673706, 1.0520555973052979, 1.1189442873001099, 1.0407577753067017, 1.030508041381836, 1.1597552299499512, 1.012803077697754, 1.086357831954956, 1.2551627159118652, 1.1110060214996338, 1.0970654487609863, 1.0498311519622803, 1.1564654111862183, 1.1231231689453125, 1.0498558282852173, 1.030531406402588, 1.1926345825195312, 1.1488009691238403, 1.1007556915283203, 1.0792577266693115, 1.186959981918335, 1.172083854675293, 1.0729470252990723, 1.0981117486953735, 1.0362964868545532, 1.0089436769485474, 1.0064067840576172, 1.0650407075881958, 1.126612901687622, 1.1422616243362427, 1.0541753768920898, 1.4877082109451294, 1.0253485441207886, 1.1859462261199951, 1.230101227760315, 1.1885370016098022, 1.0151718854904175, 1.0202388763427734, 1.1611855030059814, 1.139000654220581, 1.0476899147033691, 1.9084336757659912, 1.4899497032165527, 1.1831064224243164, 1.050469994544983, 1.0073331594467163, 1.0877039432525635, 1.0234603881835938, 1.137249231338501, 1.232871174812317, 1.0200626850128174, 1.053675651550293, 1.012014627456665, 1.1652570962905884, 1.415204644203186, 1.032576322555542, 1.229692816734314, 1.0428415536880493, 1.1915026903152466, 1.0762943029403687, 1.1174182891845703, 1.0354633331298828, 1.0360767841339111, 1.0207363367080688, 1.135820746421814, 1.2992125749588013, 1.013187050819397, 1.1456576585769653, 1.0386619567871094, 1.0662778615951538, 1.1112215518951416, 1.0909734964370728, 1.1659059524536133, 1.0570824146270752, 1.0334206819534302, 1.134641408920288, 1.149639368057251, 1.2548714876174927, 1.2660365104675293, 1.1040027141571045, 1.5857558250427246, 1.0446768999099731, 1.036277413368225, 1.0762149095535278, 1.1517910957336426, 1.1056602001190186, 1.0920534133911133, 1.0269758701324463, 1.3958333730697632, 1.127905011177063, 1.0562738180160522, 1.491377592086792, 1.2923080921173096, 1.0472806692123413, 1.4075770378112793, 1.163248062133789, 1.2995132207870483, 1.062372088432312, 1.2802716493606567, 1.0408384799957275, 1.2214082479476929, 2.3123209476470947, 1.0491572618484497, 1.0261648893356323, 1.1212078332901, 1.1246105432510376, 1.371727705001831, 1.2231289148330688]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.739830255508423] ms
 --  Average per query NF    [1.3583827018737793] ms
 --  Average per query vegas [2.3814475536346436] ms
Mean [1.149]  Median [1.103]  95th [1.424]  99th [1.685]  max [2.312]
Mean [1.149]  Median [1.103]  95th [1.424]  99th [1.685]  max [2.312]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.259210 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=0 | total-time=26.127975