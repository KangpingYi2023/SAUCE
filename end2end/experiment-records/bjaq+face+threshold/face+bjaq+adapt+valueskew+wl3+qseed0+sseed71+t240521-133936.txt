Input arguments = Namespace(data_update='valueskew', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 71, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.168387413024902
tensor(0.9958)
result is  tensor(380574.5938)
Enter testHyper
ReportEsts: [1.1675753593444824, 1.0540226697921753, 1.6887279748916626, 1.221309781074524, 1.1988155841827393, 1.0922884941101074, 1.2289059162139893, 1.0155214071273804, 1.082808256149292, 1.1097036600112915, 1.1619293689727783, 1.1631356477737427, 1.031502604484558, 1.046875, 1.1132097244262695, 1.3974006175994873, 1.264738917350769, 1.2244656085968018, 1.118125319480896, 1.1403061151504517, 1.1731153726577759, 1.0015238523483276, 1.2285584211349487, 1.140047550201416, 1.2826921939849854, 1.1645569801330566, 1.0146396160125732, 1.5279091596603394, 1.003744125366211, 1.0306174755096436, 1.1252217292785645, 1.1636433601379395, 1.0631393194198608, 1.0688000917434692, 1.1402570009231567, 1.2141245603561401, 1.470352292060852, 1.2543268203735352, 1.1151190996170044, 1.041676640510559, 1.0595968961715698, 1.217223048210144, 1.0233944654464722, 1.0053060054779053, 1.0897951126098633, 1.0612244606018066, 1.124705195426941, 1.2148947715759277, 1.0246323347091675, 1.2030457258224487, 1.1943005323410034, 1.2871105670928955, 1.1184192895889282, 1.2013972997665405, 1.0948987007141113, 1.044969916343689, 1.3682242631912231, 1.1253201961517334, 1.2496318817138672, 1.45992112159729, 1.2621545791625977, 1.2285486459732056, 1.3962117433547974, 1.0927797555923462, 1.1870503425598145, 1.2285714149475098, 1.0990359783172607, 1.021788477897644, 1.0633432865142822, 1.4105262756347656, 1.0255775451660156, 1.0265414714813232, 1.1400362253189087, 1.0268903970718384, 1.1554619073867798, 1.2882540225982666, 2.0738706588745117, 1.0156359672546387, 1.0198626518249512, 1.182405710220337, 1.2851800918579102, 1.1329349279403687, 1.0003365278244019, 1.2177693843841553, 1.236011266708374, 1.0156049728393555, 1.009737491607666, 1.0562925338745117, 1.1836146116256714, 1.027199625968933, 1.1139147281646729, 1.2887353897094727, 1.0142648220062256, 1.219587802886963, 1.0372340679168701, 1.0005238056182861, 1.1118063926696777, 1.4161841869354248, 1.034482717514038, 1.1817245483398438, 1.1584157943725586, 1.0020157098770142, 1.1900025606155396, 1.0014641284942627, 1.0221757888793945, 1.0229967832565308, 1.1105966567993164, 1.1675392389297485, 1.0536203384399414, 1.0505564212799072, 1.35905921459198, 1.0943044424057007, 1.1980113983154297, 1.0166304111480713, 1.0453168153762817, 1.15816330909729, 1.0786361694335938, 1.0185734033584595, 1.3631317615509033, 1.0030913352966309, 1.2301390171051025, 1.091831088066101, 1.1375608444213867, 1.1756484508514404, 1.2296512126922607, 1.2161576747894287, 1.166110634803772, 1.2525376081466675, 1.2907267808914185, 1.1255844831466675, 1.0898540019989014, 1.1389343738555908, 1.168427586555481, 1.4285714626312256, 1.1451019048690796, 1.1727488040924072, 1.0609381198883057, 1.0240650177001953, 1.03800368309021, 1.1794081926345825, 1.103389859199524, 1.0869345664978027, 1.0362977981567383, 1.2418482303619385, 1.0308195352554321, 1.0371553897857666, 1.0152666568756104, 1.5015538930892944, 1.161402702331543, 1.0110795497894287, 1.172888159751892, 1.1481860876083374, 1.316408395767212, 1.0466517210006714, 1.0314838886260986, 1.094632863998413, 1.1636152267456055, 1.0002813339233398, 1.0029915571212769, 1.152491807937622, 1.0438902378082275, 1.0166900157928467, 1.0506563186645508, 1.319718360900879, 1.1625615358352661, 1.1145631074905396, 1.0873658657073975, 1.2272104024887085, 1.0088331699371338, 1.008305549621582, 1.1057401895523071, 1.012555718421936, 1.1753246784210205, 1.1660257577896118, 1.0728882551193237, 1.0182422399520874, 1.0457316637039185, 1.0826631784439087, 1.3352134227752686, 1.203648328781128, 1.1262924671173096, 1.0451643466949463, 1.0337109565734863, 1.121552586555481, 1.1542918682098389, 1.132135272026062, 1.0297240018844604, 1.262473702430725, 1.1044857501983643, 1.3719937801361084, 1.0890623331069946, 1.0914634466171265, 1.5820399522781372, 1.2735776901245117, 1.7988427877426147, 1.1074285507202148, 1.1280533075332642, 1.1014492511749268, 1.0375425815582275, 1.0478419065475464]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.733443021774292] ms
 --  Average per query NF    [1.3550901412963867] ms
 --  Average per query vegas [2.3783528804779053] ms
Mean [1.151]  Median [1.123]  95th [1.411]  99th [1.690]  max [2.074]
Mean [1.151]  Median [1.123]  95th [1.411]  99th [1.690]  max [2.074]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.850174 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=valueskew', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
ValueSample - START
ValueSample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[3.5166740e-06 4.0531158e-06 1.0728836e-06 1.0025263e-02 1.0728836e-06]
Distance score: 0.0020069957245141268
SAUCE Drift detection: True
Detection latency: 0.0233s

DRIFT-DETECTED after 2-th workload
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/incremental_train.py', '--dataset=bjaq', '--end2end', '--model=face', '--model_update=adapt', '--update_size=80000', '--epochs=0']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
update_size: 76433
AdaptTask - START
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
train data shape: 80000, transfer data shape:16000
Training done; evaluating likelihood on full data:
Saved to: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
AdaptTask - END

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.058557 | Model-update-time: 2.224264


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=valueskew', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.16268539428711
tensor(0.9956)
result is  tensor(456598.9062)
Enter testHyper
ReportEsts: [1.0666801929473877, 1.0720703601837158, 1.0412979125976562, 1.2583063840866089, 1.150213599205017, 1.266304850578308, 1.0524910688400269, 1.1369134187698364, 1.1439841985702515, 1.3148459196090698, 1.0235202312469482, 1.1081904172897339, 1.0668257474899292, 1.0030333995819092, 1.091356873512268, 1.012271761894226, 1.0391662120819092, 1.0481454133987427, 1.2111656665802002, 1.3692994117736816, 1.031026840209961, 1.7187817096710205, 1.8623833656311035, 1.755943775177002, 1.0374901294708252, 1.317095160484314, 1.0512161254882812, 1.1911487579345703, 1.3221830129623413, 1.4292722940444946, 1.3583916425704956, 1.7118643522262573, 1.017408847808838, 1.2092523574829102, 1.085959553718567, 1.1054894924163818, 1.037328839302063, 1.1211215257644653, 1.1943916082382202, 1.087080478668213, 1.3000050783157349, 1.1312882900238037, 31.42934799194336, 1.0169408321380615, 1.0370680093765259, 1.1587746143341064, 1.1603866815567017, 1.091639518737793, 1.2857142686843872, 1.2575911283493042, 1.0744688510894775, 1.2792807817459106, 1.214071273803711, 1.1700010299682617, 1.0133939981460571, 1.1849678754806519, 1.0040991306304932, 1.0155726671218872, 1.0411466360092163, 1.0538535118103027, 1.4068241119384766, 1.0406217575073242, 1.0031152963638306, 1.6410117149353027, 1.0778571367263794, 1.0293776988983154, 1.101784348487854, 1.0328606367111206, 1.0218515396118164, 1.0701133012771606, 1.0903308391571045, 1.0600767135620117, 1.126198172569275, 1.232964277267456, 1.3971593379974365, 1.277511477470398, 1.0644745826721191, 2.3205127716064453, 1.0220179557800293, 1.1268019676208496, 6.447205066680908, 1.102728009223938, 1.0416990518569946, 1.1086152791976929, 1.1308748722076416, 1.3476701974868774, 1.0720645189285278, 1.3262486457824707, 1.3181072473526, 1.0104905366897583, 1.01374089717865, 1.312367558479309, 1.0749082565307617, 1.2319581508636475, 56.221923828125, 1.1002901792526245, 1.3553173542022705, 1.2736119031906128, 1.053452730178833, 1.0720003843307495, 1.264054298400879, 1.140066146850586, 1.0073529481887817, 1.0111749172210693, 1.4467953443527222, 1.890971064567566, 1.0187410116195679, 1.062455177307129, 1.0458452701568604, 1.0367028713226318, 1.311077356338501, 1.1762458086013794, 1.012184977531433, 1.0214109420776367, 1.1456431150436401, 6.805749416351318, 1.0366687774658203, 1.2402266263961792, 1.037508487701416, 1.4070796966552734, 1.0880035161972046, 1.1851311922073364, 1.1388309001922607, 1.3526891469955444, 1.0499351024627686, 1.4991562366485596, 1.0191400051116943, 1.0959349870681763, 1.0402880907058716, 1.16075599193573, 1.0659619569778442, 1.0553350448608398, 1.1171836853027344, 1.82271146774292, 1.5040568113327026, 1.13262140750885, 1.0833982229232788, 2.854438066482544, 1.027384638786316, 1.0002796649932861, 1.108263373374939, 1.1926110982894897, 1.1043518781661987, 1.0810267925262451, 1.0656712055206299, 4.264708995819092, 1.192090392112732, 1.1337250471115112, 1.153151035308838, 1.0421854257583618, 47.86069107055664, 1.261213779449463, 1.478043556213379, 1.1606279611587524, 1.0366008281707764, 1.1948813199996948, 1.0136735439300537, 1.0703125, 2.9424893856048584, 1.0704565048217773, 1.0512911081314087, 1.0755555629730225, 1.2673670053482056, 1.0915520191192627, 1.0677763223648071, 1.069437861442566, 1.0446999073028564, 1.2442322969436646, 1.0468227863311768, 1.1185564994812012, 1.0164681673049927, 1.0241777896881104, 1.7341365814208984, 1.0015337467193604, 2.0955066680908203, 1.0526940822601318, 1.0203337669372559, 1.225853443145752, 1.1083567142486572, 1.011431097984314, 1.8421052694320679, 1.3799434900283813, 1.0070379972457886, 1.7938288450241089, 1.2968460321426392, 1.0503865480422974, 1.319839358329773, 1.1018892526626587, 1.4045127630233765, 1.0639972686767578, 1.0071994066238403, 1.1027883291244507, 1.1363394260406494, 2.019108295440674, 1.0024265050888062, 1.0327798128128052, 1.4072017669677734, 1.0908617973327637, 1.1070233583450317, 1.3227874040603638]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.6062073707580566] ms
 --  Average per query NF    [1.354360580444336] ms
 --  Average per query vegas [2.2518467903137207] ms
Mean [1.932]  Median [1.108]  95th [2.023]  99th [31.594]  max [56.222]
Mean [1.932]  Median [1.108]  95th [2.023]  99th [31.594]  max [56.222]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.324992 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=1 | total-time=28.516746