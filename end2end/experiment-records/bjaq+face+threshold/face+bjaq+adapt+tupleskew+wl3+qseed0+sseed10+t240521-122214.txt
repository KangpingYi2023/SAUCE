Input arguments = Namespace(data_update='tupleskew', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 10, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.166297197341919
tensor(0.9954)
result is  tensor(380403.4375)
Enter testHyper
ReportEsts: [1.2038460969924927, 1.0651137828826904, 1.213842511177063, 1.0294798612594604, 1.2499264478683472, 1.1504082679748535, 1.250169277191162, 1.1764308214187622, 1.1246494054794312, 1.1105029582977295, 1.1180016994476318, 1.1247881650924683, 1.0328720808029175, 1.03125, 1.2045361995697021, 1.4801437854766846, 1.339969277381897, 1.18230402469635, 1.2396328449249268, 1.1224489212036133, 1.0216022729873657, 1.0427701473236084, 1.103914737701416, 1.1297718286514282, 1.0757983922958374, 1.068716049194336, 1.0836148262023926, 1.36517333984375, 1.0321654081344604, 1.0846302509307861, 1.1802057027816772, 1.1983585357666016, 1.1389451026916504, 1.0628594160079956, 1.100024700164795, 1.1673895120620728, 1.42499577999115, 1.096908450126648, 1.1189429759979248, 1.2039520740509033, 1.0885188579559326, 1.1279631853103638, 1.0034244060516357, 1.1644772291183472, 1.0418338775634766, 1.0136054754257202, 1.08077073097229, 1.3465766906738281, 1.0321049690246582, 1.1099830865859985, 1.1820513010025024, 1.3489116430282593, 1.0298229455947876, 1.120396614074707, 1.2094721794128418, 1.0380172729492188, 1.3607476949691772, 1.1265804767608643, 1.1983424425125122, 1.405735969543457, 1.3529762029647827, 1.1222639083862305, 1.3046048879623413, 1.2202208042144775, 1.1418684720993042, 1.085714340209961, 1.106796145439148, 1.03267502784729, 1.0985794067382812, 1.3894736766815186, 1.1068565845489502, 1.120644211769104, 1.2688994407653809, 1.3789372444152832, 1.185283899307251, 1.0521130561828613, 1.878966212272644, 1.0074381828308105, 1.0428295135498047, 1.414533257484436, 1.1044080257415771, 1.0841543674468994, 1.0634719133377075, 1.2477105855941772, 1.2478621006011963, 1.092257022857666, 1.0686078071594238, 1.0815637111663818, 1.0171973705291748, 1.0812337398529053, 1.043763518333435, 1.2775148153305054, 1.0187522172927856, 1.3067426681518555, 1.1818181276321411, 1.0756573677062988, 1.2932639122009277, 1.3491188287734985, 1.01694917678833, 1.1527010202407837, 1.160056710243225, 1.0390825271606445, 1.0167642831802368, 1.0117130279541016, 1.138075351715088, 1.0670827627182007, 1.0057564973831177, 1.165794014930725, 1.109239101409912, 1.0634182691574097, 1.1988393068313599, 1.1015037298202515, 1.4892677068710327, 1.0428837537765503, 1.0479888916015625, 1.15816330909729, 1.0912398099899292, 1.0301620960235596, 1.3440190553665161, 1.0269526243209839, 1.2981504201889038, 1.109562635421753, 1.2625858783721924, 1.232406497001648, 1.204457402229309, 1.2194592952728271, 1.0267690420150757, 1.0329625606536865, 1.3250428438186646, 1.1235804557800293, 1.065705418586731, 1.1521519422531128, 1.2541950941085815, 1.5, 1.2480002641677856, 1.1709109544754028, 1.0097891092300415, 1.0226138830184937, 1.0050352811813354, 1.244632363319397, 1.213599443435669, 1.0959655046463013, 1.1032698154449463, 1.274474859237671, 1.0094361305236816, 1.0861263275146484, 1.1298705339431763, 1.421201467514038, 1.066261887550354, 1.0396515130996704, 1.0475127696990967, 1.1638251543045044, 1.2915574312210083, 1.1431792974472046, 1.0681238174438477, 1.1263171434402466, 1.0688378810882568, 1.0166009664535522, 1.0139119625091553, 1.1289167404174805, 1.1376919746398926, 1.0566728115081787, 1.0037001371383667, 1.2526737451553345, 1.3801169395446777, 1.1228880882263184, 1.256284475326538, 1.1689244508743286, 1.198342204093933, 1.0484459400177002, 1.0523488521575928, 1.0666004419326782, 1.1558442115783691, 1.1078414916992188, 1.0521117448806763, 1.0459750890731812, 1.0009727478027344, 1.3073621988296509, 1.1027055978775024, 1.3263753652572632, 1.043789029121399, 1.0931026935577393, 1.0334094762802124, 1.1082737445831299, 1.1191596984863281, 1.1416490077972412, 1.021574854850769, 1.2501739263534546, 1.0232317447662354, 1.5146777629852295, 1.0425491333007812, 1.0391614437103271, 1.5494028329849243, 1.2636728286743164, 1.7045637369155884, 1.2817460298538208, 1.196790337562561, 1.0270270109176636, 1.06508207321167, 1.2276228666305542]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7779319286346436] ms
 --  Average per query NF    [1.3613998889923096] ms
 --  Average per query vegas [2.416532039642334] ms
Mean [1.156]  Median [1.121]  95th [1.406]  99th [1.551]  max [1.879]
Mean [1.156]  Median [1.121]  95th [1.406]  99th [1.551]  max [1.879]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.855209 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=tupleskew', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
TupleSkewSample - START
0.001
TupleSkewSample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[9.8347664e-06 1.9967556e-05 3.3140182e-05 9.2983246e-06 3.1828880e-05]
Distance score: 2.0813942683162168e-05
SAUCE Drift detection: True
Detection latency: 0.0229s

DRIFT-DETECTED after 2-th workload
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/incremental_train.py', '--dataset=bjaq', '--end2end', '--model=face', '--model_update=adapt', '--update_size=80000', '--epochs=0']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
update_size: 76433
AdaptTask - START
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
train data shape: 80000, transfer data shape:16000
Training done; evaluating likelihood on full data:
Saved to: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
AdaptTask - END

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 1.989207 | Model-update-time: 2.231544


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=tupleskew', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.20749282836914
tensor(0.9991)
result is  tensor(458183.0938)
Enter testHyper
ReportEsts: [1.0490366220474243, 1.0418705940246582, 1.316239356994629, 1.0468577146530151, 1.173703908920288, 1.1544311046600342, 1.2751357555389404, 1.102341890335083, 1.374650478363037, 1.0898038148880005, 1.0200344324111938, 1.0423940420150757, 2.2910053730010986, 1.3339282274246216, 1.0311118364334106, 1.0464812517166138, 1.0227553844451904, 1.1166365146636963, 1.0159226655960083, 1.3274980783462524, 1.1004875898361206, 1.1181433200836182, 1.1337002515792847, 1.1429115533828735, 1.1452949047088623, 1.2562825679779053, 1.028778314590454, 1.2040917873382568, 1.4731793403625488, 1.7620396614074707, 1.4207459688186646, 1.6440677642822266, 1.069632887840271, 1.0061941146850586, 1.0305005311965942, 1.020666480064392, 1.0675276517868042, 1.0526776313781738, 1.3116856813430786, 1.0079697370529175, 1.110075831413269, 1.2141350507736206, 1.1477749347686768, 1.0895928144454956, 1.0690518617630005, 1.1346735954284668, 1.4030077457427979, 1.0299079418182373, 1.3666666746139526, 1.0568788051605225, 1.0332785844802856, 1.0280412435531616, 1.0950419902801514, 1.1260135173797607, 1.0873258113861084, 1.0674210786819458, 1.0582419633865356, 1.0851614475250244, 1.2170957326889038, 1.1536517143249512, 1.2378753423690796, 1.0469542741775513, 1.091492772102356, 1.5151911973953247, 1.055039882659912, 1.236325740814209, 1.394366979598999, 1.0525097846984863, 1.2808860540390015, 1.036366581916809, 1.0859386920928955, 1.2225596904754639, 1.0716850757598877, 1.0249884128570557, 1.0556782484054565, 1.1137053966522217, 1.072440266609192, 1.0835801362991333, 1.2841981649398804, 1.1886518001556396, 1.2690520286560059, 1.0445427894592285, 1.0577908754348755, 1.1009249687194824, 1.4662293195724487, 1.5319149494171143, 1.4221419095993042, 1.692122459411621, 1.0011616945266724, 1.027131199836731, 1.0073684453964233, 1.3487573862075806, 1.377877950668335, 1.1582071781158447, 1.3321352005004883, 1.053000569343567, 1.0361571311950684, 1.4075039625167847, 1.1397680044174194, 1.0795893669128418, 1.0193058252334595, 1.1207115650177002, 1.7161571979522705, 1.085862398147583, 1.0530515909194946, 1.065949559211731, 1.0825802087783813, 1.0342934131622314, 1.1088825464248657, 1.0843557119369507, 1.1808208227157593, 1.0510903596878052, 1.1951535940170288, 1.2406288385391235, 1.1354866027832031, 1.1412492990493774, 1.0336121320724487, 1.1786905527114868, 1.015775203704834, 1.0796459913253784, 1.050528645515442, 1.2342679500579834, 1.2385213375091553, 1.7323734760284424, 1.0105819702148438, 1.1257356405258179, 1.2128952741622925, 1.0664557218551636, 1.0743809938430786, 1.0424418449401855, 1.163187026977539, 1.0927413702011108, 1.0755760669708252, 1.8432203531265259, 1.2572062015533447, 1.2005431652069092, 1.0069308280944824, 1.0605193376541138, 1.163748860359192, 1.0334527492523193, 1.164149284362793, 1.1001334190368652, 1.0446858406066895, 1.1420949697494507, 1.0452945232391357, 1.0990678071975708, 1.2411764860153198, 1.065993309020996, 1.1426478624343872, 1.1206271648406982, 1.127311110496521, 1.0509198904037476, 1.2736306190490723, 1.0586496591567993, 1.063087821006775, 1.0123982429504395, 1.1199207305908203, 1.0620155334472656, 1.1221808195114136, 1.2717047929763794, 1.0235650539398193, 1.4662054777145386, 1.3259893655776978, 1.0353353023529053, 1.0782427787780762, 1.1314705610275269, 1.0457690954208374, 1.5036462545394897, 1.1956543922424316, 1.200845718383789, 1.0793390274047852, 1.1037027835845947, 1.7554383277893066, 1.0441532135009766, 1.0596095323562622, 1.1220357418060303, 1.1908178329467773, 1.1039091348648071, 1.0840272903442383, 1.283768892288208, 1.8684210777282715, 1.2426388263702393, 1.1299009323120117, 1.3510618209838867, 1.33963143825531, 1.0599912405014038, 1.2596455812454224, 1.0925061702728271, 1.5555144548416138, 1.1120290756225586, 1.1274313926696777, 1.1033966541290283, 1.0869311094284058, 2.0932793617248535, 1.1166578531265259, 1.125558853149414, 1.3399087190628052, 1.1067296266555786, 1.1355060338974, 1.0732873678207397]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7451696395874023] ms
 --  Average per query NF    [1.3598084449768066] ms
 --  Average per query vegas [2.3853611946105957] ms
Mean [1.180]  Median [1.111]  95th [1.560]  99th [1.871]  max [2.291]
Mean [1.180]  Median [1.111]  95th [1.560]  99th [1.871]  max [2.291]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.419036 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=1 | total-time=28.519978