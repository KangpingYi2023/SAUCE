Input arguments = Namespace(data_update='sample', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 63, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.163076877593994
tensor(0.9933)
result is  tensor(379590.8438)
Enter testHyper
ReportEsts: [1.1592592000961304, 1.0650149583816528, 1.2071560621261597, 1.0393767356872559, 1.2400816679000854, 1.140196681022644, 1.2662131786346436, 1.070949673652649, 1.077957034111023, 1.1759076118469238, 1.1024978160858154, 1.1639831066131592, 1.1735237836837769, 1.0424107313156128, 1.1447312831878662, 1.1127480268478394, 1.1381136178970337, 1.143942952156067, 1.2104673385620117, 1.086734652519226, 1.023297905921936, 1.152495265007019, 1.1322262287139893, 1.08299720287323, 1.1678509712219238, 1.189873456954956, 1.0163288116455078, 1.4260485172271729, 1.036538004875183, 1.1167734861373901, 1.1181269884109497, 1.2365163564682007, 1.1155673265457153, 1.0788812637329102, 1.1749299764633179, 1.1390973329544067, 1.3422821760177612, 1.1621086597442627, 1.0471911430358887, 1.205269455909729, 1.027266502380371, 1.1781567335128784, 1.011757731437683, 1.0371413230895996, 1.0523980855941772, 1.0793651342391968, 1.1678640842437744, 1.2757171392440796, 1.012316107749939, 1.0033841133117676, 1.1912144422531128, 1.4481099843978882, 1.110978364944458, 1.1473745107650757, 1.235744595527649, 1.0616596937179565, 1.2532709836959839, 1.211917757987976, 1.1876684427261353, 1.397484302520752, 1.255505919456482, 1.2058460712432861, 1.276481032371521, 1.0713077783584595, 1.2313432693481445, 1.085714340209961, 1.1763602495193481, 1.064727783203125, 1.0591373443603516, 1.399999976158142, 1.0088495016098022, 1.074746012687683, 1.294028878211975, 1.2896614074707031, 1.11103093624115, 1.1777681112289429, 1.7621787786483765, 1.0071429014205933, 1.024622917175293, 1.3246164321899414, 1.076729655265808, 1.1473106145858765, 1.1000452041625977, 1.2536380290985107, 1.221278190612793, 1.0994921922683716, 1.0648137331008911, 1.0961412191390991, 1.1349228620529175, 1.060369849205017, 1.0180184841156006, 1.1813491582870483, 1.025964617729187, 1.2791075706481934, 1.1206896305084229, 1.0561861991882324, 1.144622802734375, 1.2758269309997559, 1.0166666507720947, 1.1776987314224243, 1.0804749727249146, 1.114447832107544, 1.1302450895309448, 1.0234260559082031, 1.1164226531982422, 1.0017586946487427, 1.1606634855270386, 1.1902269124984741, 1.0738885402679443, 1.0505564212799072, 1.2051846981048584, 1.085185170173645, 1.2387490272521973, 1.0009021759033203, 1.0671148300170898, 1.1237623691558838, 1.0564963817596436, 1.1390429735183716, 1.403182029724121, 1.0075923204421997, 1.3007655143737793, 1.1184628009796143, 1.0530773401260376, 1.123967170715332, 1.25, 1.208212971687317, 1.0568228960037231, 1.087660551071167, 1.301600694656372, 1.1055444478988647, 1.0161772966384888, 1.1896640062332153, 1.3206961154937744, 1.5, 1.1249909400939941, 1.0892622470855713, 1.0321961641311646, 1.2445528507232666, 1.1125041246414185, 1.190416932106018, 1.1573995351791382, 1.0131816864013672, 1.0837149620056152, 1.3419296741485596, 1.0291329622268677, 1.034957766532898, 1.046910285949707, 1.3883347511291504, 1.0367457866668701, 1.0637073516845703, 1.2009843587875366, 1.15562105178833, 1.302485466003418, 1.2377774715423584, 1.08904230594635, 1.0794819593429565, 1.2022342681884766, 1.0379853248596191, 1.0503768920898438, 1.3270068168640137, 1.267318844795227, 1.0084692239761353, 1.041758418083191, 1.232894778251648, 1.1859296560287476, 1.0072853565216064, 1.1890439987182617, 1.1978591680526733, 1.0536625385284424, 1.0522420406341553, 1.0147700309753418, 1.0349234342575073, 1.103896141052246, 1.022976040840149, 1.064713954925537, 1.0136514902114868, 1.0325559377670288, 1.27792489528656, 1.0813360214233398, 1.0259144306182861, 1.0936673879623413, 1.0917901992797852, 1.0114588737487793, 1.1072522401809692, 1.0974284410476685, 1.1205073595046997, 1.0669598579406738, 1.2745654582977295, 1.0259373188018799, 1.3347704410552979, 1.0399413108825684, 1.0737916231155396, 1.384428858757019, 1.0639269351959229, 1.9203052520751953, 1.1802679300308228, 1.2323884963989258, 1.0410958528518677, 1.148950219154358, 1.0282868146896362]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7413322925567627] ms
 --  Average per query NF    [1.367349624633789] ms
 --  Average per query vegas [2.3739826679229736] ms
Mean [1.145]  Median [1.117]  95th [1.344]  99th [1.503]  max [1.920]
Mean [1.145]  Median [1.117]  95th [1.344]  99th [1.503]  max [1.920]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.837223 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=sample', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
Sample - START
Sample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[1.7881393e-07 1.1920929e-07 1.7881393e-07 4.7683716e-07 1.1920929e-07]
Distance score: 2.1457671550706436e-07
SAUCE Drift detection: False
Detection latency: 0.0233s

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.018394 | Model-update-time: 0.000000


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=sample', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.168259859085083
tensor(0.9922)
result is  tensor(455004.6562)
Enter testHyper
ReportEsts: [1.1302945613861084, 1.0657776594161987, 1.3745927810668945, 1.722415804862976, 1.0464786291122437, 1.289036750793457, 1.081275224685669, 1.0601831674575806, 1.045110821723938, 1.0267194509506226, 1.1934306621551514, 1.2684345245361328, 1.0061475038528442, 1.0266788005828857, 1.070906400680542, 1.0257065296173096, 1.64130437374115, 1.0755419731140137, 1.0265305042266846, 1.2474199533462524, 1.2175902128219604, 1.251609444618225, 1.0573863983154297, 1.0094754695892334, 1.1916295289993286, 1.1993250846862793, 1.122799038887024, 1.2247402667999268, 1.32719886302948, 1.4814189672470093, 1.1928812265396118, 1.1020407676696777, 1.0673500299453735, 1.163277506828308, 1.0517711639404297, 1.101198434829712, 1.0185043811798096, 1.014021873474121, 1.249613642692566, 1.0169342756271362, 1.0727672576904297, 1.020148515701294, 1.0138003826141357, 1.0550192594528198, 1.0143635272979736, 1.100691795349121, 1.212799310684204, 1.014456868171692, 1.1776859760284424, 1.0667188167572021, 1.039889931678772, 1.104349970817566, 1.0682651996612549, 1.086991548538208, 1.0638220310211182, 1.1329931020736694, 1.1479227542877197, 1.0391124486923218, 1.2934352159500122, 1.1386297941207886, 1.4168514013290405, 1.0309864282608032, 1.0270639657974243, 1.6788848638534546, 1.0795717239379883, 1.072533130645752, 1.2580571174621582, 1.1793885231018066, 1.1279102563858032, 1.139356017112732, 1.0194381475448608, 1.2782496213912964, 1.2860848903656006, 1.066994309425354, 1.1600792407989502, 1.1566495895385742, 1.008378267288208, 1.2025316953659058, 1.2301777601242065, 1.0096276998519897, 1.4166666269302368, 1.0139034986495972, 1.0318524837493896, 1.0720691680908203, 1.2800365686416626, 1.399999976158142, 1.3094918727874756, 1.4420173168182373, 1.0507348775863647, 1.08327317237854, 1.1580783128738403, 1.1005213260650635, 1.230189323425293, 1.1225030422210693, 1.0989493131637573, 1.052674651145935, 1.1586049795150757, 1.2356911897659302, 1.3273870944976807, 1.3589025735855103, 1.0067472457885742, 1.1460049152374268, 1.1864407062530518, 1.0617949962615967, 1.1681205034255981, 1.0119999647140503, 1.2523101568222046, 1.025156021118164, 1.1871508359909058, 1.0245437622070312, 1.026877999305725, 1.0786768198013306, 1.3276314735412598, 1.165355920791626, 1.0491256713867188, 1.1135333776474, 1.0123051404953003, 1.074373483657837, 1.2651172876358032, 1.2336448431015015, 1.0777887105941772, 1.1479381322860718, 1.0349009037017822, 1.0282851457595825, 1.0015571117401123, 1.2651656866073608, 1.2717026472091675, 1.2890625, 1.0265103578567505, 1.0798739194869995, 1.1183650493621826, 1.0990766286849976, 1.1548550128936768, 1.3050287961959839, 1.683301329612732, 1.0480406284332275, 1.1415767669677734, 1.0513033866882324, 1.0172537565231323, 1.0305784940719604, 1.048628807067871, 1.077883005142212, 1.0500389337539673, 1.0426995754241943, 1.0917586088180542, 1.012822151184082, 1.41847825050354, 1.0690656900405884, 1.0214486122131348, 1.041885256767273, 1.1647182703018188, 1.0576196908950806, 1.0949065685272217, 1.2483049631118774, 1.0443223714828491, 1.0101666450500488, 1.0936416387557983, 1.4308942556381226, 1.0113447904586792, 1.1059828996658325, 1.0456868410110474, 1.0043667554855347, 1.0939569473266602, 1.08174729347229, 1.1882628202438354, 1.027969479560852, 1.0677354335784912, 1.073900580406189, 1.2778820991516113, 1.2285116910934448, 1.0360194444656372, 1.1111111640930176, 1.6941823959350586, 1.0656213760375977, 1.007807970046997, 1.065024733543396, 1.629193663597107, 1.0318208932876587, 1.1034013032913208, 1.1824969053268433, 1.340000033378601, 1.0784019231796265, 1.0247294902801514, 1.4073939323425293, 1.2294695377349854, 1.0219918489456177, 1.3406593799591064, 1.0612683296203613, 1.45473313331604, 1.0361686944961548, 1.133328914642334, 1.0621520280838013, 1.3605059385299683, 1.918691635131836, 1.0786315202713013, 1.2791963815689087, 1.211113691329956, 1.1708860397338867, 1.4228769540786743, 1.0003365278244019]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7319564819335938] ms
 --  Average per query NF    [1.3614964485168457] ms
 --  Average per query vegas [2.370460033416748] ms
Mean [1.154]  Median [1.097]  95th [1.431]  99th [1.694]  max [1.919]
Mean [1.154]  Median [1.097]  95th [1.431]  99th [1.694]  max [1.919]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.202682 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=0 | total-time=26.117285