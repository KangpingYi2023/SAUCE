Input arguments = Namespace(data_update='sample', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 84, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.158876895904541
tensor(0.9948)
result is  tensor(380190.0625)
Enter testHyper
ReportEsts: [1.1343741416931152, 1.0552083253860474, 1.5829031467437744, 1.1857233047485352, 1.2893539667129517, 1.1069618463516235, 1.2629550695419312, 1.1834993362426758, 1.0602232217788696, 1.1420053243637085, 1.1240310668945312, 1.1521186828613281, 1.0531280040740967, 1.0245535373687744, 1.182019829750061, 1.365823745727539, 1.3447625637054443, 1.1697149276733398, 1.165870189666748, 1.086734652519226, 1.1661583185195923, 1.1567274332046509, 1.186082363128662, 1.0849124193191528, 1.0910724401474, 1.1735985279083252, 1.0439189672470093, 1.4877936840057373, 1.0315697193145752, 1.0347331762313843, 1.206456184387207, 1.166060209274292, 1.0078821182250977, 1.0139585733413696, 1.172994613647461, 1.0090501308441162, 1.482730507850647, 1.1310609579086304, 1.1013047695159912, 1.0202834606170654, 1.0090399980545044, 1.0643444061279297, 1.0510367155075073, 1.0980509519577026, 1.0625395774841309, 1.017301082611084, 1.0544006824493408, 1.3156208992004395, 1.0863513946533203, 1.1167513132095337, 1.277008295059204, 1.4546082019805908, 1.0184319019317627, 1.300986886024475, 1.1492106914520264, 1.0148200988769531, 1.241121530532837, 1.0629627704620361, 1.0000330209732056, 1.3761354684829712, 1.1596311330795288, 1.1448166370391846, 1.4160988330841064, 1.0698808431625366, 1.1301369667053223, 1.2000000476837158, 1.1441606283187866, 1.0283774137496948, 1.0376476049423218, 1.2315789461135864, 1.225838303565979, 1.0329582691192627, 1.1641026735305786, 1.085870623588562, 1.1057543754577637, 1.1111384630203247, 1.6751244068145752, 1.0813008546829224, 1.0472222566604614, 1.3276076316833496, 1.1692860126495361, 1.026005506515503, 1.0509939193725586, 1.1257858276367188, 1.2399897575378418, 1.1128469705581665, 1.0875802040100098, 1.1725094318389893, 1.0059422254562378, 1.0158387422561646, 1.023337483406067, 1.546561598777771, 1.021637201309204, 1.2546159029006958, 1.1470588445663452, 1.0677356719970703, 1.1056790351867676, 1.3086827993392944, 1.034482717514038, 1.1515775918960571, 1.2427921295166016, 1.1652699708938599, 1.023025393486023, 1.0095168352127075, 1.1633890867233276, 1.0203012228012085, 1.1395716667175293, 1.1640489101409912, 1.1038819551467896, 1.0707594156265259, 1.1053528785705566, 1.0922646522521973, 1.2026658058166504, 1.0034537315368652, 1.1028167009353638, 1.1701030731201172, 1.0231581926345825, 1.0259253978729248, 1.3044683933258057, 1.15007483959198, 1.2310771942138672, 1.116392970085144, 1.05767822265625, 1.1441043615341187, 1.3076550960540771, 1.2310153245925903, 1.21897292137146, 1.1212772130966187, 1.3458187580108643, 1.1145625114440918, 1.2544399499893188, 1.14606773853302, 1.1351771354675293, 1.4285714626312256, 1.0750459432601929, 1.3213441371917725, 1.0423718690872192, 1.0747967958450317, 1.0841313600540161, 1.3358938694000244, 1.1090646982192993, 1.1653035879135132, 1.1056981086730957, 1.264660120010376, 1.0656013488769531, 1.1329846382141113, 1.0003471374511719, 1.3746614456176758, 1.0907994508743286, 1.1232954263687134, 1.154369592666626, 1.1425458192825317, 1.3087141513824463, 1.0688707828521729, 1.1297613382339478, 1.0187240839004517, 1.0726863145828247, 1.0287001132965088, 1.0713645219802856, 1.1881825923919678, 1.0928032398223877, 1.060552954673767, 1.0020262002944946, 1.2977839708328247, 1.273954153060913, 1.148417592048645, 1.0974746942520142, 1.3130443096160889, 1.0868172645568848, 1.0314949750900269, 1.1356539726257324, 1.1003080606460571, 1.103896141052246, 1.0839323997497559, 1.0296322107315063, 1.0650039911270142, 1.0279719829559326, 1.3378784656524658, 1.1307445764541626, 1.0085935592651367, 1.0369806289672852, 1.0343365669250488, 1.049188256263733, 1.01225745677948, 1.0793191194534302, 1.0940803289413452, 1.114540696144104, 1.2855098247528076, 1.0517643690109253, 1.404015302658081, 1.0232341289520264, 1.0458027124404907, 1.4741735458374023, 1.4015024900436401, 1.6011916399002075, 1.215047001838684, 1.0774072408676147, 1.1176470518112183, 1.196532964706421, 1.1162350177764893]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7617814540863037] ms
 --  Average per query NF    [1.371629238128662] ms
 --  Average per query vegas [2.3901522159576416] ms
Mean [1.149]  Median [1.116]  95th [1.405]  99th [1.583]  max [1.675]
Mean [1.149]  Median [1.116]  95th [1.405]  99th [1.583]  max [1.675]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.806638 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=sample', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
Sample - START
Sample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[1.6093254e-06 3.5762787e-07 1.1920929e-07 4.7683716e-07 4.1723251e-07]
Distance score: 5.960464477539062e-07
SAUCE Drift detection: False
Detection latency: 0.0231s

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.021920 | Model-update-time: 0.000000


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=sample', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.204272747039795
tensor(0.9988)
result is  tensor(458052.4688)
Enter testHyper
ReportEsts: [1.1149381399154663, 1.1280330419540405, 1.185393214225769, 1.097667932510376, 1.0373033285140991, 1.401334285736084, 1.1744840145111084, 1.1171660423278809, 1.1187762022018433, 1.0160154104232788, 1.03236722946167, 1.1640405654907227, 1.1888619661331177, 1.34375, 1.1197006702423096, 1.0889052152633667, 1.001548409461975, 1.1537706851959229, 1.0370523929595947, 1.3037899732589722, 1.1240099668502808, 1.0274755954742432, 1.105263113975525, 1.0989676713943481, 1.1769800186157227, 1.142567753791809, 1.0393309593200684, 1.1236482858657837, 1.0062569379806519, 1.3985849618911743, 1.0826486349105835, 1.2340425252914429, 1.0320873260498047, 1.134060025215149, 1.121791124343872, 1.03213632106781, 1.2292300462722778, 1.0948011875152588, 1.0779699087142944, 1.0355377197265625, 1.0783771276474, 1.120853066444397, 1.258691668510437, 1.0625, 1.0574581623077393, 1.2082273960113525, 2.0366404056549072, 1.0735658407211304, 1.0, 1.0181204080581665, 1.0290143489837646, 1.0440515279769897, 1.0814186334609985, 1.0679283142089844, 1.0515673160552979, 1.2541991472244263, 1.1444284915924072, 1.101249098777771, 1.2311352491378784, 1.1153395175933838, 1.5275779962539673, 1.0635766983032227, 1.0346252918243408, 1.6166764497756958, 1.1087164878845215, 1.016957402229309, 1.333707571029663, 1.0882731676101685, 1.0946364402770996, 1.0893794298171997, 1.0010433197021484, 1.2528831958770752, 1.0813052654266357, 1.1529747247695923, 1.2589491605758667, 1.197866678237915, 1.1220638751983643, 1.2163009643554688, 1.3323497772216797, 1.1377665996551514, 1.2128936052322388, 1.021174430847168, 1.0044230222702026, 1.0645159482955933, 1.3994090557098389, 1.4243541955947876, 1.2666079998016357, 1.8388413190841675, 1.048591136932373, 1.0480304956436157, 1.1316688060760498, 1.0162450075149536, 1.3970210552215576, 1.1419575214385986, 1.2900018692016602, 1.0358831882476807, 1.0119236707687378, 1.1710582971572876, 1.2180345058441162, 1.1268752813339233, 1.1204184293746948, 1.1589857339859009, 1.0955555438995361, 1.3247250318527222, 1.0981101989746094, 1.0420228242874146, 1.1341235637664795, 1.0875474214553833, 1.2529411315917969, 1.0447514057159424, 1.0836689472198486, 1.0747781991958618, 1.2265628576278687, 1.1641104221343994, 1.1273565292358398, 1.1815791130065918, 1.1793802976608276, 1.1465991735458374, 1.1335757970809937, 1.2241379022598267, 1.0087902545928955, 1.1537275314331055, 1.0970757007598877, 1.4409091472625732, 1.0056320428848267, 1.1064964532852173, 1.2546170949935913, 1.2654321193695068, 1.0053761005401611, 1.3873285055160522, 1.0859438180923462, 1.1038579940795898, 1.0403714179992676, 1.5196171998977661, 1.5021204948425293, 1.122936725616455, 1.0788757801055908, 1.2989671230316162, 1.0126783847808838, 1.0366523265838623, 1.0635294914245605, 1.136618733406067, 1.0599719285964966, 1.0091075897216797, 1.090413212776184, 1.1141983270645142, 1.4939758777618408, 1.024243712425232, 1.1932241916656494, 1.069844365119934, 1.0205919742584229, 1.0075329542160034, 1.1233222484588623, 1.0247055292129517, 1.0773290395736694, 1.0280613899230957, 1.2115821838378906, 1.2440944910049438, 1.0075969696044922, 1.1114903688430786, 1.0228856801986694, 1.0870000123977661, 1.1558077335357666, 1.0455782413482666, 1.113539218902588, 1.2402122020721436, 1.0218899250030518, 1.1674485206604004, 1.0667295455932617, 1.2185745239257812, 1.1314305067062378, 1.084190011024475, 1.3500627279281616, 1.1400363445281982, 1.0813361406326294, 1.0741039514541626, 1.1200162172317505, 1.0649282932281494, 1.0617324113845825, 1.1231647729873657, 1.5813953876495361, 1.0645924806594849, 1.0009690523147583, 1.2824642658233643, 1.2482807636260986, 1.1865370273590088, 1.4902184009552002, 1.0717288255691528, 1.3999457359313965, 1.0999853610992432, 1.1250250339508057, 1.0329983234405518, 1.2352865934371948, 1.8741323947906494, 1.0318602323532104, 1.0400176048278809, 1.106332540512085, 1.0652531385421753, 1.4045138359069824, 1.0994399785995483]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.74592661857605] ms
 --  Average per query NF    [1.3679659366607666] ms
 --  Average per query vegas [2.377960681915283] ms
Mean [1.156]  Median [1.115]  95th [1.443]  99th [1.839]  max [2.037]
Mean [1.156]  Median [1.115]  95th [1.443]  99th [1.839]  max [2.037]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.258437 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=0 | total-time=26.111595