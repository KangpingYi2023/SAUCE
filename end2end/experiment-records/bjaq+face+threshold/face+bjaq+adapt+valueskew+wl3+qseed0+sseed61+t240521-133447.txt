Input arguments = Namespace(data_update='valueskew', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 61, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.159723043441772
tensor(0.9977)
result is  tensor(381280.0938)
Enter testHyper
ReportEsts: [1.2311649322509766, 1.0307042598724365, 1.424903392791748, 1.096862554550171, 1.2700926065444946, 1.0891106128692627, 1.2396841049194336, 1.0177956819534302, 1.0870481729507446, 1.1657719612121582, 1.1033592224121094, 1.1019067764282227, 1.110372543334961, 1.0267857313156128, 1.165405511856079, 1.2532912492752075, 1.232877492904663, 1.1934679746627808, 1.2016205787658691, 1.045918345451355, 1.019146203994751, 1.1836764812469482, 1.1706150770187378, 1.0247316360473633, 1.224536418914795, 1.046112060546875, 1.0363175868988037, 1.6395939588546753, 1.0073935985565186, 1.1403722763061523, 1.1695636510849, 1.3693325519561768, 1.040505051612854, 1.0777270793914795, 1.2360813617706299, 1.1558358669281006, 1.3915596008300781, 1.016250491142273, 1.0137114524841309, 1.0359801054000854, 1.0801441669464111, 1.209119439125061, 1.0311874151229858, 1.0697474479675293, 1.0756391286849976, 1.0437870025634766, 1.0083891153335571, 1.309943675994873, 1.0799777507781982, 1.0913705825805664, 1.245945930480957, 1.2715750932693481, 1.002496361732483, 1.2076336145401, 1.1282987594604492, 1.1163653135299683, 1.181308388710022, 1.1711657047271729, 1.3400530815124512, 1.3721696138381958, 1.1632425785064697, 1.2002006769180298, 1.3252694606781006, 1.0601725578308105, 1.2043795585632324, 1.2000000476837158, 1.1536338329315186, 1.098429560661316, 1.0432953834533691, 1.3157894611358643, 1.1697505712509155, 1.0569639205932617, 1.2879961729049683, 1.2254230976104736, 1.01034414768219, 1.2341848611831665, 2.1389238834381104, 1.0336134433746338, 1.0859041213989258, 1.362878680229187, 1.0832778215408325, 1.1119366884231567, 1.1704585552215576, 1.2493271827697754, 1.1977366209030151, 1.0289225578308105, 1.0918382406234741, 1.0628498792648315, 1.0949982404708862, 1.0844182968139648, 1.0648828744888306, 1.3654680252075195, 1.002893328666687, 1.2832828760147095, 1.065573811531067, 1.1256277561187744, 1.1207656860351562, 1.3263380527496338, 1.0, 1.149985909461975, 1.115803837776184, 1.0162936449050903, 1.094216227531433, 1.0044118165969849, 1.0800209045410156, 1.1020005941390991, 1.2094027996063232, 1.1780104637145996, 1.0808351039886475, 1.0492873191833496, 1.1924216747283936, 1.1087985038757324, 1.1351549625396729, 1.023712396621704, 1.1584559679031372, 1.23369562625885, 1.0333951711654663, 1.0829356908798218, 1.296651005744934, 1.0033811330795288, 1.2924339771270752, 1.1120463609695435, 1.1777689456939697, 1.1954669952392578, 1.3202519416809082, 1.202744483947754, 1.0677542686462402, 1.090004324913025, 1.2896493673324585, 1.1002004146575928, 1.0549792051315308, 1.2272428274154663, 1.1566190719604492, 1.5, 1.0154660940170288, 1.0270411968231201, 1.068084955215454, 1.2065041065216064, 1.1084928512573242, 1.0765334367752075, 1.1416198015213013, 1.1139506101608276, 1.158653736114502, 1.3162732124328613, 1.1268539428710938, 1.1353991031646729, 1.0046710968017578, 1.3783947229385376, 1.0540330410003662, 1.1531250476837158, 1.1956359148025513, 1.167542576789856, 1.3327921628952026, 1.040228247642517, 1.1267499923706055, 1.1935807466506958, 1.299312949180603, 1.0045223236083984, 1.0068604946136475, 1.135183572769165, 1.1808654069900513, 1.1317390203475952, 1.0398203134536743, 1.2361477613449097, 1.165432095527649, 1.0094324350357056, 1.2374454736709595, 1.2093887329101562, 1.0104695558547974, 1.108441948890686, 1.0901317596435547, 1.2295945882797241, 1.1168831586837769, 1.2019729614257812, 1.1335150003433228, 1.069701910018921, 1.0009727478027344, 1.3000224828720093, 1.226004958152771, 1.038716435432434, 1.0436019897460938, 1.0269746780395508, 1.0006451606750488, 1.1664963960647583, 1.1818181276321411, 1.089851975440979, 1.009663462638855, 1.318532109260559, 1.0321828126907349, 1.3824537992477417, 1.011617660522461, 1.0320477485656738, 1.5672707557678223, 1.5245157480239868, 1.5513699054718018, 1.2650130987167358, 1.1303876638412476, 1.085714340209961, 1.1373087167739868, 1.0737383365631104]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.680347204208374] ms
 --  Average per query NF    [1.3644158840179443] ms
 --  Average per query vegas [2.3159313201904297] ms
Mean [1.156]  Median [1.128]  95th [1.372]  99th [1.568]  max [2.139]
Mean [1.156]  Median [1.128]  95th [1.372]  99th [1.568]  max [2.139]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.804616 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=valueskew', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
ValueSample - START
ValueSample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[1.3113022e-06 4.7683716e-07 8.9422464e-03 1.7285347e-06 1.1920929e-07]
Distance score: 0.001789176487363875
SAUCE Drift detection: True
Detection latency: 0.0244s

DRIFT-DETECTED after 2-th workload
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/incremental_train.py', '--dataset=bjaq', '--end2end', '--model=face', '--model_update=adapt', '--update_size=80000', '--epochs=0']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
update_size: 76433
AdaptTask - START
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
train data shape: 80000, transfer data shape:16000
Training done; evaluating likelihood on full data:
Saved to: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
AdaptTask - END

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.051447 | Model-update-time: 2.238626


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=valueskew', '--model_update=adapt']
/home/kangping/code_copy/SAUCE/./FACE/FACE_utils/dataUtils.py:321: RuntimeWarning: invalid value encountered in cast
  oracle_cards = oracle_cards.astype(np.int32)
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.162301301956177
tensor(0.9956)
result is  tensor(456560.7812)
Enter testHyper
ReportEsts: [1.3672764301300049, 1.168835163116455, 1.9969834089279175, 1.1231769323349, 1.1577048301696777, 1.152529239654541, 1.0383248329162598, 1.0997663736343384, 1.183632731437683, 1.0620650053024292, 1.17507004737854, 1.5653537511825562, 1.2748091220855713, 1.3197194337844849, 1.2327513694763184, 1.0371443033218384, 1.1807841062545776, 1.3767433166503906, 1.0367181301116943, 1.076218843460083, 1.22804856300354, 1.412078857421875, 1.0199203491210938, 1.3462672233581543, 1.1299012899398804, 1.0534262657165527, 1.084670066833496, 1.2996065616607666, 1.234956979751587, 1.202970266342163, 1.1200392246246338, 1.4745762348175049, 1.062783122062683, 16.423925399780273, 1.0139950513839722, 1.156249761581421, 1.0314311981201172, 1.1512274742126465, 1.215541124343872, 1.0861796140670776, 1.0085572004318237, 1.1192660331726074, 1.3669853210449219, 1.0686635971069336, 1.019486665725708, 1.020749568939209, 1.793056845664978, 1.0483566522598267, 1.1204819679260254, 1.229407548904419, 1.2383840084075928, 1.008339285850525, 1.073413372039795, 1.284484624862671, 1.428316354751587, 9.43561840057373, 1.213899850845337, 1.2414190769195557, 1.2567028999328613, 1.3309465646743774, 1.1551724672317505, 1.1619247198104858, 2.195122003555298, 1.8026409149169922, 1.0562148094177246, 1.1723988056182861, 1.0615915060043335, 1.0931435823440552, 1.0380042791366577, 1.1182245016098022, 1.3046762943267822, 1.0885193347930908, 1.0663174390792847, 1.113540768623352, 1.1145755052566528, 2.764758348464966, 17.115942001342773, 1.0778712034225464, 1.2175039052963257, 1.826215386390686, 6.9028778076171875, 3.250871181488037, 1.0038602352142334, 1.2433863878250122, 1.333019733428955, 1.3619402647018433, 1.1380846500396729, 1.4488087892532349, 1.3226896524429321, 1.0327056646347046, 1.1669788360595703, 1.2208012342453003, 1.360862135887146, 1.1253036260604858, 1.130174994468689, 1.0423308610916138, 1.510842204093933, 1.240638256072998, 1.1684213876724243, 1.0041207075119019, 1.1672461032867432, 1.0099037885665894, 1.0024570226669312, 1.0489745140075684, 1.1122254133224487, 4.437641620635986, 1.3102941513061523, 1.2565616369247437, 1.0802292823791504, 1.2173094749450684, 1.092505693435669, 1.0595086812973022, 1.3887019157409668, 1.2444533109664917, 1.1174273490905762, 1.0131630897521973, 1.1458775997161865, 1.280881643295288, 1.0224032402038574, 1.0088495016098022, 1.1549458503723145, 1.6249221563339233, 1.8390580415725708, 1.9027522802352905, 1.1312755346298218, 1.0391522645950317, 1.252350926399231, 1.046583890914917, 1.1409887075424194, 1.2224359512329102, 1.414047122001648, 1.0753718614578247, 1.1331522464752197, 3.2030386924743652, 3.1042885780334473, 1.3253247737884521, 1.3501442670822144, 6.244553089141846, 1.0329968929290771, 1.2228609323501587, 1.1479871273040771, 1.0579023361206055, 1.085732340812683, 1.3693679571151733, 1.3363456726074219, 1.053948998451233, 1.576923131942749, 1.1828385591506958, 1.0344187021255493, 1.0879015922546387, 14.54749584197998, 1.1837186813354492, 1.0869213342666626, 1.0918861627578735, 1.0531005859375, 1.4041129350662231, 1.0243867635726929, 1.2960000038146973, 1.1802358627319336, 1.2210371494293213, 1.0048681497573853, 1.1182044744491577, 1.4112613201141357, 1.1334437131881714, 1.2544821500778198, 1.2018072605133057, 1.0948253870010376, 1.322944164276123, 10.988945007324219, 1.3384672403335571, 1.0774532556533813, 1.219217300415039, 1.4434025287628174, 1.076959490776062, 1.1815708875656128, 1.0004411935806274, 1.137222409248352, 1.020829677581787, 1.2037849426269531, 1.3589720726013184, 1.1111111640930176, 1.319410800933838, 1.5863081216812134, 1.4546277523040771, 1.069704294204712, 1.5890473127365112, 1.1697248220443726, 1.1238510608673096, 1.105118751525879, 1.0787477493286133, 1.1416521072387695, 1.3866875171661377, 1.4223579168319702, 1.3113170862197876, 1.1714228391647339, 1.1355581283569336, 1.6550354957580566, 1.0075949430465698, 1.2006078958511353, 1.0913201570510864]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7213289737701416] ms
 --  Average per query NF    [1.3523685932159424] ms
 --  Average per query vegas [2.368960380554199] ms
Mean [1.632]  Median [1.169]  95th [3.109]  99th [14.566]  max [17.116]
Mean [1.632]  Median [1.169]  95th [3.109]  99th [14.566]  max [17.116]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.388457 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=1 | total-time=28.535695