Input arguments = Namespace(data_update='sample', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 39, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.171617984771729
tensor(0.9952)
result is  tensor(380350.2500)
Enter testHyper
ReportEsts: [1.0955842733383179, 1.083837628364563, 1.5513392686843872, 1.0336912870407104, 1.248824954032898, 1.1383144855499268, 1.1458191871643066, 1.1416634321212769, 1.1046831607818604, 1.1749666929244995, 1.1817399263381958, 1.1277542114257812, 1.0283888578414917, 1.0334821939468384, 1.0483402013778687, 1.25, 1.3525097370147705, 1.1502375602722168, 1.102799654006958, 1.0484694242477417, 1.0030709505081177, 1.0934462547302246, 1.1281943321228027, 1.04194974899292, 1.0782487392425537, 1.0985532999038696, 1.042511224746704, 1.3916414976119995, 1.0359095335006714, 1.0170701742172241, 1.0879744291305542, 1.089393973350525, 1.3802266120910645, 1.1114758253097534, 1.1342859268188477, 1.2266173362731934, 1.4822404384613037, 1.0382360219955444, 1.1047871112823486, 1.2810778617858887, 1.0356411933898926, 1.2331881523132324, 1.1770001649856567, 1.0569629669189453, 1.1191632747650146, 1.0665054321289062, 1.1084076166152954, 1.3741389513015747, 1.0038549900054932, 1.181049108505249, 1.1943005323410034, 1.365079402923584, 1.0379095077514648, 1.2206790447235107, 1.0469486713409424, 1.009967565536499, 1.1869158744812012, 1.1540786027908325, 1.1146820783615112, 1.3587443828582764, 1.4136587381362915, 1.1898552179336548, 1.24289071559906, 1.0114715099334717, 1.3147410154342651, 1.2285714149475098, 1.1307483911514282, 1.0312542915344238, 1.1162177324295044, 1.3263157606124878, 1.3378921747207642, 1.0558067560195923, 1.2309739589691162, 1.4024523496627808, 1.2043185234069824, 1.0595300197601318, 1.7429450750350952, 1.0522401332855225, 1.1071243286132812, 1.287176251411438, 1.254072666168213, 1.0043611526489258, 1.0455718040466309, 1.178442120552063, 1.2824233770370483, 1.0137351751327515, 1.164585828781128, 1.1367969512939453, 1.0715367794036865, 1.04262375831604, 1.0122463703155518, 1.4041624069213867, 1.0072124004364014, 1.19912850856781, 1.101694941520691, 1.0988353490829468, 1.1778666973114014, 1.3215023279190063, 1.034482717514038, 1.1314483880996704, 1.04865562915802, 1.201291561126709, 1.0221582651138306, 1.0156134366989136, 1.0357530117034912, 1.028833270072937, 1.1224539279937744, 1.216404914855957, 1.0660916566848755, 1.027170181274414, 1.2811843156814575, 1.1269230842590332, 1.119055986404419, 1.0050950050354004, 1.1883621215820312, 1.2404371500015259, 1.044748067855835, 1.1647104024887085, 1.0937535762786865, 1.1109983921051025, 1.2096290588378906, 1.119221806526184, 1.0893511772155762, 1.1141109466552734, 1.2175387144088745, 1.186339259147644, 1.2153128385543823, 1.1603306531906128, 1.3481675386428833, 1.120908498764038, 1.0439598560333252, 1.3789526224136353, 1.1730889081954956, 1.4642857313156128, 1.0017597675323486, 1.0685219764709473, 1.1193333864212036, 1.0686179399490356, 1.1363779306411743, 1.2008788585662842, 1.2109113931655884, 1.1201883554458618, 1.0832250118255615, 1.295693039894104, 1.0115264654159546, 1.1391295194625854, 1.0250017642974854, 1.1757493019104004, 1.0249831676483154, 1.1261364221572876, 1.1831133365631104, 1.1612613201141357, 1.3883877992630005, 1.0254935026168823, 1.0803146362304688, 1.1430635452270508, 1.127864956855774, 1.012535572052002, 1.028511643409729, 1.133631706237793, 1.0549983978271484, 1.0301085710525513, 1.0206149816513062, 1.3271955251693726, 1.1442424058914185, 1.0253329277038574, 1.2443214654922485, 1.3059810400009155, 1.153092861175537, 1.04473078250885, 1.0286349058151245, 1.0652016401290894, 1.2077921628952026, 1.2105556726455688, 1.041893720626831, 1.1108627319335938, 1.0456753969192505, 1.1418145895004272, 1.1154725551605225, 1.206789493560791, 1.0120097398757935, 1.145501971244812, 1.077724814414978, 1.1859040260314941, 1.1122781038284302, 1.121564507484436, 1.038403868675232, 1.2527893781661987, 1.0480930805206299, 1.3223252296447754, 1.0713950395584106, 1.0741106271743774, 1.49973726272583, 1.2985305786132812, 1.7617645263671875, 1.0584380626678467, 1.1525635719299316, 1.1343283653259277, 1.0205632448196411, 1.0842629671096802]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.762909173965454] ms
 --  Average per query NF    [1.3686800003051758] ms
 --  Average per query vegas [2.3942291736602783] ms
Mean [1.151]  Median [1.121]  95th [1.389]  99th [1.553]  max [1.762]
Mean [1.151]  Median [1.121]  95th [1.389]  99th [1.553]  max [1.762]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.810693 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=sample', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
Sample - START
Sample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[ 0.0000000e+00  1.1920929e-07 -2.9802322e-08  2.3841858e-07
  1.7881393e-07]
Distance score: 1.01327898960335e-07
SAUCE Drift detection: False
Detection latency: 0.0232s

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.018824 | Model-update-time: 0.000000


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=sample', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.16132640838623
tensor(0.9930)
result is  tensor(455388.2812)
Enter testHyper
ReportEsts: [1.143365740776062, 1.026272177696228, 1.1416780948638916, 1.1722294092178345, 1.0992177724838257, 1.385010004043579, 1.1076161861419678, 1.0195677280426025, 1.1225337982177734, 1.0623053312301636, 1.0110217332839966, 1.1603469848632812, 1.2311557531356812, 1.2533740997314453, 1.1505662202835083, 1.063484787940979, 1.656399130821228, 1.1357090473175049, 1.0640350580215454, 1.3086950778961182, 1.0029913187026978, 1.0301263332366943, 1.040349006652832, 1.0974483489990234, 1.3322889804840088, 1.1724655628204346, 1.036258339881897, 1.1422613859176636, 1.4551355838775635, 1.7606329917907715, 1.0819112062454224, 1.2928571701049805, 1.0131661891937256, 1.112971544265747, 1.0859709978103638, 1.146647572517395, 1.0284037590026855, 1.1567119359970093, 1.20843505859375, 1.0045208930969238, 1.0260944366455078, 1.0193133354187012, 1.0522013902664185, 1.0825586318969727, 1.0018565654754639, 1.174668550491333, 1.3114577531814575, 1.0900914669036865, 1.1023621559143066, 1.2182366847991943, 1.0029938220977783, 1.0581356287002563, 1.0642255544662476, 1.128191590309143, 1.0457552671432495, 1.2355865240097046, 1.1004199981689453, 1.1235930919647217, 1.280778408050537, 1.122111439704895, 1.5990098714828491, 1.0298658609390259, 1.0598546266555786, 1.5216457843780518, 1.0429123640060425, 1.1118541955947876, 1.2620484828948975, 1.0953212976455688, 1.1426517963409424, 1.1008764505386353, 1.078310489654541, 1.2314352989196777, 1.0614418983459473, 1.0805679559707642, 1.0342270135879517, 1.0037354230880737, 1.063151240348816, 1.0504348278045654, 1.2174619436264038, 1.129490613937378, 1.103621006011963, 1.0942262411117554, 1.1136442422866821, 1.2092276811599731, 1.263954758644104, 1.257525086402893, 1.2341398000717163, 1.5278722047805786, 1.0457491874694824, 1.0800000429153442, 1.2413989305496216, 1.1955701112747192, 1.3911324739456177, 1.0698710680007935, 1.1389806270599365, 1.0683646202087402, 1.135237455368042, 1.4571505784988403, 1.0030609369277954, 1.0901408195495605, 1.0600923299789429, 1.0904946327209473, 1.4431818723678589, 1.1161810159683228, 1.1380208730697632, 1.0201314687728882, 1.029805302619934, 1.1181015968322754, 1.1384180784225464, 1.1153981685638428, 1.0343937873840332, 1.1254303455352783, 1.3021827936172485, 1.2084386348724365, 1.1406446695327759, 1.1431864500045776, 1.1258143186569214, 1.1071629524230957, 1.2128701210021973, 1.0887097120285034, 1.0777323246002197, 1.0667016506195068, 1.021267294883728, 1.2662968635559082, 1.0195152759552002, 1.1940375566482544, 1.2395455837249756, 1.2898088693618774, 1.0598974227905273, 1.0453007221221924, 1.2772222757339478, 1.0531843900680542, 1.1421172618865967, 1.7658157348632812, 1.7257590293884277, 1.1654447317123413, 1.01045560836792, 1.0385615825653076, 1.008665919303894, 1.0440893173217773, 1.064601182937622, 1.1642656326293945, 1.0421593189239502, 1.0689729452133179, 1.0483168363571167, 1.0039253234863281, 1.625, 1.0591880083084106, 1.1260002851486206, 1.0277965068817139, 1.1201577186584473, 1.0386614799499512, 1.1352285146713257, 1.102665901184082, 1.009172797203064, 1.5006818771362305, 1.1500948667526245, 1.248062014579773, 1.1863207817077637, 1.0363109111785889, 1.0719819068908691, 1.1520501375198364, 1.119257926940918, 1.0849964618682861, 1.1467925310134888, 1.2879014015197754, 1.0079331398010254, 1.3355486392974854, 1.280058741569519, 1.2977546453475952, 1.1113883256912231, 1.0478103160858154, 1.789121389389038, 1.1094841957092285, 1.0082576274871826, 1.0093238353729248, 1.2855311632156372, 1.041357159614563, 1.1175932884216309, 1.180347204208374, 1.790697693824768, 1.0802174806594849, 1.0145636796951294, 1.6211518049240112, 1.3797591924667358, 1.149687647819519, 1.3277499675750732, 1.0849357843399048, 1.3461103439331055, 1.0592840909957886, 1.1623656749725342, 1.1211717128753662, 1.153685450553894, 1.8771206140518188, 1.0613579750061035, 1.0139660835266113, 1.3937337398529053, 1.0275481939315796, 1.242519736289978, 1.088270902633667]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7242627143859863] ms
 --  Average per query NF    [1.357731819152832] ms
 --  Average per query vegas [2.3665308952331543] ms
Mean [1.165]  Median [1.116]  95th [1.531]  99th [1.789]  max [1.877]
Mean [1.165]  Median [1.116]  95th [1.531]  99th [1.789]  max [1.877]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.217539 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=0 | total-time=26.071855