Input arguments = Namespace(data_update='valueskew', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 4, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.200810194015503
tensor(0.9936)
result is  tensor(379733.6250)
Enter testHyper
ReportEsts: [1.2010035514831543, 1.0045450925827026, 1.2093366384506226, 1.0991787910461426, 1.2194492816925049, 1.1283155679702759, 1.2029554843902588, 1.2771260738372803, 1.07474684715271, 1.097656011581421, 1.1300603151321411, 1.0750000476837158, 1.0950932502746582, 1.0089285373687744, 1.0856661796569824, 1.3406977653503418, 1.3524785041809082, 1.206769585609436, 1.1276278495788574, 1.086734652519226, 1.2589647769927979, 1.0546404123306274, 1.0976155996322632, 1.0481925010681152, 1.0891121625900269, 1.1274864673614502, 1.0489864349365234, 1.333608627319336, 1.0472064018249512, 1.0369240045547485, 1.112451195716858, 1.2859375476837158, 1.0009163618087769, 1.0198447704315186, 1.1278619766235352, 1.1127907037734985, 1.344170093536377, 1.2040890455245972, 1.0105165243148804, 1.051856279373169, 1.0388548374176025, 1.2088775634765625, 1.1243053674697876, 1.0541480779647827, 1.0859919786453247, 1.0532879829406738, 1.0715409517288208, 1.3070011138916016, 1.0573501586914062, 1.1285955905914307, 1.2099738121032715, 1.2307243347167969, 1.0138936042785645, 1.1332378387451172, 1.1981031894683838, 1.0407973527908325, 1.3205606937408447, 1.1448664665222168, 1.0624545812606812, 1.4098985195159912, 1.3709871768951416, 1.1960675716400146, 1.2361180782318115, 1.1375499963760376, 1.3524590730667114, 1.3428571224212646, 1.1546961069107056, 1.0247219800949097, 1.1824870109558105, 1.3368420600891113, 1.1414141654968262, 1.0922138690948486, 1.186790108680725, 1.1639567613601685, 1.1723754405975342, 1.186896800994873, 1.7733851671218872, 1.1093839406967163, 1.0213793516159058, 1.1923208236694336, 1.27424156665802, 1.0185916423797607, 1.0351738929748535, 1.2570325136184692, 1.210228681564331, 1.0969288349151611, 1.0606136322021484, 1.047011375427246, 1.0355383157730103, 1.060701608657837, 1.0547891855239868, 1.3116647005081177, 1.0105684995651245, 1.3158020973205566, 1.0773481130599976, 1.0477131605148315, 1.1333726644515991, 1.2445805072784424, 1.034482717514038, 1.0885684490203857, 1.186956524848938, 1.0274921655654907, 1.0221132040023804, 1.0007320642471313, 1.0066945552825928, 1.024882435798645, 1.1860309839248657, 1.1780104637145996, 1.072367548942566, 1.011973261833191, 1.0491266250610352, 1.14453125, 1.3190639019012451, 1.006041407585144, 1.1184653043746948, 1.164102554321289, 1.028963565826416, 1.0817748308181763, 1.2438032627105713, 1.2084722518920898, 1.2343720197677612, 1.0886573791503906, 1.091618299484253, 1.109798789024353, 1.202519416809082, 1.1876806020736694, 1.1498093605041504, 1.097142219543457, 1.3205127716064453, 1.1195725202560425, 1.2895492315292358, 1.1462929248809814, 1.145742654800415, 1.4642857313156128, 1.1559362411499023, 1.1590968370437622, 1.0210808515548706, 1.1456910371780396, 1.1079059839248657, 1.3147766590118408, 1.195778727531433, 1.0946152210235596, 1.0021989345550537, 1.3070464134216309, 1.0079083442687988, 1.019466519355774, 1.1266090869903564, 1.360554575920105, 1.1163409948349, 1.0182528495788574, 1.1112631559371948, 1.1780540943145752, 1.256632685661316, 1.18567955493927, 1.1445808410644531, 1.0485637187957764, 1.0594744682312012, 1.0095666646957397, 1.0265743732452393, 1.0750223398208618, 1.0347063541412354, 1.0244375467300415, 1.0718879699707031, 1.3253182172775269, 1.172670841217041, 1.0708955526351929, 1.1760307550430298, 1.352086067199707, 1.047541856765747, 1.0244911909103394, 1.0209025144577026, 1.0415295362472534, 1.1688311100006104, 1.106726884841919, 1.0752724409103394, 1.008012056350708, 1.0179786682128906, 1.239349126815796, 1.0566210746765137, 1.0983375310897827, 1.050229787826538, 1.009029507637024, 1.0126185417175293, 1.1256383657455444, 1.1546541452407837, 1.1226215362548828, 1.0083051919937134, 1.2633614540100098, 1.11082124710083, 1.3712526559829712, 1.0288002490997314, 1.116422414779663, 1.5048774480819702, 1.2684462070465088, 1.602729320526123, 1.2052239179611206, 1.1208003759384155, 1.0410958528518677, 1.0408215522766113, 1.1091634035110474]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.6959218978881836] ms
 --  Average per query NF    [1.365598440170288] ms
 --  Average per query vegas [2.3303234577178955] ms
Mean [1.142]  Median [1.116]  95th [1.352]  99th [1.506]  max [1.773]
Mean [1.142]  Median [1.116]  95th [1.352]  99th [1.506]  max [1.773]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.822880 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=valueskew', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
ValueSample - START
ValueSample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[8.9406967e-07 1.0050535e-02 1.1920929e-07 5.9604645e-07 5.3644180e-07]
Distance score: 0.0020105361472815275
SAUCE Drift detection: True
Detection latency: 0.0233s

DRIFT-DETECTED after 2-th workload
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/incremental_train.py', '--dataset=bjaq', '--end2end', '--model=face', '--model_update=adapt', '--update_size=80000', '--epochs=0']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
update_size: 76433
AdaptTask - START
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
train data shape: 80000, transfer data shape:16000
Training done; evaluating likelihood on full data:
Saved to: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
AdaptTask - END

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.048370 | Model-update-time: 2.228423


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=valueskew', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.172163724899292
tensor(0.9971)
result is  tensor(457252.9688)
Enter testHyper
ReportEsts: [1.125553011894226, 1.077560544013977, 1.1609822511672974, 1.5865494012832642, 1.0496628284454346, 1.816005825996399, 1.1960855722427368, 1.0929834842681885, 1.318864107131958, 1.1748608350753784, 1.2345526218414307, 1.0587812662124634, 1.1345291137695312, 1.0474227666854858, 189.95652770996094, 1.0772218704223633, 1.20895516872406, 1.14766526222229, 1.001539707183838, 1.2541475296020508, 1.2545770406723022, 1.1894723176956177, 1.066575288772583, 1.8363618850708008, 1.095381498336792, 1.1667289733886719, 1.0183539390563965, 1.30691397190094, 17.561193466186523, 1.3549884557724, 1.0528523921966553, 1.0816326141357422, 2.3796699047088623, 1.0440633296966553, 1.2271724939346313, 1.229364037513733, 1.3754714727401733, 1.0908881425857544, 1.2212790250778198, 1.016485333442688, 1.4003607034683228, 1.0817369222640991, 1.2534847259521484, 1.1442221403121948, 1.2412662506103516, 1.0672025680541992, 1.452789545059204, 1.36113703250885, 1.1333333253860474, 1.0753062963485718, 1.1960557699203491, 1.1102567911148071, 1.1009585857391357, 1.0504059791564941, 1.0827091932296753, 1.1656607389450073, 1.305189609527588, 1.0837321281433105, 1.0801081657409668, 1.4377672672271729, 1.5224586725234985, 1.0078459978103638, 3.6420092582702637, 1.389677882194519, 1.0718969106674194, 1.4160645008087158, 1.3363375663757324, 1.003530502319336, 1.1348434686660767, 1.2815749645233154, 1.2069331407546997, 1.1912777423858643, 1.2311969995498657, 1.1003981828689575, 1.2297203540802002, 1.113906741142273, 18.3125, 2.013913869857788, 1.1930804252624512, 1.0174059867858887, 1.1311827898025513, 1.0482808351516724, 1.0184253454208374, 1.208985447883606, 1.3257843255996704, 1.6510637998580933, 1.7418800592422485, 1.26188063621521, 1.0069876909255981, 1.1581242084503174, 1.0099585056304932, 1.0673664808273315, 1.5279512405395508, 1.0695440769195557, 59.81025695800781, 1.1529453992843628, 1.0268434286117554, 1.0556353330612183, 1.6732673645019531, 1.1615060567855835, 1.1441656351089478, 1.3711762428283691, 1.2347187995910645, 1.1738883256912231, 1.1045523881912231, 1.1600127220153809, 1.0657175779342651, 1.3979954719543457, 1.031518578529358, 1.0288026332855225, 1.118544578552246, 1.2069045305252075, 1.2528363466262817, 1.150755763053894, 1.332162618637085, 1.1042442321777344, 1.10822331905365, 1.2593942880630493, 1.0824886560440063, 1.355140209197998, 1.0865947008132935, 1.1168631315231323, 1.0313501358032227, 1.0869359970092773, 1.2029316425323486, 1.0968669652938843, 1.0257930755615234, 1.2827476263046265, 1.3435709476470947, 1.3429062366485596, 1.1035566329956055, 1.2982686758041382, 1.0834966897964478, 1.577689290046692, 1.1075429916381836, 1.1454658508300781, 1.1127896308898926, 1.0021079778671265, 1.302319884300232, 1.187256097793579, 1.1036583185195923, 1.1735398769378662, 1.2998874187469482, 1.0462067127227783, 1.0293008089065552, 1.4117772579193115, 1.2944785356521606, 1.1429728269577026, 1.1937931776046753, 1.0026859045028687, 1.057271122932434, 1.0680012702941895, 1.0557262897491455, 1.1307373046875, 1.368346095085144, 1.3476144075393677, 1.0317169427871704, 1.0458015203475952, 1.10379159450531, 1.1497441530227661, 3.6230905055999756, 1.249404788017273, 1.0966428518295288, 1.045499324798584, 1.0032920837402344, 2.7442052364349365, 1.21871018409729, 1.2532010078430176, 12.682432174682617, 1.013157606124878, 1.002614140510559, 1.0271036624908447, 1.1150277853012085, 1.0035070180892944, 1.0716025829315186, 1.2901333570480347, 1.0138273239135742, 1.1381062269210815, 1.0085222721099854, 1.0099003314971924, 1.355555534362793, 1.0600290298461914, 1.2277920246124268, 1.299110770225525, 1.469303011894226, 1.2456530332565308, 5.100250720977783, 1.0198578834533691, 1.3071132898330688, 1.0944938659667969, 1.142007827758789, 1.2318501472473145, 1.187364935874939, 1.4116424322128296, 1.063758373260498, 1.1235435009002686, 1.3564724922180176, 1.8461538553237915, 1.6173044443130493, 1.0871050357818604]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.6142313480377197] ms
 --  Average per query NF    [1.3551080226898193] ms
 --  Average per query vegas [2.2591233253479004] ms
Mean [2.714]  Median [1.152]  95th [2.032]  99th [18.727]  max [189.957]
Mean [2.714]  Median [1.152]  95th [2.032]  99th [18.727]  max [189.957]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.303329 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=1 | total-time=28.475609