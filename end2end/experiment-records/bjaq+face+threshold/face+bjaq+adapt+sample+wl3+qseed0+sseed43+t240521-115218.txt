Input arguments = Namespace(data_update='sample', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 43, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.165504693984985
tensor(0.9972)
result is  tensor(381098.3750)
Enter testHyper
ReportEsts: [1.1783956289291382, 1.1176049709320068, 1.4271883964538574, 1.0288481712341309, 1.2731356620788574, 1.1086478233337402, 1.2449113130569458, 1.3270801305770874, 1.054646372795105, 1.1090052127838135, 1.001725673675537, 1.1421610116958618, 1.0103203058242798, 1.0580357313156128, 1.2152116298675537, 1.3570219278335571, 1.2328124046325684, 1.1153206825256348, 1.1743788719177246, 1.1301020383834839, 1.0192604064941406, 1.1301665306091309, 1.1289037466049194, 1.1340073347091675, 1.0990769863128662, 1.1500904560089111, 1.1531531810760498, 1.4292035102844238, 1.0529283285140991, 1.1500356197357178, 1.070237636566162, 1.0855404138565063, 1.010426640510559, 1.0181504487991333, 1.1278619766235352, 1.1768001317977905, 1.3877832889556885, 1.0850508213043213, 1.0079872608184814, 1.0013190507888794, 1.0349727869033813, 1.1656991243362427, 1.0457193851470947, 1.13272225856781, 1.0684555768966675, 1.0612244606018066, 1.1042149066925049, 1.2092137336730957, 1.2062904834747314, 1.1269035339355469, 1.1582914590835571, 1.3111387491226196, 1.0378563404083252, 1.2749838829040527, 1.0563737154006958, 1.0239734649658203, 1.4093457460403442, 1.1866000890731812, 1.0259796380996704, 1.3559805154800415, 1.346714735031128, 1.2058460712432861, 1.2249306440353394, 1.0284427404403687, 1.2087912559509277, 1.2571429014205933, 1.202301025390625, 1.0547884702682495, 1.1675134897232056, 1.2526315450668335, 1.1530612707138062, 1.0842422246932983, 1.0637363195419312, 1.0991392135620117, 1.1514089107513428, 1.169958233833313, 1.7941614389419556, 1.0555047988891602, 1.1074414253234863, 1.430230975151062, 1.0841922760009766, 1.0240671634674072, 1.1183478832244873, 1.203909158706665, 1.2439937591552734, 1.0547637939453125, 1.0365288257598877, 1.0267844200134277, 1.0391420125961304, 1.0564723014831543, 1.061411738395691, 1.4437333345413208, 1.0251386165618896, 1.3698357343673706, 1.0102564096450806, 1.158989667892456, 1.1863852739334106, 1.414386510848999, 1.0714285373687744, 1.1224604845046997, 1.2427921295166016, 1.1153624057769775, 1.02695631980896, 1.0081180334091187, 1.1148535013198853, 1.0359364748001099, 1.0482218265533447, 1.216404914855957, 1.042557716369629, 1.0112825632095337, 1.0940930843353271, 1.086190938949585, 1.1584209203720093, 1.0544220209121704, 1.098759651184082, 1.1237623691558838, 1.0132536888122559, 1.0006449222564697, 1.227109432220459, 1.1051537990570068, 1.218531847000122, 1.1026631593704224, 1.1592985391616821, 1.2654799222946167, 1.2335271835327148, 1.176743745803833, 1.1625850200653076, 1.1960722208023071, 1.2469733953475952, 1.0945223569869995, 1.0566790103912354, 1.193559169769287, 1.1587942838668823, 1.4285714626312256, 1.137886643409729, 1.100026249885559, 1.0277431011199951, 1.1941463947296143, 1.0353198051452637, 1.487558364868164, 1.120762586593628, 1.1716313362121582, 1.0323255062103271, 1.1828454732894897, 1.0064513683319092, 1.0790382623672485, 1.0189098119735718, 1.594972014427185, 1.0684527158737183, 1.1123579740524292, 1.237607479095459, 1.1534419059753418, 1.3652993440628052, 1.1428368091583252, 1.1650389432907104, 1.06104576587677, 1.0565776824951172, 1.008159875869751, 1.0307104587554932, 1.2232766151428223, 1.2400301694869995, 1.0220789909362793, 1.0475267171859741, 1.229658842086792, 1.2553191184997559, 1.1003834009170532, 1.2107598781585693, 1.332093358039856, 1.0388708114624023, 1.052858829498291, 1.076327919960022, 1.0394536256790161, 1.103896141052246, 1.059187412261963, 1.194822907447815, 1.161995768547058, 1.0111758708953857, 1.1037178039550781, 1.2774749994277954, 1.0959497690200806, 1.0061053037643433, 1.0309382677078247, 1.0202988386154175, 1.0949949026107788, 1.080405592918396, 1.1236786842346191, 1.100053071975708, 1.2754703760147095, 1.0451147556304932, 1.393074631690979, 1.0061771869659424, 1.0210431814193726, 1.636937141418457, 1.184340476989746, 1.9113924503326416, 1.1202312707901, 1.0917465686798096, 1.1014492511749268, 1.0131335258483887, 1.150564432144165]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7370777130126953] ms
 --  Average per query NF    [1.356039047241211] ms
 --  Average per query vegas [2.3810386657714844] ms
Mean [1.150]  Median [1.116]  95th [1.415]  99th [1.639]  max [1.911]
Mean [1.150]  Median [1.116]  95th [1.415]  99th [1.639]  max [1.911]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.805829 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=sample', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
Sample - START
Sample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[1.4305115e-06 1.1324883e-06 4.7683716e-07 5.9604645e-07 5.9604645e-08]
Distance score: 7.390975724774762e-07
SAUCE Drift detection: False
Detection latency: 0.0233s

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.020496 | Model-update-time: 0.000000


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=sample', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.161845445632935
tensor(0.9958)
result is  tensor(456663.6250)
Enter testHyper
ReportEsts: [1.01970374584198, 1.0145282745361328, 1.166433572769165, 1.054094910621643, 1.1308494806289673, 1.0807877779006958, 1.174953579902649, 1.071058750152588, 1.0689141750335693, 1.1628893613815308, 1.004813313484192, 1.0850518941879272, 1.2395061254501343, 1.186905860900879, 1.0175098180770874, 1.0630923509597778, 1.1685261726379395, 1.0492947101593018, 1.147172451019287, 1.270951747894287, 1.1521846055984497, 5.19444465637207, 1.0027058124542236, 1.013472557067871, 1.2142746448516846, 1.098109483718872, 1.0232248306274414, 1.0543735027313232, 1.4533488750457764, 1.2082191705703735, 1.0349006652832031, 1.1904761791229248, 1.0196845531463623, 1.0096019506454468, 1.0935636758804321, 1.0601369142532349, 1.09544837474823, 1.2786400318145752, 1.2908501625061035, 1.0394257307052612, 1.0654183626174927, 1.0119047164916992, 1.490114450454712, 1.0006320476531982, 1.022016167640686, 1.2164292335510254, 1.6730444431304932, 1.2357170581817627, 1.007722020149231, 1.0363481044769287, 1.0426316261291504, 1.078000545501709, 1.0588414669036865, 1.1742208003997803, 1.0860936641693115, 1.2482147216796875, 1.1507493257522583, 1.0987727642059326, 1.217431902885437, 1.1747077703475952, 1.4843049049377441, 1.035528540611267, 1.0596556663513184, 1.390460729598999, 1.041275143623352, 1.1191343069076538, 1.3193689584732056, 1.0681452751159668, 1.2105623483657837, 1.0925147533416748, 1.1215037107467651, 1.2440589666366577, 1.0257750749588013, 1.0989831686019897, 1.0541629791259766, 1.1826075315475464, 2.055555582046509, 1.1542456150054932, 1.3449400663375854, 1.0970350503921509, 1.2373844385147095, 1.1671710014343262, 1.0383635759353638, 1.3023735284805298, 1.243983268737793, 1.3442028760910034, 1.1477677822113037, 1.4811632633209229, 1.1794520616531372, 1.076568841934204, 1.0973451137542725, 1.2882033586502075, 1.3742038011550903, 1.1268327236175537, 1.658610224723816, 1.0122768878936768, 1.0043511390686035, 1.2590852975845337, 1.2846277952194214, 1.0004390478134155, 1.2473386526107788, 1.1235647201538086, 1.2272727489471436, 1.0223907232284546, 1.2134383916854858, 1.1474978923797607, 1.0836845636367798, 1.1091647148132324, 1.1884057521820068, 1.1561740636825562, 1.0967597961425781, 1.138916254043579, 1.2512552738189697, 1.0890146493911743, 1.1165413856506348, 1.0194836854934692, 1.1758421659469604, 1.1564373970031738, 1.014352560043335, 1.0076923370361328, 1.0704565048217773, 1.1084710359573364, 1.0554171800613403, 1.4288914203643799, 1.0077208280563354, 1.0748944282531738, 1.0116041898727417, 1.2976000308990479, 1.2563323974609375, 1.0948970317840576, 1.1442539691925049, 1.1674489974975586, 1.148406744003296, 2.074122190475464, 1.7436399459838867, 1.0680243968963623, 1.0705599784851074, 1.1657087802886963, 1.144335150718689, 1.0169472694396973, 1.027571201324463, 1.2301051616668701, 1.0874197483062744, 1.047184705734253, 1.0196088552474976, 1.0719420909881592, 1.4525139331817627, 1.0317310094833374, 1.168987512588501, 1.1672288179397583, 1.156469464302063, 1.1163233518600464, 1.081118106842041, 1.077210545539856, 1.0288774967193604, 1.3370105028152466, 1.0711050033569336, 1.364341139793396, 1.1477305889129639, 1.0724132061004639, 1.0255674123764038, 1.0345704555511475, 1.391954779624939, 1.09041428565979, 1.0055972337722778, 1.078553557395935, 1.165531873703003, 1.2522698640823364, 1.0359771251678467, 1.1600202322006226, 1.2207717895507812, 1.235136866569519, 1.4035316705703735, 1.2283324003219604, 1.084302306175232, 1.0117433071136475, 1.2082710266113281, 1.0600446462631226, 1.027908205986023, 1.142486333847046, 1.2200000286102295, 1.0739293098449707, 1.0446051359176636, 1.4086335897445679, 1.3190521001815796, 1.0433522462844849, 1.2035927772521973, 1.032317042350769, 1.4278873205184937, 1.0481995344161987, 1.1589834690093994, 1.0395638942718506, 1.1036999225616455, 1.8709090948104858, 1.1063333749771118, 1.0503554344177246, 1.3130834102630615, 1.0511727333068848, 1.3839441537857056, 1.0447454452514648]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.736248016357422] ms
 --  Average per query NF    [1.3608086109161377] ms
 --  Average per query vegas [2.375439405441284] ms
Mean [1.183]  Median [1.116]  95th [1.455]  99th [2.056]  max [5.194]
Mean [1.183]  Median [1.116]  95th [1.455]  99th [2.056]  max [5.194]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.208884 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=0 | total-time=26.094015