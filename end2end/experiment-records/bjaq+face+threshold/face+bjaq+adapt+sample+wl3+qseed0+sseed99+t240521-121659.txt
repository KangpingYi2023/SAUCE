Input arguments = Namespace(data_update='sample', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 99, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.161073446273804
tensor(0.9952)
result is  tensor(380323.1875)
Enter testHyper
ReportEsts: [1.1024112701416016, 1.0443148612976074, 1.6400350332260132, 1.0010539293289185, 1.2261321544647217, 1.1353552341461182, 1.228801965713501, 1.2331106662750244, 1.0952959060668945, 1.0294785499572754, 1.058570146560669, 1.162500023841858, 1.0881989002227783, 1.0178571939468384, 1.0328311920166016, 1.3146613836288452, 1.3524785041809082, 1.098099708557129, 1.3187445402145386, 1.0510203838348389, 1.068748116493225, 1.0022857189178467, 1.1310373544692993, 1.0773438215255737, 1.1829617023468018, 1.0714285373687744, 1.1393581628799438, 1.4588979482650757, 1.0165433883666992, 1.1294883489608765, 1.1504079103469849, 1.116155743598938, 1.0068150758743286, 1.020204782485962, 1.1914840936660767, 1.1825764179229736, 1.3018176555633545, 1.0086956024169922, 1.0255590677261353, 1.0756886005401611, 1.0027340650558472, 1.1513062715530396, 1.1147369146347046, 1.0596215724945068, 1.110500693321228, 1.0804988145828247, 1.0930765867233276, 1.3291451930999756, 1.015987753868103, 1.1218273639678955, 1.2293332815170288, 1.3289183378219604, 1.015150547027588, 1.2988505363464355, 1.1294769048690796, 1.0825220346450806, 1.2635513544082642, 1.0900096893310547, 1.0223723649978638, 1.45292067527771, 1.2899999618530273, 1.1943427324295044, 1.258428692817688, 1.104072093963623, 1.4042552709579468, 1.1714285612106323, 1.13279128074646, 1.01181161403656, 1.3795541524887085, 1.24210524559021, 1.0146938562393188, 1.058583378791809, 1.287693977355957, 1.1744844913482666, 1.163181185722351, 1.0954245328903198, 1.781162142753601, 1.036152958869934, 1.1155143976211548, 1.4695143699645996, 1.1084715127944946, 1.0736552476882935, 1.0519858598709106, 1.3041826486587524, 1.33578360080719, 1.1311936378479004, 1.0868980884552002, 1.0957882404327393, 1.0477596521377563, 1.0318434238433838, 1.0528212785720825, 1.393545389175415, 1.0389659404754639, 1.4026503562927246, 1.1818181276321411, 1.04729163646698, 1.0973087549209595, 1.3648489713668823, 1.0526316165924072, 1.1447429656982422, 1.192139744758606, 1.0802552700042725, 1.0822646617889404, 1.004392385482788, 1.0286611318588257, 1.0756876468658447, 1.112067699432373, 1.1762652397155762, 1.0469728708267212, 1.0147196054458618, 1.0829763412475586, 1.1067044734954834, 1.179932713508606, 1.0441299676895142, 1.1604266166687012, 1.164102554321289, 1.0367612838745117, 1.198632836341858, 1.3125853538513184, 1.2321885824203491, 1.180438756942749, 1.0956257581710815, 1.0946189165115356, 1.1482677459716797, 1.3396317958831787, 1.1887123584747314, 1.0423556566238403, 1.1724437475204468, 1.2663934230804443, 1.0965263843536377, 1.0242658853530884, 1.1542894840240479, 1.195773720741272, 1.5, 1.079561471939087, 1.0225781202316284, 1.0523420572280884, 1.1060162782669067, 1.0697394609451294, 1.2552493810653687, 1.164866328239441, 1.0496560335159302, 1.113281488418579, 1.2962560653686523, 1.0948430299758911, 1.013000726699829, 1.104403018951416, 1.3776766061782837, 1.0881160497665405, 1.0598011016845703, 1.1916377544403076, 1.1816433668136597, 1.3660565614700317, 1.0411804914474487, 1.1874710321426392, 1.0037282705307007, 1.1531965732574463, 1.0520540475845337, 1.014650583267212, 1.2082960605621338, 1.1453253030776978, 1.0515986680984497, 1.0156813859939575, 1.2748299837112427, 1.1785268783569336, 1.1329624652862549, 1.0094594955444336, 1.2671620845794678, 1.0347920656204224, 1.065544843673706, 1.0041149854660034, 1.110819935798645, 1.1298701763153076, 1.1940590143203735, 1.1324931383132935, 1.1887487173080444, 1.1224489212036133, 1.3038288354873657, 1.2254146337509155, 1.1237856149673462, 1.0032880306243896, 1.1104029417037964, 1.0031414031982422, 1.160367727279663, 1.1314741373062134, 1.1046512126922607, 1.0132397413253784, 1.3467016220092773, 1.1445103883743286, 1.318068504333496, 1.064825415611267, 1.0284312963485718, 1.5060685873031616, 1.419273018836975, 1.8933603763580322, 1.2641878128051758, 1.0861608982086182, 1.0704225301742554, 1.0073966979980469, 1.0570275783538818]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.760291337966919] ms
 --  Average per query NF    [1.3608074188232422] ms
 --  Average per query vegas [2.3994839191436768] ms
Mean [1.153]  Median [1.114]  95th [1.403]  99th [1.641]  max [1.893]
Mean [1.153]  Median [1.114]  95th [1.403]  99th [1.641]  max [1.893]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.839942 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=sample', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
Sample - START
Sample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[7.1525574e-07 3.2782555e-06 1.1920929e-07 4.7683716e-07 4.1723251e-07]
Distance score: 1.0013579867518274e-06
SAUCE Drift detection: False
Detection latency: 0.0232s

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.026303 | Model-update-time: 0.000000


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=sample', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.172750234603882
tensor(0.9937)
result is  tensor(455692.3438)
Enter testHyper
ReportEsts: [1.0654606819152832, 1.0153073072433472, 1.2529411315917969, 1.0150094032287598, 1.0226892232894897, 1.2345831394195557, 1.1704833507537842, 1.0141010284423828, 1.1411619186401367, 1.0070832967758179, 1.0602632761001587, 1.3151280879974365, 1.1501154899597168, 1.03023362159729, 1.038502812385559, 1.0120527744293213, 1.5260748863220215, 1.1371417045593262, 1.0490057468414307, 1.2444723844528198, 1.091565489768982, 1.1547750234603882, 1.1478290557861328, 1.0248745679855347, 1.2029736042022705, 1.3263601064682007, 1.0558563470840454, 1.139523983001709, 1.0065189599990845, 1.5650224685668945, 1.115906834602356, 1.2700729370117188, 1.0985825061798096, 1.0177096128463745, 1.0983070135116577, 1.1090627908706665, 1.1446610689163208, 1.066910982131958, 1.362620234489441, 1.0135647058486938, 1.0270187854766846, 1.1079812049865723, 1.0278311967849731, 1.0534652471542358, 1.0663599967956543, 1.0635948181152344, 1.3070638179779053, 1.1616222858428955, 1.165289282798767, 1.0898046493530273, 1.0093728303909302, 1.09770929813385, 1.1018120050430298, 1.041483759880066, 1.0091890096664429, 1.7104878425598145, 1.2693958282470703, 1.0617986917495728, 1.2472002506256104, 1.2337708473205566, 1.6401028633117676, 1.0468058586120605, 1.0647666454315186, 1.3393038511276245, 1.0399718284606934, 1.1000299453735352, 1.2531808614730835, 1.0044870376586914, 1.1162006855010986, 1.0617554187774658, 1.1722280979156494, 1.2038904428482056, 1.0945103168487549, 1.0262150764465332, 1.049281120300293, 1.1622564792633057, 1.0804061889648438, 1.2094594240188599, 1.4875847101211548, 1.1203852891921997, 1.2009238004684448, 1.573899507522583, 1.120504379272461, 1.2158488035202026, 1.3270410299301147, 1.3617020845413208, 1.163536787033081, 1.53447687625885, 1.0067099332809448, 1.1060339212417603, 1.1662670373916626, 1.0456287860870361, 1.4684436321258545, 1.2081592082977295, 1.2737610340118408, 1.1124051809310913, 1.1720882654190063, 1.188433051109314, 1.3920526504516602, 1.2593917846679688, 1.2097336053848267, 1.129374623298645, 1.1045454740524292, 1.0763274431228638, 1.0751959085464478, 1.0020920038223267, 1.2252966165542603, 1.0255047082901, 1.2144927978515625, 1.267777919769287, 1.1341841220855713, 1.0993001461029053, 1.1840108633041382, 1.0653038024902344, 1.0885138511657715, 1.0589659214019775, 1.0831091403961182, 1.2802625894546509, 1.130304217338562, 1.078740119934082, 1.1487324237823486, 1.0763636827468872, 1.0046567916870117, 1.5407813787460327, 1.0080645084381104, 1.0733975172042847, 1.0604954957962036, 1.2964743375778198, 1.1367549896240234, 1.1553189754486084, 1.2067676782608032, 1.1570460796356201, 1.0576879978179932, 1.8157589435577393, 1.6512261629104614, 1.1239901781082153, 1.0123875141143799, 1.112094759941101, 1.0938177108764648, 1.0220189094543457, 1.1302706003189087, 1.0988014936447144, 1.0074249505996704, 1.0044314861297607, 1.0213885307312012, 1.1224722862243652, 1.4914286136627197, 1.1597949266433716, 1.0535887479782104, 1.0501320362091064, 1.211279034614563, 1.0695271492004395, 1.1820026636123657, 1.030440092086792, 1.0002202987670898, 1.1816624402999878, 1.1764461994171143, 1.3492063283920288, 1.1033748388290405, 1.1264545917510986, 1.0231866836547852, 1.0521042346954346, 1.2471609115600586, 1.042038917541504, 1.0729494094848633, 1.0322370529174805, 1.1712836027145386, 1.1878852844238281, 1.0600272417068481, 1.241979718208313, 1.1291908025741577, 1.2100318670272827, 1.703849196434021, 1.1244945526123047, 1.0180652141571045, 1.021690845489502, 1.1356450319290161, 1.0658973455429077, 1.1183109283447266, 1.0862809419631958, 1.4255318641662598, 1.2177919149398804, 1.07766854763031, 1.558598518371582, 1.602652907371521, 1.0002593994140625, 1.4303728342056274, 1.0477241277694702, 1.373683214187622, 1.0881181955337524, 1.1163710355758667, 1.1025513410568237, 1.3579661846160889, 2.0789473056793213, 1.0233349800109863, 1.9210525751113892, 1.3402988910675049, 1.009417176246643, 1.4340659379959106, 1.0583828687667847]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7417829036712646] ms
 --  Average per query NF    [1.3581466674804688] ms
 --  Average per query vegas [2.383636236190796] ms
Mean [1.172]  Median [1.117]  95th [1.559]  99th [1.817]  max [2.079]
Mean [1.172]  Median [1.117]  95th [1.559]  99th [1.817]  max [2.079]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.223010 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=0 | total-time=26.146229