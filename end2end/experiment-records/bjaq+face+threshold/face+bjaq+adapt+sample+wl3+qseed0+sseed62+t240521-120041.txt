Input arguments = Namespace(data_update='sample', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 62, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.17515516281128
tensor(0.9967)
result is  tensor(380905.5625)
Enter testHyper
ReportEsts: [1.1756718158721924, 1.0337425470352173, 1.4023135900497437, 1.2156243324279785, 1.2282577753067017, 1.1103389263153076, 1.2679935693740845, 1.1025760173797607, 1.0734682083129883, 1.1753697395324707, 1.0516796112060547, 1.1006356477737427, 1.110857605934143, 1.0580357313156128, 1.1418453454971313, 1.2952831983566284, 1.2858116626739502, 1.184679388999939, 1.2046830654144287, 1.0178571939468384, 1.080640196800232, 1.0699728727340698, 1.1688368320465088, 1.0892584323883057, 1.146941065788269, 1.1627486944198608, 1.1373873949050903, 1.3916414976119995, 1.0078285932540894, 1.0840198993682861, 1.146151065826416, 1.1019917726516724, 1.1940439939498901, 1.0817934274673462, 1.1658293008804321, 1.2700262069702148, 1.4192370176315308, 1.1788545846939087, 1.0342121124267578, 1.0347305536270142, 1.024832010269165, 1.1094582080841064, 1.1088818311691284, 1.0614159107208252, 1.0838791131973267, 1.1054421663284302, 1.0362964868545532, 1.2946412563323975, 1.0379369258880615, 1.0879864692687988, 1.1790281534194946, 1.3327008485794067, 1.1257717609405518, 1.3205342292785645, 1.0595546960830688, 1.033540964126587, 1.277570128440857, 1.1033334732055664, 1.1524559259414673, 1.4535542726516724, 1.249925136566162, 1.165511965751648, 1.355210542678833, 1.1146326065063477, 1.2132352590560913, 1.1428571939468384, 1.1368993520736694, 1.0140751600265503, 1.0785785913467407, 1.357894778251648, 1.142463207244873, 1.0435841083526611, 1.2551261186599731, 1.0076141357421875, 1.1745761632919312, 1.0690200328826904, 2.0331356525421143, 1.0838019847869873, 1.0859906673431396, 1.3270015716552734, 1.2342824935913086, 1.044419288635254, 1.0299134254455566, 1.2828267812728882, 1.1958032846450806, 1.1885713338851929, 1.0983271598815918, 1.0125598907470703, 1.017276644706726, 1.079857349395752, 1.0000923871994019, 1.2511796951293945, 1.052371859550476, 1.2978070974349976, 1.1890244483947754, 1.064510464668274, 1.0670030117034912, 1.3973060846328735, 1.034482717514038, 1.1675872802734375, 1.125, 1.0051512718200684, 1.1298961639404297, 1.014641284942627, 1.015940546989441, 1.0773565769195557, 1.171119213104248, 1.1745200157165527, 1.0266971588134766, 1.0665520429611206, 1.173619270324707, 1.0511211156845093, 1.1428273916244507, 1.0675904750823975, 1.1585719585418701, 1.1464647054672241, 1.0491758584976196, 1.07764732837677, 1.2864872217178345, 1.163116455078125, 1.1648926734924316, 1.1065268516540527, 1.3624725341796875, 1.0956943035125732, 1.2383720874786377, 1.1603384017944336, 1.1182115077972412, 1.1911592483520508, 1.2350119352340698, 1.152638554573059, 1.0538069009780884, 1.302543044090271, 1.1500931978225708, 1.5, 1.1727663278579712, 1.0863744020462036, 1.002815842628479, 1.0995122194290161, 1.1183924674987793, 1.3211325407028198, 1.1475434303283691, 1.0603833198547363, 1.0187879800796509, 1.321716070175171, 1.0985147953033447, 1.0065802335739136, 1.0908018350601196, 1.6845916509628296, 1.0167547464370728, 1.0854403972625732, 1.259653925895691, 1.1613895893096924, 1.3122003078460693, 1.113901972770691, 1.165600299835205, 1.035899043083191, 1.068967342376709, 1.0309510231018066, 1.039988398551941, 1.0827813148498535, 1.0598787069320679, 1.2101256847381592, 1.022993564605713, 1.2977839708328247, 1.1785268783569336, 1.0611764192581177, 1.1422369480133057, 1.2677228450775146, 1.0603471994400024, 1.1406320333480835, 1.1023378372192383, 1.1074053049087524, 1.1623376607894897, 1.1498076915740967, 1.121593952178955, 1.0268216133117676, 1.0053449869155884, 1.2541160583496094, 1.2732822895050049, 1.0724303722381592, 1.0512739419937134, 1.1786174774169922, 1.0072362422943115, 1.0377936363220215, 1.1600868701934814, 1.0983086824417114, 1.030004858970642, 1.2947747707366943, 1.1164422035217285, 1.4533692598342896, 1.0078136920928955, 1.0978262424468994, 1.627601981163025, 1.382651686668396, 1.6722919940948486, 1.1918818950653076, 1.1119216680526733, 1.0410958528518677, 1.053251028060913, 1.0634130239486694]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7543833255767822] ms
 --  Average per query NF    [1.3634538650512695] ms
 --  Average per query vegas [2.3909294605255127] ms
Mean [1.155]  Median [1.118]  95th [1.392]  99th [1.672]  max [2.033]
Mean [1.155]  Median [1.118]  95th [1.392]  99th [1.672]  max [2.033]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.832594 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=sample', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
Sample - START
Sample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[5.9604645e-07 4.7683716e-07 7.1525574e-07 1.8477440e-06 2.3841858e-07]
Distance score: 7.748603820800781e-07
SAUCE Drift detection: False
Detection latency: 0.0234s

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.025103 | Model-update-time: 0.000000


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=sample', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.216616868972778
tensor(0.9973)
result is  tensor(457360.9688)
Enter testHyper
ReportEsts: [1.1293957233428955, 1.0516890287399292, 1.116094946861267, 1.0878913402557373, 1.0678459405899048, 1.2979464530944824, 1.1956956386566162, 1.0441371202468872, 1.0038354396820068, 1.0704412460327148, 1.065282940864563, 1.2779898643493652, 1.1849148273468018, 1.2008546590805054, 1.0088738203048706, 1.0585172176361084, 1.5510470867156982, 1.1034821271896362, 1.0789932012557983, 1.2423534393310547, 1.1223442554473877, 1.1314630508422852, 1.0336254835128784, 1.0524615049362183, 1.0547749996185303, 1.2221803665161133, 1.1489307880401611, 1.1996233463287354, 1.3313379287719727, 1.1074379682540894, 1.1856170892715454, 1.188811182975769, 1.0189532041549683, 1.0552375316619873, 1.1652151346206665, 1.146196722984314, 1.0313506126403809, 1.1647003889083862, 1.3547090291976929, 1.0475901365280151, 1.0057827234268188, 1.0356347560882568, 1.2835949659347534, 1.0013062953948975, 1.0145236253738403, 1.021175503730774, 1.0938676595687866, 1.1576794385910034, 1.0603773593902588, 1.1529196500778198, 1.013083577156067, 1.0153143405914307, 1.0869954824447632, 1.1536585092544556, 1.1476519107818604, 1.3227077722549438, 1.275251865386963, 1.1132010221481323, 1.2741280794143677, 1.1673680543899536, 1.3312499523162842, 1.0794302225112915, 1.1528509855270386, 1.5247479677200317, 1.067700743675232, 1.0466769933700562, 1.278496265411377, 1.0242409706115723, 1.106302261352539, 1.048866629600525, 1.0753731727600098, 1.127652645111084, 1.065346360206604, 1.1231979131698608, 1.025652527809143, 1.2175482511520386, 1.0631670951843262, 1.246058464050293, 1.3496894836425781, 1.059649109840393, 1.1280864477157593, 1.195926547050476, 1.0019382238388062, 1.1380397081375122, 1.3446636199951172, 1.2886598110198975, 1.1847325563430786, 1.4091050624847412, 1.12071692943573, 1.121300220489502, 1.164398431777954, 1.1908676624298096, 1.2897788286209106, 1.1410150527954102, 1.1118708848953247, 1.0761404037475586, 1.334694266319275, 1.2521437406539917, 1.1444875001907349, 1.1131305694580078, 1.0195107460021973, 1.1544569730758667, 1.1975903511047363, 1.06796395778656, 1.0636883974075317, 1.1691759824752808, 1.2420052289962769, 1.228169560432434, 1.25, 1.066513180732727, 1.1372348070144653, 1.0138812065124512, 1.1574554443359375, 1.087998628616333, 1.0852842330932617, 1.0764740705490112, 1.0211378335952759, 1.2871354818344116, 1.20228910446167, 1.252252221107483, 1.0205681324005127, 1.252867579460144, 1.0069069862365723, 1.3250950574874878, 1.019441843032837, 1.08021879196167, 1.1169588565826416, 1.2457756996154785, 1.0196990966796875, 1.010136604309082, 1.0802019834518433, 1.0777015686035156, 1.187033772468567, 2.2851064205169678, 1.7950819730758667, 1.123702883720398, 1.013148307800293, 1.0030345916748047, 1.0939421653747559, 1.0327717065811157, 1.003255009651184, 1.1515620946884155, 1.0127358436584473, 1.0471140146255493, 1.011087417602539, 1.1655899286270142, 1.5187499523162842, 1.1668801307678223, 1.19464910030365, 1.1061972379684448, 1.027762532234192, 1.040776014328003, 1.0863398313522339, 1.1170670986175537, 1.032835841178894, 1.0469093322753906, 1.127260684967041, 1.2903225421905518, 1.016149878501892, 1.1278122663497925, 1.0538853406906128, 1.04347825050354, 1.071413516998291, 1.1244337558746338, 1.1585843563079834, 1.0792886018753052, 1.021276593208313, 1.0626860857009888, 1.002159595489502, 1.2310048341751099, 1.106626033782959, 1.0572127103805542, 1.5519765615463257, 1.1562556028366089, 1.009324312210083, 1.0448951721191406, 1.0998024940490723, 1.1827853918075562, 1.018775224685669, 1.1460092067718506, 1.6739130020141602, 1.085152506828308, 1.137084722518921, 1.6218717098236084, 1.471699833869934, 1.244728684425354, 1.1187307834625244, 1.0442830324172974, 1.325722098350525, 1.0344048738479614, 1.1565204858779907, 1.0467084646224976, 1.217836856842041, 1.8430838584899902, 1.0185185670852661, 1.0336488485336304, 1.2750078439712524, 1.0468636751174927, 1.518591046333313, 1.029752492904663]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7227511405944824] ms
 --  Average per query NF    [1.3572871685028076] ms
 --  Average per query vegas [2.365463972091675] ms
Mean [1.154]  Median [1.117]  95th [1.474]  99th [1.796]  max [2.285]
Mean [1.154]  Median [1.117]  95th [1.474]  99th [1.796]  max [2.285]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.243268 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=0 | total-time=26.161543