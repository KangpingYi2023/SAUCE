Input arguments = Namespace(data_update='sample', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 77, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.159935235977173
tensor(0.9932)
result is  tensor(379557.4375)
Enter testHyper
ReportEsts: [1.1423357725143433, 1.0621495246887207, 1.3886245489120483, 1.0486418008804321, 1.278496265411377, 1.0828099250793457, 1.2164788246154785, 1.2433421611785889, 1.061470627784729, 1.1003782749176025, 1.1369508504867554, 1.2302966117858887, 1.1155415773391724, 1.0290178060531616, 1.0376228094100952, 1.2203882932662964, 1.3419532775878906, 1.2496436834335327, 1.0635634660720825, 1.163265347480774, 1.175411581993103, 1.0102629661560059, 1.1926484107971191, 1.0544720888137817, 1.119986891746521, 1.0650994777679443, 1.1092342138290405, 1.3868613243103027, 1.0873486995697021, 1.013400673866272, 1.2100034952163696, 1.0696836709976196, 1.000709056854248, 1.0350409746170044, 1.1538050174713135, 1.0311447381973267, 1.3650689125061035, 1.2112563848495483, 1.1540056467056274, 1.2291017770767212, 1.0415815114974976, 1.1390904188156128, 1.0638997554779053, 1.0312877893447876, 1.0574688911437988, 1.0158730745315552, 1.0390818119049072, 1.329398274421692, 1.0438477993011475, 1.1641285419464111, 1.2877094745635986, 1.3704065084457397, 1.0614060163497925, 1.1384570598602295, 1.2163642644882202, 1.047751545906067, 1.2364486455917358, 1.1484901905059814, 1.0038361549377441, 1.4237505197525024, 1.1867974996566772, 1.157492995262146, 1.216327428817749, 1.1253126859664917, 1.1913357973098755, 1.1428571939468384, 1.1494041681289673, 1.0062423944473267, 1.079817771911621, 1.4736841917037964, 1.0884413719177246, 1.209754228591919, 1.2236374616622925, 1.2860361337661743, 1.0168088674545288, 1.1456382274627686, 1.9712492227554321, 1.060150384902954, 1.0299934148788452, 1.262973666191101, 1.0409947633743286, 1.0260192155838013, 1.0822741985321045, 1.2084357738494873, 1.308559775352478, 1.092409610748291, 1.2238798141479492, 1.0525598526000977, 1.0390269756317139, 1.0452457666397095, 1.0738425254821777, 1.356642723083496, 1.0219978094100952, 1.265869379043579, 1.0317460298538208, 1.1453256607055664, 1.0970858335494995, 1.2962212562561035, 1.034482717514038, 1.174702763557434, 1.1390820741653442, 1.1407641172409058, 1.1336474418640137, 1.0, 1.141736388206482, 1.0757805109024048, 1.0536112785339355, 1.1832460165023804, 1.0928281545639038, 1.0264712572097778, 1.0354151725769043, 1.0973782539367676, 1.2068496942520142, 1.070605993270874, 1.0796337127685547, 1.15816330909729, 1.027336835861206, 1.0045348405838013, 1.1718474626541138, 1.17137610912323, 1.2581839561462402, 1.1542017459869385, 1.1752350330352783, 1.1225227117538452, 1.2572674751281738, 1.1903631687164307, 1.1481785774230957, 1.003991723060608, 1.3148936033248901, 1.1496325731277466, 1.1630033254623413, 1.2484548091888428, 1.3032939434051514, 1.5, 1.0662741661071777, 1.105014443397522, 1.0104039907455444, 1.285203218460083, 1.1414369344711304, 1.2552493810653687, 1.1479417085647583, 1.1847740411758423, 1.067994475364685, 1.334725260734558, 1.166858196258545, 1.056213140487671, 1.133479118347168, 1.5167375802993774, 1.0042372941970825, 1.0830966234207153, 1.1058053970336914, 1.1502372026443481, 1.3143010139465332, 1.0566836595535278, 1.048776388168335, 1.1317273378372192, 1.0763098001480103, 1.0320764780044556, 1.0949947834014893, 1.1259325742721558, 1.1779186725616455, 1.0118157863616943, 1.0103248357772827, 1.3678832054138184, 1.1625615358352661, 1.116929054260254, 1.1811447143554688, 1.2398511171340942, 1.037706732749939, 1.0076342821121216, 1.0010864734649658, 1.0754257440567017, 1.1298701763153076, 1.2181352376937866, 1.0497275590896606, 1.0583760738372803, 1.0534499883651733, 1.1335421800613403, 1.105482816696167, 1.2218589782714844, 1.0145046710968018, 1.0558843612670898, 1.0207239389419556, 1.0572012662887573, 1.1401666402816772, 1.0961945056915283, 1.021252155303955, 1.2809269428253174, 1.066918969154358, 1.3057969808578491, 1.0335458517074585, 1.0110182762145996, 1.4613415002822876, 1.4391428232192993, 1.8238812685012817, 1.1667670011520386, 1.0466861724853516, 1.085714340209961, 1.0226984024047852, 1.06029212474823]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7478911876678467] ms
 --  Average per query NF    [1.358342170715332] ms
 --  Average per query vegas [2.3895490169525146] ms
Mean [1.148]  Median [1.128]  95th [1.371]  99th [1.520]  max [1.971]
Mean [1.148]  Median [1.128]  95th [1.371]  99th [1.520]  max [1.971]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.818528 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=sample', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
Sample - START
Sample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[1.1920929e-07 2.9802322e-07 5.9604645e-08 5.9604645e-08 1.1920929e-07]
Distance score: 1.3113022134803032e-07
SAUCE Drift detection: False
Detection latency: 0.0232s

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.025418 | Model-update-time: 0.000000


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=sample', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.16416621208191
tensor(0.9925)
result is  tensor(455139.5312)
Enter testHyper
ReportEsts: [1.0080773830413818, 1.0285427570343018, 1.1661971807479858, 1.0320724248886108, 1.0665935277938843, 1.3215686082839966, 1.167481541633606, 1.0097800493240356, 1.2335478067398071, 1.0072993040084839, 1.0677825212478638, 1.339456558227539, 1.02610445022583, 1.2073026895523071, 1.3771029710769653, 1.0650901794433594, 1.1650311946868896, 1.135286808013916, 1.1305338144302368, 1.2101144790649414, 1.145717740058899, 1.2583835124969482, 1.0549628734588623, 1.1165884733200073, 1.116812825202942, 1.2494152784347534, 1.0460668802261353, 1.1023364067077637, 1.3171745538711548, 1.6523765325546265, 1.121449589729309, 1.1338027715682983, 1.0161103010177612, 1.0663437843322754, 1.117379069328308, 1.1121691465377808, 1.128509283065796, 1.0463117361068726, 1.0408207178115845, 1.001814603805542, 1.0001267194747925, 1.1247059106826782, 1.0826834440231323, 1.0495551824569702, 1.0633150339126587, 1.0857046842575073, 1.2017947435379028, 1.0357979536056519, 1.0461539030075073, 1.3373494148254395, 1.1054723262786865, 1.0063145160675049, 1.1382057666778564, 1.2603431940078735, 1.000278115272522, 1.7905627489089966, 1.1987900733947754, 1.157617211341858, 1.2447752952575684, 1.1473270654678345, 1.4147982597351074, 1.0124032497406006, 1.0145717859268188, 1.427202820777893, 1.0529066324234009, 1.112329125404358, 1.278131127357483, 1.0849723815917969, 1.1686419248580933, 1.0971639156341553, 1.0193982124328613, 1.1071150302886963, 1.083897352218628, 1.0878804922103882, 1.093800663948059, 1.0888071060180664, 1.2100672721862793, 1.0456960201263428, 1.2569636106491089, 1.0562033653259277, 1.220786690711975, 1.1099361181259155, 1.0651437044143677, 1.2298601865768433, 1.3696647882461548, 1.3859648704528809, 1.0700219869613647, 1.4625080823898315, 1.0384241342544556, 1.0614060163497925, 1.2011525630950928, 1.1012489795684814, 1.315777063369751, 1.1147441864013672, 1.390575885772705, 1.0205607414245605, 1.2119086980819702, 1.2242779731750488, 1.0796610116958618, 1.1856259107589722, 1.0236953496932983, 1.1205800771713257, 1.2230392694473267, 1.2047412395477295, 1.1583507061004639, 1.2127094268798828, 1.1474294662475586, 1.2028725147247314, 1.170454502105713, 1.1305328607559204, 1.0667719841003418, 1.1085489988327026, 1.185461163520813, 1.3665807247161865, 1.0978991985321045, 1.0303775072097778, 1.0046143531799316, 1.0555833578109741, 1.0750738382339478, 1.2641509771347046, 1.059813141822815, 1.121734619140625, 1.27057945728302, 1.3165680170059204, 1.0030816793441772, 1.1926313638687134, 1.0205554962158203, 1.240797519683838, 1.154439926147461, 1.1388609409332275, 1.189115285873413, 1.1925737857818604, 1.1175302267074585, 1.5944334268569946, 1.3483575582504272, 1.0952577590942383, 1.1678459644317627, 1.0755633115768433, 1.0735028982162476, 1.0761144161224365, 1.0483494997024536, 1.1743454933166504, 1.0293383598327637, 1.047019124031067, 1.1091688871383667, 1.0523264408111572, 1.490797519683838, 1.0230985879898071, 1.2432705163955688, 1.0971548557281494, 1.0275206565856934, 1.081336498260498, 1.0909852981567383, 1.0290464162826538, 1.025831937789917, 1.0181576013565063, 1.1220089197158813, 1.4237288236618042, 1.1099414825439453, 1.2457447052001953, 1.023762822151184, 1.0640755891799927, 1.1531932353973389, 1.1320593357086182, 1.0455269813537598, 1.0642043352127075, 1.1285653114318848, 1.0650967359542847, 1.0165083408355713, 1.1595773696899414, 1.095184326171875, 1.0752683877944946, 1.6820673942565918, 1.0395981073379517, 1.1413171291351318, 1.1113146543502808, 1.2469362020492554, 1.0648112297058105, 1.03546142578125, 1.0718244314193726, 1.3469387292861938, 1.0459673404693604, 1.0918447971343994, 1.3484529256820679, 1.3015997409820557, 1.2743394374847412, 1.336459755897522, 1.0074710845947266, 1.2400836944580078, 1.0428940057754517, 1.276280164718628, 1.065231204032898, 1.1957833766937256, 1.6738499402999878, 1.0292507410049438, 1.8571428060531616, 1.261296033859253, 1.0990158319473267, 1.3305509090423584, 1.1995806694030762]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.773622512817383] ms
 --  Average per query NF    [1.3643550872802734] ms
 --  Average per query vegas [2.4092674255371094] ms
Mean [1.157]  Median [1.116]  95th [1.415]  99th [1.683]  max [1.857]
Mean [1.157]  Median [1.116]  95th [1.415]  99th [1.683]  max [1.857]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.211072 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=0 | total-time=26.085305