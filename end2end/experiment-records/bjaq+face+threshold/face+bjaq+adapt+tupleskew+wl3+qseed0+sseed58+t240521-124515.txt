Input arguments = Namespace(data_update='tupleskew', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 58, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.212840795516968
tensor(0.9945)
result is  tensor(380079.1250)
Enter testHyper
ReportEsts: [1.1936051845550537, 1.084381103515625, 1.2450522184371948, 1.1855127811431885, 1.2502940893173218, 1.1036051511764526, 1.252053141593933, 1.1764557361602783, 1.0249929428100586, 1.0608208179473877, 1.0938845872879028, 1.0866525173187256, 1.0739524364471436, 1.0223214626312256, 1.1891286373138428, 1.2208447456359863, 1.0955508947372437, 1.0701900720596313, 1.2184630632400513, 1.0229592323303223, 1.0879056453704834, 1.0689561367034912, 1.1711241006851196, 1.0045301914215088, 1.1224373579025269, 1.117540717124939, 1.0343468189239502, 1.4413208961486816, 1.0057770013809204, 1.1145356893539429, 1.0865554809570312, 1.142676830291748, 1.0947030782699585, 1.0407272577285767, 1.1012189388275146, 1.0856494903564453, 1.1798110008239746, 1.0603067874908447, 1.0487226247787476, 1.0150898694992065, 1.0082473754882812, 1.1412675380706787, 1.1510523557662964, 1.0179450511932373, 1.0993027687072754, 1.045351505279541, 1.090659499168396, 1.2189245223999023, 1.0038747787475586, 1.1049069166183472, 1.2195767164230347, 1.3038365840911865, 1.1832932233810425, 1.1500436067581177, 1.1470310688018799, 1.0115901231765747, 1.2635513544082642, 1.0683424472808838, 1.3923484086990356, 1.3778420686721802, 1.2882071733474731, 1.212499976158142, 1.3697324991226196, 1.0413473844528198, 1.2790697813034058, 1.0571428537368774, 1.1852551698684692, 1.0447602272033691, 1.1043965816497803, 1.48421049118042, 1.029826045036316, 1.0802255868911743, 1.2706031799316406, 1.0543328523635864, 1.0325392484664917, 1.0749669075012207, 2.0671019554138184, 1.0261200666427612, 1.049100399017334, 1.3574689626693726, 1.1127679347991943, 1.1796156167984009, 1.0640785694122314, 1.175513505935669, 1.2198859453201294, 1.0893288850784302, 1.154174566268921, 1.247061848640442, 1.0104591846466064, 1.1892362833023071, 1.0088112354278564, 1.338618278503418, 1.0168683528900146, 1.2844806909561157, 1.1142857074737549, 1.1870614290237427, 1.1096187829971313, 1.331621766090393, 1.034482717514038, 1.1265798807144165, 1.2390317916870117, 1.165045976638794, 1.0340224504470825, 1.0216903686523438, 1.0277196168899536, 1.067911982536316, 1.1843347549438477, 1.2181501388549805, 1.0295330286026, 1.001381516456604, 1.098189353942871, 1.0922646522521973, 1.2323758602142334, 1.0939337015151978, 1.141648292541504, 1.1182266473770142, 1.0549242496490479, 1.1699987649917603, 1.2742818593978882, 1.0857363939285278, 1.146484375, 1.0859665870666504, 1.1175568103790283, 1.1753934621810913, 1.198643445968628, 1.2408171892166138, 1.1726897954940796, 1.2637892961502075, 1.3082133531570435, 1.117234468460083, 1.1834007501602173, 1.1047683954238892, 1.1988812685012817, 1.5, 1.0181968212127686, 1.1228668689727783, 1.0338038206100464, 1.0891057252883911, 1.0723743438720703, 1.143454909324646, 1.1781572103500366, 1.094416856765747, 1.136095404624939, 1.2308326959609985, 1.0938361883163452, 1.0291037559509277, 1.1027028560638428, 1.1731141805648804, 1.105444312095642, 1.020951747894287, 1.136374592781067, 1.1611331701278687, 1.35927152633667, 1.1043628454208374, 1.1036728620529175, 1.06511390209198, 1.0908375978469849, 1.0281373262405396, 1.0047863721847534, 1.22184419631958, 1.0182172060012817, 1.0280565023422241, 1.0641230344772339, 1.3215796947479248, 1.3111110925674438, 1.1112284660339355, 1.2543506622314453, 1.1560003757476807, 1.0129190683364868, 1.1406893730163574, 1.0296909809112549, 1.1252200603485107, 1.1363636255264282, 1.4089616537094116, 1.0126022100448608, 1.0619304180145264, 1.0203272104263306, 1.2557483911514282, 1.003185749053955, 1.1310524940490723, 1.2406384944915771, 1.0207970142364502, 1.0514235496520996, 1.0990806818008423, 1.084751844406128, 1.1448203325271606, 1.0422728061676025, 1.2809269428253174, 1.0318233966827393, 1.4928550720214844, 1.046852469444275, 1.0210317373275757, 1.4818276166915894, 1.474531650543213, 1.6563071012496948, 1.1353250741958618, 1.1942476034164429, 1.1343283653259277, 1.0498478412628174, 1.037383794784546]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.8264107704162598] ms
 --  Average per query NF    [1.4282798767089844] ms
 --  Average per query vegas [2.3981308937072754] ms
Mean [1.146]  Median [1.112]  95th [1.379]  99th [1.502]  max [2.067]
Mean [1.146]  Median [1.112]  95th [1.379]  99th [1.502]  max [2.067]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.898499 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=tupleskew', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
TupleSkewSample - START
0.001
TupleSkewSample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[9.0837479e-05 8.4805489e-04 1.3232231e-05 1.5974045e-05 6.1750412e-05]
Distance score: 0.00020596981630660594
SAUCE Drift detection: True
Detection latency: 0.0229s

DRIFT-DETECTED after 2-th workload
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/incremental_train.py', '--dataset=bjaq', '--end2end', '--model=face', '--model_update=adapt', '--update_size=80000', '--epochs=0']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
update_size: 76433
AdaptTask - START
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
train data shape: 80000, transfer data shape:16000
Training done; evaluating likelihood on full data:
Saved to: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
AdaptTask - END

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.010798 | Model-update-time: 2.230392


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=tupleskew', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.167453050613403
tensor(0.9950)
result is  tensor(456327.3750)
Enter testHyper
ReportEsts: [1.0976957082748413, 1.1224262714385986, 1.5982658863067627, 1.9641000032424927, 1.0311027765274048, 1.0942741632461548, 1.1312309503555298, 1.170605182647705, 1.0051805973052979, 1.0449273586273193, 1.0075905323028564, 5.176470756530762, 1.002392292022705, 1.0714366436004639, 1.1027889251708984, 1.0163037776947021, 1.1490967273712158, 1.2020360231399536, 1.1321407556533813, 1.4444663524627686, 1.2312308549880981, 1.4166144132614136, 1.5717017650604248, 1.0316869020462036, 1.143925666809082, 1.1507868766784668, 1.0166068077087402, 1.206027626991272, 1.206364393234253, 1.4103156328201294, 1.0177462100982666, 1.6271185874938965, 1.1018238067626953, 1.2423627376556396, 1.2020376920700073, 1.096771001815796, 1.0408815145492554, 1.3071428537368774, 1.786939263343811, 1.1079213619232178, 1.005709171295166, 1.3586833477020264, 1.2527598142623901, 1.1581110954284668, 1.0867269039154053, 1.2485629320144653, 18.58823585510254, 1.366390585899353, 1.3095238208770752, 1.4725275039672852, 1.0305806398391724, 1.1253842115402222, 1.0125484466552734, 1.02949857711792, 1.0444849729537964, 1.4946407079696655, 1.158553123474121, 1.1247923374176025, 1.3407750129699707, 1.1398361921310425, 1.377892017364502, 1.0168352127075195, 1.046542763710022, 1.096659779548645, 1.1000827550888062, 1.088976263999939, 1.323309063911438, 1.0987969636917114, 1.095831274986267, 1.0973503589630127, 1.1712253093719482, 1.2500503063201904, 1.1264495849609375, 1.1342835426330566, 1.0825245380401611, 1.1653958559036255, 1.1184866428375244, 1.1042215824127197, 1.1320879459381104, 1.1110106706619263, 1.1437586545944214, 1.2246736288070679, 1.2211138010025024, 1.3118802309036255, 1.2929201126098633, 1.6170213222503662, 1.2483808994293213, 1.3686717748641968, 1.1407305002212524, 1.0780426263809204, 1.0811779499053955, 1.1655070781707764, 1.512654423713684, 1.1202811002731323, 1.478007197380066, 1.0900075435638428, 1.0053157806396484, 1.2453250885009766, 1.0107269287109375, 1.8549007177352905, 1.2271612882614136, 1.1431699991226196, 1.0149253606796265, 1.12266206741333, 1.1665087938308716, 1.1609680652618408, 1.0812015533447266, 1.166109561920166, 1.031518578529358, 1.0707632303237915, 1.0705729722976685, 1.0855034589767456, 1.345008373260498, 1.236128807067871, 1.0837500095367432, 1.1114628314971924, 1.0015579462051392, 1.1512349843978882, 1.0595252513885498, 1.0973451137542725, 1.0676770210266113, 1.0431689023971558, 1.0667287111282349, 1.4982777833938599, 1.1459566354751587, 1.1256492137908936, 1.0656839609146118, 1.081861972808838, 1.066850185394287, 1.0539497137069702, 1.1353086233139038, 1.0765708684921265, 1.0106910467147827, 1.9226456880569458, 1.8061420917510986, 1.1048970222473145, 1.0649996995925903, 1.0229051113128662, 1.0609108209609985, 1.058853268623352, 1.0203486680984497, 1.1664341688156128, 1.0102832317352295, 1.0598183870315552, 1.0324466228485107, 1.0322597026824951, 1.2944785356521606, 1.1859943866729736, 1.3154172897338867, 1.0680543184280396, 1.1551703214645386, 1.0747162103652954, 1.0773301124572754, 1.0034970045089722, 1.0145502090454102, 1.0000320672988892, 1.0629570484161377, 1.078740119934082, 1.0127372741699219, 1.0336822271347046, 1.008055567741394, 1.1452991962432861, 4.173267364501953, 1.0143399238586426, 1.1219066381454468, 1.052820086479187, 1.2042592763900757, 1.1051102876663208, 1.0804831981658936, 1.3409165143966675, 1.0218682289123535, 1.2508788108825684, 1.5917487144470215, 1.1402109861373901, 1.0998011827468872, 1.0468058586120605, 1.467576265335083, 1.0003494024276733, 1.1000707149505615, 1.2704930305480957, 1.7894736528396606, 1.1166291236877441, 1.1264411211013794, 1.5941063165664673, 1.3042266368865967, 1.1320915222167969, 1.0224210023880005, 1.0607966184616089, 1.4712218046188354, 1.1085033416748047, 1.2155817747116089, 1.059619426727295, 1.3307392597198486, 1.9504090547561646, 1.1036690473556519, 1.5065795183181763, 1.207170009613037, 1.0184202194213867, 1.0153374671936035, 1.0025113821029663]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7244248390197754] ms
 --  Average per query NF    [1.3578784465789795] ms
 --  Average per query vegas [2.366546392440796] ms
Mean [1.304]  Median [1.121]  95th [1.635]  99th [4.183]  max [18.588]
Mean [1.304]  Median [1.121]  95th [1.635]  99th [4.183]  max [18.588]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.384149 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=1 | total-time=28.580551