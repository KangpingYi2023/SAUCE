Input arguments = Namespace(data_update='sample', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 30, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.169322729110718
tensor(0.9957)
result is  tensor(380526.1250)
Enter testHyper
ReportEsts: [1.1120524406433105, 1.126448154449463, 1.4297889471054077, 1.075384259223938, 1.2614243030548096, 1.1387102603912354, 1.2299453020095825, 1.1607046127319336, 1.094299554824829, 1.01933753490448, 1.0913006067276, 1.0864406824111938, 1.0583289861679077, 1.015625, 1.2778934240341187, 1.4182184934616089, 1.2725580930709839, 1.1268408298492432, 1.2229948043823242, 1.0663264989852905, 1.139038324356079, 1.0302221775054932, 1.1298511028289795, 1.0953354835510254, 1.182308316230774, 1.2287522554397583, 1.036599040031433, 1.3768116235733032, 1.0499430894851685, 1.0445529222488403, 1.1050018072128296, 1.1301417350769043, 1.130890965461731, 1.0628242492675781, 1.2019848823547363, 1.1722354888916016, 1.1650047302246094, 1.1326463222503662, 1.0958466529846191, 1.032814383506775, 1.0135215520858765, 1.1237300634384155, 1.034671664237976, 1.0342873334884644, 1.0769068002700806, 1.0034129619598389, 1.0763789415359497, 1.2434550523757935, 1.0204559564590454, 1.162436604499817, 1.1730279922485352, 1.3222466707229614, 1.020514965057373, 1.1891160011291504, 1.0425306558609009, 1.0329160690307617, 1.1616822481155396, 1.2759718894958496, 1.1902527809143066, 1.372734785079956, 1.1293830871582031, 1.2054411172866821, 1.1308804750442505, 1.1146326065063477, 1.330645203590393, 1.4571428298950195, 1.2092574834823608, 1.0371111631393433, 1.155982494354248, 1.2526315450668335, 1.3362832069396973, 1.0227572917938232, 1.2259697914123535, 1.1507529020309448, 1.1334842443466187, 1.043247938156128, 1.7743957042694092, 1.0360214710235596, 1.0462173223495483, 1.3481308221817017, 1.2017630338668823, 1.0261670351028442, 1.0195499658584595, 1.2293546199798584, 1.2494810819625854, 1.1457644701004028, 1.0138201713562012, 1.0079312324523926, 1.0211236476898193, 1.0514968633651733, 1.0643283128738403, 1.4197275638580322, 1.0270370244979858, 1.3381959199905396, 1.0317460298538208, 1.0850733518600464, 1.0755479335784912, 1.1603795289993286, 1.0714285373687744, 1.2177698612213135, 1.1633522510528564, 1.1469792127609253, 1.0555248260498047, 1.0109809637069702, 1.0802301168441772, 1.0179681777954102, 1.2113173007965088, 1.1902269124984741, 1.0314176082611084, 1.0135356187820435, 1.2294007539749146, 1.0932835340499878, 1.1672918796539307, 1.0970011949539185, 1.1338820457458496, 1.1293532848358154, 1.0119386911392212, 1.0410163402557373, 1.294680118560791, 1.1193063259124756, 1.2525702714920044, 1.1433696746826172, 1.33980131149292, 1.100006341934204, 1.2858526706695557, 1.2198721170425415, 1.1659338474273682, 1.2480082511901855, 1.2928869724273682, 1.1045423746109009, 1.1678682565689087, 1.0563000440597534, 1.2137973308563232, 1.4642857313156128, 1.163732647895813, 1.0947755575180054, 1.0290837287902832, 1.0858536958694458, 1.1011730432510376, 1.3943148851394653, 1.1625765562057495, 1.0314836502075195, 1.2578762769699097, 1.2487791776657104, 1.0525344610214233, 1.025354027748108, 1.1389611959457397, 1.4520025253295898, 1.0351481437683105, 1.0941051244735718, 1.0097028017044067, 1.1725419759750366, 1.28549063205719, 1.0535513162612915, 1.1608766317367554, 1.0807698965072632, 1.2115697860717773, 1.0346434116363525, 1.006988763809204, 1.1219934225082397, 1.2036620378494263, 1.0239524841308594, 1.090036153793335, 1.229658842086792, 1.2010178565979004, 1.029848337173462, 1.0534149408340454, 1.3448503017425537, 1.0561308860778809, 1.0011907815933228, 1.0184229612350464, 1.0380512475967407, 1.1298701763153076, 1.1761690378189087, 1.0868529081344604, 1.0351775884628296, 1.0383868217468262, 1.3662968873977661, 1.1855876445770264, 1.09009850025177, 1.0239229202270508, 1.0034644603729248, 1.0367504358291626, 1.1521961688995361, 1.1662441492080688, 1.0866807699203491, 1.0311654806137085, 1.2855098247528076, 1.0969709157943726, 1.3212240934371948, 1.0125136375427246, 1.0543289184570312, 1.5646929740905762, 1.3165185451507568, 1.5733848810195923, 1.2439024448394775, 1.0611088275909424, 1.0133333206176758, 1.065426230430603, 1.080976128578186]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7446391582489014] ms
 --  Average per query NF    [1.3565492630004883] ms
 --  Average per query vegas [2.388089895248413] ms
Mean [1.147]  Median [1.125]  95th [1.378]  99th [1.565]  max [1.774]
Mean [1.147]  Median [1.125]  95th [1.378]  99th [1.565]  max [1.774]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.879759 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=sample', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
Sample - START
Sample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[2.9802322e-07 1.4305115e-06 7.7486038e-07 1.6093254e-06 4.7683716e-07]
Distance score: 9.179115068036481e-07
SAUCE Drift detection: False
Detection latency: 0.0234s

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.022782 | Model-update-time: 0.000000


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=sample', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.219866514205933
tensor(0.9944)
result is  tensor(456015.0312)
Enter testHyper
ReportEsts: [1.000590443611145, 1.0292414426803589, 1.0949867963790894, 1.0164680480957031, 1.0231878757476807, 1.5214357376098633, 1.3357363939285278, 1.1065114736557007, 1.2086021900177002, 1.2022324800491333, 1.126082181930542, 1.1113783121109009, 1.1995134353637695, 1.0363487005233765, 1.001960039138794, 1.0610682964324951, 2.0327022075653076, 1.0732159614562988, 1.0711473226547241, 1.2034708261489868, 1.1177626848220825, 1.675919532775879, 1.2129144668579102, 1.0086956024169922, 1.13895845413208, 1.1549445390701294, 1.0153717994689941, 1.1961156129837036, 1.3041698932647705, 1.363987684249878, 1.310598611831665, 1.4042552709579468, 1.01459538936615, 1.0381853580474854, 1.0147173404693604, 1.1091647148132324, 1.089873194694519, 1.043868899345398, 1.0069892406463623, 1.0557825565338135, 1.0316009521484375, 1.0522222518920898, 1.0275708436965942, 1.0244210958480835, 1.0468206405639648, 1.1254467964172363, 1.3982981443405151, 1.0186737775802612, 1.2148760557174683, 1.2535110712051392, 1.0565882921218872, 1.0582921504974365, 1.098654866218567, 1.1151496171951294, 1.0487436056137085, 1.3657218217849731, 1.3338818550109863, 1.048307180404663, 1.253461241722107, 1.0429201126098633, 1.5261958837509155, 1.0139490365982056, 1.0172368288040161, 1.4314327239990234, 1.119590401649475, 1.0103917121887207, 1.4055777788162231, 1.1526230573654175, 1.17634916305542, 1.108135461807251, 1.098665475845337, 1.193558692932129, 1.0261421203613281, 1.0683921575546265, 1.1152615547180176, 1.12425696849823, 1.412941336631775, 1.0480297803878784, 1.7398664951324463, 1.129801630973816, 1.224942922592163, 1.0174413919448853, 1.0586072206497192, 1.1334443092346191, 1.3647431135177612, 1.3205574750900269, 1.163217544555664, 1.7216891050338745, 1.1220052242279053, 1.0671961307525635, 1.117932915687561, 1.1625092029571533, 1.3055477142333984, 1.015709638595581, 1.2573662996292114, 1.0041468143463135, 1.0343414545059204, 1.2633063793182373, 1.0728938579559326, 1.0397404432296753, 1.068023920059204, 1.1398298740386963, 1.2033898830413818, 1.1859219074249268, 1.1346701383590698, 1.1262046098709106, 1.03061842918396, 1.1582247018814087, 1.1564245223999023, 1.0443028211593628, 1.200209140777588, 1.0223735570907593, 1.1043781042099, 1.1134535074234009, 1.0717298984527588, 1.0114868879318237, 1.0146358013153076, 1.2060835361480713, 1.0640301704406738, 1.0708661079406738, 1.0703697204589844, 1.0949170589447021, 1.0314583778381348, 1.5645933151245117, 1.0028098821640015, 1.2453107833862305, 1.0614656209945679, 1.2248061895370483, 1.032975196838379, 1.1516636610031128, 1.0450925827026367, 1.0882213115692139, 1.0275055170059204, 1.452660083770752, 1.4864176511764526, 1.026816487312317, 1.1115888357162476, 1.0786056518554688, 1.0761497020721436, 1.0057754516601562, 1.125437617301941, 1.1923861503601074, 1.0291155576705933, 1.0980230569839478, 1.0148730278015137, 1.0870139598846436, 1.409356713294983, 1.0485464334487915, 1.0009856224060059, 1.009508728981018, 1.0398554801940918, 1.0158027410507202, 1.1098692417144775, 1.1651610136032104, 1.0045921802520752, 1.2025882005691528, 1.13590669631958, 1.2460317611694336, 1.0341533422470093, 1.1475602388381958, 1.1172637939453125, 1.0840080976486206, 1.2039562463760376, 1.0996593236923218, 1.0763365030288696, 1.0690284967422485, 1.1417640447616577, 1.198517918586731, 1.0188244581222534, 1.1678826808929443, 1.1692309379577637, 1.0853798389434814, 1.5351003408432007, 1.1575616598129272, 1.0280951261520386, 1.0508413314819336, 1.1155803203582764, 1.075506329536438, 1.0016918182373047, 1.0147101879119873, 1.40816330909729, 1.1521849632263184, 1.0050554275512695, 1.5105005502700806, 1.4612442255020142, 1.1571112871170044, 1.2684375047683716, 1.0335205793380737, 1.4962689876556396, 1.0121065378189087, 1.136141061782837, 1.1177159547805786, 1.2396646738052368, 1.668686866760254, 1.009523868560791, 1.1082921028137207, 1.4745237827301025, 1.0583356618881226, 1.3675214052200317, 1.1009478569030762]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.754899501800537] ms
 --  Average per query NF    [1.3577675819396973] ms
 --  Average per query vegas [2.39713191986084] ms
Mean [1.155]  Median [1.109]  95th [1.497]  99th [1.722]  max [2.033]
Mean [1.155]  Median [1.109]  95th [1.497]  99th [1.722]  max [2.033]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.270918 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=0 | total-time=26.231727