Input arguments = Namespace(data_update='valueskew', update_size=80000, dataset='bjaq', debug=False, drift_test='js', model_update='adapt', model='face', end2end=False, query_seed=0, random_seed=42, num_workload=3)
JSON-passed parameters = {'data_updater': {'skew_ratio': '1e-3'}, 'random_seed': 12, 'face': {'learning_rate': '1e-4', 'epochs': 0, 'factor': 'auto'}}
MODEL-PATH=/home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
DATASET-PATH=/home/kangping/code_copy/SAUCE/data/bjaq/end2end/bjaq.npy
Workloads: ['QueryWorkload', 'DataUpdateWorkload', 'QueryWorkload']

WORKLOAD-START | Type: QueryWorkload | Progress: 1/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--end2end']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (382168, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-1234.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.172425508499146
tensor(0.9961)
result is  tensor(380665.2812)
Enter testHyper
ReportEsts: [1.163236141204834, 1.0845292806625366, 1.5664241313934326, 1.1867761611938477, 1.241530418395996, 1.1086478233337402, 1.2998446226119995, 1.0669933557510376, 1.0782790184020996, 1.064170479774475, 1.1266149282455444, 1.1394068002700806, 1.113668441772461, 1.0267857313156128, 1.1593366861343384, 1.2631303071975708, 1.2127482891082764, 1.384323000907898, 1.196109414100647, 1.1454081535339355, 1.1228280067443848, 1.0536526441574097, 1.125600814819336, 1.0188180208206177, 1.108878493309021, 1.1084990501403809, 1.0875563621520996, 1.388053297996521, 1.0480353832244873, 1.0857491493225098, 1.0081589221954346, 1.0168054103851318, 1.2036195993423462, 1.054663062095642, 1.1781831979751587, 1.176759958267212, 1.1189205646514893, 1.1193684339523315, 1.1199404001235962, 1.1535329818725586, 1.030610203742981, 1.211780309677124, 1.0099689960479736, 1.0502384901046753, 1.0583139657974243, 1.0759637355804443, 1.0802809000015259, 1.2483460903167725, 1.1576783657073975, 1.067681908607483, 1.2425875663757324, 1.4406837224960327, 1.0484178066253662, 1.3289650678634644, 1.0887724161148071, 1.0139081478118896, 1.1841121912002563, 1.0945409536361694, 1.0717514753341675, 1.4912751913070679, 1.3326587677001953, 1.153771996498108, 1.4051035642623901, 1.271943211555481, 1.2313432693481445, 1.4285714626312256, 1.2342519760131836, 1.0007115602493286, 1.0399818420410156, 1.2947368621826172, 1.0201126337051392, 1.0111453533172607, 1.208336353302002, 1.123905897140503, 1.017729640007019, 1.0449728965759277, 2.0030555725097656, 1.041688323020935, 1.0747895240783691, 1.2482407093048096, 1.16766357421875, 1.0880310535430908, 1.0502392053604126, 1.1455401182174683, 1.2674036026000977, 1.098209023475647, 1.0704779624938965, 1.0619208812713623, 1.0146639347076416, 1.005887746810913, 1.038633942604065, 1.2703202962875366, 1.0690053701400757, 1.3136038780212402, 1.101694941520691, 1.0607935190200806, 1.1880888938903809, 1.23073148727417, 1.0526316165924072, 1.0865087509155273, 1.2205662727355957, 1.1390843391418457, 1.0304458141326904, 1.0051244497299194, 1.0033472776412964, 1.057484745979309, 1.1684255599975586, 1.1902269124984741, 1.0624451637268066, 1.0360209941864014, 1.0397088527679443, 1.1119544506072998, 1.0421428680419922, 1.0618839263916016, 1.160658359527588, 1.1127450466156006, 1.0197463035583496, 1.0251516103744507, 1.302902340888977, 1.0230401754379272, 1.1177082061767578, 1.0818959474563599, 1.2033740282058716, 1.1780699491500854, 1.236918568611145, 1.173442006111145, 1.1231926679611206, 1.1685463190078735, 1.2581433057785034, 1.1195725202560425, 1.0303030014038086, 1.0235817432403564, 1.2007458209991455, 1.5, 1.2402539253234863, 1.2473089694976807, 1.0387976169586182, 1.2175610065460205, 1.1661633253097534, 1.0, 1.0802927017211914, 1.044538140296936, 1.102907657623291, 1.2198445796966553, 1.1766167879104614, 1.0001661777496338, 1.040907621383667, 1.2783799171447754, 1.2428003549575806, 1.0510653257369995, 1.2992525100708008, 1.127804160118103, 1.3241935968399048, 1.1340076923370361, 1.1347075700759888, 1.1211401224136353, 1.020280361175537, 1.0045019388198853, 1.1021188497543335, 1.1317218542099, 1.037561297416687, 1.1037943363189697, 1.0378820896148682, 1.3424068689346313, 1.1079812049865723, 1.0062150955200195, 1.0048985481262207, 1.3832931518554688, 1.0407326221466064, 1.0034798383712769, 1.0002753734588623, 1.1067759990692139, 1.097402572631836, 1.1679205894470215, 1.122956395149231, 1.2677350044250488, 1.0184645652770996, 1.4307957887649536, 1.1735464334487915, 1.0775189399719238, 1.021482229232788, 1.0863007307052612, 1.0431979894638062, 1.1389172077178955, 1.1104671955108643, 1.1183931827545166, 1.0304421186447144, 1.2334363460540771, 1.029170274734497, 1.3124805688858032, 1.034505844116211, 1.1016428470611572, 1.6248221397399902, 1.6547305583953857, 1.6111986637115479, 1.2336091995239258, 1.1704460382461548, 1.1515151262283325, 1.1110771894454956, 1.1226096153259277]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7816250324249268] ms
 --  Average per query NF    [1.3670587539672852] ms
 --  Average per query vegas [2.4145662784576416] ms
Mean [1.149]  Median [1.116]  95th [1.406]  99th [1.625]  max [2.003]
Mean [1.149]  Median [1.116]  95th [1.406]  99th [1.625]  max [2.003]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 1/3 | Workload-time: 11.868283 | Model-update-time: 0.000000


WORKLOAD-START | Type: DataUpdateWorkload | Progress: 2/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/Naru/eval_model.py', '--model=face', '--data_update=valueskew', '--dataset=bjaq', '--drift_test=js', '--end2end', '--update_size=80000', '--query_seed=0', '--eval_type=drift']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
ValueSample - START
ValueSample - END
load_npy_dataset_from_path - df.shape = (458601, 5)
Parsing... done, took 0.0s
Data updated!
Previous data size: (382168, 5), new data size: (76433, 5)
[8.3446503e-07 1.0524094e-02 8.3446503e-07 1.4305115e-06 2.3841858e-07]
Distance score: 0.002105486346408725
SAUCE Drift detection: True
Detection latency: 0.0237s

DRIFT-DETECTED after 2-th workload
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/incremental_train.py', '--dataset=bjaq', '--end2end', '--model=face', '--model_update=adapt', '--update_size=80000', '--epochs=0']
Torch device: cuda:1
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
update_size: 76433
AdaptTask - START
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
train data shape: 80000, transfer data shape:16000
Training done; evaluating likelihood on full data:
Saved to: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
AdaptTask - END

WORKLOAD-FINISHED | Type: DataUpdateWorkload | Progress: 2/3 | Workload-time: 2.047456 | Model-update-time: 2.217805


WORKLOAD-START | Type: QueryWorkload | Progress: 3/3
Going to run: ['python', '/home/kangping/code_copy/SAUCE/FACE/evaluate/Evaluate-FACE-end2end.py', '--dataset=bjaq', '--query_seed=0', '--end2end', '--num_workload=3', '--data_update=valueskew', '--model_update=adapt']
/home/kangping/anaconda3/envs/LndCar/lib/python3.9/site-packages/torchquad/integration/vegas_map.py:314: UserWarning: torch.searchsorted(): input value tensor is non-contiguous, this will lower the performance due to extra data copy when converting non-contiguous tensor to contiguous, please use contiguous input value tensor if possible. This message will only appear once per program. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/BucketizationUtils.h:33.)
  iy = torch.searchsorted(self.x_edges[d, :], x[:, d], side='right')
DEVICE NAME
 Tesla V100S-PCIE-32GB
GET-MODEL-PATH=./models/end2end/face/bjaq-id2-best-val.t
Load model - START
Load model from: /home/kangping/code_copy/SAUCE/models/end2end/face/bjaq-id2-best-val.t
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
Load model - END
There are 104179 trainable parameters in this model.
Parameters total size is 0.3974113464355469 MB
GET-DATASET-PATH=./data/bjaq/end2end/bjaq.npy
data shape: (458601, 5)
Save oracle results to :
./FACE/evaluate/oracle/bjaq_rng-0.csv
Found oracle card!
torch.Size([5, 2])
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
******** ANY
Took  8.209173917770386
tensor(0.9992)
result is  tensor(458230.4062)
Enter testHyper
ReportEsts: [1.0724096298217773, 1.2085814476013184, 1.160220980644226, 1.7840454578399658, 1.0227293968200684, 1.662034511566162, 1.199345350265503, 1.0760583877563477, 2.154054641723633, 1.3634287118911743, 1.1527434587478638, 1.2437275648117065, 1.1720930337905884, 1.2411764860153198, 338.257568359375, 1.0606772899627686, 1.054430365562439, 1.0334144830703735, 1.0047155618667603, 1.2896867990493774, 1.1989995241165161, 1.6384704113006592, 1.1190775632858276, 1.6630216836929321, 1.0291122198104858, 1.1698269844055176, 1.0485355854034424, 1.3232152462005615, 6.786496162414551, 1.2400285005569458, 1.044025182723999, 1.350000023841858, 3.035247325897217, 1.1137492656707764, 1.0303782224655151, 1.0794280767440796, 1.181567907333374, 1.1065421104431152, 1.3508659601211548, 1.0276557207107544, 1.3196213245391846, 1.2643678188323975, 1.0301129817962646, 1.0411311388015747, 1.041573166847229, 1.1798298358917236, 1.1747857332229614, 1.107260823249817, 1.3666666746139526, 1.1344537734985352, 1.2296606302261353, 1.0495437383651733, 1.08935546875, 1.0566688776016235, 1.0662195682525635, 1.4283971786499023, 1.3487586975097656, 1.1407462358474731, 1.0506573915481567, 1.3587169647216797, 1.6497461795806885, 1.0198209285736084, 2.3483753204345703, 1.3290603160858154, 1.1024878025054932, 1.3558818101882935, 1.1634374856948853, 1.080564260482788, 1.1287821531295776, 1.3634023666381836, 1.0358164310455322, 1.1903337240219116, 1.2359654903411865, 1.0305389165878296, 1.1319929361343384, 1.2575842142105103, 33.60439682006836, 1.4715111255645752, 1.242582082748413, 1.1087777614593506, 1.1258207559585571, 1.0767848491668701, 1.1245135068893433, 1.387900948524475, 1.308532953262329, 1.5829787254333496, 1.4802896976470947, 1.150937557220459, 1.1004436016082764, 1.1902551651000977, 1.0721992254257202, 1.2558003664016724, 1.4821834564208984, 1.0965818166732788, 57.632957458496094, 1.2487881183624268, 1.0350639820098877, 1.0120753049850464, 1.0567378997802734, 1.700440526008606, 1.1534792184829712, 1.3231157064437866, 1.2748690843582153, 1.0765255689620972, 1.0620359182357788, 1.297777771949768, 1.0392259359359741, 1.0165847539901733, 1.031518578529358, 1.1582703590393066, 1.058327317237854, 1.1302967071533203, 1.2432739734649658, 1.2412031888961792, 1.2829904556274414, 1.122340440750122, 1.2829861640930176, 1.2724632024765015, 1.1409696340560913, 1.073170781135559, 1.2154461145401, 1.074130892753601, 1.036352515220642, 1.2268030643463135, 1.1750400066375732, 1.343214511871338, 1.0826140642166138, 1.284313678741455, 1.3244203329086304, 1.0012456178665161, 1.214280605316162, 1.4155317544937134, 1.2100133895874023, 1.4513438940048218, 1.502532958984375, 1.1030550003051758, 1.0734330415725708, 1.290718674659729, 1.2346988916397095, 1.1832189559936523, 1.1360477209091187, 1.0277529954910278, 1.4091054201126099, 1.009156346321106, 1.0652635097503662, 1.4074771404266357, 1.2339180707931519, 1.180260181427002, 1.0816965103149414, 1.0537337064743042, 1.1624890565872192, 1.0113816261291504, 1.0200321674346924, 1.1041326522827148, 1.328230619430542, 1.273407220840454, 1.1205244064331055, 1.122950792312622, 1.0165194272994995, 1.0252853631973267, 3.1161632537841797, 1.26369047164917, 1.0676053762435913, 1.1882765293121338, 1.0719330310821533, 4.900000095367432, 1.2141218185424805, 1.1328544616699219, 9.053571701049805, 1.0938962697982788, 1.1339772939682007, 1.141664743423462, 1.2273656129837036, 1.2757055759429932, 1.0830479860305786, 1.2679393291473389, 1.4880039691925049, 1.4320584535598755, 1.0699232816696167, 1.081971526145935, 1.4042552709579468, 1.1728236675262451, 1.446239709854126, 1.225080966949463, 1.3005815744400024, 1.2249064445495605, 8.591032981872559, 1.0329158306121826, 1.2824674844741821, 1.071050763130188, 1.2111103534698486, 1.1253827810287476, 1.2735774517059326, 1.7103275060653687, 1.010121464729309, 1.0311952829360962, 1.284684181213379, 1.3665201663970947, 1.5736300945281982, 1.125083088874817]
********** total_n=[200] batchn=[100]  N=[3200]  nitr=[4]  alpha=[0.4]  beta=[0.2] ******
@ Average per query          [3.7139904499053955] ms
 --  Average per query NF    [1.3593077659606934] ms
 --  Average per query vegas [2.354682683944702] ms
Mean [3.482]  Median [1.177]  95th [2.164]  99th [33.845]  max [338.258]
Mean [3.482]  Median [1.177]  95th [2.164]  99th [33.845]  max [338.258]


WORKLOAD-FINISHED | Type: QueryWorkload | Progress: 3/3 | Workload-time: 12.415946 | Model-update-time: 0.000000


Experiment Summary: #data-update-times=1, #drift=1 | total-time=28.575078